{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from arch import arch_model\n",
    "\n",
    "p = print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18af65a3a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.despine()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Merge\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AtrousConvolution1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras import regularizers\n",
    "\n",
    "import theano\n",
    "theano.config.compute_test_value = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name=None\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(\"2012-09-09\", \"%Y-%m-%d\")\n",
    "date_list = [start + relativedelta(weeks=x) for x in range(0,len(df.sales))]\n",
    "df['index'] =date_list\n",
    "df.set_index(['index'], inplace=True)\n",
    "df.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>dates</th>\n",
       "      <th>sales</th>\n",
       "      <th>AUP_RUR</th>\n",
       "      <th>AUP_RUR_RRP</th>\n",
       "      <th>AUP+bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-09</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>23</td>\n",
       "      <td>5658.513739</td>\n",
       "      <td>9619.448357</td>\n",
       "      <td>6612.109391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-16</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-09-16</td>\n",
       "      <td>10</td>\n",
       "      <td>6065.175200</td>\n",
       "      <td>10238.858811</td>\n",
       "      <td>6762.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>5876.925926</td>\n",
       "      <td>9058.186700</td>\n",
       "      <td>6231.744815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>5319.947500</td>\n",
       "      <td>9415.000000</td>\n",
       "      <td>6163.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>4</td>\n",
       "      <td>6731.930000</td>\n",
       "      <td>9415.000000</td>\n",
       "      <td>6807.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ind       dates  sales      AUP_RUR   AUP_RUR_RRP    AUP+bonus\n",
       "2012-09-09    1  2012-09-09     23  5658.513739   9619.448357  6612.109391\n",
       "2012-09-16    2  2012-09-16     10  6065.175200  10238.858811  6762.978200\n",
       "2012-09-23    3  2012-09-23      9  5876.925926   9058.186700  6231.744815\n",
       "2012-09-30    4  2012-09-30      4  5319.947500   9415.000000  6163.250000\n",
       "2012-10-07    5  2012-10-07      4  6731.930000   9415.000000  6807.750000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.deepcopy(df['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-09-09    23\n",
       "2012-09-16    10\n",
       "2012-09-23     9\n",
       "2012-09-30     4\n",
       "2012-10-07     4\n",
       "Name: sales, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### написание функций для разбивки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  shuffle_in_unison (a, b):\n",
    "\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    " \n",
    "def create_Xt_Yt(X, y, percentage=0.9):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "     \n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    " \n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "хорошие результаты получали при трейн/тест 90/10(дефолт) и 80/20\n",
    "окно изменили на 26 с 52 - это увеличило точность на 10% в среднем и без переобучения\n",
    "dense input - 64 по дефолту. поменял зачем-то, надо потестировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index out of bounds\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 26\n",
    "STEP = 1\n",
    "FORECAST = 5\n",
    "\n",
    "\n",
    "X, Y = [], []\n",
    "for i in range(0, len(data), STEP): \n",
    "    try:\n",
    "        x_i = data[i:i+WINDOW]\n",
    "        y_i = data[i+WINDOW+FORECAST]  \n",
    "\n",
    "        last_close = x_i[WINDOW-1]\n",
    "        next_close = y_i\n",
    "\n",
    "        if last_close < next_close:\n",
    "            y_i = [1, 0]\n",
    "        else:\n",
    "            y_i = [0, 1] \n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        break\n",
    "\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "\n",
    "#X = [(np.array(x) - np.mean(x)) / np.std(x) for x in X] # будем использовать для регрессии\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель простая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/350\n",
      " - 1s - loss: 0.1608 - acc: 0.9280 - val_loss: 0.5624 - val_acc: 0.7857\n",
      "Epoch 2/350\n",
      " - 0s - loss: 0.1606 - acc: 0.9280 - val_loss: 0.5615 - val_acc: 0.7857\n",
      "Epoch 3/350\n",
      " - 0s - loss: 0.1600 - acc: 0.9280 - val_loss: 0.5629 - val_acc: 0.7857\n",
      "Epoch 4/350\n",
      " - 0s - loss: 0.1596 - acc: 0.9280 - val_loss: 0.5611 - val_acc: 0.7857\n",
      "Epoch 5/350\n",
      " - 0s - loss: 0.1592 - acc: 0.9280 - val_loss: 0.5598 - val_acc: 0.7857\n",
      "Epoch 6/350\n",
      " - 0s - loss: 0.1584 - acc: 0.9280 - val_loss: 0.5585 - val_acc: 0.7857\n",
      "Epoch 7/350\n",
      " - 0s - loss: 0.1574 - acc: 0.9280 - val_loss: 0.5594 - val_acc: 0.7857\n",
      "Epoch 8/350\n",
      " - 0s - loss: 0.1571 - acc: 0.9280 - val_loss: 0.5594 - val_acc: 0.7857\n",
      "Epoch 9/350\n",
      " - 0s - loss: 0.1568 - acc: 0.9280 - val_loss: 0.5620 - val_acc: 0.7857\n",
      "Epoch 10/350\n",
      " - 0s - loss: 0.1565 - acc: 0.9280 - val_loss: 0.5556 - val_acc: 0.7857\n",
      "Epoch 11/350\n",
      " - 0s - loss: 0.1564 - acc: 0.9280 - val_loss: 0.5545 - val_acc: 0.7857\n",
      "Epoch 12/350\n",
      " - 0s - loss: 0.1562 - acc: 0.9280 - val_loss: 0.5653 - val_acc: 0.7857\n",
      "Epoch 13/350\n",
      " - 0s - loss: 0.1561 - acc: 0.9240 - val_loss: 0.5607 - val_acc: 0.7857\n",
      "Epoch 14/350\n",
      " - 0s - loss: 0.1560 - acc: 0.9240 - val_loss: 0.5566 - val_acc: 0.7857\n",
      "Epoch 15/350\n",
      " - 0s - loss: 0.1559 - acc: 0.9240 - val_loss: 0.5617 - val_acc: 0.7857\n",
      "Epoch 16/350\n",
      " - 0s - loss: 0.1557 - acc: 0.9240 - val_loss: 0.5616 - val_acc: 0.7857\n",
      "Epoch 17/350\n",
      " - 0s - loss: 0.1553 - acc: 0.9280 - val_loss: 0.5574 - val_acc: 0.7857\n",
      "Epoch 18/350\n",
      " - 0s - loss: 0.1550 - acc: 0.9240 - val_loss: 0.5575 - val_acc: 0.7857\n",
      "Epoch 19/350\n",
      " - 0s - loss: 0.1540 - acc: 0.9280 - val_loss: 0.5619 - val_acc: 0.7857\n",
      "Epoch 20/350\n",
      " - 0s - loss: 0.1540 - acc: 0.9280 - val_loss: 0.5607 - val_acc: 0.7857\n",
      "Epoch 21/350\n",
      " - 0s - loss: 0.1538 - acc: 0.9280 - val_loss: 0.5625 - val_acc: 0.7857\n",
      "Epoch 22/350\n",
      " - 0s - loss: 0.1537 - acc: 0.9280 - val_loss: 0.5551 - val_acc: 0.7857\n",
      "Epoch 23/350\n",
      " - 0s - loss: 0.1536 - acc: 0.9280 - val_loss: 0.5603 - val_acc: 0.7857\n",
      "Epoch 24/350\n",
      " - 0s - loss: 0.1535 - acc: 0.9320 - val_loss: 0.5583 - val_acc: 0.7857\n",
      "Epoch 25/350\n",
      " - 0s - loss: 0.1533 - acc: 0.9280 - val_loss: 0.5597 - val_acc: 0.7857\n",
      "Epoch 26/350\n",
      " - 0s - loss: 0.1549 - acc: 0.9240 - val_loss: 0.5677 - val_acc: 0.7857\n",
      "Epoch 27/350\n",
      " - 0s - loss: 0.1529 - acc: 0.9280 - val_loss: 0.5714 - val_acc: 0.7857\n",
      "Epoch 28/350\n",
      " - 0s - loss: 0.1515 - acc: 0.9320 - val_loss: 0.5591 - val_acc: 0.7857\n",
      "Epoch 29/350\n",
      " - 0s - loss: 0.1513 - acc: 0.9280 - val_loss: 0.5576 - val_acc: 0.7857\n",
      "Epoch 30/350\n",
      " - 0s - loss: 0.1513 - acc: 0.9320 - val_loss: 0.5550 - val_acc: 0.7857\n",
      "Epoch 31/350\n",
      " - 0s - loss: 0.1512 - acc: 0.9320 - val_loss: 0.5597 - val_acc: 0.7857\n",
      "Epoch 32/350\n",
      " - 0s - loss: 0.1512 - acc: 0.9320 - val_loss: 0.5557 - val_acc: 0.7857\n",
      "Epoch 33/350\n",
      " - 0s - loss: 0.1510 - acc: 0.9320 - val_loss: 0.5590 - val_acc: 0.7857\n",
      "Epoch 34/350\n",
      " - 0s - loss: 0.1509 - acc: 0.9280 - val_loss: 0.5638 - val_acc: 0.7857\n",
      "Epoch 35/350\n",
      " - 0s - loss: 0.1507 - acc: 0.9320 - val_loss: 0.5646 - val_acc: 0.7857\n",
      "Epoch 36/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5523 - val_acc: 0.7857\n",
      "Epoch 37/350\n",
      " - 0s - loss: 0.1520 - acc: 0.9320 - val_loss: 0.5576 - val_acc: 0.7857\n",
      "Epoch 38/350\n",
      " - 0s - loss: 0.1508 - acc: 0.9320 - val_loss: 0.5600 - val_acc: 0.7857\n",
      "Epoch 39/350\n",
      " - 0s - loss: 0.1502 - acc: 0.9320 - val_loss: 0.5372 - val_acc: 0.7857\n",
      "Epoch 40/350\n",
      " - 0s - loss: 0.1496 - acc: 0.9320 - val_loss: 0.5401 - val_acc: 0.7857\n",
      "Epoch 41/350\n",
      " - 0s - loss: 0.1495 - acc: 0.9320 - val_loss: 0.5316 - val_acc: 0.7857\n",
      "Epoch 42/350\n",
      " - 0s - loss: 0.1494 - acc: 0.9320 - val_loss: 0.5328 - val_acc: 0.7857\n",
      "Epoch 43/350\n",
      " - 0s - loss: 0.1494 - acc: 0.9320 - val_loss: 0.5343 - val_acc: 0.7857\n",
      "Epoch 44/350\n",
      " - 0s - loss: 0.1492 - acc: 0.9320 - val_loss: 0.5310 - val_acc: 0.7857\n",
      "Epoch 45/350\n",
      " - 0s - loss: 0.1491 - acc: 0.9320 - val_loss: 0.5441 - val_acc: 0.7857\n",
      "Epoch 46/350\n",
      " - 0s - loss: 0.1489 - acc: 0.9320 - val_loss: 0.5492 - val_acc: 0.7857\n",
      "Epoch 47/350\n",
      " - 0s - loss: 0.1488 - acc: 0.9320 - val_loss: 0.5469 - val_acc: 0.7857\n",
      "Epoch 48/350\n",
      " - 0s - loss: 0.1487 - acc: 0.9320 - val_loss: 0.5446 - val_acc: 0.7857\n",
      "Epoch 49/350\n",
      " - 0s - loss: 0.1485 - acc: 0.9360 - val_loss: 0.5567 - val_acc: 0.7857\n",
      "Epoch 50/350\n",
      " - 0s - loss: 0.1483 - acc: 0.9320 - val_loss: 0.5536 - val_acc: 0.7857\n",
      "Epoch 51/350\n",
      " - 0s - loss: 0.1483 - acc: 0.9360 - val_loss: 0.5516 - val_acc: 0.7857\n",
      "Epoch 52/350\n",
      " - 0s - loss: 0.1483 - acc: 0.9360 - val_loss: 0.5466 - val_acc: 0.7857\n",
      "Epoch 53/350\n",
      " - 0s - loss: 0.1481 - acc: 0.9360 - val_loss: 0.5464 - val_acc: 0.7857\n",
      "Epoch 54/350\n",
      " - 0s - loss: 0.1477 - acc: 0.9360 - val_loss: 0.5430 - val_acc: 0.7857\n",
      "Epoch 55/350\n",
      " - 0s - loss: 0.1477 - acc: 0.9360 - val_loss: 0.5447 - val_acc: 0.7857\n",
      "Epoch 56/350\n",
      " - 0s - loss: 0.1476 - acc: 0.9360 - val_loss: 0.5472 - val_acc: 0.7857\n",
      "Epoch 57/350\n",
      " - 0s - loss: 0.1474 - acc: 0.9400 - val_loss: 0.5492 - val_acc: 0.7857\n",
      "Epoch 58/350\n",
      " - 0s - loss: 0.1472 - acc: 0.9360 - val_loss: 0.5500 - val_acc: 0.7857\n",
      "Epoch 59/350\n",
      " - 0s - loss: 0.1479 - acc: 0.9360 - val_loss: 0.5447 - val_acc: 0.7857\n",
      "Epoch 60/350\n",
      " - 0s - loss: 0.1502 - acc: 0.9360 - val_loss: 0.5491 - val_acc: 0.7857\n",
      "Epoch 61/350\n",
      " - 0s - loss: 0.1572 - acc: 0.9280 - val_loss: 0.5557 - val_acc: 0.7857\n",
      "Epoch 62/350\n",
      " - 0s - loss: 0.1547 - acc: 0.9280 - val_loss: 0.5471 - val_acc: 0.7857\n",
      "Epoch 63/350\n",
      " - 0s - loss: 0.1545 - acc: 0.9200 - val_loss: 0.5552 - val_acc: 0.7857\n",
      "Epoch 64/350\n",
      " - 0s - loss: 0.1544 - acc: 0.9280 - val_loss: 0.5546 - val_acc: 0.7857\n",
      "Epoch 65/350\n",
      " - 0s - loss: 0.1542 - acc: 0.9280 - val_loss: 0.5477 - val_acc: 0.7857\n",
      "Epoch 66/350\n",
      " - 0s - loss: 0.1539 - acc: 0.9280 - val_loss: 0.5473 - val_acc: 0.7857\n",
      "Epoch 67/350\n",
      " - 0s - loss: 0.1538 - acc: 0.9280 - val_loss: 0.5485 - val_acc: 0.7857\n",
      "Epoch 68/350\n",
      " - 0s - loss: 0.1536 - acc: 0.9280 - val_loss: 0.5561 - val_acc: 0.7857\n",
      "Epoch 69/350\n",
      " - 0s - loss: 0.1531 - acc: 0.9280 - val_loss: 0.5490 - val_acc: 0.7857\n",
      "Epoch 70/350\n",
      " - 0s - loss: 0.1531 - acc: 0.9280 - val_loss: 0.5548 - val_acc: 0.7857\n",
      "Epoch 71/350\n",
      " - 0s - loss: 0.1529 - acc: 0.9280 - val_loss: 0.5612 - val_acc: 0.7857\n",
      "Epoch 72/350\n",
      " - 0s - loss: 0.1528 - acc: 0.9280 - val_loss: 0.5509 - val_acc: 0.7857\n",
      "Epoch 73/350\n",
      " - 0s - loss: 0.1526 - acc: 0.9280 - val_loss: 0.5480 - val_acc: 0.7857\n",
      "Epoch 74/350\n",
      " - 0s - loss: 0.1525 - acc: 0.9280 - val_loss: 0.5591 - val_acc: 0.7857\n",
      "Epoch 75/350\n",
      " - 0s - loss: 0.1523 - acc: 0.9280 - val_loss: 0.5544 - val_acc: 0.7857\n",
      "Epoch 76/350\n",
      " - 0s - loss: 0.1523 - acc: 0.9280 - val_loss: 0.5664 - val_acc: 0.7857\n",
      "Epoch 77/350\n",
      " - 0s - loss: 0.1522 - acc: 0.9280 - val_loss: 0.5649 - val_acc: 0.7857\n",
      "Epoch 78/350\n",
      " - 0s - loss: 0.1519 - acc: 0.9280 - val_loss: 0.5646 - val_acc: 0.7857\n",
      "Epoch 79/350\n",
      " - 0s - loss: 0.1518 - acc: 0.9280 - val_loss: 0.5518 - val_acc: 0.7857\n",
      "Epoch 80/350\n",
      " - 0s - loss: 0.1517 - acc: 0.9280 - val_loss: 0.5491 - val_acc: 0.7857\n",
      "Epoch 81/350\n",
      " - 0s - loss: 0.1517 - acc: 0.9280 - val_loss: 0.5497 - val_acc: 0.7857\n",
      "Epoch 82/350\n",
      " - 0s - loss: 0.1514 - acc: 0.9280 - val_loss: 0.5411 - val_acc: 0.7857\n",
      "Epoch 83/350\n",
      " - 0s - loss: 0.1522 - acc: 0.9280 - val_loss: 0.5442 - val_acc: 0.7857\n",
      "Epoch 84/350\n",
      " - 0s - loss: 0.1513 - acc: 0.9280 - val_loss: 0.5443 - val_acc: 0.7857\n",
      "Epoch 85/350\n",
      " - 0s - loss: 0.1510 - acc: 0.9280 - val_loss: 0.5438 - val_acc: 0.7857\n",
      "Epoch 86/350\n",
      " - 0s - loss: 0.1510 - acc: 0.9280 - val_loss: 0.5461 - val_acc: 0.7857\n",
      "Epoch 87/350\n",
      " - 0s - loss: 0.1509 - acc: 0.9280 - val_loss: 0.5503 - val_acc: 0.7857\n",
      "Epoch 88/350\n",
      " - 0s - loss: 0.1507 - acc: 0.9280 - val_loss: 0.5577 - val_acc: 0.7857\n",
      "Epoch 89/350\n",
      " - 0s - loss: 0.1508 - acc: 0.9280 - val_loss: 0.5525 - val_acc: 0.7857\n",
      "Epoch 90/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5442 - val_acc: 0.7857\n",
      "Epoch 91/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5447 - val_acc: 0.7857\n",
      "Epoch 92/350\n",
      " - 0s - loss: 0.1504 - acc: 0.9320 - val_loss: 0.5449 - val_acc: 0.7857\n",
      "Epoch 93/350\n",
      " - 0s - loss: 0.1505 - acc: 0.9320 - val_loss: 0.5441 - val_acc: 0.7857\n",
      "Epoch 94/350\n",
      " - 0s - loss: 0.1511 - acc: 0.9320 - val_loss: 0.5526 - val_acc: 0.7857\n",
      "Epoch 95/350\n",
      " - 0s - loss: 0.1522 - acc: 0.9240 - val_loss: 0.5549 - val_acc: 0.7857\n",
      "Epoch 96/350\n",
      " - 0s - loss: 0.1508 - acc: 0.9320 - val_loss: 0.5535 - val_acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5532 - val_acc: 0.7857\n",
      "Epoch 98/350\n",
      " - 0s - loss: 0.1521 - acc: 0.9320 - val_loss: 0.5489 - val_acc: 0.7857\n",
      "Epoch 99/350\n",
      " - 0s - loss: 0.1517 - acc: 0.9320 - val_loss: 0.5490 - val_acc: 0.7857\n",
      "Epoch 100/350\n",
      " - 0s - loss: 0.1516 - acc: 0.9320 - val_loss: 0.5431 - val_acc: 0.7857\n",
      "Epoch 101/350\n",
      " - 0s - loss: 0.1514 - acc: 0.9320 - val_loss: 0.5457 - val_acc: 0.7857\n",
      "Epoch 102/350\n",
      " - 0s - loss: 0.1507 - acc: 0.9320 - val_loss: 0.5459 - val_acc: 0.7857\n",
      "Epoch 103/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5469 - val_acc: 0.7857\n",
      "Epoch 104/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5404 - val_acc: 0.7857\n",
      "Epoch 105/350\n",
      " - 0s - loss: 0.1511 - acc: 0.9320 - val_loss: 0.5472 - val_acc: 0.7500\n",
      "Epoch 106/350\n",
      " - 0s - loss: 0.1503 - acc: 0.9320 - val_loss: 0.5514 - val_acc: 0.7500\n",
      "Epoch 107/350\n",
      " - 0s - loss: 0.1509 - acc: 0.9320 - val_loss: 0.5459 - val_acc: 0.7857\n",
      "Epoch 108/350\n",
      " - 0s - loss: 0.1506 - acc: 0.9320 - val_loss: 0.5430 - val_acc: 0.7857\n",
      "Epoch 109/350\n",
      " - 0s - loss: 0.1500 - acc: 0.9320 - val_loss: 0.5412 - val_acc: 0.7857\n",
      "Epoch 110/350\n",
      " - 0s - loss: 0.1499 - acc: 0.9320 - val_loss: 0.5376 - val_acc: 0.7857\n",
      "Epoch 111/350\n",
      " - 0s - loss: 0.1498 - acc: 0.9320 - val_loss: 0.5376 - val_acc: 0.7857\n",
      "Epoch 112/350\n",
      " - 0s - loss: 0.1497 - acc: 0.9320 - val_loss: 0.5381 - val_acc: 0.7500\n",
      "Epoch 113/350\n",
      " - 0s - loss: 0.1497 - acc: 0.9320 - val_loss: 0.5435 - val_acc: 0.7500\n",
      "Epoch 114/350\n",
      " - 0s - loss: 0.1496 - acc: 0.9320 - val_loss: 0.5430 - val_acc: 0.7500\n",
      "Epoch 115/350\n",
      " - 0s - loss: 0.1495 - acc: 0.9320 - val_loss: 0.5406 - val_acc: 0.7500\n",
      "Epoch 116/350\n",
      " - 0s - loss: 0.1494 - acc: 0.9320 - val_loss: 0.5398 - val_acc: 0.7500\n",
      "Epoch 117/350\n",
      " - 0s - loss: 0.1493 - acc: 0.9320 - val_loss: 0.5401 - val_acc: 0.7500\n",
      "Epoch 118/350\n",
      " - 0s - loss: 0.1493 - acc: 0.9320 - val_loss: 0.5409 - val_acc: 0.7500\n",
      "Epoch 119/350\n",
      " - 0s - loss: 0.1491 - acc: 0.9320 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 120/350\n",
      " - 0s - loss: 0.1487 - acc: 0.9320 - val_loss: 0.5348 - val_acc: 0.7500\n",
      "Epoch 121/350\n",
      " - 0s - loss: 0.1493 - acc: 0.9360 - val_loss: 0.5414 - val_acc: 0.7500\n",
      "Epoch 122/350\n",
      " - 0s - loss: 0.1480 - acc: 0.9360 - val_loss: 0.5437 - val_acc: 0.7500\n",
      "Epoch 123/350\n",
      " - 0s - loss: 0.1482 - acc: 0.9360 - val_loss: 0.5423 - val_acc: 0.7500\n",
      "Epoch 124/350\n",
      " - 0s - loss: 0.1480 - acc: 0.9360 - val_loss: 0.5353 - val_acc: 0.7500\n",
      "Epoch 125/350\n",
      " - 0s - loss: 0.1479 - acc: 0.9400 - val_loss: 0.5334 - val_acc: 0.7500\n",
      "Epoch 126/350\n",
      " - 0s - loss: 0.1475 - acc: 0.9440 - val_loss: 0.5416 - val_acc: 0.7500\n",
      "Epoch 127/350\n",
      " - 0s - loss: 0.1475 - acc: 0.9440 - val_loss: 0.5411 - val_acc: 0.7500\n",
      "Epoch 128/350\n",
      " - 0s - loss: 0.1473 - acc: 0.9440 - val_loss: 0.5380 - val_acc: 0.7500\n",
      "Epoch 129/350\n",
      " - 0s - loss: 0.1472 - acc: 0.9440 - val_loss: 0.5451 - val_acc: 0.7500\n",
      "Epoch 130/350\n",
      " - 0s - loss: 0.1471 - acc: 0.9480 - val_loss: 0.5514 - val_acc: 0.7500\n",
      "Epoch 131/350\n",
      " - 0s - loss: 0.1471 - acc: 0.9440 - val_loss: 0.5361 - val_acc: 0.7500\n",
      "Epoch 132/350\n",
      " - 0s - loss: 0.1469 - acc: 0.9480 - val_loss: 0.5354 - val_acc: 0.7500\n",
      "Epoch 133/350\n",
      " - 0s - loss: 0.1468 - acc: 0.9480 - val_loss: 0.5321 - val_acc: 0.7500\n",
      "Epoch 134/350\n",
      " - 0s - loss: 0.1468 - acc: 0.9480 - val_loss: 0.5352 - val_acc: 0.7500\n",
      "Epoch 135/350\n",
      " - 0s - loss: 0.1467 - acc: 0.9480 - val_loss: 0.5364 - val_acc: 0.7500\n",
      "Epoch 136/350\n",
      " - 0s - loss: 0.1467 - acc: 0.9480 - val_loss: 0.5429 - val_acc: 0.7500\n",
      "Epoch 137/350\n",
      " - 0s - loss: 0.1467 - acc: 0.9440 - val_loss: 0.5385 - val_acc: 0.7500\n",
      "Epoch 138/350\n",
      " - 0s - loss: 0.1464 - acc: 0.9480 - val_loss: 0.5336 - val_acc: 0.7500\n",
      "Epoch 139/350\n",
      " - 0s - loss: 0.1462 - acc: 0.9480 - val_loss: 0.5343 - val_acc: 0.7500\n",
      "Epoch 140/350\n",
      " - 0s - loss: 0.1460 - acc: 0.9480 - val_loss: 0.5337 - val_acc: 0.7500\n",
      "Epoch 141/350\n",
      " - 0s - loss: 0.1459 - acc: 0.9480 - val_loss: 0.5347 - val_acc: 0.7500\n",
      "Epoch 142/350\n",
      " - 0s - loss: 0.1458 - acc: 0.9480 - val_loss: 0.5404 - val_acc: 0.7500\n",
      "Epoch 143/350\n",
      " - 0s - loss: 0.1457 - acc: 0.9480 - val_loss: 0.5344 - val_acc: 0.7500\n",
      "Epoch 144/350\n",
      " - 0s - loss: 0.1457 - acc: 0.9480 - val_loss: 0.5222 - val_acc: 0.7500\n",
      "Epoch 145/350\n",
      " - 0s - loss: 0.1456 - acc: 0.9480 - val_loss: 0.5243 - val_acc: 0.7500\n",
      "Epoch 146/350\n",
      " - 0s - loss: 0.1456 - acc: 0.9480 - val_loss: 0.5367 - val_acc: 0.7500\n",
      "Epoch 147/350\n",
      " - 0s - loss: 0.1460 - acc: 0.9480 - val_loss: 0.5142 - val_acc: 0.7500\n",
      "Epoch 148/350\n",
      " - 0s - loss: 0.1452 - acc: 0.9520 - val_loss: 0.5417 - val_acc: 0.7500\n",
      "Epoch 149/350\n",
      " - 0s - loss: 0.1452 - acc: 0.9520 - val_loss: 0.5230 - val_acc: 0.7500\n",
      "Epoch 150/350\n",
      " - 0s - loss: 0.1450 - acc: 0.9520 - val_loss: 0.5225 - val_acc: 0.7500\n",
      "Epoch 151/350\n",
      " - 0s - loss: 0.1448 - acc: 0.9560 - val_loss: 0.5261 - val_acc: 0.7500\n",
      "Epoch 152/350\n",
      " - 0s - loss: 0.1448 - acc: 0.9480 - val_loss: 0.5285 - val_acc: 0.7500\n",
      "Epoch 153/350\n",
      " - 0s - loss: 0.1445 - acc: 0.9480 - val_loss: 0.5265 - val_acc: 0.7500\n",
      "Epoch 154/350\n",
      " - 0s - loss: 0.1445 - acc: 0.9560 - val_loss: 0.5253 - val_acc: 0.7500\n",
      "Epoch 155/350\n",
      " - 0s - loss: 0.1444 - acc: 0.9560 - val_loss: 0.5292 - val_acc: 0.7500\n",
      "Epoch 156/350\n",
      " - 0s - loss: 0.1442 - acc: 0.9560 - val_loss: 0.5285 - val_acc: 0.7500\n",
      "Epoch 157/350\n",
      " - 0s - loss: 0.1441 - acc: 0.9560 - val_loss: 0.5274 - val_acc: 0.7500\n",
      "Epoch 158/350\n",
      " - 0s - loss: 0.1440 - acc: 0.9560 - val_loss: 0.5301 - val_acc: 0.7500\n",
      "Epoch 159/350\n",
      " - 0s - loss: 0.1439 - acc: 0.9520 - val_loss: 0.5310 - val_acc: 0.7500\n",
      "Epoch 160/350\n",
      " - 0s - loss: 0.1445 - acc: 0.9560 - val_loss: 0.5256 - val_acc: 0.7500\n",
      "Epoch 161/350\n",
      " - 0s - loss: 0.1437 - acc: 0.9560 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 162/350\n",
      " - 0s - loss: 0.1437 - acc: 0.9560 - val_loss: 0.5300 - val_acc: 0.7500\n",
      "Epoch 163/350\n",
      " - 0s - loss: 0.1436 - acc: 0.9560 - val_loss: 0.5290 - val_acc: 0.7500\n",
      "Epoch 164/350\n",
      " - 0s - loss: 0.1434 - acc: 0.9560 - val_loss: 0.5296 - val_acc: 0.7500\n",
      "Epoch 165/350\n",
      " - 0s - loss: 0.1438 - acc: 0.9560 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 166/350\n",
      " - 0s - loss: 0.1437 - acc: 0.9560 - val_loss: 0.5322 - val_acc: 0.7500\n",
      "Epoch 167/350\n",
      " - 0s - loss: 0.1437 - acc: 0.9560 - val_loss: 0.5299 - val_acc: 0.7500\n",
      "Epoch 168/350\n",
      " - 0s - loss: 0.1435 - acc: 0.9560 - val_loss: 0.5292 - val_acc: 0.7500\n",
      "Epoch 169/350\n",
      " - 0s - loss: 0.1435 - acc: 0.9560 - val_loss: 0.5301 - val_acc: 0.7500\n",
      "Epoch 170/350\n",
      " - 0s - loss: 0.1436 - acc: 0.9560 - val_loss: 0.5304 - val_acc: 0.7500\n",
      "Epoch 171/350\n",
      " - 0s - loss: 0.1434 - acc: 0.9560 - val_loss: 0.5388 - val_acc: 0.7500\n",
      "Epoch 172/350\n",
      " - 0s - loss: 0.1433 - acc: 0.9560 - val_loss: 0.5217 - val_acc: 0.7500\n",
      "Epoch 173/350\n",
      " - 0s - loss: 0.1432 - acc: 0.9600 - val_loss: 0.5229 - val_acc: 0.7500\n",
      "Epoch 174/350\n",
      " - 0s - loss: 0.1435 - acc: 0.9560 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 175/350\n",
      " - 0s - loss: 0.1430 - acc: 0.9560 - val_loss: 0.5307 - val_acc: 0.7500\n",
      "Epoch 176/350\n",
      " - 0s - loss: 0.1429 - acc: 0.9560 - val_loss: 0.5436 - val_acc: 0.7500\n",
      "Epoch 177/350\n",
      " - 0s - loss: 0.1429 - acc: 0.9560 - val_loss: 0.5275 - val_acc: 0.7500\n",
      "Epoch 178/350\n",
      " - 0s - loss: 0.1428 - acc: 0.9560 - val_loss: 0.5249 - val_acc: 0.7500\n",
      "Epoch 179/350\n",
      " - 0s - loss: 0.1426 - acc: 0.9600 - val_loss: 0.5223 - val_acc: 0.7500\n",
      "Epoch 180/350\n",
      " - 0s - loss: 0.1427 - acc: 0.9560 - val_loss: 0.5199 - val_acc: 0.7500\n",
      "Epoch 181/350\n",
      " - 0s - loss: 0.1426 - acc: 0.9600 - val_loss: 0.5222 - val_acc: 0.7500\n",
      "Epoch 182/350\n",
      " - 0s - loss: 0.1425 - acc: 0.9600 - val_loss: 0.5232 - val_acc: 0.7500\n",
      "Epoch 183/350\n",
      " - 0s - loss: 0.1424 - acc: 0.9600 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 184/350\n",
      " - 0s - loss: 0.1423 - acc: 0.9560 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 185/350\n",
      " - 0s - loss: 0.1420 - acc: 0.9560 - val_loss: 0.5220 - val_acc: 0.7500\n",
      "Epoch 186/350\n",
      " - 0s - loss: 0.1418 - acc: 0.9600 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 187/350\n",
      " - 0s - loss: 0.1418 - acc: 0.9560 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 188/350\n",
      " - 0s - loss: 0.1416 - acc: 0.9560 - val_loss: 0.5192 - val_acc: 0.7500\n",
      "Epoch 189/350\n",
      " - 0s - loss: 0.1416 - acc: 0.9600 - val_loss: 0.5205 - val_acc: 0.7500\n",
      "Epoch 190/350\n",
      " - 0s - loss: 0.1418 - acc: 0.9600 - val_loss: 0.5178 - val_acc: 0.7500\n",
      "Epoch 191/350\n",
      " - 0s - loss: 0.1414 - acc: 0.9600 - val_loss: 0.5207 - val_acc: 0.7500\n",
      "Epoch 192/350\n",
      " - 0s - loss: 0.1414 - acc: 0.9600 - val_loss: 0.5187 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/350\n",
      " - 0s - loss: 0.1413 - acc: 0.9560 - val_loss: 0.5181 - val_acc: 0.7500\n",
      "Epoch 194/350\n",
      " - 0s - loss: 0.1411 - acc: 0.9600 - val_loss: 0.5179 - val_acc: 0.7500\n",
      "Epoch 195/350\n",
      " - 0s - loss: 0.1410 - acc: 0.9600 - val_loss: 0.5191 - val_acc: 0.7500\n",
      "Epoch 196/350\n",
      " - 0s - loss: 0.1409 - acc: 0.9600 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 197/350\n",
      " - 0s - loss: 0.1409 - acc: 0.9600 - val_loss: 0.5175 - val_acc: 0.7500\n",
      "Epoch 198/350\n",
      " - 0s - loss: 0.1408 - acc: 0.9600 - val_loss: 0.5173 - val_acc: 0.7500\n",
      "Epoch 199/350\n",
      " - 0s - loss: 0.1407 - acc: 0.9600 - val_loss: 0.5182 - val_acc: 0.7500\n",
      "Epoch 200/350\n",
      " - 0s - loss: 0.1407 - acc: 0.9600 - val_loss: 0.5140 - val_acc: 0.7500\n",
      "Epoch 201/350\n",
      " - 0s - loss: 0.1406 - acc: 0.9600 - val_loss: 0.5158 - val_acc: 0.7500\n",
      "Epoch 202/350\n",
      " - 0s - loss: 0.1405 - acc: 0.9600 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 203/350\n",
      " - 0s - loss: 0.1405 - acc: 0.9560 - val_loss: 0.5163 - val_acc: 0.7500\n",
      "Epoch 204/350\n",
      " - 0s - loss: 0.1405 - acc: 0.9600 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 205/350\n",
      " - 0s - loss: 0.1403 - acc: 0.9600 - val_loss: 0.5149 - val_acc: 0.7500\n",
      "Epoch 206/350\n",
      " - 0s - loss: 0.1403 - acc: 0.9600 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 207/350\n",
      " - 0s - loss: 0.1402 - acc: 0.9600 - val_loss: 0.5231 - val_acc: 0.7500\n",
      "Epoch 208/350\n",
      " - 0s - loss: 0.1401 - acc: 0.9600 - val_loss: 0.5206 - val_acc: 0.7500\n",
      "Epoch 209/350\n",
      " - 0s - loss: 0.1401 - acc: 0.9600 - val_loss: 0.5203 - val_acc: 0.7500\n",
      "Epoch 210/350\n",
      " - 0s - loss: 0.1410 - acc: 0.9600 - val_loss: 0.5221 - val_acc: 0.7500\n",
      "Epoch 211/350\n",
      " - 0s - loss: 0.1414 - acc: 0.9600 - val_loss: 0.5239 - val_acc: 0.7500\n",
      "Epoch 212/350\n",
      " - 0s - loss: 0.1420 - acc: 0.9560 - val_loss: 0.5287 - val_acc: 0.7500\n",
      "Epoch 213/350\n",
      " - 0s - loss: 0.1415 - acc: 0.9560 - val_loss: 0.5369 - val_acc: 0.7500\n",
      "Epoch 214/350\n",
      " - 0s - loss: 0.1412 - acc: 0.9560 - val_loss: 0.5495 - val_acc: 0.7500\n",
      "Epoch 215/350\n",
      " - 0s - loss: 0.1406 - acc: 0.9560 - val_loss: 0.5209 - val_acc: 0.7500\n",
      "Epoch 216/350\n",
      " - 0s - loss: 0.1398 - acc: 0.9600 - val_loss: 0.5389 - val_acc: 0.7500\n",
      "Epoch 217/350\n",
      " - 0s - loss: 0.1410 - acc: 0.9560 - val_loss: 0.5131 - val_acc: 0.7500\n",
      "Epoch 218/350\n",
      " - 0s - loss: 0.1403 - acc: 0.9560 - val_loss: 0.5238 - val_acc: 0.7500\n",
      "Epoch 219/350\n",
      " - 0s - loss: 0.1393 - acc: 0.9600 - val_loss: 0.5259 - val_acc: 0.7500\n",
      "Epoch 220/350\n",
      " - 0s - loss: 0.1388 - acc: 0.9600 - val_loss: 0.5136 - val_acc: 0.7500\n",
      "Epoch 221/350\n",
      " - 0s - loss: 0.1400 - acc: 0.9560 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 222/350\n",
      " - 0s - loss: 0.1384 - acc: 0.9640 - val_loss: 0.5103 - val_acc: 0.7500\n",
      "Epoch 223/350\n",
      " - 0s - loss: 0.1385 - acc: 0.9600 - val_loss: 0.5123 - val_acc: 0.7500\n",
      "Epoch 224/350\n",
      " - 0s - loss: 0.1385 - acc: 0.9640 - val_loss: 0.5104 - val_acc: 0.7500\n",
      "Epoch 225/350\n",
      " - 0s - loss: 0.1384 - acc: 0.9640 - val_loss: 0.5123 - val_acc: 0.7500\n",
      "Epoch 226/350\n",
      " - 0s - loss: 0.1381 - acc: 0.9600 - val_loss: 0.5195 - val_acc: 0.7500\n",
      "Epoch 227/350\n",
      " - 0s - loss: 0.1377 - acc: 0.9560 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 228/350\n",
      " - 0s - loss: 0.1376 - acc: 0.9560 - val_loss: 0.5127 - val_acc: 0.7500\n",
      "Epoch 229/350\n",
      " - 0s - loss: 0.1376 - acc: 0.9560 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 230/350\n",
      " - 0s - loss: 0.1375 - acc: 0.9560 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 231/350\n",
      " - 0s - loss: 0.1374 - acc: 0.9560 - val_loss: 0.5029 - val_acc: 0.7500\n",
      "Epoch 232/350\n",
      " - 0s - loss: 0.1373 - acc: 0.9560 - val_loss: 0.5028 - val_acc: 0.7500\n",
      "Epoch 233/350\n",
      " - 0s - loss: 0.1373 - acc: 0.9560 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 234/350\n",
      " - 0s - loss: 0.1372 - acc: 0.9560 - val_loss: 0.5007 - val_acc: 0.7500\n",
      "Epoch 235/350\n",
      " - 0s - loss: 0.1371 - acc: 0.9560 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 236/350\n",
      " - 0s - loss: 0.1370 - acc: 0.9560 - val_loss: 0.5056 - val_acc: 0.7500\n",
      "Epoch 237/350\n",
      " - 0s - loss: 0.1368 - acc: 0.9560 - val_loss: 0.5130 - val_acc: 0.7143\n",
      "Epoch 238/350\n",
      " - 0s - loss: 0.1368 - acc: 0.9560 - val_loss: 0.5117 - val_acc: 0.7143\n",
      "Epoch 239/350\n",
      " - 0s - loss: 0.1365 - acc: 0.9560 - val_loss: 0.5113 - val_acc: 0.7143\n",
      "Epoch 240/350\n",
      " - 0s - loss: 0.1369 - acc: 0.9560 - val_loss: 0.5075 - val_acc: 0.7143\n",
      "Epoch 241/350\n",
      " - 0s - loss: 0.1367 - acc: 0.9560 - val_loss: 0.5103 - val_acc: 0.7143\n",
      "Epoch 242/350\n",
      " - 0s - loss: 0.1365 - acc: 0.9560 - val_loss: 0.5119 - val_acc: 0.7143\n",
      "Epoch 243/350\n",
      " - 0s - loss: 0.1362 - acc: 0.9560 - val_loss: 0.5099 - val_acc: 0.7143\n",
      "Epoch 244/350\n",
      " - 0s - loss: 0.1362 - acc: 0.9560 - val_loss: 0.5102 - val_acc: 0.7143\n",
      "Epoch 245/350\n",
      " - 0s - loss: 0.1361 - acc: 0.9560 - val_loss: 0.5115 - val_acc: 0.7143\n",
      "Epoch 246/350\n",
      " - 0s - loss: 0.1360 - acc: 0.9560 - val_loss: 0.5171 - val_acc: 0.7143\n",
      "Epoch 247/350\n",
      " - 0s - loss: 0.1359 - acc: 0.9560 - val_loss: 0.5254 - val_acc: 0.7143\n",
      "Epoch 248/350\n",
      " - 0s - loss: 0.1359 - acc: 0.9560 - val_loss: 0.5315 - val_acc: 0.7143\n",
      "Epoch 249/350\n",
      " - 0s - loss: 0.1358 - acc: 0.9560 - val_loss: 0.5330 - val_acc: 0.7143\n",
      "Epoch 250/350\n",
      " - 0s - loss: 0.1357 - acc: 0.9560 - val_loss: 0.5210 - val_acc: 0.7143\n",
      "Epoch 251/350\n",
      " - 0s - loss: 0.1356 - acc: 0.9560 - val_loss: 0.5143 - val_acc: 0.7143\n",
      "Epoch 252/350\n",
      " - 0s - loss: 0.1356 - acc: 0.9560 - val_loss: 0.5193 - val_acc: 0.7143\n",
      "Epoch 253/350\n",
      " - 0s - loss: 0.1357 - acc: 0.9560 - val_loss: 0.5165 - val_acc: 0.7143\n",
      "Epoch 254/350\n",
      " - 0s - loss: 0.1355 - acc: 0.9560 - val_loss: 0.5204 - val_acc: 0.7143\n",
      "Epoch 255/350\n",
      " - 0s - loss: 0.1354 - acc: 0.9560 - val_loss: 0.5247 - val_acc: 0.7143\n",
      "Epoch 256/350\n",
      " - 0s - loss: 0.1352 - acc: 0.9560 - val_loss: 0.5422 - val_acc: 0.7143\n",
      "Epoch 257/350\n",
      " - 0s - loss: 0.1353 - acc: 0.9560 - val_loss: 0.5293 - val_acc: 0.7143\n",
      "Epoch 258/350\n",
      " - 0s - loss: 0.1351 - acc: 0.9560 - val_loss: 0.5361 - val_acc: 0.7143\n",
      "Epoch 259/350\n",
      " - 0s - loss: 0.1351 - acc: 0.9560 - val_loss: 0.5440 - val_acc: 0.7143\n",
      "Epoch 260/350\n",
      " - 0s - loss: 0.1349 - acc: 0.9560 - val_loss: 0.5368 - val_acc: 0.7143\n",
      "Epoch 261/350\n",
      " - 0s - loss: 0.1349 - acc: 0.9560 - val_loss: 0.5442 - val_acc: 0.7143\n",
      "Epoch 262/350\n",
      " - 0s - loss: 0.1349 - acc: 0.9560 - val_loss: 0.5505 - val_acc: 0.7143\n",
      "Epoch 263/350\n",
      " - 0s - loss: 0.1347 - acc: 0.9560 - val_loss: 0.5475 - val_acc: 0.7143\n",
      "Epoch 264/350\n",
      " - 0s - loss: 0.1347 - acc: 0.9560 - val_loss: 0.5360 - val_acc: 0.7143\n",
      "Epoch 265/350\n",
      " - 0s - loss: 0.1348 - acc: 0.9600 - val_loss: 0.5394 - val_acc: 0.7143\n",
      "Epoch 266/350\n",
      " - 0s - loss: 0.1345 - acc: 0.9560 - val_loss: 0.5447 - val_acc: 0.7143\n",
      "Epoch 267/350\n",
      " - 0s - loss: 0.1346 - acc: 0.9560 - val_loss: 0.5512 - val_acc: 0.7143\n",
      "Epoch 268/350\n",
      " - 0s - loss: 0.1344 - acc: 0.9560 - val_loss: 0.5468 - val_acc: 0.7143\n",
      "Epoch 269/350\n",
      " - 0s - loss: 0.1344 - acc: 0.9560 - val_loss: 0.5470 - val_acc: 0.7143\n",
      "Epoch 270/350\n",
      " - 0s - loss: 0.1346 - acc: 0.9520 - val_loss: 0.5447 - val_acc: 0.7143\n",
      "Epoch 271/350\n",
      " - 0s - loss: 0.1346 - acc: 0.9560 - val_loss: 0.5406 - val_acc: 0.7143\n",
      "Epoch 272/350\n",
      " - 0s - loss: 0.1346 - acc: 0.9560 - val_loss: 0.5425 - val_acc: 0.7143\n",
      "Epoch 273/350\n",
      " - 0s - loss: 0.1345 - acc: 0.9560 - val_loss: 0.5458 - val_acc: 0.7143\n",
      "Epoch 274/350\n",
      " - 0s - loss: 0.1345 - acc: 0.9520 - val_loss: 0.5445 - val_acc: 0.7143\n",
      "Epoch 275/350\n",
      " - 0s - loss: 0.1345 - acc: 0.9520 - val_loss: 0.5418 - val_acc: 0.7143\n",
      "Epoch 276/350\n",
      " - 0s - loss: 0.1344 - acc: 0.9560 - val_loss: 0.5409 - val_acc: 0.7143\n",
      "Epoch 277/350\n",
      " - 0s - loss: 0.1343 - acc: 0.9560 - val_loss: 0.5420 - val_acc: 0.7143\n",
      "Epoch 278/350\n",
      " - 0s - loss: 0.1342 - acc: 0.9560 - val_loss: 0.5441 - val_acc: 0.7143\n",
      "Epoch 279/350\n",
      " - 0s - loss: 0.1341 - acc: 0.9560 - val_loss: 0.5473 - val_acc: 0.7143\n",
      "Epoch 280/350\n",
      " - 0s - loss: 0.1340 - acc: 0.9560 - val_loss: 0.5439 - val_acc: 0.7143\n",
      "Epoch 281/350\n",
      " - 0s - loss: 0.1340 - acc: 0.9560 - val_loss: 0.5389 - val_acc: 0.7143\n",
      "Epoch 282/350\n",
      " - 0s - loss: 0.1342 - acc: 0.9520 - val_loss: 0.5388 - val_acc: 0.7143\n",
      "Epoch 283/350\n",
      " - 0s - loss: 0.1340 - acc: 0.9560 - val_loss: 0.5418 - val_acc: 0.7143\n",
      "Epoch 284/350\n",
      " - 0s - loss: 0.1337 - acc: 0.9560 - val_loss: 0.5433 - val_acc: 0.7143\n",
      "Epoch 285/350\n",
      " - 0s - loss: 0.1338 - acc: 0.9560 - val_loss: 0.5449 - val_acc: 0.7143\n",
      "Epoch 286/350\n",
      " - 0s - loss: 0.1338 - acc: 0.9560 - val_loss: 0.5461 - val_acc: 0.7143\n",
      "Epoch 287/350\n",
      " - 0s - loss: 0.1329 - acc: 0.9560 - val_loss: 0.5462 - val_acc: 0.7143\n",
      "Epoch 288/350\n",
      " - 0s - loss: 0.1326 - acc: 0.9560 - val_loss: 0.5479 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/350\n",
      " - 0s - loss: 0.1326 - acc: 0.9560 - val_loss: 0.5455 - val_acc: 0.7143\n",
      "Epoch 290/350\n",
      " - 0s - loss: 0.1326 - acc: 0.9560 - val_loss: 0.5390 - val_acc: 0.7143\n",
      "Epoch 291/350\n",
      " - 0s - loss: 0.1325 - acc: 0.9560 - val_loss: 0.5402 - val_acc: 0.7143\n",
      "Epoch 292/350\n",
      " - 0s - loss: 0.1324 - acc: 0.9560 - val_loss: 0.5428 - val_acc: 0.7143\n",
      "Epoch 293/350\n",
      " - 0s - loss: 0.1323 - acc: 0.9560 - val_loss: 0.5475 - val_acc: 0.7143\n",
      "Epoch 294/350\n",
      " - 0s - loss: 0.1323 - acc: 0.9560 - val_loss: 0.5501 - val_acc: 0.7143\n",
      "Epoch 295/350\n",
      " - 0s - loss: 0.1322 - acc: 0.9560 - val_loss: 0.5504 - val_acc: 0.7143\n",
      "Epoch 296/350\n",
      " - 0s - loss: 0.1321 - acc: 0.9560 - val_loss: 0.5478 - val_acc: 0.7143\n",
      "Epoch 297/350\n",
      " - 0s - loss: 0.1320 - acc: 0.9560 - val_loss: 0.5482 - val_acc: 0.7143\n",
      "Epoch 298/350\n",
      " - 0s - loss: 0.1320 - acc: 0.9560 - val_loss: 0.5480 - val_acc: 0.7143\n",
      "Epoch 299/350\n",
      " - 0s - loss: 0.1321 - acc: 0.9560 - val_loss: 0.5400 - val_acc: 0.7143\n",
      "Epoch 300/350\n",
      " - 0s - loss: 0.1320 - acc: 0.9560 - val_loss: 0.5407 - val_acc: 0.7143\n",
      "Epoch 301/350\n",
      " - 0s - loss: 0.1320 - acc: 0.9560 - val_loss: 0.5421 - val_acc: 0.7143\n",
      "Epoch 302/350\n",
      " - 0s - loss: 0.1318 - acc: 0.9560 - val_loss: 0.5460 - val_acc: 0.7143\n",
      "Epoch 303/350\n",
      " - 0s - loss: 0.1317 - acc: 0.9560 - val_loss: 0.5492 - val_acc: 0.7143\n",
      "Epoch 304/350\n",
      " - 0s - loss: 0.1317 - acc: 0.9560 - val_loss: 0.5526 - val_acc: 0.7143\n",
      "Epoch 305/350\n",
      " - 0s - loss: 0.1316 - acc: 0.9560 - val_loss: 0.5531 - val_acc: 0.7143\n",
      "Epoch 306/350\n",
      " - 0s - loss: 0.1316 - acc: 0.9560 - val_loss: 0.5510 - val_acc: 0.7143\n",
      "Epoch 307/350\n",
      " - 0s - loss: 0.1315 - acc: 0.9560 - val_loss: 0.5519 - val_acc: 0.7143\n",
      "Epoch 308/350\n",
      " - 0s - loss: 0.1314 - acc: 0.9560 - val_loss: 0.5489 - val_acc: 0.7143\n",
      "Epoch 309/350\n",
      " - 0s - loss: 0.1314 - acc: 0.9560 - val_loss: 0.5504 - val_acc: 0.7143\n",
      "Epoch 310/350\n",
      " - 0s - loss: 0.1314 - acc: 0.9560 - val_loss: 0.5545 - val_acc: 0.7143\n",
      "Epoch 311/350\n",
      " - 0s - loss: 0.1313 - acc: 0.9560 - val_loss: 0.5591 - val_acc: 0.7143\n",
      "Epoch 312/350\n",
      " - 0s - loss: 0.1312 - acc: 0.9560 - val_loss: 0.5639 - val_acc: 0.7143\n",
      "Epoch 313/350\n",
      " - 0s - loss: 0.1312 - acc: 0.9560 - val_loss: 0.5654 - val_acc: 0.7143\n",
      "Epoch 314/350\n",
      " - 0s - loss: 0.1311 - acc: 0.9560 - val_loss: 0.5654 - val_acc: 0.7143\n",
      "Epoch 315/350\n",
      " - 0s - loss: 0.1311 - acc: 0.9560 - val_loss: 0.5662 - val_acc: 0.7143\n",
      "Epoch 316/350\n",
      " - 0s - loss: 0.1310 - acc: 0.9560 - val_loss: 0.5646 - val_acc: 0.7143\n",
      "Epoch 317/350\n",
      " - 0s - loss: 0.1310 - acc: 0.9560 - val_loss: 0.5630 - val_acc: 0.7143\n",
      "Epoch 318/350\n",
      " - 0s - loss: 0.1309 - acc: 0.9560 - val_loss: 0.5618 - val_acc: 0.7143\n",
      "Epoch 319/350\n",
      " - 0s - loss: 0.1308 - acc: 0.9560 - val_loss: 0.5625 - val_acc: 0.7143\n",
      "Epoch 320/350\n",
      " - 0s - loss: 0.1309 - acc: 0.9560 - val_loss: 0.5625 - val_acc: 0.7143\n",
      "Epoch 321/350\n",
      " - 0s - loss: 0.1307 - acc: 0.9560 - val_loss: 0.5632 - val_acc: 0.7143\n",
      "Epoch 322/350\n",
      " - 0s - loss: 0.1307 - acc: 0.9560 - val_loss: 0.5576 - val_acc: 0.7143\n",
      "Epoch 323/350\n",
      " - 0s - loss: 0.1306 - acc: 0.9560 - val_loss: 0.5659 - val_acc: 0.7143\n",
      "Epoch 324/350\n",
      " - 0s - loss: 0.1306 - acc: 0.9560 - val_loss: 0.5662 - val_acc: 0.7143\n",
      "Epoch 325/350\n",
      " - 0s - loss: 0.1305 - acc: 0.9560 - val_loss: 0.5606 - val_acc: 0.7143\n",
      "Epoch 326/350\n",
      " - 0s - loss: 0.1305 - acc: 0.9560 - val_loss: 0.5543 - val_acc: 0.7143\n",
      "Epoch 327/350\n",
      " - 0s - loss: 0.1305 - acc: 0.9560 - val_loss: 0.5607 - val_acc: 0.7143\n",
      "Epoch 328/350\n",
      " - 0s - loss: 0.1304 - acc: 0.9560 - val_loss: 0.5594 - val_acc: 0.7143\n",
      "Epoch 329/350\n",
      " - 0s - loss: 0.1303 - acc: 0.9560 - val_loss: 0.5604 - val_acc: 0.7143\n",
      "Epoch 330/350\n",
      " - 0s - loss: 0.1302 - acc: 0.9560 - val_loss: 0.5555 - val_acc: 0.7143\n",
      "Epoch 331/350\n",
      " - 0s - loss: 0.1302 - acc: 0.9560 - val_loss: 0.5611 - val_acc: 0.7143\n",
      "Epoch 332/350\n",
      " - 0s - loss: 0.1302 - acc: 0.9560 - val_loss: 0.5596 - val_acc: 0.7143\n",
      "Epoch 333/350\n",
      " - 0s - loss: 0.1302 - acc: 0.9560 - val_loss: 0.5596 - val_acc: 0.7143\n",
      "Epoch 334/350\n",
      " - 0s - loss: 0.1300 - acc: 0.9560 - val_loss: 0.5558 - val_acc: 0.7143\n",
      "Epoch 335/350\n",
      " - 0s - loss: 0.1299 - acc: 0.9560 - val_loss: 0.5580 - val_acc: 0.7143\n",
      "Epoch 336/350\n",
      " - 0s - loss: 0.1300 - acc: 0.9560 - val_loss: 0.5559 - val_acc: 0.7143\n",
      "Epoch 337/350\n",
      " - 0s - loss: 0.1299 - acc: 0.9560 - val_loss: 0.5556 - val_acc: 0.7143\n",
      "Epoch 338/350\n",
      " - 0s - loss: 0.1298 - acc: 0.9560 - val_loss: 0.5554 - val_acc: 0.7143\n",
      "Epoch 339/350\n",
      " - 0s - loss: 0.1298 - acc: 0.9560 - val_loss: 0.5556 - val_acc: 0.7143\n",
      "Epoch 340/350\n",
      " - 0s - loss: 0.1297 - acc: 0.9560 - val_loss: 0.5588 - val_acc: 0.7143\n",
      "Epoch 341/350\n",
      " - 0s - loss: 0.1296 - acc: 0.9560 - val_loss: 0.5600 - val_acc: 0.7143\n",
      "Epoch 342/350\n",
      " - 0s - loss: 0.1296 - acc: 0.9560 - val_loss: 0.5617 - val_acc: 0.7143\n",
      "Epoch 343/350\n",
      " - 0s - loss: 0.1296 - acc: 0.9560 - val_loss: 0.5608 - val_acc: 0.7143\n",
      "Epoch 344/350\n",
      " - 0s - loss: 0.1292 - acc: 0.9560 - val_loss: 0.5636 - val_acc: 0.7143\n",
      "Epoch 345/350\n",
      " - 0s - loss: 0.1300 - acc: 0.9560 - val_loss: 0.5582 - val_acc: 0.7143\n",
      "Epoch 346/350\n",
      " - 0s - loss: 0.1293 - acc: 0.9560 - val_loss: 0.5605 - val_acc: 0.7143\n",
      "Epoch 347/350\n",
      " - 0s - loss: 0.1289 - acc: 0.9560 - val_loss: 0.5658 - val_acc: 0.7143\n",
      "Epoch 348/350\n",
      " - 0s - loss: 0.1287 - acc: 0.9560 - val_loss: 0.5604 - val_acc: 0.7143\n",
      "Epoch 349/350\n",
      " - 0s - loss: 0.1286 - acc: 0.9560 - val_loss: 0.5619 - val_acc: 0.7143\n",
      "Epoch 350/350\n",
      " - 0s - loss: 0.1286 - acc: 0.9560 - val_loss: 0.5640 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 350, \n",
    "          batch_size = 15, \n",
    "          verbose=2, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f030c11d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f030cac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее, добавили слой, два сигмоида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6679 - acc: 0.5600 - val_loss: 0.7056 - val_acc: 0.3571\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.6209 - acc: 0.6960 - val_loss: 0.6781 - val_acc: 0.5357\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.5829 - acc: 0.7560 - val_loss: 0.6549 - val_acc: 0.6071\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.5487 - acc: 0.7880 - val_loss: 0.6300 - val_acc: 0.7500\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 0.5205 - acc: 0.7840 - val_loss: 0.6147 - val_acc: 0.6786\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.4981 - acc: 0.7800 - val_loss: 0.6053 - val_acc: 0.6786\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.4770 - acc: 0.7800 - val_loss: 0.5956 - val_acc: 0.7143\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 0.4595 - acc: 0.7920 - val_loss: 0.5873 - val_acc: 0.7143\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.4444 - acc: 0.7840 - val_loss: 0.5815 - val_acc: 0.7143\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 0.4312 - acc: 0.8120 - val_loss: 0.5755 - val_acc: 0.7143\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.4212 - acc: 0.8000 - val_loss: 0.5728 - val_acc: 0.7143\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.4094 - acc: 0.8120 - val_loss: 0.5705 - val_acc: 0.7143\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.4010 - acc: 0.8120 - val_loss: 0.5675 - val_acc: 0.7143\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.3911 - acc: 0.8080 - val_loss: 0.5633 - val_acc: 0.7143\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3869 - acc: 0.8080 - val_loss: 0.5641 - val_acc: 0.7143\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3779 - acc: 0.8240 - val_loss: 0.5580 - val_acc: 0.7143\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3714 - acc: 0.8160 - val_loss: 0.5569 - val_acc: 0.7143\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3688 - acc: 0.8240 - val_loss: 0.5520 - val_acc: 0.7143\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3622 - acc: 0.8280 - val_loss: 0.5547 - val_acc: 0.7143\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3545 - acc: 0.8320 - val_loss: 0.5611 - val_acc: 0.7143\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3533 - acc: 0.8360 - val_loss: 0.5584 - val_acc: 0.7143\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.3472 - acc: 0.8320 - val_loss: 0.5544 - val_acc: 0.7143\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3427 - acc: 0.8280 - val_loss: 0.5500 - val_acc: 0.7143\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3398 - acc: 0.8400 - val_loss: 0.5580 - val_acc: 0.7143\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3359 - acc: 0.8320 - val_loss: 0.5538 - val_acc: 0.7143\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3336 - acc: 0.8400 - val_loss: 0.5525 - val_acc: 0.7143\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3292 - acc: 0.8360 - val_loss: 0.5456 - val_acc: 0.7143\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3260 - acc: 0.8440 - val_loss: 0.5375 - val_acc: 0.7143\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3232 - acc: 0.8440 - val_loss: 0.5404 - val_acc: 0.7143\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3212 - acc: 0.8440 - val_loss: 0.5386 - val_acc: 0.7143\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3183 - acc: 0.8440 - val_loss: 0.5491 - val_acc: 0.7143\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.3147 - acc: 0.8400 - val_loss: 0.5621 - val_acc: 0.7143\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3134 - acc: 0.8480 - val_loss: 0.5484 - val_acc: 0.7143\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3088 - acc: 0.8480 - val_loss: 0.5484 - val_acc: 0.7143\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3071 - acc: 0.8480 - val_loss: 0.5471 - val_acc: 0.7143\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.3049 - acc: 0.8480 - val_loss: 0.5472 - val_acc: 0.7143\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.3028 - acc: 0.8520 - val_loss: 0.5427 - val_acc: 0.7143\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.3023 - acc: 0.8480 - val_loss: 0.5518 - val_acc: 0.7143\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2997 - acc: 0.8520 - val_loss: 0.5412 - val_acc: 0.7143\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2972 - acc: 0.8440 - val_loss: 0.5362 - val_acc: 0.7143\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2938 - acc: 0.8520 - val_loss: 0.5345 - val_acc: 0.7143\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2922 - acc: 0.8480 - val_loss: 0.5346 - val_acc: 0.7143\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2894 - acc: 0.8520 - val_loss: 0.5347 - val_acc: 0.7143\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2885 - acc: 0.8520 - val_loss: 0.5259 - val_acc: 0.7143\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2858 - acc: 0.8520 - val_loss: 0.5363 - val_acc: 0.7143\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2847 - acc: 0.8560 - val_loss: 0.5338 - val_acc: 0.7143\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2842 - acc: 0.8520 - val_loss: 0.5440 - val_acc: 0.7143\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2827 - acc: 0.8560 - val_loss: 0.5370 - val_acc: 0.7143\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2790 - acc: 0.8600 - val_loss: 0.5446 - val_acc: 0.7143\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2802 - acc: 0.8640 - val_loss: 0.5425 - val_acc: 0.7143\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2772 - acc: 0.8600 - val_loss: 0.5360 - val_acc: 0.7143\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2738 - acc: 0.8560 - val_loss: 0.5315 - val_acc: 0.7143\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2732 - acc: 0.8640 - val_loss: 0.5331 - val_acc: 0.7143\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2708 - acc: 0.8640 - val_loss: 0.5512 - val_acc: 0.7143\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2698 - acc: 0.8640 - val_loss: 0.5355 - val_acc: 0.7143\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2676 - acc: 0.8640 - val_loss: 0.5245 - val_acc: 0.7143\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2657 - acc: 0.8680 - val_loss: 0.5240 - val_acc: 0.7143\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2655 - acc: 0.8680 - val_loss: 0.5177 - val_acc: 0.6786\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2621 - acc: 0.8680 - val_loss: 0.5422 - val_acc: 0.7143\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2599 - acc: 0.8720 - val_loss: 0.5389 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2586 - acc: 0.8760 - val_loss: 0.5309 - val_acc: 0.7143\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2565 - acc: 0.8680 - val_loss: 0.5368 - val_acc: 0.7143\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2535 - acc: 0.8800 - val_loss: 0.5360 - val_acc: 0.6786\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2510 - acc: 0.8760 - val_loss: 0.5341 - val_acc: 0.7143\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2502 - acc: 0.8840 - val_loss: 0.5420 - val_acc: 0.6786\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2492 - acc: 0.8800 - val_loss: 0.5299 - val_acc: 0.6786\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2469 - acc: 0.8800 - val_loss: 0.5301 - val_acc: 0.6786\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2450 - acc: 0.8800 - val_loss: 0.5193 - val_acc: 0.6786\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2437 - acc: 0.8760 - val_loss: 0.5223 - val_acc: 0.6786\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2442 - acc: 0.8880 - val_loss: 0.5324 - val_acc: 0.6786\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.2400 - acc: 0.8840 - val_loss: 0.5425 - val_acc: 0.6786\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2373 - acc: 0.8880 - val_loss: 0.5124 - val_acc: 0.6786\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2369 - acc: 0.8840 - val_loss: 0.5196 - val_acc: 0.6786\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2355 - acc: 0.8800 - val_loss: 0.5300 - val_acc: 0.6786\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2324 - acc: 0.8840 - val_loss: 0.5196 - val_acc: 0.6786\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2321 - acc: 0.8920 - val_loss: 0.5208 - val_acc: 0.6786\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2285 - acc: 0.8880 - val_loss: 0.5377 - val_acc: 0.6786\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2280 - acc: 0.8920 - val_loss: 0.5209 - val_acc: 0.6786\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2252 - acc: 0.8960 - val_loss: 0.5070 - val_acc: 0.6786\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2253 - acc: 0.9000 - val_loss: 0.5245 - val_acc: 0.6786\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.2223 - acc: 0.9040 - val_loss: 0.5329 - val_acc: 0.6786\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2214 - acc: 0.9000 - val_loss: 0.5478 - val_acc: 0.6786\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2215 - acc: 0.9080 - val_loss: 0.5435 - val_acc: 0.6786\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2189 - acc: 0.9080 - val_loss: 0.5266 - val_acc: 0.6786\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2172 - acc: 0.9040 - val_loss: 0.5375 - val_acc: 0.6786\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.2140 - acc: 0.9120 - val_loss: 0.5410 - val_acc: 0.6786\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2135 - acc: 0.9120 - val_loss: 0.5292 - val_acc: 0.6786\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2126 - acc: 0.9120 - val_loss: 0.5288 - val_acc: 0.6786\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2098 - acc: 0.9160 - val_loss: 0.5416 - val_acc: 0.6786\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2098 - acc: 0.9040 - val_loss: 0.5462 - val_acc: 0.6786\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2087 - acc: 0.9120 - val_loss: 0.5400 - val_acc: 0.6786\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2072 - acc: 0.9080 - val_loss: 0.5342 - val_acc: 0.6786\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2050 - acc: 0.9200 - val_loss: 0.5616 - val_acc: 0.6429\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2052 - acc: 0.9120 - val_loss: 0.5522 - val_acc: 0.6429\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2024 - acc: 0.9280 - val_loss: 0.5458 - val_acc: 0.6786\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2014 - acc: 0.9160 - val_loss: 0.5365 - val_acc: 0.6786\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2002 - acc: 0.9200 - val_loss: 0.5246 - val_acc: 0.7143\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1987 - acc: 0.9240 - val_loss: 0.5377 - val_acc: 0.6786\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1969 - acc: 0.9240 - val_loss: 0.5445 - val_acc: 0.6429\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1973 - acc: 0.9200 - val_loss: 0.5357 - val_acc: 0.7143\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1950 - acc: 0.9200 - val_loss: 0.5468 - val_acc: 0.6429\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1940 - acc: 0.9280 - val_loss: 0.5529 - val_acc: 0.6429\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1906 - acc: 0.9280 - val_loss: 0.5447 - val_acc: 0.6429\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1895 - acc: 0.9320 - val_loss: 0.5266 - val_acc: 0.7143\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1907 - acc: 0.9240 - val_loss: 0.5152 - val_acc: 0.7143\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1877 - acc: 0.9320 - val_loss: 0.5292 - val_acc: 0.7143\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1854 - acc: 0.9320 - val_loss: 0.5322 - val_acc: 0.7143\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1846 - acc: 0.9320 - val_loss: 0.5329 - val_acc: 0.6786\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1834 - acc: 0.9320 - val_loss: 0.5367 - val_acc: 0.7143\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1813 - acc: 0.9320 - val_loss: 0.5291 - val_acc: 0.7143\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1793 - acc: 0.9360 - val_loss: 0.5303 - val_acc: 0.7143\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1771 - acc: 0.9400 - val_loss: 0.5402 - val_acc: 0.7143\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1746 - acc: 0.9360 - val_loss: 0.5582 - val_acc: 0.6786\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1740 - acc: 0.9440 - val_loss: 0.5551 - val_acc: 0.6786\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1721 - acc: 0.9480 - val_loss: 0.5393 - val_acc: 0.7143\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.1717 - acc: 0.9440 - val_loss: 0.5381 - val_acc: 0.7143\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1694 - acc: 0.9440 - val_loss: 0.5403 - val_acc: 0.7143\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1713 - acc: 0.9400 - val_loss: 0.5336 - val_acc: 0.7143\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1679 - acc: 0.9440 - val_loss: 0.5359 - val_acc: 0.7143\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1665 - acc: 0.9480 - val_loss: 0.5504 - val_acc: 0.6786\n",
      "Epoch 121/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 172us/step - loss: 0.1655 - acc: 0.9440 - val_loss: 0.5535 - val_acc: 0.6786\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1631 - acc: 0.9480 - val_loss: 0.5425 - val_acc: 0.7143\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.1631 - acc: 0.9560 - val_loss: 0.5454 - val_acc: 0.6786\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1612 - acc: 0.9520 - val_loss: 0.5632 - val_acc: 0.6786\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1597 - acc: 0.9520 - val_loss: 0.5699 - val_acc: 0.6786\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1594 - acc: 0.9480 - val_loss: 0.5480 - val_acc: 0.6786\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1571 - acc: 0.9560 - val_loss: 0.5549 - val_acc: 0.6786\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1560 - acc: 0.9560 - val_loss: 0.5582 - val_acc: 0.6786\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1545 - acc: 0.9560 - val_loss: 0.5452 - val_acc: 0.6786\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1540 - acc: 0.9560 - val_loss: 0.5457 - val_acc: 0.6786\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1517 - acc: 0.9560 - val_loss: 0.5415 - val_acc: 0.6786\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1564 - acc: 0.9600 - val_loss: 0.5550 - val_acc: 0.6786\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1521 - acc: 0.9560 - val_loss: 0.5813 - val_acc: 0.6786\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1503 - acc: 0.9560 - val_loss: 0.5625 - val_acc: 0.6786\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1476 - acc: 0.9600 - val_loss: 0.5557 - val_acc: 0.6786\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1454 - acc: 0.9600 - val_loss: 0.5625 - val_acc: 0.6786\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1434 - acc: 0.9640 - val_loss: 0.5583 - val_acc: 0.6786\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1427 - acc: 0.9680 - val_loss: 0.5511 - val_acc: 0.6786\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1400 - acc: 0.9680 - val_loss: 0.5580 - val_acc: 0.6786\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1396 - acc: 0.9680 - val_loss: 0.5776 - val_acc: 0.6786\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1393 - acc: 0.9600 - val_loss: 0.5628 - val_acc: 0.6786\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1387 - acc: 0.9640 - val_loss: 0.6006 - val_acc: 0.6786\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1376 - acc: 0.9680 - val_loss: 0.5510 - val_acc: 0.6786\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1333 - acc: 0.9680 - val_loss: 0.5649 - val_acc: 0.6786\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1329 - acc: 0.9640 - val_loss: 0.5670 - val_acc: 0.6786\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1310 - acc: 0.9800 - val_loss: 0.5698 - val_acc: 0.6786\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1292 - acc: 0.9800 - val_loss: 0.5994 - val_acc: 0.6786\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1284 - acc: 0.9680 - val_loss: 0.5900 - val_acc: 0.6786\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1274 - acc: 0.9720 - val_loss: 0.5674 - val_acc: 0.6786\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1266 - acc: 0.9680 - val_loss: 0.5879 - val_acc: 0.6786\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.1248 - acc: 0.9760 - val_loss: 0.5830 - val_acc: 0.6786\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1238 - acc: 0.9840 - val_loss: 0.5594 - val_acc: 0.6786\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1227 - acc: 0.9760 - val_loss: 0.5572 - val_acc: 0.6786\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1217 - acc: 0.9840 - val_loss: 0.5911 - val_acc: 0.6786\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1218 - acc: 0.9840 - val_loss: 0.6103 - val_acc: 0.6786\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1194 - acc: 0.9720 - val_loss: 0.6037 - val_acc: 0.6786\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1177 - acc: 0.9840 - val_loss: 0.6018 - val_acc: 0.6786\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1165 - acc: 0.9840 - val_loss: 0.5989 - val_acc: 0.6786\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1161 - acc: 0.9880 - val_loss: 0.5852 - val_acc: 0.6786\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1160 - acc: 0.9840 - val_loss: 0.6073 - val_acc: 0.6786\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1157 - acc: 0.9840 - val_loss: 0.6029 - val_acc: 0.6786\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1144 - acc: 0.9840 - val_loss: 0.5902 - val_acc: 0.6786\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1132 - acc: 0.9840 - val_loss: 0.5906 - val_acc: 0.6786\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1127 - acc: 0.9800 - val_loss: 0.6236 - val_acc: 0.6786\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1112 - acc: 0.9880 - val_loss: 0.5920 - val_acc: 0.6786\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1093 - acc: 0.9920 - val_loss: 0.6067 - val_acc: 0.6786\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1096 - acc: 0.9880 - val_loss: 0.6025 - val_acc: 0.6786\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1084 - acc: 0.9840 - val_loss: 0.6435 - val_acc: 0.6786\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1084 - acc: 0.9840 - val_loss: 0.6214 - val_acc: 0.6786\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1061 - acc: 0.9880 - val_loss: 0.6363 - val_acc: 0.6786\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1046 - acc: 0.9880 - val_loss: 0.6174 - val_acc: 0.6786\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1040 - acc: 0.9880 - val_loss: 0.6022 - val_acc: 0.6786\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1033 - acc: 0.9920 - val_loss: 0.6099 - val_acc: 0.6786\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1014 - acc: 0.9920 - val_loss: 0.6264 - val_acc: 0.6786\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1014 - acc: 0.9880 - val_loss: 0.6317 - val_acc: 0.6786\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0992 - acc: 0.9920 - val_loss: 0.6210 - val_acc: 0.6786\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0981 - acc: 0.9920 - val_loss: 0.6477 - val_acc: 0.6786\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0985 - acc: 0.9920 - val_loss: 0.6143 - val_acc: 0.6786\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0966 - acc: 0.9920 - val_loss: 0.6029 - val_acc: 0.6786\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0980 - acc: 0.9880 - val_loss: 0.6305 - val_acc: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0952 - acc: 0.9920 - val_loss: 0.6384 - val_acc: 0.6786\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0939 - acc: 0.9920 - val_loss: 0.6416 - val_acc: 0.6786\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0929 - acc: 0.9920 - val_loss: 0.6290 - val_acc: 0.6786\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.0922 - acc: 0.9920 - val_loss: 0.6348 - val_acc: 0.6786\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0919 - acc: 0.9920 - val_loss: 0.6421 - val_acc: 0.6786\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0912 - acc: 0.9920 - val_loss: 0.6488 - val_acc: 0.6786\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0906 - acc: 0.9920 - val_loss: 0.6628 - val_acc: 0.6786\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0905 - acc: 0.9920 - val_loss: 0.6552 - val_acc: 0.6786\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0892 - acc: 0.9920 - val_loss: 0.6639 - val_acc: 0.6786\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0881 - acc: 0.9920 - val_loss: 0.6521 - val_acc: 0.6786\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0873 - acc: 0.9920 - val_loss: 0.6511 - val_acc: 0.6786\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0872 - acc: 0.9920 - val_loss: 0.6719 - val_acc: 0.6786\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0862 - acc: 0.9920 - val_loss: 0.6546 - val_acc: 0.6786\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0859 - acc: 0.9920 - val_loss: 0.6730 - val_acc: 0.6786\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0846 - acc: 0.9920 - val_loss: 0.6912 - val_acc: 0.6786\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0840 - acc: 0.9920 - val_loss: 0.6530 - val_acc: 0.7143\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0833 - acc: 0.9920 - val_loss: 0.6596 - val_acc: 0.6786\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0826 - acc: 0.9920 - val_loss: 0.6588 - val_acc: 0.6786\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0811 - acc: 0.9920 - val_loss: 0.6668 - val_acc: 0.7143\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0800 - acc: 0.9920 - val_loss: 0.7014 - val_acc: 0.6786\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0800 - acc: 0.9920 - val_loss: 0.7051 - val_acc: 0.6429\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0797 - acc: 0.9920 - val_loss: 0.6992 - val_acc: 0.6429\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0784 - acc: 0.9920 - val_loss: 0.6793 - val_acc: 0.6429\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0777 - acc: 0.9920 - val_loss: 0.6786 - val_acc: 0.6429\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0767 - acc: 0.9920 - val_loss: 0.7024 - val_acc: 0.6429\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0761 - acc: 0.9920 - val_loss: 0.7095 - val_acc: 0.6429\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0764 - acc: 0.9920 - val_loss: 0.7194 - val_acc: 0.6429\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0754 - acc: 0.9920 - val_loss: 0.6917 - val_acc: 0.6429\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0749 - acc: 0.9920 - val_loss: 0.6868 - val_acc: 0.6429\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0733 - acc: 0.9920 - val_loss: 0.7045 - val_acc: 0.6429\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0728 - acc: 0.9920 - val_loss: 0.7104 - val_acc: 0.6429\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0719 - acc: 0.9920 - val_loss: 0.7070 - val_acc: 0.6786\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0720 - acc: 0.9920 - val_loss: 0.7294 - val_acc: 0.6429\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0713 - acc: 0.9920 - val_loss: 0.7072 - val_acc: 0.6786\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0712 - acc: 0.9920 - val_loss: 0.7125 - val_acc: 0.6786\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0697 - acc: 0.9960 - val_loss: 0.7324 - val_acc: 0.6429\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0693 - acc: 0.9960 - val_loss: 0.7368 - val_acc: 0.6429\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0686 - acc: 0.9960 - val_loss: 0.7465 - val_acc: 0.6429\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0684 - acc: 0.9960 - val_loss: 0.7226 - val_acc: 0.6429\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0681 - acc: 0.9960 - val_loss: 0.7286 - val_acc: 0.6786\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0668 - acc: 0.9960 - val_loss: 0.7147 - val_acc: 0.6429\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0669 - acc: 0.9920 - val_loss: 0.7390 - val_acc: 0.6429\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0665 - acc: 0.9960 - val_loss: 0.7472 - val_acc: 0.6429\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0651 - acc: 0.9960 - val_loss: 0.7327 - val_acc: 0.6429\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0651 - acc: 0.9960 - val_loss: 0.7528 - val_acc: 0.6429\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0638 - acc: 0.9960 - val_loss: 0.7548 - val_acc: 0.6429\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0645 - acc: 0.9960 - val_loss: 0.7587 - val_acc: 0.6429\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0635 - acc: 0.9960 - val_loss: 0.7643 - val_acc: 0.6429\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0625 - acc: 0.9960 - val_loss: 0.7754 - val_acc: 0.6429\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0622 - acc: 0.9960 - val_loss: 0.7493 - val_acc: 0.6429\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0615 - acc: 0.9960 - val_loss: 0.7550 - val_acc: 0.6071\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0612 - acc: 0.9960 - val_loss: 0.7570 - val_acc: 0.6429\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0603 - acc: 0.9960 - val_loss: 0.7734 - val_acc: 0.6071\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0609 - acc: 0.9960 - val_loss: 0.7545 - val_acc: 0.6071\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0599 - acc: 0.9960 - val_loss: 0.7632 - val_acc: 0.6429\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0602 - acc: 0.9960 - val_loss: 0.7692 - val_acc: 0.6429\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0602 - acc: 0.9960 - val_loss: 0.7600 - val_acc: 0.6071\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0579 - acc: 0.9960 - val_loss: 0.7659 - val_acc: 0.6429\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0573 - acc: 0.9960 - val_loss: 0.7816 - val_acc: 0.6429\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0575 - acc: 0.9960 - val_loss: 0.7885 - val_acc: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0561 - acc: 0.9960 - val_loss: 0.7624 - val_acc: 0.6429\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0558 - acc: 0.9960 - val_loss: 0.7641 - val_acc: 0.6429\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0561 - acc: 0.9960 - val_loss: 0.8003 - val_acc: 0.6071\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0562 - acc: 0.9960 - val_loss: 0.8056 - val_acc: 0.6071\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0545 - acc: 0.9960 - val_loss: 0.7764 - val_acc: 0.6071\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0540 - acc: 0.9960 - val_loss: 0.7739 - val_acc: 0.6429\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0539 - acc: 0.9960 - val_loss: 0.7903 - val_acc: 0.5714\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0536 - acc: 0.9960 - val_loss: 0.7933 - val_acc: 0.5714\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0525 - acc: 0.9960 - val_loss: 0.7860 - val_acc: 0.6071\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0520 - acc: 0.9960 - val_loss: 0.7846 - val_acc: 0.6071\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0514 - acc: 0.9960 - val_loss: 0.8101 - val_acc: 0.6071\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0515 - acc: 0.9960 - val_loss: 0.7955 - val_acc: 0.5714\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0503 - acc: 0.9960 - val_loss: 0.7856 - val_acc: 0.6071\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0501 - acc: 0.9960 - val_loss: 0.7715 - val_acc: 0.6429\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0500 - acc: 0.9960 - val_loss: 0.7812 - val_acc: 0.6429\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0493 - acc: 0.9960 - val_loss: 0.7997 - val_acc: 0.5714\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0489 - acc: 0.9960 - val_loss: 0.7651 - val_acc: 0.6429\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0486 - acc: 0.9960 - val_loss: 0.7593 - val_acc: 0.6429\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0474 - acc: 0.9960 - val_loss: 0.7716 - val_acc: 0.5714\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0471 - acc: 0.9960 - val_loss: 0.7813 - val_acc: 0.5714\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.0464 - acc: 0.9960 - val_loss: 0.7879 - val_acc: 0.5714\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0468 - acc: 0.9960 - val_loss: 0.7823 - val_acc: 0.5714\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0459 - acc: 0.9960 - val_loss: 0.7904 - val_acc: 0.5714\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0461 - acc: 0.9960 - val_loss: 0.7712 - val_acc: 0.5714\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0449 - acc: 1.0000 - val_loss: 0.7980 - val_acc: 0.5714\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.7888 - val_acc: 0.5714\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0443 - acc: 0.9960 - val_loss: 0.7875 - val_acc: 0.5714\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.7999 - val_acc: 0.5714\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0435 - acc: 0.9960 - val_loss: 0.7973 - val_acc: 0.5714\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0440 - acc: 0.9960 - val_loss: 0.7902 - val_acc: 0.5714\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0425 - acc: 0.9960 - val_loss: 0.8269 - val_acc: 0.5714\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0425 - acc: 1.0000 - val_loss: 0.8107 - val_acc: 0.5714\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0426 - acc: 0.9960 - val_loss: 0.8047 - val_acc: 0.5714\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.8316 - val_acc: 0.5714\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.8043 - val_acc: 0.5714\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.8234 - val_acc: 0.5714\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.8207 - val_acc: 0.5714\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.8089 - val_acc: 0.5714\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0406 - acc: 1.0000 - val_loss: 0.8313 - val_acc: 0.5714\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.5714\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.7974 - val_acc: 0.5714\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.5714\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.8270 - val_acc: 0.5714\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.8312 - val_acc: 0.5714\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.8504 - val_acc: 0.5714\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0389 - acc: 0.9960 - val_loss: 0.8372 - val_acc: 0.5714\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.8293 - val_acc: 0.5714\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.8133 - val_acc: 0.5714\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.8297 - val_acc: 0.5714\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0366 - acc: 1.0000 - val_loss: 0.8339 - val_acc: 0.5714\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.8193 - val_acc: 0.5714\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.8224 - val_acc: 0.5714\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.8400 - val_acc: 0.5714\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.8191 - val_acc: 0.5714\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.8379 - val_acc: 0.5714\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.8431 - val_acc: 0.5714\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.8446 - val_acc: 0.5714\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.8490 - val_acc: 0.5714\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.5714\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.8498 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.8583 - val_acc: 0.5714\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.8656 - val_acc: 0.5714\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.8631 - val_acc: 0.5714\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.8406 - val_acc: 0.5714\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.8123 - val_acc: 0.5714\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.8583 - val_acc: 0.5714\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.5714\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.8395 - val_acc: 0.5714\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.5714\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.8478 - val_acc: 0.5714\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.8516 - val_acc: 0.5714\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.8396 - val_acc: 0.5714\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.8611 - val_acc: 0.5714\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.8802 - val_acc: 0.5714\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 0.5714\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.8392 - val_acc: 0.5714\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.5714\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.8827 - val_acc: 0.5714\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.8834 - val_acc: 0.5714\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.8481 - val_acc: 0.5714\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.8605 - val_acc: 0.5714\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.8846 - val_acc: 0.5714\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.8844 - val_acc: 0.5714\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.5714\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.5714\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.5714\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.8799 - val_acc: 0.5714\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.8863 - val_acc: 0.5714\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.5714\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.8887 - val_acc: 0.5714\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.8796 - val_acc: 0.5714\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8691 - val_acc: 0.5714\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8970 - val_acc: 0.5714\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8946 - val_acc: 0.5714\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.8800 - val_acc: 0.5714\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.8691 - val_acc: 0.5714\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.5714\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.5714\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.8911 - val_acc: 0.5714\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.8951 - val_acc: 0.5714\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.9011 - val_acc: 0.5714\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.8924 - val_acc: 0.5714\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.9040 - val_acc: 0.5714\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.9149 - val_acc: 0.5714\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.9234 - val_acc: 0.5714\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.8982 - val_acc: 0.5714\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.8824 - val_acc: 0.5714\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.8889 - val_acc: 0.5714\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.9167 - val_acc: 0.5714\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.9199 - val_acc: 0.5714\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.8993 - val_acc: 0.5714\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.8843 - val_acc: 0.5714\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.8888 - val_acc: 0.5714\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.9192 - val_acc: 0.5714\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.9246 - val_acc: 0.5714\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.8886 - val_acc: 0.5714\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.8864 - val_acc: 0.5714\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.9091 - val_acc: 0.5714\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.5714\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.9165 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.9209 - val_acc: 0.5714\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.9183 - val_acc: 0.5714\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.9163 - val_acc: 0.5714\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.9117 - val_acc: 0.5714\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.9166 - val_acc: 0.5714\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.9375 - val_acc: 0.5714\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.9271 - val_acc: 0.5714\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.9420 - val_acc: 0.5714\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.9333 - val_acc: 0.5714\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.9314 - val_acc: 0.5714\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.9243 - val_acc: 0.5714\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.9302 - val_acc: 0.5714\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.9279 - val_acc: 0.5714\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.9565 - val_acc: 0.5714\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.9228 - val_acc: 0.5714\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.9157 - val_acc: 0.5714\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.9221 - val_acc: 0.5714\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.9243 - val_acc: 0.5714\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.9328 - val_acc: 0.5714\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.5714\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.9472 - val_acc: 0.5714\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.9305 - val_acc: 0.5714\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.9109 - val_acc: 0.5714\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.9243 - val_acc: 0.5714\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.9366 - val_acc: 0.5714\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.9148 - val_acc: 0.5714\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.9240 - val_acc: 0.5714\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.5714\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5714\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.9179 - val_acc: 0.5714\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5714\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.5714\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.9469 - val_acc: 0.5714\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.9368 - val_acc: 0.5714\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9466 - val_acc: 0.5714\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.9566 - val_acc: 0.5714\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9590 - val_acc: 0.5714\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.9648 - val_acc: 0.5714\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.5714\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.5714\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.5714\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.9840 - val_acc: 0.5714\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.9651 - val_acc: 0.5714\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.9675 - val_acc: 0.5714\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.5714\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.5714\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.9715 - val_acc: 0.5714\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.9747 - val_acc: 0.5714\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9998 - val_acc: 0.5714\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9694 - val_acc: 0.5714\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.9739 - val_acc: 0.5714\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.9815 - val_acc: 0.5714\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.9731 - val_acc: 0.5714\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.9981 - val_acc: 0.5714\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.0004 - val_acc: 0.5714\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9887 - val_acc: 0.5714\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.9802 - val_acc: 0.5714\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9610 - val_acc: 0.5714\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.5714\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.5714\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.9829 - val_acc: 0.5714\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.9937 - val_acc: 0.5714\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 1.0061 - val_acc: 0.5714\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.5714\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.9694 - val_acc: 0.5714\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.9849 - val_acc: 0.5714\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.5714\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.0045 - val_acc: 0.5714\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.0040 - val_acc: 0.5714\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.5714\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.5714\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.5714\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.0080 - val_acc: 0.5714\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.9983 - val_acc: 0.5714\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.5714\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.5714\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.5714\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.9980 - val_acc: 0.5714\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.0015 - val_acc: 0.5714\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.5714\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.5714\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.5714\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.5714\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.9744 - val_acc: 0.5714\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.5714\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.9677 - val_acc: 0.5714\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.9977 - val_acc: 0.5714\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.5714\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.5714\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.0152 - val_acc: 0.5714\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.0049 - val_acc: 0.5714\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.5714\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.0062 - val_acc: 0.5714\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.9878 - val_acc: 0.5714\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.5714\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.0015 - val_acc: 0.5714\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.0064 - val_acc: 0.5714\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.9929 - val_acc: 0.5714\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0348 - val_acc: 0.5714\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0509 - val_acc: 0.5714\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 1.0176 - val_acc: 0.5714\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.0420 - val_acc: 0.5714\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 1.0420 - val_acc: 0.5714\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 1.0370 - val_acc: 0.5714\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0386 - val_acc: 0.5714\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0344 - val_acc: 0.5714\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.0491 - val_acc: 0.5714\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.0553 - val_acc: 0.5714\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.0362 - val_acc: 0.5714\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0308 - val_acc: 0.5714\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0521 - val_acc: 0.5714\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0439 - val_acc: 0.5714\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0558 - val_acc: 0.5714\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.0595 - val_acc: 0.5714\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0473 - val_acc: 0.5714\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.0606 - val_acc: 0.5714\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 1.0572 - val_acc: 0.5714\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0218 - val_acc: 0.5714\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0723 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 1.0689 - val_acc: 0.5714\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.5714\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0414 - val_acc: 0.5714\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.0376 - val_acc: 0.5714\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0426 - val_acc: 0.5714\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.5714\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.0487 - val_acc: 0.5714\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.5714\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0802 - val_acc: 0.5714\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0617 - val_acc: 0.5714\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.0747 - val_acc: 0.5714\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.0881 - val_acc: 0.5714\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0721 - val_acc: 0.5714\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0668 - val_acc: 0.5714\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.0792 - val_acc: 0.5714\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0537 - val_acc: 0.5714\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.0484 - val_acc: 0.5714\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 1.0760 - val_acc: 0.5714\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0899 - val_acc: 0.5714\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0605 - val_acc: 0.5714\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.0585 - val_acc: 0.5714\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.5714\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.0854 - val_acc: 0.5714\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.0618 - val_acc: 0.5714\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.0828 - val_acc: 0.5714\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.0989 - val_acc: 0.5714\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.0736 - val_acc: 0.5714\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.1046 - val_acc: 0.5714\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.0998 - val_acc: 0.5714\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.0967 - val_acc: 0.5714\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.1116 - val_acc: 0.5714\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 1.0724 - val_acc: 0.5714\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.0959 - val_acc: 0.5714\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.1176 - val_acc: 0.5714\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 1.0817 - val_acc: 0.5714\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.1246 - val_acc: 0.5714\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.1219 - val_acc: 0.5714\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.1142 - val_acc: 0.5714\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.0978 - val_acc: 0.5714\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.5714\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.1046 - val_acc: 0.5714\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.1255 - val_acc: 0.5714\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.1290 - val_acc: 0.5714\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.1303 - val_acc: 0.5714\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.1130 - val_acc: 0.5714\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.0427 - val_acc: 0.6071\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.6071\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 1.0626 - val_acc: 0.6071\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0664 - val_acc: 0.6071\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.6071\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.0714 - val_acc: 0.6071\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.6071\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.6071\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.0145 - val_acc: 0.6071\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.0031 - val_acc: 0.6071\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.0156 - val_acc: 0.6071\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0344 - val_acc: 0.6071\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 1.0392 - val_acc: 0.6071\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.0409 - val_acc: 0.6071\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.0188 - val_acc: 0.6071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0332 - val_acc: 0.6071\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.6071\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0558 - val_acc: 0.6071\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.1008 - val_acc: 0.6071\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0648 - val_acc: 0.6071\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.6071\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.0530 - val_acc: 0.6071\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.0162 - val_acc: 0.6071\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.6071\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.0361 - val_acc: 0.6071\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd81PX9wPHXO5e9yWIkQJAlU2QJ4kIFERXcE2utrfZX62jVVlu109YOK1onjta6raOioiKImw0qU/YIgSQkZO/c5/fH53u5ywBCyOWSy/v5eNzjuz7fu89Xw73vs8UYg1JKKQUQEugMKKWU6jg0KCillKqnQUEppVQ9DQpKKaXqaVBQSilVT4OCUkqpehoUlGohEfm3iPyxhWl3iMiZR/s+SrU3DQpKKaXqaVBQSilVT4OCCipOtc0dIvKtiJSJyDMi0l1E3heREhFZICLdfNLPEJF1IlIoIp+IyBCfa8eLyCrnvleByEafda6IfO3c+5WIjGxlnn8kIltEpEBE5opIL+e8iMiDIpIrIkXOMw13rk0XkfVO3vaIyO2t+g+mVCMaFFQwugiYAgwCzgPeB34FpGD/5m8GEJFBwMvArUAqMA94R0TCRSQc+B/wPJAE/Nd5X5x7RwPPAjcAycCTwFwRiTiSjIrI6cCfgUuBnsBO4BXn8lTgFOc5EoHLgHzn2jPADcaYOGA48PGRfK5SB6NBQQWjfxpjcowxe4DPgaXGmNXGmCrgLeB4J91lwHvGmI+MMTXA34Eo4ERgAhAGzDbG1BhjXgeW+3zGj4AnjTFLjTF1xpjngCrnviNxFfCsMWaVk7+7gIkikgnUAHHAsYAYYzYYY/Y699UAQ0Uk3hhzwBiz6gg/V6lmaVBQwSjHZ7+imeNYZ78X9pc5AMYYN7AbSHeu7TENZ4zc6bPfF7jNqToqFJFCoLdz35FonIdSbGkg3RjzMfAI8CiQIyJzRCTeSXoRMB3YKSKfisjEI/xcpZqlQUF1ZdnYL3fA1uFjv9j3AHuBdOecRx+f/d3AfcaYRJ9XtDHm5aPMQwy2OmoPgDHmYWPMGGAYthrpDuf8cmPMTCANW8312hF+rlLN0qCgurLXgHNE5AwRCQNuw1YBfQUsBmqBm0UkVEQuBMb73PsU8GMROcFpEI4RkXNEJO4I8/AScK2IjHLaI/6Ere7aISLjnPcPA8qASqDOafO4SkQSnGqvYqDuKP47KFVPg4Lqsowx3wGzgH8C+7GN0ucZY6qNMdXAhcD3gQPY9oc3fe5dgW1XeMS5vsVJe6R5WAjcA7yBLZ30By53Lsdjg88BbBVTPrbdA+BqYIeIFAM/dp5DqaMmusiOUkopDy0pKKWUqqdBQSmlVD0NCkoppeppUFBKKVUvNNAZOFIpKSkmMzMz0NlQSqlOZeXKlfuNMamHS9fpgkJmZiYrVqwIdDaUUqpTEZGdh0+l1UdKKaV8aFBQSilVT4OCUkqpep2uTaE5NTU1ZGVlUVlZGeis+FVkZCQZGRmEhYUFOitKqSAVFEEhKyuLuLg4MjMzaTipZfAwxpCfn09WVhb9+vULdHaUUkEqKKqPKisrSU5ODtqAACAiJCcnB31pSCkVWEERFICgDggeXeEZlVKBFTRBQSmlOrydi2H93EDn4pA0KLSBwsJCHnvssSO+b/r06RQWFvohR0qpDmH9XMhZZ/c3vAP/mgavXQ2VRYHN1yFoUGgDBwsKdXWHXgxr3rx5JCYm+itbSqlAKthuA8DjJ0LJPvjaZ6XWnPWBy9dhaFBoA3feeSdbt25l1KhRjBs3jsmTJ3PllVcyYsQIAM4//3zGjBnDsGHDmDNnTv19mZmZ7N+/nx07djBkyBB+9KMfMWzYMKZOnUpFRUWgHkcpdTSqSuDATnh4lPfcqv9A/hbo6ZzLWRuYvLVAUHRJ9fW7d9axPru4Td9zaK94fnPesINev//++1m7di1ff/01n3zyCeeccw5r166t7zr67LPPkpSUREVFBePGjeOiiy4iOTm5wXts3ryZl19+maeeeopLL72UN954g1mzdIVFpTqdB46F6tKG5zZ/BAe2wwk/hv2bbSmig9KSgh+MHz++wViChx9+mOOOO44JEyawe/duNm/e3OSefv36MWqU/RUxZswYduzY0V7ZVUq1hR1fwF/7Nw0I8emQtRzqqiF5AETENk3TnNoq2Nf+JYqgKykc6hd9e4mJianf/+STT1iwYAGLFy8mOjqa0047rdmxBhEREfX7LpdLq4+U6kyWPQXzbm/+Wv/JsPoFu588AMJjoLrs8O/5wZ2w4ln4+QaI79V2eT0MLSm0gbi4OEpKSpq9VlRURLdu3YiOjmbjxo0sWbKknXOnlGoTdbXe/doqWyXkcbCAAND/dO9+8gAIi4Ga8sN/3i7nu6I098jyeZQ0KLSB5ORkJk2axPDhw7njjjsaXJs2bRq1tbWMHDmSe+65hwkTJgQol0qpVtu1FP6QDFnOWi7v3QYvXmyrdz79a8O0585ueNx7AoRGQXgsxKY5JYUWVB+5nDnOyvYfff6PQNBVHwXKSy+91Oz5iIgI3n///WavedoNUlJSWLvWW3d4++2H+NWhlGpfXz7k7U761T9hxCWweb49/vZV+OrhhuljUpoe9zoe6qpABMKjobIFnWFc4XZbmnN0+T9CGhSUUsojdyPEpEKM0zvQGPjoXu/19f+zr/r0G5q+R7Rz77gfQubJEBoB5z8GbmfcUngMFO+1+7XV4K61gaIxDQpKKRVgj51gt7/eB2FRUHHg0Omzlnn3Q6Ngyu+gWz/7hT7kPDjmNHstyWdm47AYqCmzA9qeOgOKs+C3zYxwrq2yWw0KSinVjtxuqK1oWKWz9xvoMwFK9nrPjf6eHYTmy3e6il9ut4EE4BfbICKu+c8Lj4bCXfDA4EPnyxOQ2jkoaEOzUqrryf7aBoG6Gjsf0Z96wT+O9V7P32q3xT5B4dQ74doPmn+/hD7egAAHDwhgq49aoj4otG/vIy0pKKWCW8k++O59GHutPc7bBHNOtfX9Wcuhtpk1Sgq2wt5v4YNf2uNbvoWEdDvwzOPK/8LOL2DM9yHpmJbnJ6wFQcEYbylk55fw7s/h3H+0/DOOggYFpVRwe/ES2PctDDrLDgJb8Yw9v+Pzg9+zby1s/djOVxSfDnE97fnIBEjoDUW7IXMSDJp65Plx1zRzzg0hPhU3tVVgfCbUXPEMnPQzSOx95J93hLT6qA20dupsgNmzZ1Ne3oKBLEqp1tn3rd3+Ywj8cwwsfaLh9V6jYdr93uMeI2Dzh5C9GoZfDDd8BqHh3us/WQzXLWh5NVBjnl5FPX0mzPOUVrYshBcuhryN9jjcp2Qye7i38dmPNCi0AQ0KSnUS+VsaHkcnw7Xvw4T/854787cQkwYRCXDOA03HHUTEQe9xrc/DiTfbtomBPqWM2koozoYXLoQtH8H/nPy4axveu/7t1n9uC2n1URvwnTp7ypQppKWl8dprr1FVVcUFF1zA7373O8rKyrj00kvJysqirq6Oe+65h5ycHLKzs5k8eTIpKSksWrQo0I+iVHCpaTSH2IVPwcp/w9gfwBvXQWIfCIu011wRdoBZQh+4aaX9oo7yw3on4dHQdyLsXtown1sXeo9znfUWJv+q4TiJ1MP0WGoDwRcU3r8T9q1p2/fsMQLOvv+gl32nzp4/fz6vv/46y5YtwxjDjBkz+Oyzz8jLy6NXr1689957gJ0TKSEhgX/84x8sWrSIlJSUg76/UqqVygsaHo+81L4AYrtDQob3WqgTFCLj7Yt4/+bNt/qpttIOnAuNbNjwnTYMZj4Kb98Iwy6Ensf5N09o9VGbmz9/PvPnz+f4449n9OjRbNy4kc2bNzNixAgWLFjAL3/5Sz7//HMSEhICnVWlgs/+zQ1nIK0oOHjafic3HFR2+t12G9XNP3lrLDTSu1+aCzlrmpYEwmO8VUi+6f2ZLX+9sYg8C5wL5BpjhjdzXYCHgOlAOfB9Y8yqo/7gQ/yibw/GGO666y5uuOGGJtdWrlzJvHnzuOuuu5g6dSr33ntvM++glGoVtxseGWv3f/gxZIzxlhT6nQLjm/6bbOCEG+yrvYh49/81zW6Pu9JOqPfUZHscHmO7zoIdPNcO/FlS+Dcw7RDXzwYGOq/rgcf9mBe/8p06+6yzzuLZZ5+ltNTOgrhnzx5yc3PJzs4mOjqaWbNmcfvtt7Nq1aom9yqlgM/+BruX2b76a9+w1cGbF8ADQ6As/+D3+ZYKnj7dNty+eLE9nvYXGHKuf/N9xKTpqb4nQvpo73F4DCT3t9Ng9J3YLrnyW1AwxnwGHKLsxkzgP8ZaAiSKSE9/5ceffKfO/uijj7jyyiuZOHEiI0aM4OKLL6akpIQ1a9Ywfvx4Ro0axX333cfdd9ui6vXXX8/ZZ5/N5MmTA/wUSrWD6nL49G+2a2VVCXz4a9jxpfd6cTZ8/Ed4+Qq7nsDrP4CnToddi6EkGzbMhQM7YM5p8NsE22gMtsqo8eR0z19oVzsDiE5qh4c7QtJMUMg8qeGxb5fUdhLIhuZ0YLfPcZZzbm/jhCJyPbY0QZ8+fdolc0eq8dTZt9xyS4Pj/v37c9ZZZzW576abbuKmm27ya96UCoiC7fDJn2Hijd4G0sWPwKL7bK+eyiJ7nL0aTvq5nSSuyllnIK6nHS0M9ovd029/3Vt2FHL2anv8zi12LMEzU7w9di57AV6dBXk+QSKqAwaFpP4Nj895oGEbB7R+LMRRCGRDczNhEtNcQmPMHGPMWGPM2NTUVD9nSynVJt65xa438OosW98P3gVjaipsozDAnlXw4kXw2ve83TK79W24stkOJ0Ds+NxOVufrb/29AQEgdYh3P9LpUuo7+Kyj6HMCXPq893hg0x+NhDUzpbafBbKkkAX4jtnOALIDlBelVFvLWWerPwp3wXs/h+2f2cVmwFYBbZhr92t9xhKsfcNut38OVUUwdKYdsFVZCKnH2hJDTqPF7BvPXRSbBsdfbWc4vfI1vzxam/H89wCI6+Hdv+p1+9wh7f+7PZAlhbnA98SaABQZY5pUHbWUMc0WMoJKV3hGFSSqy6F8vx0kBrDyX3aSubWv2+MVz9h1igdPt6OHPUKj7DQQVc5kcCf93HttxCXe/bE/gN8UeksCvvdHxMHMR2DWGxDisq+OylMScEV4l98EGDjFPkMA+C0oiMjLwGJgsIhkich1IvJjEfmxk2QesA3YAjwF/KS1nxUZGUl+fn5Qf2kaY8jPzycysn36Kit1VIqy7LbHCO9kcs2REEhzqntOvwd+uQMGOZ0WE3o3HKw1cKo3gMSk2Ybacdd5r4+5Fm7b0HwDbkcVkwznPQS3fhvonNTzW/WRMeaKw1w3wI1t8VkZGRlkZWWRl5fXFm/XYUVGRpKRkXH4hEoFWtEuu03IsK+SvXYVMmNg/yZ7PPnXcNzlMP8emzY2zU454VmLoOdx9gv+9HtgyWOQNtTOElqWa2crBfse5fm2F1JsWvsNPGtLY74f6Bw0EBTTXISFhdGvX7/DJ1RK+Z8xTn14KCQPhBGX2uqkcx+06w5UFtn1ij3dRD0lCeM0RnuqVDxrFJxyu30BnHwbvHIldMu0xyEuOOdBG0COu7JdHi/YBUVQUEr50f9+Ynv3XP/JodNVFNqVzDa9b5etPOH/IDYVTrjevjwiG03xcuovbGPzcGegmWcSu8Rmup8few7curbhnEUhId62C3XUNCgopQ7t6xcbHu/fYhtFu/VteP6Fi2DPCvurPXkgnHVfy94/OsnWq3t4RibHpjWfvh0WmunKdEI8pVRTm+ZDSaMF493OSmCPjIGHRnrPF+2xaxnvWWGP934Dwy9qfa8fz32x3Vt3vzoqWlJQSnm56+C922wX0m6ZcNNq77XyfNtO4JG/1TYav3x50/cZcl7r8zD9AUgfC71PaP17qFbToKCU8spZZwMC2AFmn/3Ne600Bxb8znv8z9E0cdLPbUmh+7DW5yGuO5x0a+vvV0dFg4JSwa6qBBCI8Jlcze226xAPOLPhoKmCbT43CnzyJ+/hloV2qciIeKgqbvo5rgjbfTQAo3BV29H/e0oFu7/0gydOsoFg8WN2NtFP/mSrfda/DY9Pgt8nw5cP2eogsP3/L3ra7vc71W4X/MZ2F71ufvOf062vBoQgoCUFpYLZ/i3groED22H50/DhXXZZx93L7PWdX3rnEvKsBRzXy3YTBVuSiEyA3znTSVz2vB2BHJMKZY0Gi3bTsULBQIOCUsHsu/e8+1lOICjLs2sRgy0pAEy+2y77+On9MMpnMgLPwvU/mA+7l9ggAbbNIGe9HaWcvwWyVx1dO4LqMDQoKBWsCrbB+rneY0/pYP8m7zKV5fn2V/+pd9jqpf6nQ8bYpu/V5wT78pj6RzsyOfMkO0V29ipIGeS/Z1HtRoOCUp1NeYH9hT/m+97J38oL4JuXYfQ1tkG5KAsedqZl7jkK9n4NhTvtcWmj8Qee6SRCQhp+8R9KjxHe/VPuAASGXdDaJ1IdiLYKKdXZvHk9vHurd/nJulobED78lf3Vbowda+AxwWcC4tRjm76fJyi0VkIGnDfbTmanOj0NCkp1Bm63HTVcXmC7hYJdbvK1a+APybD0CXsuaxns/Ao2fQCjZsHo78HwC73vM3Smd98zt5Bncjml0OojpTq2Vf+BHiPhy9l2feJ0n/r+D34FpfvsfuEu73bJYxAeB9P/BuHOjKOe3kJjfwDfvmYXsrnsBVj4Oxgyo32fSXVo0tkWphk7dqxZsWJFoLOhlP/V1cAfUux+SKjtHQR2dTGwM4v2ngDHnAqf/sWOIagpt2l7jYYf+qxxnLsRSrJtQ3JViR1o1hHXLVZ+IyIrjTHN9CJoSKuPlAo0Y+yrsYLt3n1PQADbGJzq9PTpeZx3nqFjz7VrIrtrG04tDZB2rA0IYBex0YCgDkKDglKBtug+eHAY5H3X8LxndHFjiX3tUpUAyf2h+3C7wMywC2wXUWgaFJRqIQ0KSgVSZbGddK54jw0Ob/zIu8hM/uaGacX555rUzy7sDpAy0HZLveBxOHa6HUwGGhRUq2lDs1L+tGuJ7QbqGRnsq67WNh57eEYXDzrLfqkv+G3D9J7lKjPGQ98TbbtBz5EN0wycau/rOaqtnkB1MVpSUMpfqkrg2bOaX2+gbD88PAreudnOGTRgivfavjX2Pmg4riAi3m4zxtrSQeOAALY66a49LR+EplQjWlJQyl/ynDaBXYu953I32OkmPvsbFO225wafbUsBnvEHX872pq8p9+7/cAEc2AmhEYf+XJf+s1atp389SrUFY7xTTnjkbfTuF++FzfNtycBj5mOw7k2Y+FNv1VFjp98LH9wJPYZD6mD7UsqPNCgodTTK8u1C84+MhZmP2uqe5y+Eqb+HnT4lhH80M73E8VfZF0BCetPr9xbY9YpHXuKfvCvVDA0KSh2Nv/nMG/T2jTBoGlQVwYe/hupSO+/QlgUH717qEd9Mb6HWLnyv1FHQoKBUW9r0gd1Wl9rt0PMhd33ToNB4vqH4Xt79az+A6jK/ZVGpQ/FrUBCRacBDgAt42hhzf6PrfYDngEQnzZ3GmHn+zJNSh1W4y44Mjk46+vdKGQhxPe3+qXfahWhK9sGAMxqmi03z7vedePSfq1Qr+S0oiIgLeBSYAmQBy0VkrjFmvU+yu4HXjDGPi8hQYB6Q6a88KdWsHV8AApmT7PHsERCdDL/Ydsjb6geZHYwr3AaWqffZksHJtx+8Z1CIC068CfqedKS5V6pN+XOcwnhgizFmmzGmGngFmNkojQGcztckANl+zI9STZXth3+fA/+ebo/rnDmGyvPtdu0bUHGg4T2lufa+z/7e9P1u+NyuSgYQ7zQexyTDaXcevqvo1D/C4Gmtew6l2og/q4/Sgd0+x1lA4xE1vwXmi8hNQAxwZnNvJCLXA9cD9OnTp80zqrqwHV9498sL7FoEHlsWwOs/gOEXwcXP2nNl+fD3gQ3f47IX7PQSdTW2ZFCaa8+PvNSfOVfKL/wZFKSZc42ngrwC+Lcx5gERmQg8LyLDjfGM53duMmYOMAfs1Nl+ya3qeta9BVk+07D/fRC4a7zHS5+029JcqK2C1c/bNQwai0m1M496DDgDrnjFTjmhVCfjz6CQBfT2Oc6gafXQdcA0AGPMYhGJBFKAXD/mSym7vsB/v9/wnG9AADvYDOyv/0//Cp83qi464f/sttfohudF7ChlpTohfwaF5cBAEekH7AEuB65slGYXcAbwbxEZAkQCeX7Mk+qKivbY3j2uMO+5b15uPu20+217QmkurHrOnqsqhdUvNEz3s3W2V5GOJVBBxm9BwRhTKyI/BT7Edjd91hizTkR+D6wwxswFbgOeEpGfYauWvm8621JwqmMr2QcPDrU9f2orbS+gkZfBnpXeNOFxUF1i90/4sf2lv+wp7/WtC+125mPw9k/svk5NrYKUX8cpOGMO5jU6d6/P/npgkj/zoLq4rYvsdvunkLXc7s+7vWGaXqPg9LvtgDPP/EXHnmvXOg6LgZw19tzAKTD6Gtj7TfvkXakA0BHNKngZA9+8ZPfLmqmVzBhnA0V8L+gzoeG1+J5w82r4/AEbFFwRtgpqxsP+z7dSAaTrKajgZIwdR7D9M3t8YEfD65knw+UvwZQ/2HaEgxlzLYSEwuRmeh0pFYS0pKCCR1WJnZ7CGFj5LCz6Iww6GyqLYNdXNhAUZ8NV/7WL0QBMuvnQ7xmdBL/a27CRWqkgpkFBBYd9a+CJk+DS52H3Ulj8iD0/81HIXgUrEuGSfx9+gZrmhIa3aVaV6sg0KKjgsOZ1u93xBSx70ns+Jtk2EA+c0vx9SqkGNCiozq2mwlYPecYUVBYFNj9KdXIaFFTndl+PhsffvmK3qUPg5NvaPz9KdXLa+0h1Lm43bF5gG5MbzF4qkOgzWeK5D+oylkq1ggYF1bkseRRevAg2vgcF273nu/WFK171Oc5s96wpFQy6VlDwzJWvOq91b9ltcTY8Ndl7PnkgdB9qp7juPQFiuwcmf0p1cl0nKHz1T1v/XFsd6JyoI/XVI3ZG0+K9sGeVPfdpowFnJ9xgt8Mvgus+hJCu86etVFvqOg3NUUl2auTiLEg6JtC5US1VnA3zf233K4uoX5KjPB8S+8KVr0FYlK0+Ukodta7zc8rTCFm4K7D5UC2zaykU7rYvj60f2ykneo6yxxnjIO1YDQhKtSENCqrjcbvhxUvsojalOfacyxmJnNgHUgd795VSbarrBIX4dBCXBoXOoGg3VBVBSQ6UOYvwZZ5kt90yYep9MPAsXQNZKT/oOkHBFWoDgwaFji93g92W5UFpHiDe9Y5Tj4XYVLjqNUgbErAsKhWsukxD85bcEhJcaaQU7kICnRl1cB/cZRe3ASjfb6uPopNs76LMk3T8gVJ+1mWCwsINuaTkRXFB7TYNCh1NdbmdniLvO1j6hPd8WT4UbLNrIYtAj+GBy6NSXUSXCQrdosPJMqlIyZd2rIJOh9xxLH4EFt3X9Hx1iV1G85RftH+elOqiukybQmJ0GFkmBTFuO1ZBdRx53x36+rgftk8+lFJdJyh0i7ElBUAbmwPpo3th7RveY3cd7FpiZzU9fpY9N/YHcN1HMPIyuHMXxOmUFUq1ly5VfbTbpNkDDQrt48+9of9kuPQ/9tgY+PIhu595Cnz8B0gZaEtuF/8Lhl8I5872Ln3Ze3xg8q1UF9aFgkIYe00SbnERcmBnoLPTNVQVw/q3YfFjMPEnUF7gvfb2jbD5Q7uf2AeGzLD7uhayUgHVZaqPEqLCqMNFSXh3KNSg4He+Ew9+eBdUFMLffOac2vKRd3/iTXYciVIq4LpMUAh1hRAfGUpueG/v4CjV9oyBJU/A/kaNx58/0CidG4670k5zPeaa9sufUuqQutTPs24x4WwNH8TA3Jds3/jw6EBnKfjkfQcf/BJiGy2TueJfTdOefjckpLdPvpRSLeLXkoKITBOR70Rki4jceZA0l4rIehFZJyIv+TM/idHhrJcBYOoge5U/P6rryN9qexB5VBbZbek+u53wE7utLrFrHYy9zps2rlHgUEoFnN+Cgoi4gEeBs4GhwBUiMrRRmoHAXcAkY8ww4FZ/5QdsY/OSuqEQGgnr5/rzo7qGsv3wz9G20bh4r93mrmuYZtSV3v3eE2D89d7jEFf75FMp1WL+LCmMB7YYY7YZY6qBV4CZjdL8CHjUGHMAwBiT68f80C06nOzKUDu52rq3dHnOlqiphKVzbGmgshhy1nuv5TgB4JuX4b/XwOoX4N2fNbw/Otm7P3SGd9prpVSH1KKgICK3iEi8WM+IyCoRmXqY29IBnxVSyHLO+RoEDBKRL0VkiYhMO8jnXy8iK0RkRV5eXkuy3KzE6DAKy2tsNUZZLuz8otXv1WV8/gC8fweseR3euRken2jnJALvSORumbB7adN7+59u5y2a9Qac+6CtLhKBa96xg9OUUh1OS0sKPzDGFANTgVTgWuD+Q9/S7LxzptFxKDAQOA24AnhaRBKb3GTMHGPMWGPM2NTU1BZmualu0eGUVtVSfcwUCI+1X3Tq0Er22m1NmbfX1lcP2Smt8zZCZAJc9Gzz9172gg0CA860o5Q9+p2iA9OU6qBaGhQ8X/DTgX8ZY76h+S99X1lAb5/jDCC7mTRvG2NqjDHbge+wQcIvukXbgVGFtS449lw7sMp3QJVq+t/D7VSxhYRCjBOQv3wI/j4ADuywA896jvSmH3iWbVy++n8QHtMuWVZKtZ2WBoWVIjIfGxQ+FJE4wH2Ye5YDA0Wkn4iEA5cDjVt3/wdMBhCRFGx10raWZv5IJcXYJR0Lyqph0s1QVQJfPOivj+t8Nn8Ef+0HO7+yxxUHbHsB2LaF4kYxfetCiO1uRyHPeASuedcufjPtz3Z6C6VUp9PSoHAdcCcwzhhTDoRhq5AOyhhTC/wU+BDYALxmjFknIr8XEWdOAz4E8kVkPbAIuMMYk9+K52iR7vE2KOQWV0H3YXbCtSWPd91qpJpKqKnwHu/80m63LrLbeXd4r1UWequSfMU6k9WNvhr6neyffCql2k1LB69NBL42xpSJyCxgNPDQ4W4yxswD5jU6d6/PvgF+7rz8rnt8JACWcFxEAAAdXElEQVQ5xZX2xLQ/2/WA37gO9m+2pYeuVOXx0HEQ1Q1uXOKccGoEKwvt1rdk8OlfvFVJvmLT/JpFpVT7amlJ4XGgXESOA34B7AT+47dc+UlqnFNSKKmyJ6KTbN330Jnw6f3w1Bm26+XyZ2Drx+B222kbPIr3witXeXvfBErOeph/t81fS/iWBjz2fmMHmOVtgLoae654j90umwNvXg815d707loYdDb8cCGMusqO9QBvSUEpFRRaWlKoNcYYEZkJPGSMeUZEOt2ENZFhLhKiwrwlBbArsJ3/BNRWwaYP4E/pUOt8icZnOIvEvwExybaBdeO7kDEOTvLrOLtD++BOuyLZoGl23WKwAaKiAGJSGqbd9CG8dClc8hwMO9+eK9wN2z/zpvlDClzwJBT5LD707at2G9cLSpwSw7kPQnxPyBgLueshe7WWFJQKMi0tKZSIyF3A1cB7zmjlTjnHcff4iIZBAewcSFe8Yufi8QSE8Dg7z3/2anjmTPtrusgZdrH8adi3Fp481Q7sOpjaKnhuhrfh9khVldhpJHwZA5Hxdt/zxQ3w4a/gb/1tV1FfO5yxGJ51DHZ8CbOH25KGr29esV1OB0+34ws8LnrKux/f07t/1etw1p9teqVU0GhpSeEy4ErseIV9ItIH+Jv/suU/3eMjySmuanpBBE65A5IHQvpoqC6Dj/8IPUfBoj/a7queL9ii3fDEJLu/92s4wWfqhmVP2ZXEeo2CPifaX/T7N8PP1sK+b+37icCBnfZXdlgUlOyzo4VTBzXM0wd32lHCP/4S0obYRexfvAQObLfXv34ZTvoZLPozrHnNnvv2VTjxp9738Awwy9toq8Y8vYmgYSlgm9O4PHi6bTTe+y1sng99J8EVr0Jto0Aak2LXSFBKBZUWBQUnELwIjBORc4FlxphO16YAkBYXydbc/QdP4KliAbj8RftFumyObYwGuOgZ+wU9/27b7gC2NNHreNi5GObdbs+tfd0O2gKoq7LdPV++DIZdCEPOg9evtb2fLpwDb//U9vm/aYWdvXXNa3D897xVPE9Mgoh4SO7vDQipQ2x7wPMX2Hs9dn5pg0JFIZTnQ85ae76mHP7YHdw13rRn/RH6nWqrjZ6abKez7nuivdZzpHf8weBmB5orpYJQi4KCiFyKLRl8gu2i8k8RucMY0+n6cnaPjyC3pAq32xAScrjxd9hJ2864B965xf5qHjQNImJh1pu2i+aTp8Cc05reFx4LWxbY/aoS75fzujftC+yv+qn3wbZPQEJsaeHTv8DiRyAizjZse1QV2+ATkwpleZDUz97jOwHd4HPs8daPbYnC01toyu9tUNrxuT0+/R6YeKMtpYD91f/rHNi3xgYepVSXJcY0nnmimUQi3wBTPBPWiUgqsMAYc5yf89fE2LFjzYoVK1p9/3Nf7eA3c9ex4u4zSYmNaPmNxthqn8byt9oqmc+c2rSRl8N5s+0X+PMX2Pl+DuyAmDQ73xLYUb85a21vn9DIplUzABnjIWtZ0/PnP25LAQOn2BLMsjkw4hJb9bX+bVh0X9N7bt9sq6q2LLTVWaf+smt1vVVKISIrjTFjD5eupW0KIY1mMM2nk67a5juA7YiCQnMBAewv69Pvtr/et30KFzxh0/Y9Ee7aY6uO/trfBoSIBFtFFJtm2ywen+StDmosa5kNJOc/Zr/oJ99t14AYOtP7hd7vFBsUBk2zs4/29InRt66BXUtticLTQ2jAGfallFIH0dKg8IGIfAh4Wikvo9GgtM6iR4KtMtlTWMHQXvFt98bnzm4aOFyh9nXVa/DcebZKyPMFHR4D0+637QzHnmu7ujbWe7wtEQycYo8Hntnw+pDzbCN092H2uO8k77XEPvallFJHoKUNzXeIyEXAJGybwhxjzFt+zZmfZCbbJTh37C9r2zc+WEkC7C/6771tp5H2NXiardqpq7FBofcJtmvs0ids20J8C5aq7DHcux8RC6O/Z3sVKaVUK7R4jWZjzBvAG37MS7tIjA4nMTqM7fltHBQO55jTmj/vKTlc8Qpknmy/2D2//Bt3UW2JGf9sTe6UUgo4TFAQkRKaroEAtrRgjDFtWP/SfjKTY9q+pHC0Bp/t3R8yw06/0e/UwOVHKdUlHTIoGGPi2isj7emYlBgWbwvw/EWHIqJTTyulAqJT9iA6WpkpMewtqqSiui7QWVFKqQ6lywYFgJ0FHawKSSmlAqxLBoV+yTYobM/ToKCUUr66ZFAYkBZLiMCGfSWBzopSSnUoXTIoRIW7OCY1lvXZRYHOilJKdShdMigADO8Vz9o9xYHOhlJKdShdNyikJ7CvuJL9pc2sraCUUl1Ulw0KnnmP1mVraUEppTy6bFAY1isBgLV7tF1BKaU8umxQSIgKY2BaLMt3FAQ6K0op1WF02aAAMK5fEit2HKC2zh3orCilVIfQpYPCyQNSKK2qZZmWFpRSCujiQeGUQamEh4Ywf11OoLOilFIdgl+DgohME5HvRGSLiNx5iHQXi4gRkcOuH9qWYiJCOWVgCh+tz6Ela1UrpVSw81tQEBEX8ChwNjAUuEJEhjaTLg64GVjqr7wcytRhPdhTWKED2ZRSCv+WFMYDW4wx24wx1cArwMxm0v0B+CtQ6ce8HNSZQ7oTIvDhun2B+HillOpQ/BkU0oHdPsdZzrl6InI80NsY08yq9Q3SXS8iK0RkRV5eXptmMikmnHGZScxfr0FBKaX8GRSaW8m+vuJeREKAB4HbDvdGxpg5xpixxpixqampbZhF66xhPdiUU8qGvVqFpJTq2vwZFLKA3j7HGUC2z3EcMBz4RER2ABOAue3d2Axw3nG9SIwO4zdz17X3RyulVIfiz6CwHBgoIv1EJBy4HJjruWiMKTLGpBhjMo0xmcASYIYxZoUf89Ss1LgIbjilP8u2F7Arv7y9P14ppToMvwUFY0wt8FPgQ2AD8JoxZp2I/F5EZvjrc1trxqhehAg8t3hHoLOilFIBE+rPNzfGzAPmNTp370HSnubPvBxOemIUFxyfwbNfbmdcZhLThvcIZHaUUioguvSI5sb+cP4wjkmJYfaCTTqYTSnVJWlQ8BEdHsoNp/Rn474S3l+rXVSVUl2PBoVGZozqRa+ESG5+eTXrdQEepVQXo0GhkcgwF6/9eCJR4S7+8O563G6tRlJKdR0aFJqR0S2aX00fwuJt+dz15hptX1BKdRl+7X3UmV0+rjdZB8p5dNFWXC7hvvOHI9LcIG2llAoeGhQOQkS4bcpgqmrcPP3FdnolRPLT0wcGOltKKeVXGhQOISRE+NX0IeSWVPH3+ZvIKa7i1+cMITLMFeisKaWUX2hQOIyQEOHBy0aRFhfB019sZ82eIuZcPYa0+MhAZ00ppdqcNjS3gCtEuPvcoTx+1Wi+21fClU8vpayqNtDZUkqpNqdB4QicPaInT149hq15pUx98DPe+Sabqtq6QGdLKaXajAaFI3TKoFRevX4i0eEubnp5NRc8+hVZB3RmVaVUcNCg0Arj+yXx7s0nMfuyUew+UM6MR75k6bb8QGdLKaWOmgaFVooIdXH+8em8feMkEqPDuOKpJfzs1a/JKQ7IUtNKKdUmNCgcpWNSY/nfjZP43sRM5n6TzYQ/L+Six7/ig7V7dSS0UqrTkc72xTV27FizYkW7L87WIlvzSnnnm2weW7SV6jo3V4zvw73nDiUqXMc1KKUCS0RWGmMOu9yxlhTaUP/UWG49cxBv/N+JTB3anZeX7eLkvy7i319up6bOHejsKaXUYWlJwU+MMXy6KY+HFm5m9a5CeidF8ZPTBnDF+D6BzppSqgvSkkKAiQinDU7jrZ9M4olZY4gMdXHXm2u45ZXV2oVVKdVhaVBoB9OG9+C9m0/mx6f2Z/66HM55+Au+2rpfG6KVUh2OBoV2Eh4awp1nH8sHt55Mckw4Vz61lDP/8SlfbN4f6KwppVQ9DQrtrG9yDG/dOIk/zByGMTDrmaUMuvt9FqzPCXTWlFJKG5oDqbKmjpeX7eKhhZspr6rjrOE9+PmUQfRLiQl01pRSQUYbmjuByDAX107qx4Kfn8o5I3vyycZczvzHp/xp3gadhVUpFRBaUuhAtu8v4zdz1/HZpjySYsK5ZmImN5x6jC7qo5Q6ai0tKWhQ6GCMMXy8MZe/z9/Ehr3FAFw0OoNfnzOEpJjwAOdOKdVZtTQo+HXlNRGZBjwEuICnjTH3N7r+c+CHQC2QB/zAGLPTn3nq6ESEM4Z05/Rj0/h4Yy4frN3Hm6v3sHxHAZeMyeD7kzKJiwwLdDaVUkHKbyUFEXEBm4ApQBawHLjCGLPeJ81kYKkxplxE/g84zRhz2aHeN9hLCs1ZvqOAe99eV19ymDq0O9+flMn4zCRCXdospJQ6vI5QUhgPbDHGbHMy9AowE6gPCsaYRT7plwCz/JifTmtcZhLv33Iyy7YX8M432bzzbTbz1+cwtGc8P5syiMmDUzU4KKXahD+DQjqw2+c4CzjhEOmvA95v7oKIXA9cD9CnT9edO2h8vyTG90vitqmDeH1lFnM+28aP/rOC1LgIThqQwo2TBzAgLTbQ2VRKdWL+DArSzLlm66pEZBYwFji1uevGmDnAHLDVR22Vwc4qMTqcH558DN8/MZMFG3J5fskOW4L4JptLx/XmxP7JnDuyV6CzqZTqhPwZFLKA3j7HGUB240Qicibwa+BUY0yVH/MTdEJdIUwb3oNpw3uwr6iSW15ZzUtLd/HS0l18tD6HWRP6Mi4zKdDZVEp1Iv5saA7FNjSfAezBNjRfaYxZ55PmeOB1YJoxZnNL3rcrNjQfiYrqOmYv3MTzi3dSXl3H1RP68qvpQ3ShH6W6uA4xTkFEpgOzsV1SnzXG3CcivwdWGGPmisgCYASw17lllzFmxqHeU4NCy1RU1/HA/O94+ovtpCdGcenY3kwb3oOkmHBS4yICnT2lVDvrEEHBHzQoHJmvtu5n9oLNLNteAEBMuIsHLj2Os4b1QKS5Zh+lVDDSoKAa2JJbwjNf7OC9b7MprqwlMzma04/tzqwJfTgmVXssKRXsNCioZtXWufnf19m8uSqLpdsLqHMbzjg2jYvGZFBaVUt6YhSTBqQEOptKqTamQUEd1s78Ml5bsZuXlu7iQHlN/fmHLh/FzFHpAcyZUqqtaVBQLVZb52bhxlz+uyKLXQVlbMop5bKxvfnp6QPonRQd6OwppdqABgXVKrV1bh74aBNPfLqV0BDhrGE9GNw9jvOPT9cAoVQnpkFBHZXt+8t48KNNrNx5gD2FFSREhfG7GcOYcVwvQkK015JSnY0GBdVm1mQV8YPnlpNXUsWg7rFMGdqdC45PZ0BaXKCzppRqIQ0Kqk253Ya532Tz4tKdrNpViNsYxmUmMS6zG+ePSmdgdw0QSnVkGhSU3+SXVvH8kp3MW7OXTTmlhLmEGcelMzIjgcE94hjTtxthOpW3Uh2KBgXVLvJLq/j7/O+Yt2YfRRW2W2tkWAjnj0rnlEGpDOsVT9/kmADnUimlQUG1K2MMuSVVrN5VyMINOby1eg+1bvu3NX1ED84Z0YszhqQRGaYT8ykVCBoUVEAVlFWzLa+UT77L45kvtlNRU1dfzTSqdwKpcRGcMaS7VjMp1U40KKgOo6q2jqXbCnhr9R7e/Tabmjr7Nzc8PZ4Lj89geHoCA9Ji6RYdppP0KeUnGhRUh1RaVct3+4qZvz6HBetz2JpXVn8tPTGKacN7MDIjgf6psQztGa9jIpRqIxoUVIdnjGFfcSUb95WwNbeUzzbvZ8m2fKpr3QCkxEYwtm83Zo7qxcDucWQmRxOq1U1KtYoGBdUp1dS52ZZXxrrsIj7blMfibfnkFNtVWhOjwzh5YCrpiVEc3yeRSQNSiI3w54qySgWPlgYF/RelOpQwVwiDe8QxuEccF47OoLbOzbIdBewtrOTLrfv5YvN+9pdW4TYQ5hIGdY+jV2IUI9MTGNUnkT5J0fRJita2CaVaSYOC6tBCXSGc2N+u73DRmAwAqmvdrNx5gE825bJhr616+mh9Tv09aXER9EqMYnSfbvRIiGBQdzugLi4yLCDPoFRnokFBdTrhoSFM7J/MxP7J9edyiyvZvr+MTbmlrN55gC15pbywdGd9+4QI9EuOISrcRff4SPomRzN9RE+O7RFHTHgoImjpQim0TUEFscqaOooratiUU8rKnQdYl11EUUUNBWXVbMkrxfdPv19KDCcPTGFAWiwDUmMZkBZLalyEBgoVNLRNQXV5kWEuIsNcpMVHctLAhkuM7sovZ8O+Yr7bV0J1rZul2/N5a9UeSqpq69PERYY2CBK9EqOIiwwlMzmGvsnabqGCk5YUlHJ4purYklva8JVXSl5JVYO0UWEueiREEu4KYWiveBKjwxiYFkdKbDixkaEckxJLfFQoEaEuXDrWQnUAWlJQ6giJCN3jI+keH8mkAQ1LFkXlNWQXVXDAqXralV/O3uJK9hVVsmx7AQVl1VTU1DX7vvGRoYzLTCIuMpRuMeEM6h5HdLiLpJhwCstrOKFfEmnxke3xiEodlgYFpVogITqMhGjbe+nERgEDoM5tB+IVlFZTXFnDtv1llFfVUlnjZk9hOV/vLqSyxk1eSVWT4CEC/VNjiY0IJb1bFBGhIaTFRZISG05ybDjJMRGEuoSeCVGkJ0YRHqoD+JT/aFBQqg24QoT0RPulDTQpaXi43YY9hRVU1NRRUFZNdLiLjzfmsmFvMcUVtazdU0RNrZv9pdVU17mbfY+4CFviSIoJJzE6jJjwULrFhBEbEUZUmIukmLD660kx4SRFhxMXGUZ4aIhWZanD0qCgVDsKCRF6J0U3ODcyI7FJOmMMJVW15JdWs7+0ippaN3sKK9hbVElBWTUHyqvttqya3QXl7C+tpqK67qCBxCMiNMQJJuHERriIjQglJiK0fhsT7rLbiFBiIlxEhYXWV3WFiFBT5ybMFcKg7rE65UiQ8mtQEJFpwEOAC3jaGHN/o+sRwH+AMUA+cJkxZoc/86RUZyAixEeGER8ZRr+Uli9SVFPnprC8pj5oFJRVk19WTVlVLVU1bsqqazngBJWyqjryy6rZmV9OaVUtZVW1lFU33y7SnPDQEGLCXUSHhxIV7iIqzEVkWAgRoc42zEWksx/Z6Fqkcy2i/pqLiFBvOnufN224K0QnR2wnfgsKIuICHgWmAFnAchGZa4xZ75PsOuCAMWaAiFwO/AW4zF95UirYhblCSI2LIDUuolX3u92Gipo6yqpqKa2qdfbrKCirAoQwl1BUUcPuggrKq2spr66jrLqWypo6KqrrqHQCT36Zm6qaOqpq3VTW1NlXrZs6d+t7O4aHhhDhCiHUJYS6Qgj37IcIYc5+mCuEsBBvmrBG10JDPPfabahL6tOHuUIIcwmhIc7WFdLgnE3jue5N4/n8MOc9XCFCiAghYkuGoSGCK8Te53KOPQGuutZNRU0dCVEdZ7S9P0sK44EtxphtACLyCjAT8A0KM4HfOvuvA4+IiJjO1k9WqSAREiL11Udpfnj/mjpPkHBTVWu3lTV1jfa9aWwwcdLX2Oqx2jpDTZ2bmjpDrdt7XOv2nHdTXeumrLqOWue4ts5QU5/WSV/npsZtqK1zcxSxqtVCQwSD7aQQFxGKyyUItpRot959t7FVf7+YNpiZo9L9my8/vnc6sNvnOAs44WBpjDG1IlIEJAP7/ZgvpVSAhDm/vuM6WA/cOrc3sNQ2Cji+gchz3XOu1u2krfMGJLcx1LnBbYyzb1+1nm2doc5t30sEYiJCyS2uwhiD24DBYAwYsFtj05VW1bW6BHgk/BkUmqsAbByPW5IGEbkeuB6gT58+R58zpZTy4QoRXCG6fjiAP7sPZAG9fY4zgOyDpRGRUCABKGj8RsaYOcaYscaYsampqX7KrlJKKX8GheXAQBHpJyLhwOXA3EZp5gLXOPsXAx9re4JSSgWO36qPnDaCnwIfYrukPmuMWScivwdWGGPmAs8Az4vIFmwJ4XJ/5UcppdTh+XWcgjFmHjCv0bl7ffYrgUv8mQellFItp0MSlVJK1dOgoJRSqp4GBaWUUvU0KCillKrX6VZeE5E8YGcrb08huEdLB/PzBfOzQXA/nz5bx9DXGHPYgV6dLigcDRFZ0ZLl6DqrYH6+YH42CO7n02frXLT6SCmlVD0NCkoppep1taAwJ9AZ8LNgfr5gfjYI7ufTZ+tEulSbglJKqUPraiUFpZRSh6BBQSmlVL0uExREZJqIfCciW0TkzkDn50iJyLMikisia33OJYnIRyKy2dl2c86LiDzsPOu3IjI6cDk/PBHpLSKLRGSDiKwTkVuc88HyfJEiskxEvnGe73fO+X4istR5vledKeYRkQjneItzPTOQ+W8JEXGJyGoRedc5DqZn2yEia0TkaxFZ4ZwLir/N5nSJoCAiLuBR4GxgKHCFiAwNbK6O2L+BaY3O3QksNMYMBBY6x2Cfc6Dzuh54vJ3y2Fq1wG3GmCHABOBG5/9PsDxfFXC6MeY4YBQwTUQmAH8BHnSe7wBwnZP+OuCAMWYA8KCTrqO7BdjgcxxMzwYw2RgzymdMQrD8bTZljAn6FzAR+NDn+C7grkDnqxXPkQms9Tn+Dujp7PcEvnP2nwSuaC5dZ3gBbwNTgvH5gGhgFXa98v1AqHO+/m8UuwbJRGc/1Ekngc77IZ4pA/vFeDrwLnaZ3aB4NiefO4CURueC7m/T8+oSJQUgHdjtc5zlnOvsuhtj9gI42zTnfKd9Xqc64XhgKUH0fE71ytdALvARsBUoNMbUOkl8n6H++ZzrRUBy++b4iMwGfgG4neNkgufZwK4bP19EVjrrxUMQ/W025tdFdjoQaeZcMPfF7ZTPKyKxwBvArcaYYpHmHsMmbeZch34+Y0wdMEpEEoG3gCHNJXO2neb5RORcINcYs1JETvOcbiZpp3s2H5OMMdkikgZ8JCIbD5G2Mz5fA12lpJAF9PY5zgCyA5SXtpQjIj0BnG2uc77TPa+IhGEDwovGmDed00HzfB7GmELgE2zbSaKIeH6Y+T5D/fM51xOwy9V2RJOAGSKyA3gFW4U0m+B4NgCMMdnONhcb0McThH+bHl0lKCwHBjo9IsKxa0HPDXCe2sJc4Bpn/xpsXbzn/PecnhATgCJPUbcjElskeAbYYIz5h8+lYHm+VKeEgIhEAWdiG2UXARc7yRo/n+e5LwY+Nk4FdUdjjLnLGJNhjMnE/rv62BhzFUHwbAAiEiMicZ59YCqwliD522xWoBs12usFTAc2Yetyfx3o/LQi/y8De4Ea7K+R67B1sQuBzc42yUkr2N5WW4E1wNhA5/8wz3YStoj9LfC185oeRM83EljtPN9a4F7n/DHAMmAL8F8gwjkf6Rxvca4fE+hnaOFznga8G0zP5jzHN85rnee7I1j+Npt76TQXSiml6nWV6iOllFItoEFBKaVUPQ0KSiml6mlQUEopVU+DglJKqXoaFJRqRyJymmcmUaU6Ig0KSiml6mlQUKoZIjLLWQPhaxF50pnQrlREHhCRVSKyUERSnbSjRGSJM3/+Wz5z6w8QkQXOOgqrRKS/8/axIvK6iGwUkRflEJM8KdXeNCgo1YiIDAEuw06ENgqoA64CYoBVxpjRwKfAb5xb/gP80hgzEjuK1XP+ReBRY9dROBE7Ih3sLLC3Ytf2OAY7f5BSHUJXmSVVqSNxBjAGWO78iI/CTnjmBl510rwAvCkiCUCiMeZT5/xzwH+d+XLSjTFvARhjKgGc91tmjMlyjr/GrpPxhf8fS6nD06CgVFMCPGeMuavBSZF7GqU71Bwxh6oSqvLZr0P/HaoORKuPlGpqIXCxM3++Zz3evth/L56ZP68EvjDGFAEHRORk5/zVwKfGmGIgS0TOd94jQkSi2/UplGoF/YWiVCPGmPUicjd2ta0Q7My0NwJlwDARWYldMewy55ZrgCecL/1twLXO+auBJ0Xk9857XNKOj6FUq+gsqUq1kIiUGmNiA50PpfxJq4+UUkrV05KCUkqpelpSUEopVU+DglJKqXoaFJRSStXToKCUUqqeBgWllFL1/h+eIMyAM9DZPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f26909da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f27948748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее+, добавили слой, два сигмоида, уменьшаем кол-во эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6637 - acc: 0.5560 - val_loss: 0.6865 - val_acc: 0.5714\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.6127 - acc: 0.7120 - val_loss: 0.6565 - val_acc: 0.7143\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.5733 - acc: 0.7840 - val_loss: 0.6450 - val_acc: 0.7143\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.5407 - acc: 0.7440 - val_loss: 0.6250 - val_acc: 0.7143\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.5136 - acc: 0.7920 - val_loss: 0.6141 - val_acc: 0.7143\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.4889 - acc: 0.7960 - val_loss: 0.6045 - val_acc: 0.7143\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.4703 - acc: 0.8120 - val_loss: 0.5950 - val_acc: 0.7143\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.4538 - acc: 0.7920 - val_loss: 0.5866 - val_acc: 0.7143\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.4392 - acc: 0.7960 - val_loss: 0.5777 - val_acc: 0.7143\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.4274 - acc: 0.8040 - val_loss: 0.5706 - val_acc: 0.7143\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.4185 - acc: 0.7960 - val_loss: 0.5721 - val_acc: 0.7143\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.4067 - acc: 0.7960 - val_loss: 0.5686 - val_acc: 0.7143\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.4001 - acc: 0.8040 - val_loss: 0.5684 - val_acc: 0.7143\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3932 - acc: 0.8080 - val_loss: 0.5639 - val_acc: 0.7143\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3822 - acc: 0.8080 - val_loss: 0.5603 - val_acc: 0.7143\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3761 - acc: 0.8080 - val_loss: 0.5509 - val_acc: 0.7143\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3709 - acc: 0.8360 - val_loss: 0.5554 - val_acc: 0.7143\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3656 - acc: 0.8120 - val_loss: 0.5510 - val_acc: 0.7143\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3602 - acc: 0.8280 - val_loss: 0.5480 - val_acc: 0.7143\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3564 - acc: 0.8200 - val_loss: 0.5426 - val_acc: 0.7143\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3535 - acc: 0.8280 - val_loss: 0.5472 - val_acc: 0.7143\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3487 - acc: 0.8320 - val_loss: 0.5441 - val_acc: 0.7143\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3439 - acc: 0.8320 - val_loss: 0.5430 - val_acc: 0.7143\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.3415 - acc: 0.8320 - val_loss: 0.5384 - val_acc: 0.7143\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3399 - acc: 0.8320 - val_loss: 0.5377 - val_acc: 0.7143\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3348 - acc: 0.8280 - val_loss: 0.5332 - val_acc: 0.7143\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3325 - acc: 0.8400 - val_loss: 0.5346 - val_acc: 0.7143\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3288 - acc: 0.8440 - val_loss: 0.5358 - val_acc: 0.7143\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3260 - acc: 0.8400 - val_loss: 0.5315 - val_acc: 0.7143\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.3236 - acc: 0.8440 - val_loss: 0.5315 - val_acc: 0.7143\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.3210 - acc: 0.8440 - val_loss: 0.5465 - val_acc: 0.6786\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3196 - acc: 0.8440 - val_loss: 0.5371 - val_acc: 0.7143\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 136us/step - loss: 0.3169 - acc: 0.8440 - val_loss: 0.5333 - val_acc: 0.7143\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3149 - acc: 0.8480 - val_loss: 0.5436 - val_acc: 0.7143\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.3112 - acc: 0.8520 - val_loss: 0.5420 - val_acc: 0.7143\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3097 - acc: 0.8480 - val_loss: 0.5494 - val_acc: 0.6786\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3065 - acc: 0.8520 - val_loss: 0.5431 - val_acc: 0.6786\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3041 - acc: 0.8520 - val_loss: 0.5389 - val_acc: 0.6786\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3013 - acc: 0.8520 - val_loss: 0.5426 - val_acc: 0.6786\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.3012 - acc: 0.8560 - val_loss: 0.5298 - val_acc: 0.7143\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2983 - acc: 0.8560 - val_loss: 0.5249 - val_acc: 0.7143\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2955 - acc: 0.8560 - val_loss: 0.5196 - val_acc: 0.7143\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2937 - acc: 0.8560 - val_loss: 0.5184 - val_acc: 0.7143\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2919 - acc: 0.8560 - val_loss: 0.5309 - val_acc: 0.6786\n",
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2888 - acc: 0.8600 - val_loss: 0.5348 - val_acc: 0.6786\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2890 - acc: 0.8680 - val_loss: 0.5283 - val_acc: 0.6786\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2860 - acc: 0.8640 - val_loss: 0.5306 - val_acc: 0.6786\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2828 - acc: 0.8640 - val_loss: 0.5262 - val_acc: 0.6786\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2806 - acc: 0.8600 - val_loss: 0.5211 - val_acc: 0.6786\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2782 - acc: 0.8680 - val_loss: 0.5283 - val_acc: 0.6786\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2773 - acc: 0.8720 - val_loss: 0.5367 - val_acc: 0.6786\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2737 - acc: 0.8640 - val_loss: 0.5313 - val_acc: 0.6786\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.2727 - acc: 0.8680 - val_loss: 0.5327 - val_acc: 0.6786\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2687 - acc: 0.8720 - val_loss: 0.5303 - val_acc: 0.6786\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2676 - acc: 0.8720 - val_loss: 0.5279 - val_acc: 0.6786\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2659 - acc: 0.8640 - val_loss: 0.5243 - val_acc: 0.6786\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2655 - acc: 0.8720 - val_loss: 0.5285 - val_acc: 0.6786\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2625 - acc: 0.8800 - val_loss: 0.5322 - val_acc: 0.6786\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2600 - acc: 0.8840 - val_loss: 0.5334 - val_acc: 0.6786\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2571 - acc: 0.8840 - val_loss: 0.5156 - val_acc: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2538 - acc: 0.8880 - val_loss: 0.5140 - val_acc: 0.7143\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2510 - acc: 0.8920 - val_loss: 0.5178 - val_acc: 0.6786\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2494 - acc: 0.9040 - val_loss: 0.5211 - val_acc: 0.6786\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2495 - acc: 0.8760 - val_loss: 0.5181 - val_acc: 0.6786\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2471 - acc: 0.8920 - val_loss: 0.5182 - val_acc: 0.6786\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2440 - acc: 0.9040 - val_loss: 0.5113 - val_acc: 0.6786\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2427 - acc: 0.9000 - val_loss: 0.5074 - val_acc: 0.7143\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2409 - acc: 0.9080 - val_loss: 0.5066 - val_acc: 0.7143\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2396 - acc: 0.9000 - val_loss: 0.5119 - val_acc: 0.7143\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2373 - acc: 0.9120 - val_loss: 0.5135 - val_acc: 0.7143\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2355 - acc: 0.9040 - val_loss: 0.5128 - val_acc: 0.7143\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2350 - acc: 0.9000 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2318 - acc: 0.9080 - val_loss: 0.5118 - val_acc: 0.7500\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2302 - acc: 0.9080 - val_loss: 0.5209 - val_acc: 0.7143\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2293 - acc: 0.8960 - val_loss: 0.5164 - val_acc: 0.7143\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2281 - acc: 0.9040 - val_loss: 0.5054 - val_acc: 0.7500\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2252 - acc: 0.9120 - val_loss: 0.5023 - val_acc: 0.7500\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2234 - acc: 0.9120 - val_loss: 0.5140 - val_acc: 0.7143\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2230 - acc: 0.9040 - val_loss: 0.5153 - val_acc: 0.7143\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2208 - acc: 0.9120 - val_loss: 0.5059 - val_acc: 0.7500\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2206 - acc: 0.9040 - val_loss: 0.4944 - val_acc: 0.7500\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2180 - acc: 0.9080 - val_loss: 0.4939 - val_acc: 0.7500\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2149 - acc: 0.9200 - val_loss: 0.4950 - val_acc: 0.7500\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2156 - acc: 0.9080 - val_loss: 0.4961 - val_acc: 0.7500\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2142 - acc: 0.9160 - val_loss: 0.5097 - val_acc: 0.7500\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2117 - acc: 0.9120 - val_loss: 0.4976 - val_acc: 0.7500\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2116 - acc: 0.9080 - val_loss: 0.4890 - val_acc: 0.7500\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2083 - acc: 0.9080 - val_loss: 0.4926 - val_acc: 0.7500\n",
      "Epoch 89/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2063 - acc: 0.9160 - val_loss: 0.4810 - val_acc: 0.7500\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2059 - acc: 0.9080 - val_loss: 0.4935 - val_acc: 0.7500\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.2031 - acc: 0.9080 - val_loss: 0.4993 - val_acc: 0.7500\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2019 - acc: 0.9120 - val_loss: 0.5027 - val_acc: 0.7500\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2003 - acc: 0.9080 - val_loss: 0.4988 - val_acc: 0.7500\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1988 - acc: 0.9200 - val_loss: 0.5010 - val_acc: 0.7500\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1968 - acc: 0.9120 - val_loss: 0.5014 - val_acc: 0.7500\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1957 - acc: 0.9160 - val_loss: 0.4894 - val_acc: 0.7500\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1941 - acc: 0.9120 - val_loss: 0.4879 - val_acc: 0.7143\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1919 - acc: 0.9120 - val_loss: 0.4925 - val_acc: 0.7143\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1918 - acc: 0.9160 - val_loss: 0.5058 - val_acc: 0.7500\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1900 - acc: 0.9200 - val_loss: 0.4945 - val_acc: 0.7143\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1885 - acc: 0.9200 - val_loss: 0.4864 - val_acc: 0.7143\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1859 - acc: 0.9240 - val_loss: 0.4824 - val_acc: 0.7143\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1851 - acc: 0.9240 - val_loss: 0.4873 - val_acc: 0.7143\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1822 - acc: 0.9280 - val_loss: 0.4865 - val_acc: 0.7143\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1823 - acc: 0.9240 - val_loss: 0.4819 - val_acc: 0.6786\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1805 - acc: 0.9320 - val_loss: 0.4816 - val_acc: 0.6786\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1780 - acc: 0.9320 - val_loss: 0.4878 - val_acc: 0.6786\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1774 - acc: 0.9280 - val_loss: 0.4843 - val_acc: 0.6786\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1776 - acc: 0.9360 - val_loss: 0.5022 - val_acc: 0.6786\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1759 - acc: 0.9320 - val_loss: 0.5135 - val_acc: 0.6786\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1745 - acc: 0.9280 - val_loss: 0.5154 - val_acc: 0.6786\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1722 - acc: 0.9320 - val_loss: 0.4987 - val_acc: 0.6786\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1706 - acc: 0.9280 - val_loss: 0.4970 - val_acc: 0.6786\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1690 - acc: 0.9240 - val_loss: 0.5011 - val_acc: 0.6786\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1676 - acc: 0.9240 - val_loss: 0.5177 - val_acc: 0.6786\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1650 - acc: 0.9320 - val_loss: 0.5089 - val_acc: 0.6786\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1652 - acc: 0.9360 - val_loss: 0.4992 - val_acc: 0.6786\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1630 - acc: 0.9280 - val_loss: 0.5106 - val_acc: 0.6786\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1626 - acc: 0.9400 - val_loss: 0.5175 - val_acc: 0.6786\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1603 - acc: 0.9320 - val_loss: 0.5148 - val_acc: 0.6786\n",
      "Epoch 121/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 152us/step - loss: 0.1601 - acc: 0.9360 - val_loss: 0.5048 - val_acc: 0.6786\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.1591 - acc: 0.9440 - val_loss: 0.5208 - val_acc: 0.6786\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1590 - acc: 0.9440 - val_loss: 0.5251 - val_acc: 0.6786\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1562 - acc: 0.9400 - val_loss: 0.5275 - val_acc: 0.6786\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1564 - acc: 0.9440 - val_loss: 0.5210 - val_acc: 0.6786\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1539 - acc: 0.9440 - val_loss: 0.5101 - val_acc: 0.6786\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1539 - acc: 0.9440 - val_loss: 0.5240 - val_acc: 0.6786\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1511 - acc: 0.9400 - val_loss: 0.5315 - val_acc: 0.6786\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1508 - acc: 0.9440 - val_loss: 0.5275 - val_acc: 0.6786\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1494 - acc: 0.9440 - val_loss: 0.5274 - val_acc: 0.6786\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1473 - acc: 0.9400 - val_loss: 0.5224 - val_acc: 0.6786\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1467 - acc: 0.9480 - val_loss: 0.5190 - val_acc: 0.6786\n",
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1439 - acc: 0.9480 - val_loss: 0.5222 - val_acc: 0.6786\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1434 - acc: 0.9520 - val_loss: 0.5278 - val_acc: 0.6786\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1431 - acc: 0.9560 - val_loss: 0.5379 - val_acc: 0.6786\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1422 - acc: 0.9520 - val_loss: 0.5412 - val_acc: 0.6786\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1410 - acc: 0.9480 - val_loss: 0.5395 - val_acc: 0.6786\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1405 - acc: 0.9560 - val_loss: 0.5392 - val_acc: 0.6786\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1397 - acc: 0.9480 - val_loss: 0.5440 - val_acc: 0.6786\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1383 - acc: 0.9520 - val_loss: 0.5387 - val_acc: 0.6786\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1382 - acc: 0.9520 - val_loss: 0.5396 - val_acc: 0.6786\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1376 - acc: 0.9560 - val_loss: 0.5447 - val_acc: 0.6786\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1368 - acc: 0.9560 - val_loss: 0.5592 - val_acc: 0.6429\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1362 - acc: 0.9640 - val_loss: 0.5551 - val_acc: 0.6786\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1347 - acc: 0.9600 - val_loss: 0.5529 - val_acc: 0.6786\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1365 - acc: 0.9480 - val_loss: 0.5458 - val_acc: 0.6786\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1362 - acc: 0.9520 - val_loss: 0.5494 - val_acc: 0.6786\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1351 - acc: 0.9440 - val_loss: 0.5597 - val_acc: 0.6786\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1323 - acc: 0.9560 - val_loss: 0.5521 - val_acc: 0.6786\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1307 - acc: 0.9560 - val_loss: 0.5485 - val_acc: 0.6786\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1306 - acc: 0.9640 - val_loss: 0.5516 - val_acc: 0.6786\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1294 - acc: 0.9560 - val_loss: 0.5589 - val_acc: 0.6786\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1284 - acc: 0.9600 - val_loss: 0.5545 - val_acc: 0.6786\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1268 - acc: 0.9640 - val_loss: 0.5643 - val_acc: 0.6786\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1272 - acc: 0.9600 - val_loss: 0.5570 - val_acc: 0.6786\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1257 - acc: 0.9600 - val_loss: 0.5502 - val_acc: 0.6786\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1250 - acc: 0.9600 - val_loss: 0.5432 - val_acc: 0.7143\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1240 - acc: 0.9520 - val_loss: 0.5697 - val_acc: 0.6786\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1239 - acc: 0.9680 - val_loss: 0.5639 - val_acc: 0.6786\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1231 - acc: 0.9600 - val_loss: 0.5658 - val_acc: 0.6786\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1210 - acc: 0.9600 - val_loss: 0.5576 - val_acc: 0.6786\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1234 - acc: 0.9560 - val_loss: 0.5740 - val_acc: 0.6786\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1207 - acc: 0.9640 - val_loss: 0.5775 - val_acc: 0.6786\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1195 - acc: 0.9640 - val_loss: 0.5672 - val_acc: 0.6786\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1192 - acc: 0.9480 - val_loss: 0.5805 - val_acc: 0.6786\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1189 - acc: 0.9560 - val_loss: 0.5842 - val_acc: 0.6786\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.866 - 0s 160us/step - loss: 0.1177 - acc: 0.9600 - val_loss: 0.5741 - val_acc: 0.6786\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1173 - acc: 0.9600 - val_loss: 0.5756 - val_acc: 0.6786\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1159 - acc: 0.9600 - val_loss: 0.5728 - val_acc: 0.6786\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1153 - acc: 0.9600 - val_loss: 0.5649 - val_acc: 0.7143\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.1149 - acc: 0.9640 - val_loss: 0.5742 - val_acc: 0.6786\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1138 - acc: 0.9600 - val_loss: 0.5782 - val_acc: 0.6786\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1132 - acc: 0.9640 - val_loss: 0.5874 - val_acc: 0.6786\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1128 - acc: 0.9640 - val_loss: 0.5837 - val_acc: 0.6786\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1120 - acc: 0.9640 - val_loss: 0.5793 - val_acc: 0.6786\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 0s 140us/step - loss: 0.1105 - acc: 0.9640 - val_loss: 0.5794 - val_acc: 0.6786\n",
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1097 - acc: 0.9640 - val_loss: 0.5878 - val_acc: 0.6786\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1095 - acc: 0.9720 - val_loss: 0.5842 - val_acc: 0.6786\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1094 - acc: 0.9600 - val_loss: 0.5870 - val_acc: 0.6786\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1078 - acc: 0.9680 - val_loss: 0.5950 - val_acc: 0.6786\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1070 - acc: 0.9680 - val_loss: 0.6001 - val_acc: 0.6786\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1066 - acc: 0.9720 - val_loss: 0.5866 - val_acc: 0.6786\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1061 - acc: 0.9720 - val_loss: 0.5708 - val_acc: 0.7143\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1062 - acc: 0.9680 - val_loss: 0.5820 - val_acc: 0.6786\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1047 - acc: 0.9720 - val_loss: 0.5898 - val_acc: 0.6786\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1038 - acc: 0.9680 - val_loss: 0.5903 - val_acc: 0.6786\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1033 - acc: 0.9680 - val_loss: 0.5852 - val_acc: 0.6786\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1029 - acc: 0.9720 - val_loss: 0.5743 - val_acc: 0.7143\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1026 - acc: 0.9680 - val_loss: 0.5554 - val_acc: 0.7143\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1016 - acc: 0.9720 - val_loss: 0.5565 - val_acc: 0.7143\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1007 - acc: 0.9680 - val_loss: 0.5695 - val_acc: 0.6786\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1004 - acc: 0.9680 - val_loss: 0.5663 - val_acc: 0.6786\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0991 - acc: 0.9720 - val_loss: 0.5723 - val_acc: 0.6786\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0995 - acc: 0.9720 - val_loss: 0.5863 - val_acc: 0.6786\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0989 - acc: 0.9680 - val_loss: 0.5777 - val_acc: 0.6786\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0983 - acc: 0.9680 - val_loss: 0.5801 - val_acc: 0.6786\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0962 - acc: 0.9680 - val_loss: 0.5746 - val_acc: 0.6786\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0959 - acc: 0.9720 - val_loss: 0.5824 - val_acc: 0.6786\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0950 - acc: 0.9800 - val_loss: 0.5899 - val_acc: 0.6786\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0936 - acc: 0.9720 - val_loss: 0.5815 - val_acc: 0.6786\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0927 - acc: 0.9760 - val_loss: 0.5805 - val_acc: 0.6786\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0926 - acc: 0.9720 - val_loss: 0.5811 - val_acc: 0.6786\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0916 - acc: 0.9760 - val_loss: 0.5804 - val_acc: 0.6786\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0907 - acc: 0.9760 - val_loss: 0.5868 - val_acc: 0.6786\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0903 - acc: 0.9760 - val_loss: 0.5876 - val_acc: 0.6786\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0899 - acc: 0.9800 - val_loss: 0.5841 - val_acc: 0.6786\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0886 - acc: 0.9720 - val_loss: 0.5803 - val_acc: 0.6786\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0880 - acc: 0.9760 - val_loss: 0.5911 - val_acc: 0.6786\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0874 - acc: 0.9760 - val_loss: 0.5848 - val_acc: 0.6786\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0873 - acc: 0.9760 - val_loss: 0.5837 - val_acc: 0.6786\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0875 - acc: 0.9760 - val_loss: 0.5823 - val_acc: 0.6786\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0859 - acc: 0.9760 - val_loss: 0.5835 - val_acc: 0.6786\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0859 - acc: 0.9760 - val_loss: 0.5938 - val_acc: 0.6786\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0855 - acc: 0.9760 - val_loss: 0.5839 - val_acc: 0.6786\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0850 - acc: 0.9800 - val_loss: 0.5880 - val_acc: 0.6786\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0832 - acc: 0.9800 - val_loss: 0.5965 - val_acc: 0.6786\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0831 - acc: 0.9800 - val_loss: 0.5898 - val_acc: 0.6786\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0826 - acc: 0.9800 - val_loss: 0.5910 - val_acc: 0.6786\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0820 - acc: 0.9840 - val_loss: 0.5932 - val_acc: 0.6786\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0812 - acc: 0.9760 - val_loss: 0.5960 - val_acc: 0.6786\n",
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0812 - acc: 0.9760 - val_loss: 0.5927 - val_acc: 0.7143\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0806 - acc: 0.9800 - val_loss: 0.6037 - val_acc: 0.6786\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0800 - acc: 0.9800 - val_loss: 0.6138 - val_acc: 0.6786\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0797 - acc: 0.9760 - val_loss: 0.6104 - val_acc: 0.6786\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0800 - acc: 0.9840 - val_loss: 0.6196 - val_acc: 0.6786\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0797 - acc: 0.9760 - val_loss: 0.5969 - val_acc: 0.6786\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0782 - acc: 0.9840 - val_loss: 0.5917 - val_acc: 0.7143\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0784 - acc: 0.9800 - val_loss: 0.6101 - val_acc: 0.7143\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0775 - acc: 0.9840 - val_loss: 0.5946 - val_acc: 0.6786\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0769 - acc: 0.9800 - val_loss: 0.6010 - val_acc: 0.6786\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0762 - acc: 0.9800 - val_loss: 0.6047 - val_acc: 0.6786\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0759 - acc: 0.9760 - val_loss: 0.6094 - val_acc: 0.6786\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0750 - acc: 0.9800 - val_loss: 0.6068 - val_acc: 0.6786\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0742 - acc: 0.9800 - val_loss: 0.6129 - val_acc: 0.6786\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0747 - acc: 0.9800 - val_loss: 0.6026 - val_acc: 0.7143\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0755 - acc: 0.9840 - val_loss: 0.6017 - val_acc: 0.6786\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0736 - acc: 0.9840 - val_loss: 0.6155 - val_acc: 0.6786\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0734 - acc: 0.9800 - val_loss: 0.6218 - val_acc: 0.6786\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0723 - acc: 0.9840 - val_loss: 0.6207 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0723 - acc: 0.9840 - val_loss: 0.6365 - val_acc: 0.6786\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0726 - acc: 0.9760 - val_loss: 0.6385 - val_acc: 0.6786\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0707 - acc: 0.9840 - val_loss: 0.6213 - val_acc: 0.6786\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0706 - acc: 0.9880 - val_loss: 0.6295 - val_acc: 0.6786\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0716 - acc: 0.9760 - val_loss: 0.6241 - val_acc: 0.6786\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0699 - acc: 0.9800 - val_loss: 0.6086 - val_acc: 0.7143\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0688 - acc: 0.9840 - val_loss: 0.6201 - val_acc: 0.7143\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0684 - acc: 0.9800 - val_loss: 0.6271 - val_acc: 0.7143\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0683 - acc: 0.9840 - val_loss: 0.6359 - val_acc: 0.6786\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0675 - acc: 0.9840 - val_loss: 0.6296 - val_acc: 0.6786\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0672 - acc: 0.9840 - val_loss: 0.6230 - val_acc: 0.6786\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f24b73198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAGDCAYAAAD5+0frAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XdYl+Xix/H3zd4goIACbkFxC7iyrCw1K8us1JYn0/apX1mnXTZP57Q7mS3TNLVsqKmVWY5yhLgF9wRUVJC9vzy/P8CvEqhoII7P67q6Lr7Pc9/3cz/fc53iw72MZVmIiIiIiIiInEsc6roDIiIiIiIiIqdKYVZERERERETOOQqzIiIiIiIics5RmBUREREREZFzjsKsiIiIiIiInHMUZkVEREREROScozArIiLyNxljJhhjXq5m2V3GmD613ScREZHzncKsiIiIiIiInHMUZkVERAQAY4xTXfdBRESkuhRmRUTkglA+vfcxY8w6Y0yuMeYzY0yQMeZHY0y2MWa+MabeMeWvNcYkGGMyjDELjTGtj7nXyRizqrzeV4DbX551tTFmTXndpcaY9tXs4wBjzGpjTJYxJskY88Jf7l9U3l5G+f3h5dfdjTFvGmN2G2MyjTF/lF/rbYxJruJ76FP+8wvGmG+MMZONMVnAcGNMrDFmWfkz9hlj/meMcTmmfpQx5hdjTLoxJtUY85QxJtgYk2eMCTimXBdjzEFjjHN13l1ERORUKcyKiMiF5AbgCqAVcA3wI/AUEEjZfxP/CWCMaQVMBR4G6gNzgR+MMS7lwW4GMAnwB6aXt0t53c7AeOBuIAD4CJhljHGtRv9ygdsBP2AAcK8x5rrydsPL+/t+eZ86AmvK670BdAF6lPfpcaC0mt/JQOCb8md+CdiA/yv/TroDlwP3lffBG5gP/AQ0BFoAv1qWtR9YCNx0TLu3AtMsyyquZj9EREROicKsiIhcSN63LCvVsqwU4HfgT8uyVluWVQh8D3QqL3czMMeyrF/Kw9gbgDtlYbEb4Ay8Y1lWsWVZ3wArjnnGSOAjy7L+tCzLZlnWRKCwvN4JWZa10LKs9ZZllVqWtY6yQH1J+e1bgPmWZU0tf26aZVlrjDEOwJ3AQ5ZlpZQ/c2n5O1XHMsuyZpQ/M9+yrJWWZS23LKvEsqxdlIXxI324GthvWdablmUVWJaVbVnWn+X3JlIWYDHGOAJDKQv8IiIitUJhVkRELiSpx/ycX8Vnr/KfGwK7j9ywLKsUSAIald9LsSzLOqbu7mN+bgw8Wj5NN8MYkwGEldc7IWNMV2PMgvLpuZnAPZSNkFLexvYqqgVSNs25qnvVkfSXPrQyxsw2xuwvn3r8ajX6ADATaGOMaUbZ6HemZVlxp9knERGRk1KYFRERqWwvZaEUAGOMoSzIpQD7gEbl144IP+bnJOAVy7L8jvnHw7KsqdV47hRgFhBmWZYvMA448pwkoHkVdQ4BBce5lwt4HPMejpRNUT6W9ZfPHwKbgJaWZflQNg37ZH3AsqwC4GvKRpBvQ6OyIiJSyxRmRUREKvsaGGCMubx8A6NHKZsqvBRYBpQA/zTGOBljBgGxx9T9BLinfJTVGGM8yzd28q7Gc72BdMuyCowxscCwY+59CfQxxtxU/twAY0zH8lHj8cBbxpiGxhhHY0z38jW6WwC38uc7A88AJ1u76w1kATnGmEjg3mPuzQaCjTEPG2NcjTHexpiux9z/AhgOXAtMrsb7ioiInDaFWRERkb+wLGszZes/36ds5PMa4BrLsoosyyoCBlEW2g5Ttr72u2PqxlO2bvZ/5fe3lZetjvuAF40x2cBzlIXqI+3uAa6iLFinU7b5U4fy26OB9ZSt3U0HXgccLMvKLG/zU8pGlXOBCrsbV2E0ZSE6m7Jg/tUxfcimbArxNcB+YCtw6TH3l1C28dSq8vW2IiIitcZUXPIjIiIicvqMMb8BUyzL+rSu+yIiIuc3hVkRERGpEcaYGOAXytb8Ztd1f0RE5PymacYiIiLytxljJlJ2Bu3DCrIiInImaGRWREREREREzjkamRUREREREZFzjsKsiIiIiIiInHOc6roDpyowMNBq0qRJXXdDREREREREasHKlSsPWZZV/2Tlzrkw26RJE+Lj4+u6GyIiIiIiIlILjDG7q1NO04xFRERERETknFNrYdYYM94Yc8AYs+E4940x5j1jzDZjzDpjTOfa6ouIiIiIiIicX2pzZHYC0O8E9/sDLcv/GQV8WIt9ERERERERkfNIra2ZtSxrsTGmyQmKDAS+sMoOul1ujPEzxoRYlrXvVJ9VXFxMcnIyBQUFp9nbc4ObmxuhoaE4OzvXdVdERERERETqVF1uANUISDrmc3L5tUph1hgzirLRW8LDwys1lJycjLe3N02aNMEYUzu9rWOWZZGWlkZycjJNmzat6+6IiIiIiIjUqbrcAKqq1GlVVdCyrI8ty4q2LCu6fv3KOzQXFBQQEBBw3gZZAGMMAQEB5/3os4iIiIiISHXUZZhNBsKO+RwK7D3dxs7nIHvEhfCOIiIiIiIi1VGXYXYWcHv5rsbdgMzTWS97NsjIyGDs2LGnXO+qq64iIyOjFnokIiIiIiJyfqvNo3mmAsuACGNMsjFmhDHmHmPMPeVF5gI7gG3AJ8B9tdWX2na8MGuz2U5Yb+7cufj5+dVWt0RERERERM5btbmb8dCT3LeA+2vr+WfSE088wfbt2+nYsSPOzs54eXkREhLCmjVrSExM5LrrriMpKYmCggIeeughRo0aBUCTJk2Ij48nJyeH/v37c9FFF7F06VIaNWrEzJkzcXd3r+M3ExEREREROTvV5W7GtWLMDwkk7s2q0TbbNPTh+Wuijnv/3//+Nxs2bGDNmjUsXLiQAQMGsGHDBvuuw+PHj8ff35/8/HxiYmK44YYbCAgIqNDG1q1bmTp1Kp988gk33XQT3377LbfeemuNvoeIiIiIiMj5oi7XzJ63YmNjKxyf895779GhQwe6detGUlISW7durVSnadOmdOzYEYAuXbqwa9euM9VdERERERE5S9hKLbamZtd1N84J593I7IlGUM8UT09P+88LFy5k/vz5LFu2DA8PD3r37l3l8Tqurq72nx0dHcnPzz8jfRURERERkbNDbmEJD01bw/yNqXz+jxgujWhQ1106q2lktgZ4e3uTnV31X08yMzOpV68eHh4ebNq0ieXLl5/h3omIiIiIyNlub0Y+g8ct47dNqXi6OPLl8j113aWz3nk3MlsXAgIC6NmzJ23btsXd3Z2goCD7vX79+jFu3Djat29PREQE3bp1q8OeioiIiIicGZv2Z7EhJYvBXUJrpL3Z6/YS1dCXpoGeFa6nZhXwc8J+hsSE4+J0dKzOsiy+WZlM8wZedA6vVyN9OKKg2MYXy3aRllNkv3ZJq/r0aBFYodyBrAImL99NYUkpAM6ODtzarTHBvm4Vym3cl8Xt4+PIL7Lx2fAY4nam8/HiHaRmFRDkU7HsEZv3ZxO3M42hseE4OR59b1upxZQ/d5N8+PgzPR+9MqLCd3WuMmWbCp87oqOjrfj4+ArXNm7cSOvWreuoR2fWhfSuIiIiInJu+jlhPw9PW0N+sY3xw6O5LDLo5JVOYPmONIZ8vJyWDbyY+1AvnMvDm2VZ3D4+jt+3HiK2qT/jbu2Cv6cLBcU2nvh2HTPW7MXZ0fDq9e24MTqsJl6NQzmF3D1pJSt3H8bNuawftlILW6nFU1e1ZsRFTTHGkLA3k7smxpOaVWAPjoUlpXRrGsCUkV0xxgBQYivl6vf/ID23iMl3daVVkDe703K55L8LGX1lKx64rGWlPvySmMpD01aTV2Sjd0R93h/aCW835wrTlF2dHCh/RCWrnr0CD5ezd1zTGLPSsqzok5U7e99ARERERETOKZZlMW7RDv7z8ybah/qRnV/MmB8S6dE8EDdnx9Nqs8RWyvMzE/B2dWLrgRy+WLabEReVbbb6c0Iqv289xIB2IfyyMZXrPljCfwe35/WfNrFqTwYPXd6SlbsP89g369h+MJfH+0bg4HCchFcNm/dnM2LiCg5mF/LBsM4MaB8CQF5RCf/31RpenrOR7QdzubhlII9OX4uvuzM/PHgRUQ19AZi0bBfPzkxg7vr99rpf/rmHTfuzGXdrZ1oFeQPQOMCTni0CmLYiift6t7D32bIsPvl9B6/9uIn2jXwZ0D6E13/azA0fLuXl69rx/KwENu/PYsy1UdzRo8lpv+e5QmFWRERERKSGTV6+m7ScIh7qU3lU7e/ILijmlTkbiWnizw01NH33ZCzLYvLy3XyzMpmTzeksKLaxJTWHAe1DePPGDsTtTOf28XF89sdO7r+0RaXyxbZS3pi3mWXb0+zXgnzceGlgW/tU3EnLd7M5tSzsTVuRxDu/bOGaDiF4uzrz0uxEIoK8eXdIR9YmZ3L3pHhu/ng5bs4OjL2lM1e1C6HYVsrzsxIYt2g78xL24+VWFoHqebgw5toomhwzbTmnsIQxsxLYfJzdhLcfyMHD1Ymv7+5OhzA/+3UPFyc+vKULb8zbzNiF25kat4cOob58cns0DY6ZJjysa2OmxiXx8pxELo2sT16RjTfnbaZXy0D6RgVXeNaQmHAenLqaP7Yd4uJW9SkqKeXZGRv4Kj6JAe1CeOPGDri7ONImxJf7vlzJTR8tw9vVifHDY+h9gWwcpTArIiIiIlKDtqZm88KsBEpKLWKb+tO9eUCNtJt8OI8RE+LZnJrNzDV76dEigBBf9xpp+3iKbaW8MCuBL//cQ7tGvgR6uZy0zuAuodx1UTMcHAwXt6pP36gg3v9tK9d1akQjv6P9zcwv5oEpq/h96yG6NfPHvXzkdum2Qwz84A8+vT2GYF833pq3xR72IoJ96Pv2Yl7/cTON6rmTkpHPtFHdcHJ0oEvjesy4vyfv/bqVW7s1pn1oWdh0dnTgleva0rahL78k7rc/f3VSBteNXcK4W7vQrVkAKRn5jJiwgq0HcujZIhDHKgZwm7UJ4vF+kTT0q/y9OzgYHu8XSUSwN+uTMxndN6LSaLSjg+HFgVEMHreMDxZs41B2EXlFNp6/Jso+7fiIK6OCqOfhzNS4su/+nskr+XNnOv+8rAUP92llH629qGUg39/fk3ELtzPy4mb20d0LgdbMnmMupHcVEREROddYlsWtn/3J+uRMvN2c8XJ1YvY/L7Kv8QQoLbWqnOpqWRZ5RbYq203cl8W9k1dSWFLKswPa8OzMDVzRJoj/DetcoVxBsQ1bac38fp9bVMIjX63lj22HuOeS5qc9RTcpPY8+by3i8tYN+O/gDgDsyyzg7knx7EnP45Xr23HTMetZN+3PYsSEeNJyC2nb0Je1yRn89PDFNK/vBcB/ftrE2IXbcXF0oF/bYN4b2um03m93Wi53TljBnvQ87u3dgil/7qGw2MYHt3Tm4lb1T6vN6nrkqzX8sG4vxTaLURc346mrqv79/pU5iXy+ZBeN6rmzL6OA/wxuz3WdGtVq384GWjMrIiIiInKG/bhhP0u2pfHSwCiCfNwYNWklk5bt5s7yNZ5fxycxZlYCd/VqxsN9WtpH49Jzi7jvy5Us35F+3LYbB3gwbVQMLRp4sS+zgLfnb2FY10P0aB5IaanFf37ezMeLt1NDWRYAZ0fDfwe3/1ubJ4X5e3Bf7xa8PX8Lc9cfHRn183Bm0oiudGtWceQ6MtiHGff3ZNSkeOJ3H+buS5rZgyzA/Ze24LtVKWQVFB83BFZH4wBPvruvJw9MWcV7v24lzN+dqSO70vIMjGw+0T+SeYmp1PNw5MHLKk+/PmJIbDif/L6TnIISpozsSnQT/1rv27lEI7PnmAvpXUVERETOJXlFJfR5cxG+Hi7MfvAiHAzc8fkKVu8+zK+PXsJnS3by0aIdNPR1Y29mAdd0aMh/B7cnKT2POyeuIDWrkLsvboa3W+XxJhdHBwZ2bEQ9z7JpvgXFNvq8tQgPF0em39ODx6avZV5iKtd1bEibhj419k7dmwXSLtT3b7dTVFLKjNUpZOSXHWXjYAx9o4IJ8/c4bp2CYhvzElO5sk1Qpem6Ow7mkFNYYp9K/HcU20qZs24fF7eqj7/nyadR15QNKZm4OTvSooHXCcst2nKQlg28qpzafL6q7siswmwNyMjIYMqUKdx3332nXPedd95h1KhReHgc///Ix6rrdxURERGpyvrkTNo09MHxFKahrtx9mMO5R8/p7BjuR6CXa4UyxbZSEvdm0T7Ut9KawmNl5heTmlVQ5XrBxL1ZNAn0OOFRJKWlFst3pNmn+To4QGzTALxcqz+R8Y2fN/O/BduYfk93YspH0LYfzKHfO4vxdnMmPbeIW7uF8/w1UXz2x05e/2kTrYN9SErPw9XZkY9v73JK56HOS9jPqEkr8fd0ISOviGevbsPwHk1O+D2JnAs0zfgMysjIYOzYsacdZm+99dZqh1kRERGRs80viamM/CK+2seBlNhKeWl2IhOX7a5wPdDLhY9vj7YHuoy8Iu6dvIplO9K4oXMorw5qi6tT5eNdtqSWHZeScjifpwe04c6eZYGutNTi7flbeP+3bUQEefPpHdFVjgTmFpbw8Fdr+CUxtcL1ZvU9GX9HTIXdbqtiWRaf/bGTDxZu4/pOjexBFqB5fS9GXdyMDxdu54Vr2nBHedi855LmNA305OFpa2gc4MFnw2MqbI5UHVe0CeKyyAbE7Uzns+ExXHqB7GArcoRGZmvAkCFDmDlzJhEREVxxxRU0aNCAr7/+msLCQq6//nrGjBlDbm4uN910E8nJydhsNp599llSU1MZPXo0ERERBAYGsmDBgpM+q67fVURERORYBcU2rnh7EUnp+UQEefPTw71OODKYVVDMA1NWs3jLQe66qCkDO5ZtZpNdUMyT369nX2YB/x3cnnaNfBkxMZ6Uw/n0bxfMzDV7iW3iz7jbulSYCrpw8wEenLIaV2dH2jbyYeHmgwzrGs6T/SP517frmLt+P32jgli6PQ1XJwc+ui2aLo2Pjn7uzchnxMR4Nu/P4sn+re3rN/dm5vPEt+uwwL7bbVWKSkp5buYGpq1I4qp2wbx5Y0fcXSoGbsuyOJRTRH1v10r103IK8XJzqjKkV0dhiY2ColJ8PZxPq77I2ejCHZn98QnYv75m2wxuB/3/fdzb//73v9mwYQNr1qxh3rx5fPPNN8TFxWFZFtdeey2LFy/m4MGDNGzYkDlz5gCQmZmJr68vb731FgsWLCAwMLBm+ywiIiJnnGVZTFi6i75RwRfM+raPFu0gKT2f6zo2ZMaavazak1EhLG5IyeT71SkcGT9ZtOUAu9PyeP2GdtwcE16hrRn39eTuySt5aNoaPFwccXN25MuRXYlp4s/lrYMYPX0t132whD6tg4CyEdXpK5OICPbh0zuiCfFxs5/zOXN1CnnFNp66KpKRvZqx/WAuIyauYOgny7kpOhQXR0csLGav20dBka3S2ZztQn2JDPbmzgkruO2zP7kxOgy3KgLn2uQMVu4+zAOXtuCRK1pVuduvMabKIAsQ4FX19epydXI87SAscq47/8JsHZs3bx7z5s2jU6eyLcJzcnLYunUrvXr1YvTo0fzrX//i6quvplevXnXcUxEREalp61MyGfNDIr9uPMCkEbHn/drFpPQ8xi7cxoD2Ibx8fTvmJaYyLW6PPczmFpYwYuIKDucW4+pUdjSNn2fZDrZVnb1az9OFySO68sIPCSTuzeK9IZ0IDyibFnxth4aE1XPnka/XMj0+yV6nf7sQ/nNDezzL17Y+3i+SZvW9+GDBNp66qjVXtCkLvi0aeDHjvp7839drmLl6r71+o3ruvHdXpyrX2h7Z7Xb09LX8sGZvpfsAbi6OvHVTBwZ1Dj2dr1BE/obzL8yeYAT1TLAsiyeffJK777670r2VK1cyd+5cnnzySa688kqee+65OuihiIiI1JZfNx4A4I9th/g5YT/92obUcY9q1ytzNuJgDE9f1RovVycGdmzIjNV7ee6aNni7OfP+b9tIzSrk23u706Vx9Y4UcXFy4NXr21V5r1N4PRaM7n3SNgZ3CWVwl8rhsp6nCxP+EVutfhzh6+7MJ7efdLajiNSB8y/M1gFvb2+ys7MB6Nu3L88++yy33HILXl5epKSk4OzsTElJCf7+/tx66614eXkxYcKECnU1zVhERC50JbZSHv9mHR3D/bitW+MaHdU8lFPIczM38MClLU94bMlPG/YzNW4Pz17dmhYNTv2syd82HaBjmB8FxTZemr2RS1o1qLR+8q8Kim088vUadh7Ks1+7oXMj7urV7JSffyIHs8u+g9im/pV2vP1uVTKfL9lFySkcUGpZFpv2Z/NY3wj7lOohMeFMjUti5pq99GgewGd/7OCGzqHVDrIiIqdCYbYGBAQE0LNnT9q2bUv//v0ZNmwY3bt3B8DLy4vJkyezbds2HnvsMRwcHHB2dubDDz8EYNSoUfTv35+QkJBqbQAlIiJyvpq0fDffrU7hu9UpbNqfzZhro3B2dKiRtv/z0ybmrt9P8uF8ZtzXs9K6Rsuy+HDRdv7z02aMgevHHmbsLZ3p1bJ+tZ+RmlXA+pRMHu8XQZfwetz88XI+XLiNR66MOGG9cYu2M3f9fi6LbICjg2FLajbjFm3nzp5Nq1x/eTo27c9ixIR49mbm8+OG/WxJzebFgW1xNIb/ztvMhwu30zrEh9B6p7bOt1uzAO7q1dT+uX2oL61DfJgat4dfElNxc3LkX/1P/P4iIqdLYbaGTJkypcLnhx56qMLn5s2b07dv30r1HnzwQR588MFa7ZuIiMjZ7mB2IW/N20KvloG0beTLhwu3szstl7HDuvztXVpX7znM1/HJtA/1ZV1yJl/HJzEk9ujGQ4UlNp78bj3frUrhmg4NebhPS+7/chXDP1/BC9e04doOjaps19PVEadjwvaCTWVTjC+PDCIi2JuBHRsybvEOrmofQohPWUj0cHWsENCT0vP4cOF2runQkPeHlu23MXNNCg9NW8O6lEw6hvkd972KSkrJLz8T9UTidqXz8LTVeLk5MeO+nvycsJ+xC7ez61Aevu7O/JSwn6Gx4bw48O//8cAYw9DYMJ6bmQDAs1e3oYG3299qU0TkeBRmRUREpM7956dNFJTYeOHaKJrX96JZoCdPfb+eeyavZOqobqfdrq3U4rmZCTTwdmXKyG7c+fkKXv9pE/3aBuPn4UJ6bhF3T4pnxa7DPNynJQ9d3hJjDN/c24N/Tl3NszMTeLY8mP1VqyAvZt5/kX0a8a+bDtDIz51WQV4APNm/Nb8kptLvnd/tdQK9XPnots72abcvzU7E0cHw1FWR9jKXtKqPg4HfNqYeN8z+sfUQD0xdRUZecbW+h7aNfPj09hiCfd3oEOZH8/pePPHdOmylFs9effRc1powsGMjXp27kXB/D27v3rhG2hQRqYrCrIiIiNSpVXsOM31lMndf0ozm9cuC4I3RYaTnFvHaj5vYkppd5U6z1fF1fBLrUzJ5d0hHvFydGDMwigHv/c5bv2zhtm6NuXPiClKzCnlvaCeu7dDQXs/L1YlPbo9m1toUDudWDoyZ+cW8++tW+zTigmIbf2w9xI3RofZQGOzrxtd3dyduZzoAFjBp2S6Gfvwn/xncHj8PZ+YlpvKvfpGE+B6d3uvn4UJ0Y39+3XSgyinKk5fv5vlZCbSo78WDl7XkZBHU3cWRgR0b4uFy9Ne+G7qEEhniTUGxrcbXs/q6O/PFnV0J8nGtsWniIiJVUZgVERGRSoptpaxNKjsv9EQjdgXFNvZm5NOsPIRWR1ZBMcu2p2GVHzz6/m/bCPJx5cHLWlYoN7hLKG/M28zUuD08f01UtdpOzSpg9Z7DAJRaZSO+sU387UG1dYgPt3dvwhfLdvH9qhRcnR2ZNqobncPrVWrL0cFwfafjH7eyKy2XcYt3cEOXUHYeyiW/2MZlkQ0qlGnbyJe2jXztnwd1asQ9k1fy8Fdr8HFzolmgJ3de1KRS25e1bsC/f9zEvsx8e9C1lVq8NDuRCUt3cVlkA94b2gkv19P/VS6qoe/JC52m2Kba8ElEat95E2Ytyzrvz3I78h99ERGR2pSRV8S9k1exbEcaV7cP4Y0bO+DmXPWOvA9MWcWiLQf58aGLadHg5IF2x8EcRkyMZ+ehXPs1Y+D9KoJZgJcrV0YF8/3qFP7VL/K4fTjWg1NWE7cr3f7ZxcmBMQOjKvyO8H9XtGLu+n34e7rw2fAYGvmd2qZHRzx1VWvmJ6by0uxEGvq54+7sSLdmlc9OPVY9TxcmjejKMzPWM31lMu8P64yrU+X3ujyyLMz+tukAt3Qtm6o7adkuJizdxZ09m/L0gNY41tDmUCIi56rzIsy6ubmRlpZGQEDAeRtoLcsiLS0NNzdtoiAiIrXnSNhMOZzPDZ1D+W51MkmH8/nk9i6VNvL5bVMq88vPVR3zQwJf3Bl7wv8OL91+iHsnr8LRwfDp7dE0Kt8518vViTB/jyrrDIsNZ866ffycsJ+BHaveiOmIbQeyiduVzr29m9tHYgO9XKnv7VqhnK+7M/MfvQR3Z8e/NQ02yMeNf17ektd+3IS7syMXtQysVuB2cXLg9Rva82T/1tTzdKmyTIsGXoT5u/PbxrIweyinkDd/Kdsg69mrW5+3v++IiJyK8yLMhoaGkpyczMGDB+u6K7XKzc2N0NDjT3cSERH5O5ZuO8S9X5aFzSkjuxLdxJ8ro4J4eNoarvvfEj69I8Z+RmtBsY0xPyTSvL4nQ2LCeWXuRn5OSKVf22CgbKfd8Ut2si8jv7x8Kd+uSqZpoCef3RFDeEDV4fWvujcLINzfgyl/7rGH2Yy8IqbE7WFYbDh+HkfD4NS4JJwdDSMuakqgl+vxmgTAx+3v7ZB8xD96NuWr+CR2HMzl8r9MMT4RY8xxg+yR+5dHBjE1bg/5RbayDbKKyzbIUpAVESlzXoRZZ2dnmjZtevKCIiIiUqWpcXt4dsYGmgZ6Mn54jH2ktG9UMNPv6c5dE+MZPG4p7w3pRJ82QXz2x052p+UxaUQs3ZsF8O2qZF6ancglrepTWGLjnskrWb4jHV93Z45kr8tbN+C/N3Y4pSDp4GC4OSaM//68mR0HcwDs05R3HszlvzevYqoHAAAgAElEQVR2AMrC9XerkrmiTdBJg2xNcnFy4NXr2/HCrAT6tAmq0bYvi2zAhKW7+HDhNr6Or7hBloiIgDnX1mFGR0db8fHxdd0NERGR84Kt1OK1uRv59I+dXNKqPu8P61Rl2EzNKmDkF/GsT8nkvt7N+eyPnfRu1YBxt3UB4M8dadz88XJuig5lxa7DpBzO5/XB7U64gVJ1HcgqoPu/f6NXy0BW78nA0cHQtak/P27Yz3f39aBzeD372ayTRsTSq2X9v/3Ms0FhiY1OL/5CXpGNBt6u/Da699/a8ElE5FxhjFlpWVb0ycrp34giIiIXkKyCYh6aupqU8um/eUU2kg/nM7xHE54Z0Bqn46whDfJx46tR3Xl0+ho+WLAdVycHnrm6tf1+12YBDOzYkK/jkwnwdGHqqK41duRLAx83+rRuwM8JqbRs4MX44TH4e7qwas9hnp+ZwIz7ezItLokwf3d6Ng+skWeeDVydHLmoRSDzElN5ekBrBVkRkb/QvxVFREQuIO/8spWFWw5yZZsgHMrn/z50eUtujA47aV13F0f+N7QzExrvooGPK6H1Kq57fWZAGwI8XflHzybH3dDpdD3WN4ImAZ7cf1kL+8jx0wPa8M+pq3n9p00s25HGY30jcDjPdvi979IWRIb4VDgDV0REymiasYiIyBlkWRZpuUX2z54uTri7VN4Bt6iklKyC4irb8HBxxMOl8t+j/1rHx80ZF6ejI61bUrPp/+7v3BQdxmuD2v2d1zgrWJbFkI+X8+fOdBwdDMueuIwGPtr1X0TkXKdpxiIiImcZy7J4YMpq5qzfZ7/m7uzIGzd2YED7EPu1VXsOc/eklRzMLqyyHVcnB14b1I5BnY+uR92QksnIL+LZl1lgvxbk48pHt0XTMcwPy7J4fmYC3m5OPN43ohbe7swzxjBmYBQD3vuDyyIbKMiKiFxgFGZFRETOkPkbDzBn/T6GxobRJqTsiJsZa/Zy/5RV7DjYigcua8GstXt57Jt1hPi6MebaKKqaNTtn/T4e+Xot2w/m8OgVEcxL3M//fbUWf08XXrimDY4OhlILPv1jBzd/tIw3buyAMbBsRxovX9f2hEfCnGsig32YcldXGgd41nVXRETkDNM0YxERkRqQW1jCtgM5dAjzq/J+QbGNK95ehJuTI3Mf6oVz+UZLhSU2nvh2Pd+vTqFDmB9rkzKIberPR7d2OW7oLLaV8uyMDUxbkUSHUF/WJmfSKdyPj2+Lpr730WNp0nIKuXvSSuJ3H8bL1YnGAR7MeuAiHM+zdaUiInJ+qe4046q3LBQREZFT8vYvWxj4wRJW7j5c5f2PFu0gKT2fMddG2YMslO1Y+9ZNHRh9ZSvWJmUwuEsok0d0PeHoqbNj2TTjZwa0Zl1KJtd2aMjUkd0qBFmAAC9XvhzZlUGdG1FQbOPFgVEKsiIict7QyKyIiMjfVFBso9trv5KRV0y7Rr7MuL9nhdCYlJ5Hn7cW0adNEB8M63zcdjLyivB1d8aY6gfO6tSxLIvswpIqz48VERE522hkVkRELhilpRafLN5B4t6sWn1Osa2UTxbvYEtqdoXrPyfsJyOvmJujw1ifkslXK5Ls90pspbwwKwEHY3j6qtZ/bbICPw+XUwqy1a1jjFGQFRGR847CrIiInPOmr0zilbkbueHDpfycsL9WnpGRV8Qd4+N4Ze5GHpiyimJbqf3e1Lg9hPm789qgdsQ29ec/P2/icG4RWQXFjJgYz6+bDjC6bwQN/dxrpW8iIiIXIoVZERE5p2XmFfP6T5vpGOZHq2Bv7pm8knGLtlOTy2h2HMzh+rFLid91mGFdw9mSmsMXy3YDsPNQLst3pDMkJhwHB8OYa6PILijhmRkbGPzhUpZsO8Rrg9ox4qKmNdYfERER0dE8IiJyFrMsixdmJfD71kP2a83qe/LaoPb2zY7e+mUzGXlFTBoRS/P6Xjw6fS3//nET2w/k8Mr17XBxOvp320VbDvLBb9sY3TeC2Kb+1erDkSDr6GD4cmRXohvXI+VwPu/8soVrOoQwbcUeHB0MN3YpO/O1dYgPt3VrzISlu/Bxc+KLO2Pp0SKwBr8VERERAYVZERE5i/2ckMrEZbvp0TyAAC9XSi2LXzemct0HSxg/PAZbqcWk5bu5tVtjohr6AvD+kE40r+/Fe79uZXd6HuNu7YK/pwsTl+5izA8JGGO45dPlvDaoPYPLA+jxWJbF87MSKC21mPVAT/tZps9f04a+7yzm5dkbWbr9EJdHNqCBj5u93iNXtsLV2YGbosNoXt+r9r4gERGRC5jCrIiInBUKim24OTvaP+cX2XhpdiIRQd58cWcsTuXH2axLzuCuifEMGruEhn7u+Hm48MgVrez1HBwMj1zRimaBnjz+7TquH7uE2Cb+TF+ZTJ/WQbw4MIrR09cyevpath/M4bErI3A4znE18xJT+X3rIZ67uo09yAI0q+/FXb2a8eHC7QAMjQ2vUM/HzZkn+594sycRERH5e7RmVkRE6lSxrZRnZ2yg3Qs/M3n5bvv1DxdtJyUjnzEDo+xBFqB9qB8zH+hJk0BPth7I4fG+Efh5VD6T9bpOjZg6shu5hSVMX5nMqIub8dFtXWjo587EO2MZ1jWcDxdu574vV5FXVFKpfkGxjRd/KAvTt3dvXOn+A5e2INjHjYa+blzcqn4NfRsiIiJSXTpnVkRE6kxmfjEPTFnF71sP0by+J9sP5vKPnk24vXsT+r6zmH5Rwbw3tFOVdfOKSlix6zC9WgQed2QVYH9mATsO5lRat2pZFp8v2cXLcxJp09CHT2+PIdj36FTht3/Zwru/bmXqyG50bx5QZdvbDuRgK7WICPY+jbcXERGRqlT3nFmFWREROWM2pGSy7UAOALZSi7ELt7EnPY9XrmvHoM6NeHXuJsYv2YmXqxOllsVvj/auEDBrw4JNB3hw6mo8XR155IpWuDo5UlRSyjMzN9A3Kpj3jxOmRUREpHZUN8xqzayIiNS6Y0dBS4/5G6qfhzOTRnSlW7Oykc/nrmlD8waePD8zgSf6R9Z6kAW4NLIB397bgzsnrOBf366v0Lenroqs9eeLiIjI6dHIrIiI1KpiWynPz0pgyp97uLJNEI/3i8SxfFpwfW9XvFwr/101t7AEzyqu16aCYhv7MgvsnwO9XPB2cz6jfRARERGNzIqInNV+WLsXH3dnLjlLNg6asGQnnRvXo32o399ua/P+bCYu20WJrRSALak5rEnK4N7ezU+4c/CxznSQBXBzdqRpoOfJC4qIiMhZQWFWROQMyy4o5vFv1lHPw5nf/3WZfZSyrmw7kMMLPyTSOMCDnx++uMLxOKfqt02pPDhlNRbg6142quns6MAbN3Y46ZmuIiIiIqdCYVZE5AybuWYv+cU28jNtLN5ykEsjG9Rpf6bF7cHBwO60PD77Yyf3X9rilNuwLIvP/tjJq3M3EtXQl09ujz4j611FRETkwqVzZkVEzrBpK/YQEeRNgKcLU+P2VLi3cV8WN41bxrLtadVub9uBHG777E/7LsGnorDExrerkunXNph+UcG8/9tWUjLy7fcnL9/NTeOWsTU1+7htFNtKeer7Dbw8ZyNXtgnm67u7K8iKiIhIrVOYFRE5g9YnZ7IhJYtbuoUzuEsov246wIGssk2HSkstnv5+PXG70rntsz/5ekXSSduzLIvnZm7g962HeG7mBk51U795CakczitmSEw4z1zdGoBX52ykxFbKC7MSeGbGBlbtOcygsUtZtOVgpfqZecXcMT6OqXF7uK93c8be0hl3l9OfpiwiIiJSXQqzInJeyS0sqbW2D2YXknw4j+TDeRzILqiyjGVZFJbYjtvG1BV7cHN2YGDHRtwcE4at1GL6ymQAvludwqo9GTx7dRu6Nw/g8W/X8drcjdhKjx9Q567fz9LtacQ29Wfp9jTmrt9/3LKWZZFXVPH7mRq3h9B67lzUIpDQeh7c37sFc9bvY9CHS5mwdBcjezVlwejeNKrnzp0TVvD5kp3272BdcgbXj13Cil3pvHljBx7vF1mtzZ1EREREaoLCrIicNzbuy6Lji/OYuSalxtv+asUeYl+dz0WvL+Ci1xcQ+8qvTFq+u1K5p77fwOVvLiKroLjSvdzCEmat2cuAdg3xdXemWX0vujXz56sVSWTmFfPvHzfSKdyPf/RowufDY7itW2M+WryDeyavrDKk5xWV8PKcRNqE+DB5RFfahPjw8pzESoH1yLNHTVpJ55d+Yc66fQDsTstl6fY0hsSE2UPoyIubEe7vQeLeLF4b1I6nB7QhzN+Db+7twaUR9RnzQ6L9O7j2f0vIyC9myshu3KDNnUREROQM0wZQInLe+PLP3RTbLF6avZHLIhvU2Bmh6blFvDp3E53D63FzTBgA36xM5j8/bqJvVBANvMvWh67YlW5fA/ve/K08c3WbCu3MXreXnMIShsaG2a8NjQ3noWlr+MeEONJyi/h8eCwODgYHDC9d15bm9T15cXYig8ct47M7omno526v+8GCbezLLOD9oZ1wcXLgxYFRDB63jA8WbOOxvpH2cnsz8hkxMZ7N+7NoVt+L+6esYsfBVuQW2XB0MNwYfbQ/bs6OfHlXV3KLSogM9rFf93J14qPbovklMdUe1A1wUctAQnyP9klERETkTFGYFZFzzr7MfAqKSyucCZpXVMKM1XvpEObHuuQM3q0iTB5RUGxjXmIqhcVl04GdHR3o1zb4uEfS/PfnzeQWlvDvQe1oGeQNQEwTf/q+vZjXf9zMmzd1wFZq8dzMBBr6utG1WQCfL93FTTFhtCovb1kWU+OSaNHAiy6N69nb7hsVjJ+HM6v2ZDCsazjtQn0rPHt4z6Y0DvTkwSmrGfjBEh7u0xIXRwcKS0r5ZPFOBnVqRHQTfwCim/hzfadGfLJ4JyG+7rg6lZV799etFBTZGD88hm7NAnji23W8+csWHAxcFhlEkE/FzZrC/D2q/B4cHQz92gYf938XERERkTNJYVZEzikFxTZuHLeMnMISFjzam3qeLgDMXrePnMISnr6qNd+vTmbC0l3cHBNmD5/HGvNDAlPjKm6u9K/MSO7t3bxS2XXJGUxbsYcRPZtWaKtpoCcjejXlw4XbGdY1jMS9WWzcl8UHwzrTvXkAv206wAuzEvjyrq4U2yyembGeNUkZjLk2CmOOrit1c3ZkaGw40+OTeezKiCrf+dKIBnx7bw9GTFzB099vsF8P8HThif6RFco+2T+SxVsO8syMo+XC/N358q6u9mD99s0dadHAi3fmb+UfPZsc76sWEREROauZU935sq5FR0db8fHxdd0NEakj787fytvzy0YVh8aG88r17QAYNHYJmfnFzH/kEg7nFXPpGwtp26hsLemx4XFtUgbXjV3Cbd0aM7JXMwD+76s1HMopZMHo3hXKlpZaDPpwKcmH81kw+pJK05ZzC0u4/M1F+Hk4sy+zgKiGPnx5V9nzJi3bxbMzE3j5urb8sHYvf+5M55+XteDhPq0qbZJkK7UoKik96S7AhSU2DmQV2j/7e7rg6Vr5b5K5hSWk5xbZPzfwccXVqXLbBcW2445Gi4iIiNQVY8xKy7KiT1auVjeAMsb0M8ZsNsZsM8Y8UcX9xsaYX40x64wxC40x2kFE5DxnWRYfL97OlhOcWwplgeyteZtJSs+zX0tKz2Pswm0MaB/CHT2aMCVuDxtSMtm8P5tVezIYGhuOMQZ/TxdGX9mKJdvS+HbV0c2gSkstnpuVQICnK4/1jSDM34Mwfw+GdQ1nV1oey3ZUPNv1m1XJrEnK4KmrIqtcf+vp6sTTA1qzaX82uYUlFUZdh3VtTJsQH56ZsYHVezJ45+aOPHJlRJW7/To6mGodZ+Pq5Gjvc5i/R5VB9ki/ji1XVZAFFGRFRETknFZrYdYY4wh8APQH2gBDjTF/XcD2BvCFZVntgReB12qrPyJydliXnMmrczcxuYqdgI/1dXwS7/22jYEfLCF+VzoAL89JxMEYnr6qNQ/3aUWApwvPzdzA1Lg9uDg6MKjz0b+HDevamJgm9Xjsm7V8vHg7lmXxzcpk1lYRTq9qF4KPmxPTjpl6nJlfzOs/biK6cT2u79TouP28un0IQ2PDeKJ/ZIVpyI4OhtcGtSOmST2mjurKdSdoQ0REREROXW2umY0FtlmWtQPAGDMNGAgkHlOmDfB/5T8vAGbUYn9E5CxwZLffE43Mlm2WtIeWDbwoKbUY9smfDOsazs8JqTzWN8K+o++/+kXy2DfrWJOUwVXtQvAvXz8LZWHyizu7Mnr6Wl6du4nN+3NYuPlAleHUzdmRQZ1DmfLnHtJzi/D3dOHtX7ZwOK+ILwbGVph6/FfGGF4b1L7Kex3C/Jh+T49qfzciIiIiUn21Oc24EXDsDivJ5deOtRa4ofzn6wFvY0xALfZJROpQTmEJs9buBWBras5xy63ak8GW1BzuvKgp39/Xgy6N6zFh6S6aBHhwV6+m9nI3dA6lU7gfpVbZ+tm/cndx5P2hnfjnZS34dlUyh/OKGDMwqspwOiQ2jCJbKd+tSmbjviy+WLaLW7o2Jqqhb6WyIiIiIlL3anNktqqhjL/uNjUa+J8xZjiwGEgBSio1ZMwoYBRAeHjlX1hF5Nzww9q95BXZuLp9CLPX7eNQTiGBXq6Vyk2L24OniyPXdGiIl6sTX4yI5dPfd9KrZWCF9Z8ODoY3b+zA3PX76N6s6r+DOTgYHrkygqhGvuQWlhw3nEYG+9AxzI9pK5KYl5iKr7szj17ZqmZeXERERERqXG2OzCYDYcd8DgX2HlvAsqy9lmUNsiyrE/B0+bXMvzZkWdbHlmVFW5YVXb9+/VrssojUpqlxe4gI8ubmmLJ/NVQ11TiroJjZ6/ZxbceyIAtl58De27s5bRtVDqLN6nvxwGUtq9xY6Vh9o4IrrKmtyrDYcLYdyCFuZzqP94vEz8PlhOVFREREpO7UZphdAbQ0xjQ1xrgAQ4BZxxYwxgQaY4704UlgfC32R0TqUMLeTNYlZzI0Nsx+3umW/ZXD7Mw1e8kvtjEk5szPwri6Qwjerk60a+TLTdFhJ68gIiIiInWm1qYZW5ZVYox5APgZcATGW5aVYIx5EYi3LGsW0Bt4zRhjUTbN+P7a6o+I1K1pcUm4OjlwfadQfNyd8HV3ZsuByutmp8XtoXWID+1Dz/xaVQ8XJ76+pzsBni44nmSkV0RERETqVm2umcWyrLnA3L9ce+6Yn78BvqnNPohI3csrKmHG6hSuaheCr0fZkTitgrwqjcyuT84kYW8WLx1nk6YzoXWIT508V0REREROTW1OMxYRIS2nkNs/iyO7sIRbuzW2X28V5M2W1Gws6+i+cDPWpODi5MC1HXUmq4iIiIicmMKsiNSaLanZXDd2CetTMvlgWGe6NK5nv9cqyJusghIOZBfar/226QA9mgfg6+5cF90VERERkXOIwqyI1IqFmw9ww9ilFBSX8vXd3RnQPqTC/ZZBXgBsLp9qvONgDjsP5XJ5ZIMz3lcREREROfcozIpIjZu4dBd3TlhBqL8HM+/vSYcwv0plIo7saFx+PM9vmw4AcKnCrIiIiIhUQ61uACUiF5YSWyljfkhk0vLd9GkdxLtDOuLpWvW/ZgK8XAnwdLGH2V83HiAy2JvQeh5nsssiIiIico5SmBWR07Z5fzaPTl9DalbZuteiklIy84u5++JmPN4v8qTH27QM8mJLag6Z+cWs2JXOqIubnYlui4iIiMh5QGFWRE7Lgs0HeHDKatxdHOnTOsh+vWeLAK5u37BabUQEefPNymQWbzlISanF5a01xVhEREREqkdhVkROiWVZfL5kFy/PSSQy2IfPhkcT4ut+Wm21DPImt8jGpOW7qefhTMeweievJCIiIiKCNoASkVM0Y00KL85O5PLWQUy/p/tpB1mAiOCyTaDidqZzaUSDk05LFhERERE5QiOzIlJt2QXFvDJnEx3C/Bh3a5e/HT5bNfC2/3yZphiLiIiIyCnQyKyIVNu787eSllvISwOjamQU1dfDmQberjg5GHq1rF8DPRQRERGRC4VGZkWkWrakZvP50l0MiQmnfWjlc2NPV7dmARQU2/B1d66xNkVERETk/KcwKyInZVkWL8xKwMvVicf6RtRo2+8O6Yhl1WiTIiIiInIBUJgVOQ+l5xbxwYJt3NatMU0CPY9bbuO+LD5evIPCEhsALo4OPHh5S5rX96pQbu76/SzdnsZL17XF39OlRvtqjMFo3ycREREROUUKsyLnma2p2dw5cQVJ6fmsT8nkq1HdMFWkxfmJqfxz2mqcHAxBPm4ApGTks/NQLt/f1xOH8jWxeUUlvDwnkTYhPgyLDT+j7yIiIiIicjzaAErkPLJoy0EGjV1KflEpw3s0IW5nOrPW7q1QxrIsPv19ByMnxdOigRe/PHKJ/Z9Xrm/L2uRMpq9Mspf/YME29mUW8GINbfokIiIiIlITFGZFzkK/bkxlwHu/syYpo9p1Fmw+wJ0TVtConjszH+jJs1e3oV0jX16du5GcwhIAikpKefK79bw8ZyP92wbz1aju9lFZgOs6NiKmST1e/2kzmXnF7DyUyyeLdzKocyOim/jX+HuKiIiIiJwuhVmRs0xuYQlPfb+ehL1Z3PzRMmav23vSOgXFNp6buYFmgZ58c28PGvm54+hgGDMwitSsQt7/bSsZeUXcMT6OaSuSeODSFvxvaGfcXRwrtGOM4YVro8jIK+KtXzYz5ocEXJwceKJ/ZG29roiIiIjIadGaWZGzzP8WbCM1q5BPb49m3KLtPDBlNdsO5NCvbbC9TLNAL1ycjv4t6qNFO0hKz2fKXV3xcj36f+vO4fW4sUson/2+k5827GdfRgFv3dSBQZ1Dj/v8qIa+3NqtMROX7QbgmQGtaeDtdtzyIiIiIiJ1QWFW5Cyy42AOn/6+g8FdQunTJoherQJ58tv1vDN/K+/M32ovFxnszWfDY2jk505Seh5jF25jQPsQerQIrNTmv/pH8lPCfrILSpgysmu1pgs/ekUEs9ftI8DThTt6NKnJVxQRERERqRHGOscOeIyOjrbi4+PruhsiNc6yLO74fAWrdx/mt9G9qe/tar++bHsamfnFABzOK+a1uRtxdXbkk9u7MG7RdhZvOcSvj15CQz/3KtvenZaLh4uTvc3q2JuRj7uzI/Vq+CgeEREREZETMcastCwr+mTlNDIrcpb4OSGVxVsO8tzVbSqETmNMpRHXmCb1GDExnps+WkaxzeKxvhHHDbIAjQOOf9bs8ZyoPRERERGRuqYNoETOAj+s3ctD01YTGezNbd0bn7R8yyBvZtzfky6N6xEZ7M1dvZqegV6KiIiIiJw9NDIrUocsy+K9X7fx9vwtxDSpx7hbu+DsWL2/Mfl7ujBtVHdspZbOfxURERGRC47CrEgNyCsq4c15W0hKzzulemm5RazcfZhBnRvx2qB2uDo5nrzSXyjIioiIiMiFSGFW5G/an1nAXV+sIGFvFhFB3qdU1xjDU1dFMrJXM4xRKBURERERqS6FWZG/YX1yJnd9sYKcghI+uyOayyKD6rpLIiIiIiIXBIVZEWDmmhTenb+Vx/tF0K9tiP16Zl4xj05fy58706qsl1dkI9jHjW/v60FksM+Z6q6IiIiIyAVPYVYuaJZl8fb8rbz361Y8XBy5Z/IqHusbwX29m7MrLY8RE1eQlJ7H4C5huDlX3pjJw8WR4T2antL5rSIiIiIi8vcpzMoFq6DYxujpa5m9bh+Du4Ty3DVteOb7Dfz3582sScpgxa50DDB5RFe6Nguo6+6KiIiIiMgxFGblgnQgu4CRX6xkXXIGT/SP5O6LyzZgendIR5rX9+Lt+VtoXt+T8cNjaBzgWdfdFRERERGRv1CYlQtO4t4s7pq4gsN5xYy7tQt9o4Lt94wxPNSnJVe0CSI8wAMvV/1fRERERETkbKTf1OWcYSu1mLN+H92bBVRao7rzUC6/bkzFsk7cRl6RjY8Wb8fHzZnp93SnbSPfKsu1aajNnEREREREzmYKs3JOyC0s4aFpq5m/8QANfd349I4Ye+BctOUgD3y5iuzCkmq11THMj49u60KQj1ttdllERERERGqRwqyc9VIy8rlrYjxbUrN54NIWfLMymcHjlvLekE6kZOQz5ocEIoJ9+PCWzgRWY1dhTxdHjDFnoOciIiIiIlJbFGblrLY7LZcbPlxGYbGN8cNjuKRVfW7r3piRX8Rz1xfxAPRpHcS7QzriqfWtIiIiIiIXDP32L2e1T37fQVZBMbMfvIhWQd4ABPm48dWo7rw0J5FATxce6tMKRweNtIqIiIiIXEgUZuWslVdUwszVexnQLsQeZI9wd3Hk1evb1VHPRERERESkrjnUdQfk7Hb7+Di+WrGnTp49Z90+sgtLGBITVifPFxERERGRs5fCrBzX/7d353FunfW9x7+/kTT74rE9XuIlYwfHWwIhOLkpXEJIWkgCJaEtkFBKWApdoC23FMpSSkrbe9vbW1poAyUsbaA0AUqgaUhDIISU0KSxs5DdseOM433VLPbMaLQ8948jzWg0kkbS6Gj9vF8vvzw6OufokXR0pO95tvDpKf3ns8d0x+OHq/L4Nz/4gtYPdOnCdYur8vgAAAAAahfNjJHTs0fGJElPHBiRc66kEYDHp2J69sipgtY9e3m3OluD04/98AvD+viVmxl5GAAAAMAchFnklAqzJ05P6fDopFb2dRS1/e6jp/Tum7Zr74nxgtYfXNKpL7/jAp010K2bH3xBoYDpl85fVXS5AQAAADQ+wixySq9RfXz/SFFh9r5dx/VbX39IbcEWfeaa89TbHsq7/shEVH96+1N64w0/1d9ec55uffiAXrN1hZZ0zz9vLAAAAIDmQ5hFTjuPjGnzyl7tPDyqJw6O6jVbV0zfNzw+pZ/sOq7Xv3jlnGbAtzz4gj7+3Sf0ooFufem6bVqzuLOgx3vZmf1692+UZSAAACAASURBVE3b9a5/8uaPfeuFa8v3ZAAAAAA0FMIssnLOadeRMV1+zgrFEwk9cWBk1v1f/Mke3XDPcwq0mK48d+X08p2Hx/Tx7z6hl5+1RJ/71fPVM0+NbLo1izv17d96uT74zZ/p6FhEP7d+SdmeDwAAAIDGQphFVsdPTSk8HtWGZT2KxBL6ya7js+6/++mjkqQ/u/0pXbJxQJ2tQTnn9MnbnlBPe1CfvealRQXZlJ72kG58+7aSB5wCAAAA0ByYmgdZpQZ/2riiR+eu6tOxsYiOjk5Kkg4MT+iZw2O6fOsKHRyZ1OfueU6SdPtjh/TAnpP6g9dsVH9X64IenyALAAAAIB9qZpFVKsxuWN6t1qB3zePxAyO6rLddP3rGq5X90OUb1dEa0I3/uUdXnLtCf/69p3XOql5dS19XAAAAAD6jZhZZPXtkTP2dIQ10t2nLyl6ZeWFWkn709BENLunU+qVd+ugVm9QabNFbvvCADo9O6k/ecI4CLdSqAgAAAPAXYRZZPXvklDYs75GZqastqLMGuvXEgVGNT8X00+dO6NWblsnMtKy3XR/4+Q06FYnpV162Wi87s7/aRQcAAADQBGhmjDmcc3r2yJiuPm/V9LJzzujVA3tO6r92n9BULKHLNi2fvu+6lw+qtyOk16ZN3QMAAAAAfqJmFnMcHp3U2GRMZy/vnl52zqo+HR6d1Dd27FNXa0AXrls8fV8o0KI3b1ujvo7iRy8GAAAAgFIQZjHHs0dOSZI2LO+ZXnbuqj5J0g+eOqKLzx6YHhQKAAAAAKqBRII5nj3sjWR8dlqY3XJG7/Tfl25aVvEyAQAAAEA6wmwNOzA8obufPlLxx332yJiWdrdpcdpcsT3tIa1f2iUz6ZKNhFkAAAAA1UWYrWF/deczes9Xd2hsMlrRx3326CltXNE9Z/kvbF2uX9i8XAM9bRUtDwAAAABkYjTjGhWLJ/TjZ48p4aSHXxjWq84eqMjjJhJOu46M6c3b1sy576NXbK5IGQAAAABgPoTZGvXIvmENj3s1stufP1nWMJtIOH3+3uf0093H59wXizuNT8W1cUVPli0BAAAAoDYQZmvU3U8fVbDFdOaSTj04dLJs+x2fiun3v/Ez3fnkYZ2zqlcdocCcdV65YWnFaoIBAAAAoBSE2Rp1zzNHdeG6xdq8sldfe2CvIrG42oJzg2cxDo9M6te/ul1PHRzVJ16/Re96xaDMrEwlBgAAAIDK8XUAKDO73Mx2mtluM/tIlvvXmtk9ZvaImT1mZlf6WZ56se/kuHYeGdOlm5bpgsHFmool9MSBkazrOuf0uzc/ot//xqNyzuXc59hkVL/8+f/S88dO60vXbdO7/+c6giwAAACAuuVbmDWzgKQbJF0haYuka81sS8ZqfyTpm865l0q6RtLn/CpPPbln51FJ0mWbl+uCwX5J0oPPh7Oue+cTh3Xbzw7q1kcO6IdPH825z7/70W4dHJnQTe+6UJduWl7+QgMAAABABflZM3uhpN3OuT3OuSlJt0i6KmMdJ6k3+XefpIM+lqdu3P30Ua1f2qV1S7u0pLtN6we6tD1Lv9mJqbj+9PantGlFjzYs69anbn9Sk9H4nPV2Hx3TV+57Xm/ZtkbbBhdX4ikAAAAAgK8KCrNm9m0ze52ZFRN+V0nal3Z7f3JZuuslvc3M9ku6Q9LvFLH/hnQ6EtP9z53QpZuWTS+7cHCxdgydVCIxuxnx5368WwdHJvWpq87Rn7xhq/adnNAX7t0zax3nnK6/7Sl1tgb0oddurMhzAAAAAAC/FRpOPy/prZJ2mdlfmNmmArbJ1iEzs1PntZL+yTm3WtKVkr6WLTCb2XvNbIeZ7Th27FiBRa5PP919XFPxhC7dPBNmLxhcrNHJmHYeGZteNnT8tL5w7x5dfd4ZunDdYr38RUv1uhev1Od+vFv7To5Pr3fnE4d13+7j+oPXbtSS7raKPhcAAAAA8EtBoxk7534o6Ydm1icvgP7AzPZJ+qKkf3bORbNstl/SmrTbqzW3GfG7JV2efIz7zaxd0lJJszp/OudulHSjJG3bti33KEcN4K6njqinLagL0poDX7jO+3vH0EltXtmreMLp+n9/UqGA6aNXbp5e749et1k/evqoPvCNR/WKFy2VJH1rxz5tXtmrt164trJPBAAAAAB8VHCzYTNbIukdkn5d0iOSPiPpfEk/yLHJdkkbzGydmbXKG+Dptox1XpB0WXL/myW1S2rsqtccEgmnv75rp/71of16/UtWKhSYeWtW93doRW+7HhwK63Qkpt/42kP68c5j+uBrNmp5b/v0eiv7OvSx123Wz/YN67N379Jn796l8am4/uzqcxQM+DpwNQAAAABUlOWbzmV6JbNbJW2S9DV5zYIPpd23wzm3Lcd2V0r6W0kBSV9xzv25mX1K0g7n3G3J0Y2/KKlbXhPkDzvn7spXlm3btrkdO3YU9uzqxMRUXB/81qO64/HDesu2NfrTq89Ra3B2+Pydmx/R/c+d0EBPm3YeHtUnf3Grrnv5YHUKDAAAAAA+MbOHcmXMdAU1M5b09865H2W7I9+DOOfukDewU/qyP077+ylJryiwDA0pkXB625f/Ww+/ENbHr9ysX39l9vlfLxzs17//7KAi0bi+8o4LdMnGZVn2BgAAAADNodAwu9nMHnbODUuSmfVLutY5x7ywC3R4dFIP7Q3rQ6/dqPdcvD7neleeu1KP7R/Rey5er7OX91SwhAAAAABQewrtSPmeVJCVJOdcWNJ7/ClSczk6FpEkbVqRP6Au6W7TX73pJQRZAAAAAFDhYbbF0tq+mllAUqs/RWouR0cnJUnLetrnWRMAAAAAkFJoM+PvS/qmmf2DvIGaflPSnb6VqokcSdbMLutlDlgAAAAAKFShYfYPJf2GpN+SZJLukvQlvwrViManYhqdiGlF3+wa2GOjk2oxaUkXFd0AAAAAUKiCwqxzLiHp88l/KMHf/Wi3vvPwAT3wsctmLT86FtGS7jbmgQUAAACAIhQUZs1sg6T/I2mLpOmqRedc7uF3McuB8IQOj05qbDKqnvbQ9PIjo5Na1kMTYwAAAAAoRqHVgf8or1Y2JunVkr4q6Wt+FaoRjUxEJUkHhydnLT86FtHyXgZ/AgAAAIBiFBpmO5xzd0sy59xe59z1ki71r1iNZybMTsxafnQsQs0sAAAAABSp0AGgJs2sRdIuM3u/pAOSlvlXrMYzmgyzB9LCbCye0PFThFkAAAAAKFahNbMfkNQp6XclvUzS2yRd51ehGtHo5Nwwe+L0lJyTBmhmDAAAAABFmbdm1swCkt7snPuQpFOS3ul7qRqMcy5rM+Ojo94cs8upmQUAAACAosxbM+uci0t6mZlZBcrTkCaicUXjTpI3qnHKkVFvMKhl1MwCAAAAQFEK7TP7iKR/M7NvSTqdWuicu9WXUjWYVK1si2XUzI55NbP0mQUAAACA4hQaZhdLOqHZIxg7SYTZAqTC7ODSLg0dP61YPKFgoEVHx7ya2QHCLAAAAAAUpaAw65yjn+wCjIx7YXbzyl7tOXZah0cntbq/U0dGI1rS1apQoNBxuAAAAAAAUoFh1sz+UV5N7CzOuXeVvUQNKFUzu2Vlr7732CEdHPbC7LGxSWplAQAAAKAEhTYzvj3t73ZJb5R0sPzFaUzpYVaa6Td7dCyi5Qz+BAAAAABFK7SZ8bfTb5vZzZJ+6EuJGtDoZEyStGllj6SZuWaPjE5q4/KeqpULAAAAAOpVqZ01N0haW86CNLJUzeyynnYt7mrVgeEJxRNOx09NaVkvzYwBAAAAoFiF9pkd0+w+s4cl/aEvJWpAoxNR9bQHFWgxrVrUoQPhCZ08PaV4wtHMGAAAAABKUGgzY9rCLsDIRFR9HSFJ0hmL2rXn2GkdGfWm5WGOWQAAAAAoXkHNjM3sjWbWl3Z7kZld7V+xGsvsMNuhg8MTOjYWkSQN9FAzCwAAAADFKrTP7CedcyOpG865YUmf9KdIjSc9zK5a1KHTU3E9e2RMEjWzAAAAAFCKQsNstvUKndan6WWGWUl65IVhSWIAKAAAAAAoQaFhdoeZfdrMzjKz9Wb2N5Ie8rNgjWR0Iqre9mSY7ffC7KP7hrWoM6S2YKCaRQMAAACAulRomP0dSVOSviHpm5ImJL3Pr0I1mpGJqPo6Z/rMStLh0UmaGAMAAABAiQodzfi0pI/4XJaGNBmNKxJLTDczXtLVqrZgiyKxBNPyAAAAAECJCp1n9geS3pQc+Elm1i/pFufca/0sXCMYnYhKknqTYdbMm2t2z/HTGqBmFqicn3xa+ulnZm73rJDec4/U2pl7mwc+L/34L2Zudy6R3nuP1N6Xe5sdX5Hu/pTkXO516k3vKu95B/Ocs+6/QTq2U3rDZytXLgAA0NQKHcRpaSrISpJzLmxmy3wqU0MZSYbZVM2s5DU13nP8tJYxLQ9QObvuktp6pI1XSiP7pJ13SCd2SStfkn+bUIe0+Q3S6AHpmdulo09Lay/Kvc3uuyULSOf+cvmfQzWEn/deh5PPS8s25V7vme9Jhx+XfvEzklnlygcAAJpWoWE2YWZrnXMvSJKZDUpqoGoH/2QLs6kRjZczkjFQOeEh6azLpCv/r3ToMS/Mhofyh9nwkLT257xtju/ywmx4KH+YDQ9Jqy/wtmkE+7Z7YTY8lD/MhoekyKg0EZY6F1eqdAAAoIkVGmY/Luk+M7s3eftiSe/1p0iNJVfNrCRqZoFKiU5IY4ek/kHvdv+Z3v/hodzbJOLS8AvSlqu9231rJFn+bZzz7h985YKLXDNSr1m+5x2dlEYPJtd7njALAAAqoqDRjJ1zd0raJmmnvBGNPyhvRGPMI3uY9UIsc8wCFTL8gvd/Kpi190kdi/MHtNEDUiI2s02oXeo9I/824yekqVMz2zSCrqVSqCv/8x7Zp+nGOvnWAwAAKKNCB4D6dUm/J2m1pEclXSTpfkmX+le0xjCaJcxetnm53vHyQb14dZ5BZACUTypgpYfM/sH8watc29Q7s8Kfd+bfAAAAPip0ntnfk3SBpL3OuVdLeqmkY76VqoGMTMQkSb3tM9cNFne16vo3bFVbMFCtYgHNhTC7MIU+70AbYRYAAFRMoWF20jk3KUlm1uace0bSRv+K1ThGJqLqag0oGCj0pQZQduEhr6ls19KZZf2DXvPjRDz3Ni1Bb1qa9G3GDnl9cLNu87z3/6K1Cy9zLUmF2VzTDYWHpGC7tPLFhFkAAFAxhSas/Wa2SNJ3Jf3AzP5N0kH/itU4Riais5oYA6iC8JAXyNKnjOkf9PrEjh7IvU3fGimQ1hujf533f6oPbqaTQ1L3ivxz19aj/kEpNiGdOpr9/tTr27+OMAsAACqm0AGg3uicG3bOXS/pE5K+LOlqPwvWKEYmouolzALVlQpb6eYbpbdc2zSCQp93/6A0sl+KRytSLAAA0NyKbvvqnLvXOXebc27KjwI1mlFqZoHqSk2XQ5gtXb7nnf769g9KLpEc3RgAAMBfdOT0Gc2MgSo7fUyKjs8Nmb2rvD6x2QLa5Kg3zU7mNvmmqYlFvCbLjRhmU32Asz3v9OmICpmTFgAAoEwIsz4jzAJVlmuE4UDQ6xObLXgN782+Tb5paoaTc602YpgNtUs9OebYnX591xFmAQBARRFmfTY6SZgFqirfdDm5gmm5t2kEhTzvnpVSoJUwCwAAKoIw66NoPKHxqThhFqimVLDKNl3OQsJs5jQ1qWl5mi7Mpk1H1NIiLTqTMAsAACqCMOujkQlvRM++TsIsUDXhIa+JbKh97n39g16fz8nRudu0L5I6FmXfJjru9cXN3CbYLnUvL0uxa07/oDR2UIpOzl4eHpo9HVGu0AsAAFBmhFkfTYdZamaB6gkPSYvXZb8vtTzVR7aQbXL1C02N6NvSoKfVxTnm2A3vnV0bTZgFAAAV0qC/umpDKswyzyxQRfmmy5kvmBa1zd7GbWIsFf5a9Q9KkyPSRLgixQIAAM2LMOuj6TDbTpgFqiI6KY0enD+Ynnx+Zlkinj+Ypvrepm+Tay7bRjIdZtOedywijeyf/bxTNbjprw8AAIAPCLM+GqWZMVBdwy8o73Q57X1SR//s2sbRg1IimnubbNPUjJ+UpsYaO8x2DUihztnPO9t0REzPAwAAKoQw6yP6zAJVVsh0OZl9PP3apt5lm2M32/NedObs+wAAAHxCmPURNbNAlVUszDb4tDwphTzvtm6vFpcwCwAAfEaY9dHIRFQdoYBag7zMQFWEh7ymsV0DudfpH/SaIyfiM9tYQOpdnXubxetmT1MzPdfqmWUodA3LnGM313REjGgMAAAqgJTlo5GJKLWyQDWlBmUyy71O/6DXR3b04Mw2i9ZIgWD+baSZaWrCQ16gS8212qgy59jNNR0RYRYAAFRAnl9rWKj+8ON6W8vj0oN7ql2U5jCwUVp38dzlO//DG3F1Pq3d0ovfLLUESnv8534knXhu/vWC7d7jBNtKe5x6cfqEdGKXtPai8uzvuXukE7uL2+bwY9KKc/Ovkwqm//0P3t8HHpq/uXDq/u1fkpZukPZtb/wmxtLMc7z/76W+NdKhx6TlW7Kv98St0n/fmP9CQqbOxdLWXypuG6BaRg9KY4elVedXuyT5OSc9e6e04bW1Pw/2ocekjkUzo8YXa/SQ9Mzt2e+zFmnrG73zDGrD3vulpWdLXUsWvq+JYenJ70iJmHc72Cad+yYp1LHwfaeLTUnP3ytt+IXCt4nHpN0/lM5+bXm+3w4/Ib1wf/b7Qp3eb8xA81SmEWZ99NYjf6UzY0PSHdUuSZMIdUkfOzD7RDF+Urr5msL30bcqeyCeTzwq/ctbpPhUYeu3dXtfqo3svz4j3f856WMHpWDrwvYVjyVf30jx257/9vz3L9viXWC4/+9nlm29Ov82Szd4Fz8e/MLMsv/xm8WXrd4s3yoFWqWffmZm2Ut/de56Z7xUcnHpPz5U/GMs2yot21R6GYFKuefPpZ13Sh8u4CJmNe39L+978K3fks5+TbVLk9833uadP958U2nb3/c3s8/LmcZPSK/6cGn7RnnFItJNvyi9/P3Sz1+/8P098jXprj+avSzYIb34TQvfd7onvi199zel335AWra5sG2euV361nXSe+4pz8Wv2z8g7d+e+/7uZcWF7TpHmPVRe2JcD3Zdogt/+8vVLkrje+SfpR9+Ujp1ROpZMbM8NdflL31ROuvS3NuPHpC+cLF0ck9pYXZkvxdkL/9L6dxfyb1edFz623O9x2l0J57zmu+O7JOWnLWwfY0e8ILs5X/hXWktmM1/Fb57mfThPVJ0YmZZ5zxXiTv6pT/Y5b2fhW7TCPpWSx9+Xool+wrnen03vU76w70zV8gLcfgx6Wtv9D4bhFnUgxPPSePHpYmwd06oVakWLSd2S6rhMBuLeF032npL38fJ56Tl50pv/+7c+/7hlc3x3Vsvhvd5vxGKbXGVy4nnvM/h+3d4v8c+vcWf93v68/Rc4WE2tc3JPeUJsyeek17yVuk1fzp7+fhJ6YYLmu44J8z6KOSmFA31SF1Lq12Uxrd8q/d/eGh2mE0NzLPi3PzvQ0e/1BIsvZ9farsV58z/fjfLSK+p5xh+fuFhNrWv5Vv9+Ty1dnn/itqms/H7yGbT1u39m0/HouL2u/I87/9m+GygMUyf4/bWdpidLudQNUsxv9S81alB5kppjhkekpbn+B5evL72X4NmUu7jMjwk9a+bee97z/Dn/S6l3Om/hxZqckSaOOl1rcs8zjuXeK0Um+w4r/HOE/Wt1U0pEWivdjGaQ6ovX+YHOHV7vlFmWwJeH52FhtlC+k02w+A4zpX3i6oZ5nFtdh39Xo1Mo3820BiiE9LYIe/vWj9m6yXMpso3NebVMBUrEfdqdnN9TzTDd289SQW78N6ZEfIXtL+h2e+9X+/3gsJsEdvk3Nde7/9sx3m2+eCbAGHWR62aUiLQ4IP81Iq+NZIse5gtdJTZhZwAwkNeX8Kelf4+Tr0YPyFNnfL+LleYbQlKvasWvi/UJjOp/8zG/2ygMaRGMpdq/5itmzCbVmtVSlnHDnnNS/OF2bFDs7uUoHpS73Fk1GuqvxDxmNelqWbD7N7Z/5fj8bloM40w65dEXK2KyQWpma2IUHv2JiWZV+ryWWiYXbS2sJGQ+weTfWyjpT1WPUh/HcsVZgt9fVG/mvBLGHWq3Oc4P6XKN7xXSiSqWpS8Zr2mJTTHLORHvjT7QgSqZ6Hvd7rRA94YDZlhNn0++HKIjHn95KXCP/exKWl0f3Hb5FNomC1HbXedIMz6JZYcdZUwWznZfgiH9xYXZifC3vDuxSo2NLuEdxWxUaXeh74FNN3O3B9NjBtf/2Dt/+AGpPKf4/yS6l/Xt9YbuO3UkWqXKLfwULKVlUp7TQsNs7X8fjWT8F7vuJQW/p5ke+/9uHiRqlntW1v4d9XIPu83X99aryIjVuCsFznLMCS1L8o9LkXmfPBNwNcwa2aXm9lOM9ttZh/Jcv/fmNmjyX/PmlkJKaI2JaaSzVgIs5WTGWZTV8OKCZmSd4IqVrFhNrVNo0pdZV1/cXn6wxBmm0P/YO3/4AYk75wU6pJWb6vtc3nqx/dZlyRvD1WrJPML7/WmSuteXnqYtYA36no2zfDdWy9S42qsf5V3288wW873O7Wvsy7xmrSn+s0Xuo3cwisy5vs91ITHuW9h1swCkm6QdIWkLZKuNbMt6es45/6Xc+4859x5kv5O0q1+lafSpiLelB0WIsxWTGZ/mNTVML9D5kRYmhwmzKYLD0ndK7wfJgvtD5OqWSDMNr5m+GygMaR+UC5e533XxIuYhqqSUp+l9ZfMvl1rUuGmf7D07gbhIS/IBkLZ7+9a2pQjvdak8ZPeQF/Lt0pdy8oTZjPH1fAzzK6/pPB9z9lmgU2qCbNz+Fkze6Gk3c65Pc65KUm3SLoqz/rXSrrZx/JUVHQyOf9ksKO6BWkmmU1Kih0Bt9QTQL6R5bLpWekNFtXIJ5pU8+7p13QBJ+9iX1/Ur/513v+N/NlAY0gPXomY12evFqU+S4MXK+sgibUiFW6mw6wPLaSadKTXmpT++6wc70mqiXogbcbRrgEp1Fn+MNveV9xUcuEhKdAmrbmo8G1ymW/EbskbX2Shj1Nn/AyzqySl16XvTy6bw8zOlLRO0o9y3P9eM9thZjuOHauPNuBTk6clSRZiNOOKyQyjxYbZ9j5vepCiw2yRj7PQaYDqQfoPvdTthexLIsw2g1yjkgO1JLMWUardYzbVv657wKu1rOVySjOv6WgJfQsL6Y5CmK0NqQvc5Qyzme+9HxcvUo/Tt0aylsLDbP+ZXkVGsH1h5Rk9KCWi+Y/zULvU49McuzXKzzCbbbbrXB3nrpH0r865eLY7nXM3Oue2Oee2DQwMlK2AfopNeaOntRQyJQzKI1uYDbR5zV2L2UepYXa+uWwX+jj1IjblDXLQPzjzmhBmUYhga23/4AYkb2CV6Hj9hNlUGWv5eycz3BQ7SGLklPe+FBpmm2ik15qU/rupHDM85LqQ4VeYDbZKvQV+V6W2aWnxnm8lfg/V8mfdB36G2f2S1qTdXi3pYI51r1EDNTGWpGjEq5kN0Ge2cjKblKSuhrUUcZiXGmY7l0jtvf4+Tr0Y2SfJec+xrdt7XxZ68u7o92rO0fga+bOBxpD+g7J3lddXr1aP2VlhtobncZ5+Tc8s7QLBcIHdUZpwpNeaFB7yBvpq7Vz4DA/5xtUo58WLRMI7zor5PKW34kgvT6kIs1n5GWa3S9pgZuvMrFVeYL0tcyUz2yipX9L9Ppal4mZqZukzWzGZTUpKGQG3f53XHyGRtZFAdiU9zmDyBLzAicJrUfoV9tT/Cz15UyvbPGr5Bzcgzf5BWcvdRjL71/UPSqcOS1Pj1SxVduEhbyCg1q7SwmwxP/KL3TfKLzPgpZaVtK/khYzF6+be1z8oRU9Lp4+Xtu90Y4e8EYyL+W0zEfYGwZy1zQJmeAgP5R+xO6V/0GuSXM45dmuYb2HWOReT9H5J35f0tKRvOueeNLNPmdkb0la9VtItzjVWm494cjTjAGG2stKvwpUaMosdzCP8fGmPIzXmF2rmj4oFh9kSXl/Ur1r+wQ1I0snkBbvUQCu1WguS2b8uNcBaOefdLJf07+vuFV4XoWJe05MZF1FzaeTv3nqSLcyeLHGgyHwXMsoxCGWux+kflE4flaZO59kmy8X9yKg34FmpZcg3YndK/6DKMg1QnfB1nlnn3B3OubOdc2c55/48ueyPnXO3pa1zvXNuzhy09S6erJkNttFntqJSPyoyr4YVs71U+BddPCYN7yPMpgsPeYMcdC/3bi+kP0whI/ehsdTyD25A8s5xPWd4A61ItRtms/34Tl9eS8JpzTdbWopvoREektqSgzjm04Qjvdac9HE1pIXP8FBQmC1x3/keZ3rfeUbeLvdnsNBKmlr+rPvA1zDbzBLJWoVgGzWzFZXqD7N/+8ztYreXCj8BjO6XXLz4xynHwEi1KjzkPb9UX+WF9IcZPeDVlBNmm0eTfQmjDmX+oOwf9PrsTY5UqUA51EuYjU1536WZr2mxYbb/TK+7UT5NONJrzUkfV0Na+MBI+cbVKOfFi/CQN4JxX3I4oEKmksscIHShNcWE2awIsz6JJ9uphwizlZX6AO/58ezbhSp2MI9SR9pt7/UGjWrEE022H3qp5aXsK30faHxN9iWMOpTzHFfC3Kh+yuxf17lEau2uvc/WyD7vgme2MFtoD7RiuhXVak16s8hsepv624/aylCHV/NbrjCb3sS3kO+q8JA3CGZbd3KbBVRkRMak8eOFHefdy6RgR9Mc54RZv0QnJBFmKy4zzBYzXY7kTbjdt8b/MJvaptFONM7Nbi4mEWZRnFr9wQ1I3oAqYwfLd47zU+aPbz/m3SyHbOf5VN/CQgZJzBxldj61+Bo0k1zvd6mjDs93IaNc73fmkRNtGQAAE2hJREFU43Qullp75g+z6du0dnkDnZX0e6jAEbul2v2s+4Qw65NENCJJCrV1VbkkTSbVpOToU7OvhhWjmBNAeMirye1d5e/j1ItsfZUX0h8mVbPQO8/IfWgcTfYljDqT6stdL2E284dvLX62coWb9PvyyRxldj5NNtJrzQkPeQN8da+YWVbMxYt0hYyr4VeYLeS7qpyfwWIv7tfiZ90nhFm/RCeUcKa2tvZql6S5pJqUSKXX5hUbZhet9aZnKOVxhvd5g0g1imzNhxYydUV4SFq0xqsxR/Nooi9h1JlsPyjbkwMP1doxm++HdC1NIBEe8i54pr67peLCbCk/8ptopNeak+rf3JIWQUq9IJQ5Ync25bh4MXXaG7l4zucpT1/feHT2QFfp5SmlS0KpYbaWPus+Icz6xMUmFVFIbSF+hFdc5mAXpWw/fkKaHJ1/3WL66WR7HBf3Br5oFLlOtgu5EkkT4+bTRF/CqDPlPsf5JVf/uv5BKTYhnTpajVJllzlooFTcIIklhdkC943yy3WRJXVfsftK3z6bcly8yNXEt3/Qa+KeSMzdJltf8NQ2o/u9gc+KKsNQYSN2pz/O1Cnv92yDI8z6xKbDLC9xxZUjzEreCWo+Cw2zqX00iukvloy+yoRZFKMWf3ADkndOCnZ4A6ykq7Uwm+/Ht1RjZR2aW862bq+rUKFhNn2U2fnU4mvQLLKNqyGVPjBSwWG2hH0X8jj9g1JsUjp1pLhtSpnhodARu9MfJ70cDYyk5ROLRTSpVrUGeIkrrlxhdr4TwMSw17+DMDsjPOQNbtCa0Ve8f9CbtqKY/jCTo94VRcJs82nEzwYaQyp4Zf6g7B/0+u4l4lUoVBb5fkin319tzuW+aFnoBYLwkDeuQrC1sMdsspFea0q2cTUkqa1H6lxaWpidb1yNsobZdRn7zjM9T7k/g8Ve3K+1z7qPaAPrE4tPakohtbQUeAUF5VOuMPvd35a+98Hc6yViC3uc3lVSS0j6/sele/53afuoNRPD0sqXzF2eeo3+7mXegFmFWOjri/qVes//5U1SkHEHGtbis6R3fG9281JJ+upV0tGnq1Om+YyflF7083OX9w96fff+eqNXS1htyRkV5pw/F62VZN532w8+UelSzeVc9nAjecueuFX6f2fn38dEWFrzPwp/zNTAPdu/JD3+rSIKiwXL973ePyj97Bbp2TsL39/k6PzjanQv9y5e/OCT0n/+VTGlnRE5JbX1zm3im3oeN79l7nfV1Om5fcHTt/nWO715jwt16qi08YrC10/Vdv/7B6Tvfyz7Or/7qNTaWfg+axRh1ict8Ygiaqt2MZrTptdJl36iuC+3dB2LpNf8mXRi9/zrhrqk9a8u7XFaAtIVfykdfqy07WvV5l+cu2z9JdJF75Oip4vbV6hTOuuycpQK9WTJi6RXfUQ6dbjaJYFfju+W9t7nDarSkzaq6UTYm1pt7c9JAxurVry8XnzN3GWbXu8F8FgNjZC7eL03fUi6YJv3vXP0qeqUKZtAq3TOL81dftFve9N0qYC+81uzbJ/PZZ+Qdt1V3DYoj1CXtO5Vc5df8lHpmX8vfn/rL8l/v5l3zB98uPh9p1t9wdwWGUvO8so9dij7NitfMneA0N4zvN+oxTYztoB0/tsLXz/UIV3+l9KxPBcGSxm8tAaZq7MBNrZt2+Z27NhR7WLMa+enL1d89Ii2XP9ItYsCAEBt2fVD6eu/LL3r+9Lai2aWH3xEuvES6S1flza/vmrFAwBUl5k95JzbNt96NdAWpjG1xCOaMmpmAQCYI1d/rmJHpgUANDXCrE+CiYhiVuBgBAAANJNFaySZdPL52ctzjYgOAEAWhFmfBOIRRVuomQUAYI5gmzcIXraa2c6l3uimAADMgzDrk2AiongLNbMAAGSVbeoV5pYGABSBMOuToJtSjJpZAACyI8wCABaIMOuTkJtSIkCYBQAgq/5Bb/qlqXHvdjwmDe8jzAIACkaY9UnITSneUsRkyAAANJNUaB1+wft/dL/k4oRZAEDBCLM+aXURJQL0mQUAIKvM6XmYlgcAUCTCrB8SCbUqpkSQmlkAALLKDLOpaXoIswCAAhFm/RCblCS5AGEWAICsupZKrd2za2YDrVLvGdUsFQCgjhBm/ZAKs9TMAgCQndnsEY3DQ9KitVJLoIqFAgDUE8KsH5JhVkFGMwYAIKfMMEsTYwBAEQizfkiF2RA1swAA5JQKs84RZgEARSPM+iAW8ebMs2BHlUsCAEAN6x+UYhPS8WelyWHCLACgKIRZH8SmJiRJRs0sAAC5pcLrnh/Pvg0AQAEIsz6ITiZrZgmzAADkRpgFACwAYdYHsSmvz2xLa2eVSwIAQA3rWyPJpKH7vNuLzqxqcQAA9YUw64NYsmY2QM0sAAC5hdq9eWUjo1LnEqm9t9olAgDUEcKsD1J9ZgNtDAAFAEBeqabFNDEGABSJMOuD+JRXMxtsJcwCAJAXYRYAUCLCrA/iyT6zgTb6zAIAkBdhFgBQIsKsDxJRr5kxNbMAAMyDMAsAKBFh1geJqFczG6LPLAAA+a08T2oJSWe8tNolAQDUmWC1C9CIXHIAqFaaGQMAkN/A2dLHD0mBULVLAgCoM9TM+sBFJzTpQmprDVS7KAAA1D6CLACgBIRZP8QmFVFIrQFeXgAAAADwA2nLD7FJTapVbSFeXgAAAADwA2nLBxaLKOJCagvSzBgAAAAA/ECY9YGlamaDvLwAAAAA4AfSlg8sHlFEIcIsAAAAAPiEtOWDlvikptQmM6t2UQAAAACgIRFmfRCIRxS11moXAwAAAAAaFmHWB4FERFMthFkAAAAA8Ath1geBRERRa6t2MQAAAACgYRFmfRBMRBSnZhYAAAAAfEOY9UEwMaVYCzWzAAAAAOAXwqwPQomI4oRZAAAAAPANYdYHQTeleKC92sUAAAAAgIZFmC23REKtiioRoM8sAAAAAPiFMFtu8YgkKUHNLAAAAAD4hjBbbtEJSZIL0GcWAAAAAPxCmC23mFcz64LUzAIAAACAXwiz5RbzamZFmAUAAAAA3xBmy42aWQAAAADwHWG23JJ9Zi1En1kAAAAA8AthttySNbMKdla3HAAAAADQwAizZRafGpcktYRoZgwAAAAAfiHMllk04jUzbmklzAIAAACAX3wNs2Z2uZntNLPdZvaRHOu82cyeMrMnzexf/CxPJcQiXs1soLWjyiUBAAAAgMYV9GvHZhaQdIOkX5C0X9J2M7vNOfdU2jobJH1U0iucc2EzW+ZXeSolNpUcAIowCwAAAAC+8bNm9kJJu51ze5xzU5JukXRVxjrvkXSDcy4sSc65oz6WpyLiyTAbJMwCAAAAgG/8DLOrJO1Lu70/uSzd2ZLONrOfmtkDZna5j+WpiFSYDbQymjEAAAAA+MW3ZsaSLMsyl+XxN0i6RNJqST8xs3Occ8OzdmT2XknvlaS1a9eWv6RllEiG2RA1swAAAADgGz9rZvdLWpN2e7Wkg1nW+TfnXNQ597yknfLC7SzOuRudc9ucc9sGBgZ8K3A5JKYmJUmhdsIsAAAAAPjFzzC7XdIGM1tnZq2SrpF0W8Y635X0akkys6Xymh3v8bFMvktEJxRxIbUGA9UuCgAAAAA0LN/CrHMuJun9kr4v6WlJ33TOPWlmnzKzNyRX+76kE2b2lKR7JH3IOXfCrzJVgotNalIhtYUIswAAAADgFz/7zMo5d4ekOzKW/XHa307S7yf/NYbohCJqVVvQ1yl8AQAAAKCpkbjKLRbRpAsRZgEAAADARySucotOKqJWtRJmAQAAAMA3JK4ys3iyzywDQAEAAACAbwizZWYxr2a2LcRLCwAAAAB+IXGVmcXpMwsAAAAAfiNxlVkgHvH6zAZ4aQEAAADALySuMmtJRDRlrTKzahcFAAAAABoWYbbMgvGIYi2t1S4GAAAAADQ0wmyZBRIRRa2t2sUAAAAAgIZGmC2zYCKieAthFgAAAAD8RJgts5CLKBYgzAIAAACAnwiz5eScQi6quNFnFgAAAAD8RJgtp9ikJCkRbK9yQQAAAACgsRFmyykVZmlmDAAAAAC+IsyWU5QwCwAAAACVEKx2ARpK14De2fsldfcMVLskAAAAANDQqJktp0BQL7gBJdp6q10SAAAAAGhohNkyi8QSagvysgIAAACAn0hdZTYVS6gtxMsKAAAAAH4idZWZVzMbqHYxAAAAAKChEWbLLBKL08wYAAAAAHxG6ioj55wisYRaCbMAAAAA4CtSVxlF407OiZpZAAAAAPAZqauMpuIJSaLPLAAAAAD4jDBbRpFoXJIYzRgAAAAAfEbqKiMz08VnD2h1f0e1iwIAAAAADS1Y7QI0ksVdrfrquy6sdjEAAAAAoOFRMwsAAAAAqDuEWQAAAABA3SHMAgAAAADqDmEWAAAAAFB3CLMAAAAAgLpDmAUAAAAA1B3CLAAAAACg7hBmAQAAAAB1hzALAAAAAKg7hFkAAAAAQN0hzAIAAAAA6g5hFgAAAABQdwizAAAAAIC6Y865apehKGZ2TNLeapdjHkslHa92IQBxLKJ2cCyiVnAsolZwLKJW1OKxeKZzbmC+leouzNYDM9vhnNtW7XIAHIuoFRyLqBUci6gVHIuoFfV8LNLMGAAAAABQdwizAAAAAIC6Q5j1x43VLgCQxLGIWsGxiFrBsYhawbGIWlG3xyJ9ZgEAAAAAdYeaWQAAAABA3SHMlpGZXW5mO81st5l9pNrlQXMxsyEze9zMHjWzHclli83sB2a2K/l/f7XLicZjZl8xs6Nm9kTasqzHnnk+mzxPPmZm51ev5Gg0OY7F683sQPLc+KiZXZl230eTx+JOM3ttdUqNRmRma8zsHjN72syeNLPfSy7n3IiKynMsNsS5kTBbJmYWkHSDpCskbZF0rZltqW6p0IRe7Zw7L2149Y9Iuts5t0HS3cnbQLn9k6TLM5blOvaukLQh+e+9kj5foTKiOfyT5h6LkvQ3yXPjec65OyQp+R19jaStyW0+l/wuB8ohJumDzrnNki6S9L7kMce5EZWW61iUGuDcSJgtnwsl7XbO7XHOTUm6RdJVVS4TcJWkm5J/3yTp6iqWBQ3KOfefkk5mLM517F0l6avO84CkRWa2sjIlRaPLcSzmcpWkW5xzEefc85J2y/suBxbMOXfIOfdw8u8xSU9LWiXOjaiwPMdiLnV1biTMls8qSfvSbu9X/gMFKDcn6S4ze8jM3ptcttw5d0jyTmaSllWtdGg2uY49zpWohvcnm25+Ja27BcciKsLMBiW9VNJ/i3MjqijjWJQa4NxImC0fy7KMoaJRSa9wzp0vr6nS+8zs4moXCMiCcyUq7fOSzpJ0nqRDkv46uZxjEb4zs25J35b0AefcaL5VsyzjeETZZDkWG+LcSJgtn/2S1qTdXi3pYJXKgibknDuY/P+opO/IaxJyJNVMKfn/0eqVEE0m17HHuRIV5Zw74pyLO+cSkr6omeZyHIvwlZmF5IWHrzvnbk0u5tyIist2LDbKuZEwWz7bJW0ws3Vm1iqv4/RtVS4TmoSZdZlZT+pvSa+R9IS8Y/C65GrXSfq36pQQTSjXsXebpLcnR+68SNJIqskd4IeMfodvlHdulLxj8RozazOzdfIG3nmw0uVDYzIzk/RlSU875z6ddhfnRlRUrmOxUc6NwWoXoFE452Jm9n5J35cUkPQV59yTVS4WmsdySd/xzlcKSvoX59ydZrZd0jfN7N2SXpD0piqWEQ3KzG6WdImkpWa2X9InJf2Fsh97d0i6Ut6AEuOS3lnxAqNh5TgWLzGz8+Q1kxuS9BuS5Jx70sy+KekpeaN9vs85F69GudGQXiHp1yQ9bmaPJpd9TJwbUXm5jsVrG+HcaM7VbBNoAAAAAACyopkxAAAAAKDuEGYBAAAAAHWHMAsAAAAAqDuEWQAAAABA3SHMAgAAAADqDmEWAIA6Z2aXmNnt1S4HAACVRJgFAAAAANQdwiwAABViZm8zswfN7FEz+4KZBczslJn9tZk9bGZ3m9lAct3zzOwBM3vMzL5jZv3J5S8ysx+a2c+S25yV3H23mf2rmT1jZl83M6vaEwUAoAIIswAAVICZbZb0FkmvcM6dJyku6VcldUl62Dl3vqR7JX0yuclXJf2hc+7Fkh5PW/51STc4514i6eWSDiWXv1TSByRtkbRe0it8f1IAAFRRsNoFAACgSVwm6WWSticrTTskHZWUkPSN5Dr/LOlWM+uTtMg5d29y+U2SvmVmPZJWOee+I0nOuUlJSu7vQefc/uTtRyUNSrrP/6cFAEB1EGYBAKgMk3STc+6jsxaafSJjPTfPPnKJpP0dF9/xAIAGRzNjAAAq425Jv2JmyyTJzBab2Znyvot/JbnOWyXd55wbkRQ2s1cml/+apHudc6OS9pvZ1cl9tJlZZ0WfBQAANYKrtgAAVIBz7ikz+yNJd5lZi6SopPdJOi1pq5k9JGlEXr9aSbpO0j8kw+oeSe9MLv81SV8ws08l9/GmCj4NAABqhjmXrzUTAADwk5mdcs51V7scAADUG5oZAwAAAADqDjWzAAAAAIC6Q80sAAAAAKDuEGYBAAAAAHWHMAsAAAAAqDuEWQAAAABA3SHMAgAAAADqDmEWAAAAAFB3/j+tEkD2WfqkIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f27961be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее-2, попробовали tanh вместо sigmoid, плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.6494 - acc: 0.6040 - val_loss: 0.5133 - val_acc: 0.7857\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.4659 - acc: 0.7840 - val_loss: 0.4978 - val_acc: 0.7143\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.3974 - acc: 0.7960 - val_loss: 0.4891 - val_acc: 0.7500\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3708 - acc: 0.7960 - val_loss: 0.4864 - val_acc: 0.7857\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.3444 - acc: 0.8200 - val_loss: 0.4942 - val_acc: 0.7500\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3280 - acc: 0.8480 - val_loss: 0.5024 - val_acc: 0.7143\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3130 - acc: 0.8440 - val_loss: 0.5044 - val_acc: 0.7143\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3029 - acc: 0.8520 - val_loss: 0.4760 - val_acc: 0.7500\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2889 - acc: 0.8680 - val_loss: 0.4833 - val_acc: 0.7500\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2801 - acc: 0.8640 - val_loss: 0.4903 - val_acc: 0.7500\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2721 - acc: 0.8720 - val_loss: 0.4578 - val_acc: 0.7500\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2619 - acc: 0.8880 - val_loss: 0.4487 - val_acc: 0.7500\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.2541 - acc: 0.8760 - val_loss: 0.4511 - val_acc: 0.7857\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2461 - acc: 0.9040 - val_loss: 0.4968 - val_acc: 0.7143\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.2397 - acc: 0.8840 - val_loss: 0.4744 - val_acc: 0.7500\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2357 - acc: 0.8880 - val_loss: 0.4425 - val_acc: 0.7857\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2257 - acc: 0.9200 - val_loss: 0.4640 - val_acc: 0.7500\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2225 - acc: 0.9120 - val_loss: 0.4567 - val_acc: 0.7857\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2187 - acc: 0.9200 - val_loss: 0.4697 - val_acc: 0.7143\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2104 - acc: 0.9320 - val_loss: 0.4577 - val_acc: 0.7143\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2084 - acc: 0.9240 - val_loss: 0.4613 - val_acc: 0.7500\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1988 - acc: 0.9320 - val_loss: 0.4647 - val_acc: 0.7143\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1972 - acc: 0.9320 - val_loss: 0.4849 - val_acc: 0.6786\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1965 - acc: 0.9280 - val_loss: 0.4735 - val_acc: 0.7143\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1940 - acc: 0.9280 - val_loss: 0.4742 - val_acc: 0.7143\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1870 - acc: 0.9360 - val_loss: 0.4877 - val_acc: 0.7143\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1836 - acc: 0.9400 - val_loss: 0.4705 - val_acc: 0.6786\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1776 - acc: 0.9520 - val_loss: 0.4671 - val_acc: 0.6786\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1743 - acc: 0.9360 - val_loss: 0.4582 - val_acc: 0.6786\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1697 - acc: 0.9480 - val_loss: 0.4496 - val_acc: 0.6786\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1731 - acc: 0.9320 - val_loss: 0.4519 - val_acc: 0.7143\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1642 - acc: 0.9480 - val_loss: 0.4552 - val_acc: 0.7500\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1618 - acc: 0.9560 - val_loss: 0.4298 - val_acc: 0.6786\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1564 - acc: 0.9560 - val_loss: 0.4791 - val_acc: 0.6786\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1507 - acc: 0.9560 - val_loss: 0.4430 - val_acc: 0.7143\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1521 - acc: 0.9520 - val_loss: 0.4531 - val_acc: 0.7143\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1511 - acc: 0.9560 - val_loss: 0.4721 - val_acc: 0.7500\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1408 - acc: 0.9600 - val_loss: 0.4833 - val_acc: 0.7143\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1403 - acc: 0.9640 - val_loss: 0.4345 - val_acc: 0.7143\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1407 - acc: 0.9560 - val_loss: 0.4758 - val_acc: 0.7143\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1342 - acc: 0.9560 - val_loss: 0.4349 - val_acc: 0.7143\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1341 - acc: 0.9560 - val_loss: 0.4563 - val_acc: 0.7143\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1316 - acc: 0.9600 - val_loss: 0.4572 - val_acc: 0.7143\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1292 - acc: 0.9760 - val_loss: 0.4807 - val_acc: 0.7143\n",
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1238 - acc: 0.9720 - val_loss: 0.4956 - val_acc: 0.7143\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.1211 - acc: 0.9760 - val_loss: 0.4643 - val_acc: 0.7500\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1160 - acc: 0.9720 - val_loss: 0.4782 - val_acc: 0.7500\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1137 - acc: 0.9720 - val_loss: 0.4698 - val_acc: 0.7500\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1109 - acc: 0.9800 - val_loss: 0.4890 - val_acc: 0.6786\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1111 - acc: 0.9720 - val_loss: 0.5049 - val_acc: 0.7143\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1073 - acc: 0.9840 - val_loss: 0.5138 - val_acc: 0.7143\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.1038 - acc: 0.9840 - val_loss: 0.5100 - val_acc: 0.7143\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.1022 - acc: 0.9840 - val_loss: 0.5045 - val_acc: 0.7143\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0995 - acc: 0.9840 - val_loss: 0.4974 - val_acc: 0.7500\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0968 - acc: 0.9840 - val_loss: 0.5331 - val_acc: 0.7143\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0963 - acc: 0.9840 - val_loss: 0.5140 - val_acc: 0.7500\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0952 - acc: 0.9880 - val_loss: 0.5092 - val_acc: 0.7500\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0928 - acc: 0.9880 - val_loss: 0.5344 - val_acc: 0.7143\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0919 - acc: 0.9920 - val_loss: 0.5126 - val_acc: 0.7500\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0870 - acc: 0.9840 - val_loss: 0.5473 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0898 - acc: 0.9880 - val_loss: 0.5532 - val_acc: 0.7143\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0872 - acc: 0.9880 - val_loss: 0.5478 - val_acc: 0.7143\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0864 - acc: 0.9920 - val_loss: 0.5508 - val_acc: 0.7143\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0841 - acc: 0.9920 - val_loss: 0.5546 - val_acc: 0.7500\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0820 - acc: 0.9840 - val_loss: 0.5632 - val_acc: 0.7143\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0815 - acc: 0.9920 - val_loss: 0.5654 - val_acc: 0.7500\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0817 - acc: 0.9880 - val_loss: 0.5540 - val_acc: 0.7500\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0762 - acc: 0.9920 - val_loss: 0.5693 - val_acc: 0.7143\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0756 - acc: 0.9920 - val_loss: 0.6092 - val_acc: 0.7143\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0737 - acc: 0.9920 - val_loss: 0.5636 - val_acc: 0.7143\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0739 - acc: 0.9960 - val_loss: 0.5211 - val_acc: 0.7500\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0710 - acc: 0.9920 - val_loss: 0.5292 - val_acc: 0.7143\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0694 - acc: 0.9960 - val_loss: 0.5341 - val_acc: 0.7143\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0670 - acc: 0.9960 - val_loss: 0.5274 - val_acc: 0.7500\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0664 - acc: 0.9920 - val_loss: 0.5274 - val_acc: 0.7143\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0636 - acc: 0.9960 - val_loss: 0.5264 - val_acc: 0.7143\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0633 - acc: 0.9960 - val_loss: 0.5171 - val_acc: 0.7500\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0603 - acc: 0.9960 - val_loss: 0.5178 - val_acc: 0.7143\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0589 - acc: 1.0000 - val_loss: 0.5486 - val_acc: 0.7143\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0588 - acc: 1.0000 - val_loss: 0.5609 - val_acc: 0.7143\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.5586 - val_acc: 0.7500\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0555 - acc: 1.0000 - val_loss: 0.5602 - val_acc: 0.7500\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.7500\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0539 - acc: 1.0000 - val_loss: 0.5636 - val_acc: 0.7143\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.7143\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0516 - acc: 1.0000 - val_loss: 0.5494 - val_acc: 0.7143\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.5571 - val_acc: 0.7143\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0494 - acc: 0.9960 - val_loss: 0.5593 - val_acc: 0.7857\n",
      "Epoch 89/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.5455 - val_acc: 0.7143\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0478 - acc: 1.0000 - val_loss: 0.5461 - val_acc: 0.7143\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.5538 - val_acc: 0.7143\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.5739 - val_acc: 0.7500\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0446 - acc: 1.0000 - val_loss: 0.5856 - val_acc: 0.7143\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.7143\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.5701 - val_acc: 0.7143\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.5660 - val_acc: 0.7143\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.5726 - val_acc: 0.7143\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.5988 - val_acc: 0.7143\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0418 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.7143\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.7143\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.7500\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.7143\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.7143\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.5975 - val_acc: 0.7143\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.6120 - val_acc: 0.7500\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.6057 - val_acc: 0.7143\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.6078 - val_acc: 0.7500\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.6045 - val_acc: 0.7143\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.6103 - val_acc: 0.7143\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.6180 - val_acc: 0.7143\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.7143\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.7500\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.7143\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.7500\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.6165 - val_acc: 0.7143\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.6217 - val_acc: 0.7500\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 0.7500\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.6289 - val_acc: 0.7143\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.7143\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 0.7500\n",
      "Epoch 121/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 164us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.6393 - val_acc: 0.7500\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6451 - val_acc: 0.7143\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.7500\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.7500\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.7143\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.7500\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.7500\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.6428 - val_acc: 0.7500\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6495 - val_acc: 0.7143\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6611 - val_acc: 0.7143\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6685 - val_acc: 0.7143\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6695 - val_acc: 0.7143\n",
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6607 - val_acc: 0.7143\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 0.7143\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6720 - val_acc: 0.7143\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6713 - val_acc: 0.7143\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6799 - val_acc: 0.7143\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6866 - val_acc: 0.7143\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6783 - val_acc: 0.7500\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6816 - val_acc: 0.7500\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.7143\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.6955 - val_acc: 0.7500\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6897 - val_acc: 0.7143\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6848 - val_acc: 0.7500\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6894 - val_acc: 0.7500\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6916 - val_acc: 0.7500\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.7143\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6941 - val_acc: 0.7143\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6989 - val_acc: 0.7500\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.7500\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.7500\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.7143\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.7500\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.7500\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.7203 - val_acc: 0.7143\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.7179 - val_acc: 0.7143\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.7206 - val_acc: 0.7143\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.7500\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.7143\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.7143\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.7143\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.7500\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7463 - val_acc: 0.7500\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.7143\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.7500\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.7143\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7576 - val_acc: 0.7500\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.7642 - val_acc: 0.7143\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.7143\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.7688 - val_acc: 0.7143\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.7759 - val_acc: 0.7143\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 144us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.7759 - val_acc: 0.7143\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7812 - val_acc: 0.7500\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.7807 - val_acc: 0.7500\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.7842 - val_acc: 0.7500\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.7500\n",
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.7871 - val_acc: 0.7143\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.7500\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.7933 - val_acc: 0.7500\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.8085 - val_acc: 0.7500\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.7500\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.7143\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8052 - val_acc: 0.7143\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8078 - val_acc: 0.7500\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.8099 - val_acc: 0.7500\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.8211 - val_acc: 0.7143\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.8194 - val_acc: 0.7143\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.8212 - val_acc: 0.7500\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.8233 - val_acc: 0.7143\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.8306 - val_acc: 0.7500\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.7500\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.7143\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.8272 - val_acc: 0.7143\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.8241 - val_acc: 0.7143\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.8178 - val_acc: 0.7500\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.8262 - val_acc: 0.7500\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 0.7143\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.8345 - val_acc: 0.7500\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.8346 - val_acc: 0.7143\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.8405 - val_acc: 0.7500\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.8399 - val_acc: 0.7143\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.8418 - val_acc: 0.7143\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.8465 - val_acc: 0.7500\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.8475 - val_acc: 0.7143\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8460 - val_acc: 0.7143\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.8465 - val_acc: 0.7143\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.8580 - val_acc: 0.7500\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.8524 - val_acc: 0.7500\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.7143\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.8563 - val_acc: 0.7143\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.8519 - val_acc: 0.7143\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.8562 - val_acc: 0.7500\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8686 - val_acc: 0.7143\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.8752 - val_acc: 0.7143\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.8627 - val_acc: 0.7143\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.8624 - val_acc: 0.7143\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 148us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.7143\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8670 - val_acc: 0.7143\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.7143\n",
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8803 - val_acc: 0.7143\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8801 - val_acc: 0.7500\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 0.7500\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.8853 - val_acc: 0.7143\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.8901 - val_acc: 0.7143\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.8981 - val_acc: 0.7143\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.8925 - val_acc: 0.7143\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.8896 - val_acc: 0.7143\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.8886 - val_acc: 0.7143\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.8939 - val_acc: 0.7143\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.9055 - val_acc: 0.7500\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9048 - val_acc: 0.7143\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.9071 - val_acc: 0.7143\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.9059 - val_acc: 0.7500\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9163 - val_acc: 0.7500\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.7143\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.9071 - val_acc: 0.7143\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.9081 - val_acc: 0.7143\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.9101 - val_acc: 0.7143\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.9145 - val_acc: 0.7500\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.9194 - val_acc: 0.7143\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.7143\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.9222 - val_acc: 0.7143\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.9257 - val_acc: 0.7143\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.9328 - val_acc: 0.7500\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9388 - val_acc: 0.7500\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.9319 - val_acc: 0.7143\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.9367 - val_acc: 0.7143\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f1cbae320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAGDCAYAAADu2dciAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xd4HNX1//H3kaxi2bJkS3LvttwBGxubEpveq4GQQOgEklASQkiAFJKQkPD9kZBCSCjBlCT0FgImYMCACeBewUWWsS3JTcWSVay69/fH7Eqr6nVZrbT6vJ5Hj3Zn7p05u9pZ7dl754w55xARERERERGJBjGRDkBERERERETkUFGSKyIiIiIiIlFDSa6IiIiIiIhEDSW5IiIiIiIiEjWU5IqIiIiIiEjUUJIrIiIiIiIiUUNJroiISJiY2ZNm9usQ2242s1PCHZOIiEi0U5IrIiIiIiIiUUNJroiIiLTJzLpFOgYREZFQKckVEZEuzT9N+IdmtsrMys3scTPrZ2ZvmVmpmb1rZr2D2p9nZp+bWbGZfWBm44PWTTGzZf5+zwOJTfZ1jpmt8Pf9xMwODzHGs81suZntMbMcM/tFk/Vf8W+v2L/+av/y7mb2ezPbYmYlZvaxf9kJZpbbwvNwiv/2L8zsJTP7p5ntAa42s+lm9ql/H9vN7C9mFh/Uf6KZzTOzIjPbaWY/NrP+ZlZhZmlB7aaaWb6ZxYXy2EVERPaXklwRERG4CDgVGAOcC7wF/BhIx/tf+V0AMxsDPAvcCmQAc4H/mFm8P+F7DfgH0Ad40b9d/H2PBOYA3wLSgEeA180sIYT4yoErgVTgbOA7ZnaBf7tD/fE+6I9pMrDC3+93wFTgWH9MPwJ8IT4n5wMv+ff5L6AO+L7/OTkGOBm40R9DMvAu8F9gIDAaeM85twP4ALgkaLuXA88552pCjENERGS/KMkVERGBB51zO51zecACYKFzbrlzrgp4FZjib/c14E3n3Dx/kvY7oDteEnk0EAf80TlX45x7CVgctI/rgUeccwudc3XOuaeAKn+/NjnnPnDOrXbO+Zxzq/AS7eP9q78BvOuce9a/30Ln3AoziwGuBb7nnMvz7/MT/2MKxafOudf8+9zrnFvqnPvMOVfrnNuMl6QHYjgH2OGc+71zrtI5V+qcW+hf9xReYouZxQKX4n0RICIiEhZKckVERGBn0O29Ldzv6b89ENgSWOGc8wE5wCD/ujznnAvquyXo9jDgB/7pvsVmVgwM8fdrk5nNMLP5/mm+JcC38UZU8W8ju4Vu6XjTpVtaF4qcJjGMMbM3zGyHfwrzb0KIAeDfwAQzG4k3Wl7inFt0gDGJiIjsk5JcERGR0G3DS1YBMDPDS/DygO3AIP+ygKFBt3OAe51zqUE/Sc65Z0PY7zPA68AQ51wK8DAQ2E8OMKqFPgVAZSvryoGkoMcRizfVOZhrcv9vwDog0znXC286975iwDlXCbyAN+J8BRrFFRGRMFOSKyIiEroXgLPN7GR/4aQf4E05/gT4FKgFvmtm3czsQmB6UN/HgG/7R2XNzHr4C0olh7DfZKDIOVdpZtOBy4LW/Qs4xcwu8e83zcwm+0eZ5wAPmNlAM4s1s2P85wBvABL9+48Dfgrs69zgZGAPUGZm44DvBK17A+hvZreaWYKZJZvZjKD1TwNXA+cB/wzh8YqIiBwwJbkiIiIhcs6txzu/9EG8kdJzgXOdc9XOuWrgQrxkbjfe+buvBPVdgnde7l/86zf624biRuAeMysF7sZLtgPb3QqchZdwF+EVnTrCv/p2YDXeucFFwP8BMc65Ev82/443Cl0ONKq23ILb8ZLrUryE/fmgGErxpiKfC+wAsoATg9b/D6/g1TL/+bwiIiJhY41PHRIRERE59MzsfeAZ59zfIx2LiIhENyW5IiIiElZmdhQwD++c4tJIxyMiItFN05VFREQkbMzsKbxr6N6qBFdERNqDRnJFREREREQkamgkV0RERERERKKGklwRERERERGJGt0iHcChkp6e7oYPHx7pMERERERERCQMli5dWuCcy9hXu6hJcocPH86SJUsiHYaIiIiIiIiEgZltCaWdpiuLiIiIiIhI1FCSKyIiIiIiIlFDSa6IiIiIiIhEjag5J7clNTU15ObmUllZGelQwi4xMZHBgwcTFxcX6VBEREREREQiJqqT3NzcXJKTkxk+fDhmFulwwsY5R2FhIbm5uYwYMSLS4YiIiIiIiERMVE9XrqysJC0tLaoTXAAzIy0trUuMWIuIiIiIiLQlqpNcIOoT3ICu8jhFRERERETaEvVJbqQVFxfz17/+db/7nXXWWRQXF4chIhERERERkeilJDfMWkty6+rq2uw3d+5cUlNTwxWWiIiIiIhIVApbkmtmc8xsl5mtaWW9mdmfzWyjma0ysyOD1l1lZln+n6vCFWN7uPPOO8nOzmby5MkcddRRnHjiiVx22WUcdthhAFxwwQVMnTqViRMn8uijj9b3Gz58OAUFBWzevJnx48dz/fXXM3HiRE477TT27t0bqYcjIiIiIiLSoYWzuvKTwF+Ap1tZfyaQ6f+ZAfwNmGFmfYCfA9MAByw1s9edc7sPJphf/udzvti252A20cyEgb34+bkT22xz3333sWbNGlasWMEHH3zA2WefzZo1a+qrIM+ZM4c+ffqwd+9ejjrqKC666CLS0tIabSMrK4tnn32Wxx57jEsuuYSXX36Zyy+//JA+FhERERERkWgQtiTXOfeRmQ1vo8n5wNPOOQd8ZmapZjYAOAGY55wrAjCzecAZwLPhirU9TZ8+vdFlfv785z/z6quvApCTk0NWVlazJHfEiBFMnjwZgKlTp7J58+Z2i1dEDlxlTR2Lviyizrmw7yutRzyHD25+isOWwnI2FZSHff8iIiLS+WX27cng3kmRDuOgRfI6uYOAnKD7uf5lrS1vxsxuAG4AGDp0aJs729eIa3vp0aNH/e0PPviAd999l08//ZSkpCROOOGEFi8DlJCQUH87NjZW05VFOoGi8mqueWIRK3NL2m2f3zs5k1tPyayvtv7O5zu4+dnlVNf62i0GERER6bzuOX8iVx4zPNJhHLRIJrktXfPGtbG8+ULnHgUeBZg2bVr4h0oOQHJyMqWlpS2uKykpoXfv3iQlJbFu3To+++yzdo5ORMIhr3gvVzy+kLzde/n9V49gZEaPfXc6SM8s3Mqf3suiqLyaX5w3kZeX5XLny6s4bHAqPzt7PLExusyYiIiItC0aRnEhskluLjAk6P5gYJt/+QlNln/QblEdYmlpaRx33HFMmjSJ7t27069fv/p1Z5xxBg8//DCHH344Y8eO5eijj45gpCJdR1lVLTv3VDIqo2ezdV9s28POPQ0zKiYO7EXfXomN2vh8jsWbi6iobl4lvbKmjnve+IKyqlr++c0ZHDW8z6F/AC2YPCSVPj3ieeSjTazMLWZVbgkzM9N5+PKp9EiI5Fu9iIiISPsyF8Zzxfzn5L7hnJvUwrqzgZuBs/AKT/3ZOTfdX3hqKRCotrwMmBo4R7c106ZNc0uWLGm0bO3atYwfP/5gH0an0dUer8iB2OYfZd1cWMH/XXQ4F08dXL/u7ws28es31zZq3zspjieumc7kId75rjV1Pn700ipeXZ7X6j4ykhN4+trpjB/QKzwPog2PfJjNb99axzmHD+CBSyYT301XihMREZHoYGZLnXPT9tUubF/vm9mzeCOy6WaWi1cxOQ7AOfcwMBcvwd0IVADX+NcVmdmvgMX+Td2zrwRXRCQUG3eVceXjCymtrGXykFRuf3Elu8ur+ebMEfzunfU8ND+bMyf154ZZIzEzKqpqufOV1Vz22Gc8csVUpg3rw03PLOP9dbv43smZnDiub4v7GZHeg5Tuce386DzfOn4U500eSL/kRGI0RVlERES6oLCO5LYnjeR2vccrHdvu8mr21tQxMLX7fvVZntNwtbB+vRKZODClWbttxXvpHhdL7x7xjZbX1vlY+GURVbXNpxGXVtbyi9c/JzYmhqeuPYrRfXvy/edXMHf1Dg4fnMKq3BIunT6UX18wqdH5q7v2VHLlnEVk55cxKqMn63eW8usLJvGNGcNCflwiIiIicvAiPpIrIl3Xuh17uPLxRficY/7tJ5CcuO9RzcAo67aSxhXG//XNGRw3Or3+/p7KGs558GPiYo2nr53B2P7JAOytrqsfZW3NkD7d+ed1MxiW5hWCevDSI0lNWsMzC7dy04mjuP20sfWViQP69krk+W8dwzefWszKnBIeuuxIzjpsQMjPhYiIiIi0LyW5InJILdlcxLVPLia+WwwFZdU89tEmbjttbJt9VuYUc/UTi4iNMZ64+ij69IjHATf9axm/fWstr9/0lfqpt498mE1ReTXpPeO55JFPmXO1Nyr7zacWs2TLbn569vhWiz2N7tuzURGm2Bjj3gsmcctJoxmQ0vqIc0r3OJ69/miKKqrpm5zYajsRERERiTwluSJywJxzLN68mz17awDYWVrJr974goEp3Xn6uunc99Y6HlvwJZcfPay+QrFzjmVbd7O73OtTWF7FL//zBX16xPOP62YwIr3hcju3nz6G7z+/kv+s2sb5kwexo6SSxz/+kvMnD+T208ZyxeMLufzvCxmYmsjWogoevHQK5xw+cL8eg5m1meAGdIuNUYIrIiIi0gkoyRWRA1Lnc9z97zX8a+HWRssnDerFk9dMJ71nAj88fSxvf76DP7ybxW8vPAyfz3Hv3LU8/vGXjfqM7ZfM09dNp1+TS/Wcf8QgHvvoS+5/ez1nTOrPH+ZtwOeD208by5A+Sbz47WO5as4iNheWM+fqo5iZmRH2xy0iIiIiHZuS3DArLi7mmWee4cYbb9zvvn/84x+54YYbSEqKjosyS/Soqq3jtudX8ubq7Xxr1sj60VMzGNMvuf6yNcPSevCNGcP4x2dbuOrYYTz64SZeWZ7H1ccO56IjGy7dk9mvJ4lxsc32ExNj3HXWOK54fBG/eP1zXlyaw9XHjmBIH++YyEhO4NWbjqWsspa0ngnt8MhFREREpKNTkhtmxcXF/PWvfz3gJPfyyy9XkiuH1LbivXy+bc9BbeOpTzbz8cYCfnLWeK6fNbLNtrecNJqXluZy4V8/oaK6jttPG8NNJ45uVuCpNTMzM5iZmc6zi3JITujGzSeNbrQ+oVssCT2bJ8giIiIi0jUpyQ2zO++8k+zsbCZPnsypp55K3759eeGFF6iqqmL27Nn88pe/pLy8nEsuuYTc3Fzq6ur42c9+xs6dO9m2bRsnnngi6enpzJ8/P9IPRaLE9U8vOegkNzbG+N1Xj+DiqYP32TatZwI3nTia//f2On59wSQuP3r/L71z55njWLjpE757ciZ9mlw2SEREREQkWNdJct+6E3asPrTb7H8YnHlfm03uu+8+1qxZw4oVK3jnnXd46aWXWLRoEc45zjvvPD766CPy8/MZOHAgb775JgAlJSWkpKTwwAMPMH/+fNLT09vch0io1u3Yw+fb9nDLSaM5fWL/A95OWs/4kIo1BXz7+JFcMm3wAU8pnjgwhcU/OYWUpH1fikhEREREurauk+R2AO+88w7vvPMOU6ZMAaCsrIysrCxmzpzJ7bffzh133ME555zDzJkzIxypdHbOOTbuKmN0356NpgW/ujyPbjHG1ccOb9dzWM3soPenBFdEREREQtF1ktx9jLi2B+ccd911F9/61rearVu6dClz587lrrvu4rTTTuPuu++OQIQSLZ5bnMNdr6zm/osP56vThgBeNeR/L9/G8WMyVKRJRERERKJWTKQDiHbJycmUlpYCcPrppzNnzhzKysoAyMvLY9euXWzbto2kpCQuv/xybr/9dpYtW9asr0ioKqpreWDeBgAemLeBypo6AD7bVMiOPZXMPnJQJMMTEREREQkrJblhlpaWxnHHHcekSZOYN28el112GccccwyHHXYYF198MaWlpaxevZrp06czefJk7r33Xn76058CcMMNN3DmmWdy4oknRvhRSHsrr6olO7+sxXVr8kqoqK5tte/fF3xJfmkVPzx9LNtLKnnif5sBeGVZHskJ3ThlfL9whCwiIiIi0iGYcy7SMRwS06ZNc0uWLGm0bO3atYwfPz5CEbW/rvZ4o9lPX1vNMwu38tsLD+NrRw0FvOnuf/0gm/vfXs/Egb148prpZCQ3nnZcUFbF8f9vPl/JTOeRK6Zx3ZOLWbS5iLdvncWpD3zI2YcP4P9dfEQkHpKIiIiIyEExs6XOuWn7aqeRXJEOxjnH/HX5xJhxx8urefjDbHw+x6/fXMv9b69n1pgMNuWX89WHPyGnqKJR3wffy6Ky1sePzhgHwB1njqO8qpYr5yyivLqO2VP2fckfEREREZHOrOsUnhLpJL4sKCeveC8/P3cCy7cWc99b63hteR7rdpRy9bHDufucCSzPKebaJxdz0d8+4cdnjScxLoaK6jr+tXArXztqCKMyegIwpl8yF08dzAtLchmU2p0ZI/pE+NGJiIiIiISXklyRDmZBVgEAJ43ry1XHDKd3UhxPfbqF204dwy0njcbMmDqsNy9++xiueHwhtz6/or5vSvc4bj05s9H2bjt1LG+u2s7FUwcTE2OIiIiIiESzqE9ynXONrhMaraLl3GrxktyhfZIYltYDgF+cN5FbTs4kvcllf8b0S+a9H5zQaMrygJREUpPiG7Xrn5LIx3ecRHJi1B/uIiIiIiLRneQmJiZSWFhIWlpaVCe6zjkKCwtJTEyMdChykGrqfHyaXcAFUxou82NmzRLcgJ4J3Rg/oNc+t9u7R/w+24iIiIiIRIOoTnIHDx5Mbm4u+fn5kQ4l7BITExk8WEWFOrvlW4spr65jZmZ6pEMREREREemUojrJjYuLY8SIEZEOQyRkH2flE2NwzCgluSIiIiIiB0KXEBIJg035ZRSVV+93v4+yCpg8JJWU7nFhiEpEREREJPopyRU5xN5ctZ3T//gR1zyxaL8KgpVU1LAqt5ivZGaEMToRERERkeimJFfkEPrnZ1u4+dllpPdMYGVuCW+u3h5y30+yC/A5mKXzcUVEREREDpiSXJFDwDnHg+9l8dPX1nDi2L68e9vxjOufzP1vr6e61hfSNj7KKiA5oRtHDEkNc7QiIiIiItFLSa7IQfL5HL/8zxf8ft4GLpwyiEeumEqPhG7cceY4thRW8MzCLfvcxrwvdvLKslxmjckgLlaHpYiIiIjIgdKnaZGDUFPn47YXVvDkJ5u57isj+N1Xj6hPUk8Yk8ExI9P48/sbKa2saXUbLy7J4dv/XMq4Ab341QWT2it0EREREZGoFNWXEBIJVU2dj/nrdlHVytTio0emkZGc0GjZ3uo6bvzXUuavz+eHp4/lxhNGYWb1682Mu84ax3l/+R+//M8XHD+meUGpdTv28ND8bGZmpvPw5d4IsIiIiIiIHDh9ohYB7n1zLU9+srnV9f16JfD0tTMY2z8Z8CohX/vUYpZv3c1vZh/GZTOGttjv8MGpXHTkYF5amstLS3NbbHP2YQN44GtHkNAt9qAfh4iIiIhIV2f7c4mT/d642RnAn4BY4O/OufuarB8GzAEygCLgcudcrn9dHbDa33Src+68tvY1bdo0t2TJkkP8CKQr2FJYzikPfMi5RwzkxhNGNVufX1rN955bTlWtjzlXT2Nw7ySufHwRXxaU86evT+bMwwa0uX3nHNn55UDzY61bTAzD0pIajQCLiIiIiEhzZrbUOTdtn+3CleSaWSywATgVyAUWA5c6574IavMi8IZz7ikzOwm4xjl3hX9dmXOuZ6j7U5LbtW0v2UtNrWNoWtJ+9735mWW8t3YXH/zwBPr1SmyxTU5RBVc8vpAdeyrpkxRPyd4aHr1yGseN1uV+RERERETaQ6hJbjgLT00HNjrnNjnnqoHngPObtJkAvOe/Pb+F9SIh+fY/lnLdU4v3u9/KnGLeWLWdb84c0WqCCzCkTxIvfedYRvftSWWtj2dvOFoJroiIiIhIBxTOc3IHATlB93OBGU3arAQuwpvSPBtINrM051whkGhmS4Ba4D7n3GthjFU6sY27SlmZWwJAXvFeBqV2D6mfc4773lpHnx7x3DBr5D7bp/dM4LUbj6Oq1qcCUSIiIiIiHVQ4R3JbOsmw6dzo24HjzWw5cDyQh5fUAgz1D0VfBvzRzJqdLGlmN5jZEjNbkp+ffwhDl87k1eV59bc/zmr8OnDOsXBTIXW+5tPyP9iQz6ebCvnuSaNJTowLaV/dYmOU4IqIiIiIdGDhTHJzgSFB9wcD24IbOOe2OecudM5NAX7iX1YSWOf/vQn4AJjSdAfOuUedc9Occ9MyMppfnkWin8/neG35NmaNyaBvcgIfZRU0Wv/xxgK+9uhn/GfltmZ953z8JYNSu3PZjGHtFa6IiIiIiIRZOJPcxUCmmY0ws3jg68DrwQ3MLN3MAjHchVdpGTPrbWYJgTbAccAXiDSxaHMRecV7uejIQczMzOB/Gwsajdq+7L9sz4cbGo/wVtbUsfDLIk6f2J/4buE8DEREREREpD2F7dO9c64WuBl4G1gLvOCc+9zM7jGzwOWATgDWm9kGoB9wr3/5eGCJma3EK0h1X3BVZpGAV5fl0SM+ltMm9GfWmHSKK2r4fJt3fm55VS1vf74TgAVZBQRXEl/0ZRHVtT5mjlHxKBERERGRaBLWkwudc3OBuU2W3R10+yXgpRb6fQIcFs7YpPOrrKlj7urtnDFpAN3jY+urHS/IKuDwwan8d80O9tbU8bVpQ3h+SQ7rdpQyfkAvwJvGHB8bw4wRfSL5EERERERE5BDTPE3ptN5du5PSqlouPHIQ4FU/njCgFwv8xadeW5HHkD7d+d4pmQD1ywE+2pDP1GG9SYpXESkRERERkWiiJFc6rVeX5dGvVwJHj0yrXzZzTDpLt+zmy4Jy/rexgNmTBzEwtTuZfXuywF+UaldpJet2lGqqsoiIiIhIFFKSK53SIx9m8966XVw8dTCxMQ1Xq5o5OoOaOsdPXl2Nz8HsIwcD8JXMdBZ9WURlTR3/2+glu7MyVZFbRERERCTaKMmVTsU5x2/nruW3b63jnMMH8L2TxzRaP214bxK6xfBJdiGTh6QyIr0H4CW0VbU+Fm8uYsGGAvr0iGeC//xcERERERGJHkpypdOo8znueHkVj3y0icuPHsqfvj6l2eV/EuNimeGfvhw4Vxdgxsg+xMUaC7IKWLCxgONGpxMTNAIsIiIiIiLRQUmudBrPL87hhSW53HLSaH51/qRG05SDnTGxP8kJ3Tjn8IH1y5LiuzF1WG9eWJJDfmkVMzN1Pq6IiIiISDRSaVnpFCqqa/nDuxuYOqw3t506BrPWR2EvnT6E8ycPpEdC45f3zMwMPttU5L+tJFdEREREJBopyZWwys4vIz42hiF9khot9/kc76/bRcneGgBiY4zjx2TQu0d8i9t5fMGX5JdW8fDlR7aZ4AKYWbMEF7zE9v631zO6b08GpHQ/wEckIiIiIiIdmZJcCRufz3HVnEXExhjzvn98o/Nnn/hkM79644tG7YenJfGP62Y0S4gLyqp4+MNsTp/Yj6nD+hxwPBMHpjC4d3fOmNj/gLchIiIiIiIdm5JcCZvFm4vI3b0XgGcWbuHq40YAULK3hgffz+K40Wn8dvbhAGwuLOeWZ5dz0d8+4R/XzWBs/+T67Tz4XhaVtT5+dMa4g4onNsZ497bjiYvVqegiIiIiItFKSa6EzavL80iKj2XiwF78+f2NXDR1MMmJcTz8YTbFFTXcdeZ4hqZ5o7ZD05J44VvHcOWchXz14U+4/fSxdI+LparWx78WbuVrRw1hVEbPg44pMS72oLchIiIiIiIdl5JcCYvKmjreXL2dMyb155pjR3DuXz7m0Y82cdmMocz5+EsumDyQSYNSGvUZ2z+Zl759LFfNWcTd//68fnlaj3huPTmzvR+CiIiIiIh0QkpyJSzeW7uL0spaZk8ZxGGDUzj3iIE8tmATa7fvwTn4wWljW+w3pE8S/711Fjv3VNYv69MjvsVCUiIiIiIiIk3p5EQJi1eX59KvVwLHjvIu1fPD08ZS53O8u3YXVx4zrFlxqWDx3bxqzIEfJbgiIiIiIhIqJblyyBWVV/PB+nzOnzyI2Bjvcj9D05K4YdZI+vVK4KYTR0c4QhERERERiVYaIpND7o1V26j1OWZPGdRo+Q9PH8d3T84koZuKP4mIiIiISHhoJFcOSH5pFStziltc98qyPMb1T2b8gF7N1inBFRERERGRcFKSKwfkwfezuPjhT9hSWN5o+dItRazIKebiqYMjFJmIiIiIiHRlSnLlgGzKL6emznH/2+vrlznn+M3cdfRNTuCyGUMjGJ2IiIiIiHRVSnLlgGwpKicu1nhj1fb6acvvfLGTpVt2c+spY0iK1+neIiIiIiLS/pTkyn6rqfOxrbiSb8wYRlqPeH771lpq63z833/XMSqjB5dM01RlERERERGJDCW5st+2Fe+lzueYMLAX3z05k882FfG951awKb+cO84YR7dYvaxERERERCQylI3IfttSWAHA0D5JXDp9KMPSknhz9XamDevNqRP6RTg6ERERERHpypTkyn7bUuQlucPSkojvFsNPzhpPcmI3fnz2eMwswtGJiIiIiEhXpupAst+2FpYT3y2GfsmJAJw2sT/LxvUlTtOURUREREQkwpSVyH7bUljB0D5JxMQ0jNoqwRURERERkY5AmYnst61FFQzrkxTpMERERERERJpRkiv7xTnH1qIKhqYpyRURERERkY5HSa40Ul3r44P1u1pdX1BWTUV1nUZyRURERESkQwprkmtmZ5jZejPbaGZ3trB+mJm9Z2arzOwDMxsctO4qM8vy/1wVzjilwX9WbuPqJxazOrekxfVbi8oBNJIrIiIiIiIdUtiSXDOLBR4CzgQmAJea2YQmzX4HPO2cOxy4B/itv28f4OfADGA68HMz6x2uWKXBhl2lACzdUtTi+oZr5PZot5hERERERERCFc6R3OnARufcJudcNfAccH6TNhOA9/y35wetPx2Y55wrcs7tBuYBZ4QxVvHL3uWN1K7IKW5x/ZbCCsxgSJ/u7RmWiIiIiIhISMKZ5A6UCUuJAAAgAElEQVQCcoLu5/qXBVsJXOS/PRtINrO0EPtiZjeY2RIzW5Kfn3/IAu/KNuWXAbC8lSQ3p6iCAb0SSegW255hiYiIiIiIhCScSa61sMw1uX87cLyZLQeOB/KA2hD74px71Dk3zTk3LSMj42Dj7fJq6nxsLaogOaEbWworKCyratZmiyori4iIiIhIBxbOJDcXGBJ0fzCwLbiBc26bc+5C59wU4Cf+ZSWh9JVDb0thBbU+xzlHDABanrK8pbCCYTofV0REREREOqhwJrmLgUwzG2Fm8cDXgdeDG5hZupkFYrgLmOO//TZwmpn19hecOs2/TMIo2z9V+fzJg4iNsWZJbnlVLQVlVRrJFRERERGRDitsSa5zrha4GS85XQu84Jz73MzuMbPz/M1OANab2QagH3Cvv28R8Cu8RHkxcI9/mYRRIMmdOLAX4/ons3xr4yR3a1GgsrKSXBERERER6Zi6hXPjzrm5wNwmy+4Ouv0S8FIrfefQMLIr7SB7Vzl9kxNIToxjytBU/r18Gz6fIybGO0U6cPmgYRrJFRERERGRDiqc05Wlk9lUUMaojJ4ATB7Sm9Kq2vrRXfAqKwM6J1dERERERDosJbkCgHOO7F1ljOrrJbBThqYCNJqyvKWonJTucaQkxUUkRhERERERkX1RkttFrcgprh+ZBSgoq2ZPZW39SO6ItB6kdI9jec7u+jZbCis0VVlERERERDo0JbldUJ3PcfUTi7j9xZX1ywLTkgNJbkyMccSQ1PqR3OcWbeV/GwuYNCil/QMWEREREREJkZLcLmh1XgnFFTUs/LKI3N3eaO6m/HIARvXtWd9uypBUNuws5YF5G7jzldXMzMzgp2ePj0jMIiIiIiIioVCS2wUt2JBff/vfK7YB3khuYlwMA3ol1q+bMjQVn4M/v5fFeUcM5LErp5EUH9aC3CIiIiIiIgdFSW4XtCCrgEmDejFtWG9eXZ7nFZ3KL2Nkes/6ywUBTBnam369ErjmuOH88WuTie+ml4uIiIiIiHRsGpbrYsqqalm2dTfXzxrJ4N7d+cmra1iTt4fs/DImD+ndqG1K9zg+u+tkzKyVrYmIiIiIiHQsGprrYj7LLqTW55iZmc45hw0kPjaGZxdvJXf3XkZlNL/+rRJcERERERHpTDSS28UsyMqne1wsU4f1JqFbLCeN68uLS3JwrqGysoiIiIiISGelkdwuZsHGAmaM7ENCt1gAZh85iJo6ByjJFRERERGRzk9JbheSu7uCTfnlzMzMqF924ti+pCbFYQYj0ptPVxYREREREelMlOR2IR9nFQAwMzO9fll8txgumz6UIwan0j0+NlKhiYiIiIiIHBI6J7cLWbCxgH69Esjs23ha8g9PHxuhiERERERERA4tjeR2EXU+x/82FvCV0RnNKiabmaooi4iIiIhIVFCS20W8tWY7xRU1nDy+b6RDERERERERCRsluV1Ada2P+99ez7j+yZw+sX+kwxEREREREQkbJblRJqeogsWbixote2bhFrYUVnDHmeOIjdG0ZBERERERiV5KcqPMT15bw1cf/pS/L9gEQGllDX9+fyPHjEzjhDEZ++gtIiIiIiLSuam6chSprKlj4aZCeiV249dvrmV3RTUxZhSVV3PXWeNUXEpERERERKKektwosnhzEVW1Pv76jSN5d+0uHpqfDcA5hw/g8MGpEY5OREREREQk/JTkRpGPswqIj43hmFFpnDSuL+k943l2UY6ugysiIiIiIl2Gktwo8lFWAVOH9SYp3vuz/uC0sdx26hhNUxYRERERkS5DhaeiRH5pFWu372HmmPRGy5XgioiIiIhIV6IkN0r8b2MBADNHq4KyiIiIiIh0XUpyo8RHWfn0Topj4sBekQ5FREREREQkYpTkRgHnHB9nFXDc6HRiYjQ9WUREREREui4luVFgw84ydpVWMStTU5VFRERERKRrC2uSa2ZnmNl6M9toZne2sH6omc03s+VmtsrMzvIvH25me81shf/n4XDG2dktyMoH4CuZ6ftoKSIiIiIiEt3CdgkhM4sFHgJOBXKBxWb2unPui6BmPwVecM79zcwmAHOB4f512c65yeGKL5p8lFXAqIweDEztHulQREREREREIiqcI7nTgY3OuU3OuWrgOeD8Jm0cEKiUlAJsC2M8UWlTfhmfbCzg5PH9Ih2KiIiIiIhIxIUzyR0E5ATdz/UvC/YL4HIzy8Ubxb0laN0I/zTmD81sZhjj7NTuf3s9Cd1iuH7myEiHIiIiIiIiEnHhTHJbKvPrmty/FHjSOTcYOAv4h5nFANuBoc65KcBtwDNm1uzaOGZ2g5ktMbMl+fn5hzj8jqW8qpY3V22nztfwFC7bupu31uzg+lkjyUhOiGB0IiIiIiIiHUM4k9xcYEjQ/cE0n458HfACgHPuUyARSHfOVTnnCv3LlwLZwJimO3DOPeqcm+acm5aREd2Vhf/52RZuemYZ33tuOdW1Ppxz3Dd3Hek9EzSKKyIiIiIi4he2wlPAYiDTzEYAecDXgcuatNkKnAw8aWbj8ZLcfDPLAIqcc3VmNhLIBDaFMdYOL2tXGXGxxhurtlOyt4aLpw5m0eYifn3BJHokhPPPKCIiIiIi0nmELTtyztWa2c3A20AsMMc597mZ3QMscc69DvwAeMzMvo83lflq55wzs1nAPWZWC9QB33bOFYUr1s4gO7+MacP6cOGRg7jzldUsyCpgZHoPvnbUkH13FhERERER6SLCOgTonJuLV1AqeNndQbe/AI5rod/LwMvhjK0zcc6RvauM8yYP5KvThpCaFM9dr6zmZ+dMIC42rJc6FhERERER6VQ0z7UTKCyvZk9lLaMyegJw6oR+nDK+L2Yt1fYSERERERHpujQM2Alk7yoDqE9yASW4IiIiIiIiLVCS2wlk55cDMDKjR4QjERERERER6diU5HYC2fllJMbFMDCle6RDERERERER6dCU5HYCm/LLGJnek5gYTVEWERERERFpi5LcTiA7v5xRfXvuu6GIiIiIiEgXpyS3g6usqSNndwWjdD6uiIiIiIjIPinJ7eA2F5bjXOPKyiIiIiIiItIyJbkdXPYuVVYWEREREREJlZLcDm5TvneN3JHpGskVERERERHZFyW5HVx2fhmDUrvTPT420qGIiIiIiIh0eCEluWb2spmdbWZKituZKiuLiIiIiIiELtSk9W/AZUCWmd1nZuPCGJP4OefIzi9TZWUREREREZEQhZTkOufedc59AzgS2AzMM7NPzOwaM4sLZ4Bd2Y49lVRU1zFSlZVFRERERERCEvL0YzNLA64GvgksB/6El/TOC0tkwqZ8r7KyRnJFRERERERC0y2URmb2CjAO+AdwrnNuu3/V82a2JFzBdXXZ/srKozWSKyIiIiIiEpKQklzgL86591ta4ZybdgjjkSDZu8pITuhGRnJCpEMRERERERHpFEKdrjzezFIDd8yst5ndGKaYxG/DzjJG9u2JmUU6FBERERERkU4h1CT3eudcceCOc243cH14QhLwKiuv27GHCQOSIx2KiIiIiIhIpxFqkhtjQcOJZhYLxIcnJAHYVVrF7ooaxvXvFelQREREREREOo1Qz8l9G3jBzB4GHPBt4L9hi0r4YvseAMYPUJIrIiIiIiISqlCT3DuAbwHfAQx4B/h7uIISWLe9FICx/TVdWUREREREJFQhJbnOOR/wN/+PtIO12/cwKLU7Kd3jIh2KiIiIiIhIpxHqdXIzgd8CE4DEwHLn3MgwxdXlrduxh/EqOiUiIiIiIrJfQi089QTeKG4tcCLwNPCPcAXV1VXW1JGdX67zcUVERERERPZTqElud+fce4A557Y4534BnBS+sLq2jbvKqPM5VVYWERERERHZT6EWnqo0sxggy8xuBvKAvuELq2tb66+sPE7TlUVERERERPZLqCO5twJJwHeBqcDlwFXhCqqrW7ejlMS4GIan9Yh0KCIiIiIiIp3KPkdyzSwWuMQ590OgDLgm7FF1cWu372Fsv2RiYyzSoYiIiIiIiHQq+xzJdc7VAVPNbL8zLjM7w8zWm9lGM7uzhfVDzWy+mS03s1VmdlbQurv8/dab2en7u+/OyjnH2u17VHRKRERERETkAIR6Tu5y4N9m9iJQHljonHultQ7+EeCHgFOBXGCxmb3unPsiqNlPgRecc38zswnAXGC4//bXgYnAQOBdMxvjT7ij2q7SKnZX1DCuv87HFRERERER2V+hJrl9gEIaV1R2QKtJLjAd2Oic2wRgZs8B5wPBSa4DAkOWKcA2/+3zgeecc1XAl2a20b+9T0OMt9MKFJ3SSK6IiIiIiMj+CynJdc4dyHm4g4CcoPu5wIwmbX4BvGNmtwA9gFOC+n7WpO+gpjswsxuAGwCGDh16ACF2PGu3lwLo8kEiIiIiIiIHIKQk18yewBt1bcQ5d21b3VpY1nQblwJPOud+b2bHAP8ws0kh9sU59yjwKMC0adOare+M1u3Yw8CURFKS4iIdioiIiIiISKcT6nTlN4JuJwKzaZha3JpcYEjQ/cEt9LkOOAPAOfepmSUC6SH2jQrVtT4e+TCbsqpaAD7NLuSwQSkRjkpERERERKRzCnW68svB983sWeDdfXRbDGSa2QggD6+Q1GVN2mwFTgaeNLPxeAl0PvA68IyZPYBXeCoTWBRKrJ3NW2u28/t5G0joFoMZGMZJ4/tGOiwREREREZFOKdSR3KYygTZPgnXO1ZrZzcDbQCwwxzn3uZndAyxxzr0O/AB4zMy+jzcd+WrnnAM+N7MX8IpU1QI3RWtl5VeW5TEotTsLfnQiMbouroiIiIiIyEEJ9ZzcUhqfE7sDuGNf/Zxzc/EuCxS87O6g218Ax7XS917g3lDi66x2lVayICuf75wwSgmuiIiIiIjIIRDqdGVdtDUMXl+xDZ+D2VMGRzoUERERERGRqBATSiMzm21mKUH3U83sgvCF1TW8ujyPwwenMLpvz0iHIiIiIiIiEhVCSnKBnzvnSgJ3nHPFwM/DE1LXsGFnKZ9v28PsKc0u/ysiIiIiIiIHKNQkt6V2B1q0SvAKTsXGGOceMTDSoYiIiIiIiESNUJPcJWb2gJmNMrORZvYHYGk4A4s6r38XXroWAJ/P8e8VeczKTCe9Z0Ljdm98H9bNbWEDYbTmFfjvj/fdbv5vYOmTzZcXb4V/XgSVJc3XiUj7qtkLz14K+RsiHYmIiIhIRISa5N4CVAPPAy8Ae4GbwhVUVCovgPz1AHy2qZDtJZXMPrJJwanaKlgyB754rX1jW/MyrPjnvtsteQJWvdB8+aYPYOO7sGvtIQ9NRPZT0SZYPxe2fBzpSEREREQiItTqyuXAnWGOJbolptSPdK7M9X6fODajcZuSXO93cU57RuaNxFaVgs8HMa1871FTCeW7oFtiC/398VbuCV+MIhKawHGo41FERES6qFCrK88zs9Sg+73N7O3whRWFElPqP3RW1/oASIpv8h1DSU7j3+2lJAecD6rL2mjjT8D35EFdbfP+oOnKIh1B4DjU8SgiIiJdVKjTldP9FZUBcM7tBvqGJ6QoldgLqvaAz0dNnY/YGCM2xhq3Kd7q/d6TB3U17RNXVSns3e2/3cbIT/EW77erg9LtTdb5467Sh2qRiAscx20dzyIiIiJRLNQk12dmQwN3zGw44MIRUNRKTAEcVO2hps5HXKw1bxOY9ut8sGdb+8QVPDW6rZGf4NHlQFLbdBsaORKJPI3kioiISBcX6mWAfgJ8bGYf+u/PAm4IT0hRKqGX97tqD9V1PuJiW/h+ITiRLMmB3sPCH1dJiElucZPYAupqvZHnffUXkfZR6Z90o+NRREREuqiQRnKdc/8FpgHr8Sos/wCvwrKEKjHF+11ZQnWtj/iWktziHOjRt+F2ewgelW2rUE1JDvTwF8oKjq10uzeFeV/9RaR9qPCUiIiIdHEhjeSa2TeB7wGDgRXA0cCnwEnhCy3K1Ce5e6ip60l8t5ZGcrfC0KNh7evtV3xqf0Zy0zL9fYIS41D7i0j70HRlERER6eJCPSf3e8BRwBbn3InAFCA/bFFFo0T/dOXKEmrqXPPpynW1UJIH6ZnQs39DoadwK94KCf4EvM3CU1shdaj3U9zC+bkJKSp0I9IRqPCUiIiIdHGhJrmVzrlKADNLcM6tA8aGL6woFDxduaXCU4FpvylDIHVIO05XzoF+E/2xFbfcpq4GSrd5caUMaVKEyn+730SNHIl0BBrJFRERkS4u1CQ313+d3NeAeWb2b6Cdyv9GiaDR0praFgpPBRLHlhLJcCrJgbSR0K176x+K92zzKj4HJ+A+n7//Vu9c3Z599aFapCMIHIfVZc2vaS0iIiLSBYR0Tq5zbrb/5i/MbD6QAvw3bFFFo0bTlX3Nz8kNjIimDPUSyXVveIlkTKjfQxyAmkoo2+ntM7FX64VqghPw2iqoq4LyfEju58WdMsQbqVahG5HICz4Oq/ZAUp/IxSIiIiISAfudQTnnPnTOve6cqw5HQFErNg7ietRPV25WXTlwbmvKYC9prKuG8l3hjSlw6Z/Uof4ktZWR2KYJODQkvoFzdRN7aSRXpCOoLIHYhIbbIiIiIl1MGIcJpRl/IlhT20LhqcC03/gkSPVfHzf48j7hEChulTqk7SQ3kNCmDPYS2kBsPh+U5Db0r90LtfruQySiKksavoxSkisiIiJdkJLc9uRPJKvrfMS1NF05xf/BNPABNexJbiB5HQIJvVqvxlq8BXr2g7jEhhhLcrwpy3VV3ghvKBWaRSS8air9x6T/ONXxKCIiIl2Qktz25E8ka+p8xDetrlyS05DcpjSZEhwuJTlgMdBr4L6nKwdiSuzltS3OaXyublD1aBGJkEBSq5FcERER6cKU5LYnfyJZU9ekurJz3rTfQCKZ0BO69w7/ZYSKcyB5oHe+8L4KTwU+NIM3clu8Neg8YiW5Ih1C4BgOnFagYnAiIiLSBSnJbU/+CsTVtU2qK5ftgtrKhnNxoX0uIxQoGlUfWwsJauC825SgJDd1qBdbIMlNHdKoerSIREjg+EsZ2vi+iIiISBeiJLc9BQpP1TUpPBU87TcgdWj4z8kNHqFNTPHO5aupbNymfJdX6TmQDAfiDExXTkxp+AF9qBaJpMpi73fKIP99HY8iIiLS9SjJbU+BwlO1dY2T3OBpvwGpQ71E0rnwxFJXC3u2BU2R9o/ENi1UUz9aG5TkpgyB6lLYsaZhxKi1/iLSfgLHX/c+EJ+s41FERES6JCW57SmhF/hqiKmrbFx4qqWR3JQhUFMOe3eHJ5bSbeDqgkZyU73fTUd+WkzA/bfzljYeCW6pv4i0n8DxFygQp+NRREREuiAlue3Jnwgm1pU1GcnN8S7BE0gUIfyXEQq+fBAEnVPbZOSntQQcwFfTcDu+p1epWYVuRCIncPwFTiFQkisiIiJdkJLc9hSU5DYqPBVcACog3JcRqp+GPKxRbPXn9NW3y/FGeROSG5YFF8gKxB0T47XRh2qRyKks8b5siu9ZXwNAREREpKsJa5JrZmeY2Xoz22hmd7aw/g9mtsL/s8HMioPW1QWtez2ccbYbfyKZ5CtvXngqeKQUGpLHcI3kBpLnlMGNYmv2obgkp3kCntQH4pL8cQbFrZEjkciqLPFOizDT8SgiIiJdVrdwbdjMYoGHgFOBXGCxmb3unPsi0MY59/2g9rcAU4I2sdc5Nzlc8UWEP5HsZRUNI7nOeaOlw2c2btu9tzcaE65r5RZvhR59IS7Ru99W4am00Y2XmXkjzQXrG5+rm5CiQjcikVS1p+ELq4ReULUusvGIiIiIREDYklxgOrDRObcJwMyeA84Hvmil/aXAz8MYT+T5E8lkKogLFJ6qLPYqFTcdyQ0kkqFMV66tgr3F+24XrOjL5qOw0HjkJ5CAjzyxef9Uf5IbPMq7r5Ej57yfmA4ySz5Qudqs7XZt8fna//FUV0BVacvrEntBXPdDsx+fz3tuWnp+ygvBV+vd7hbvfSnTVDif39rqxkXZuqdCt4TQtxvqazHUx9DWc9WamsrWj5eEnhDfI/RtBVSWNJxfv78juQfyGA7WgbxG2upzsMdjW8/BoXwt1tVARVHD/cSUhi8cg1WXQ1VZw/0e6RAT27zd3mLv/0BLWusTCU3/V3Xv7b1/NNXac+0clOe3fNWBmG7QI23fMezd7f3NWhLK8xsT67XbH4fi/eFAnis4dMdz09dia+K6N7wHBaurhYrC/d9vUhrE7uOjatPnKqkPxMa13aetv0lFkXeMgredpD77F3NVmfd8BfTIaPlvdLB/uwN6Xe1tXDsllOf3QGI71A72b3IgQn1+K0saLr9pMd77w4E+Pz6f9x4XcKCfBQKavhZ79m3/v10EhTPJHQQEZ2i5wIyWGprZMGAE8H7Q4kQzWwLUAvc5514LV6DtJmgkt366ckuX6AlIHRLadOXHToKda/Y/nkkXNdyO7wEW2/jNb+9ur8Jz0wQcoM9IL2lPCvpQkZjSdryLHoNP/wLfW9kxDrL/3gkFWXDFKwfWf+N78MKVcOvq9nnDBe+D1h8mtF51u9cg+P7nB//8Ogd/mQpHXQ/H3Nh43crn4dUbGi+75i0YdmzjZW//GHZ+Dlcd4NkG2fPhuW/Arauaf6h8+jzY+mnD/YzxcNNnoW/704dg6RNwy9K22714tfehbfbDrbfx+eCPh8HM2+Co60KP4aHpULyl5XUJveAH6/b/n1vlnoZK6Ym9vPvOhfZP+g+HwYWPwNgz92+fB+Ola70PLBc+Gnqff98MVSXwtX82Xr57C/zlKLj2vzDoyAOL57ETYOzZcMIdjZdnzYMXr/Fei02P9SfOhLwlDff7Hwbf/rjt/fxjNmxe0HA/bXTz12LNXnhgfOMP70dcBrP/1rjdthXw6AlAK5ebm3ABXPJU2/G0l8dOhp2rG+4PPgq++W7jNhVF8MfD4atPQuYpjdfNvxc+ur/17V/8BEy6sPX1OYvg8VNbX3/4171jINj2VfDILBo9v2f9DqZf3/p2gjkHDx4JM74FR38ntD4Aj8yEgg0N94d9Ba55s3Gbsl3wpyPgsudhxKzG6967B7b8D657J/R9tqa6HH4/LrSZWhYLNy+GtFGNl79wJax/s+U+bRl3Dnz9X62vdw4eOqrxZ49RJ+/7//ojs2Di+TDrh42Xr30Dnv9G42WXvwyjm7wWW7O3GB6Y4H12Cph+A5zV5HWbswieOtc77gOnjQU8+3VIHgDn/rH1/dTVwB8mwsk/hynfaL1dMJ8P/jwFSrc3LBt7Flz6bGj9Aebe7r3XXv5S6H0OVvb73ntmsEuehgnnh2+fdbXe83vST+HIK1pvt2sd/O0YcL6GZaf/Bo656cD2++Zt3meTgPhk+MHaxnVxQlVR5L0Wa/c2LDv6JjjjNwcWWycUziS3pU9VrV309evAS865uqBlQ51z28xsJPC+ma12zmU32oHZDcANAEOHtpAkdjT+JNcbyQ0kuU2qHAdLGQK5i9veZm21l0iMPSv0N+GA4PZmzQvVtHT5oIBZP4Qjvt74w/O+Ct3kLfE+1FcU7v834eGQuwRKdxx4/7xlUF0G+eth2DGHLq62FOd4Ce6UK2DglMbrst+HdW9AbeXBj+bu3Q1Fm7zLRDW1fSV0S/TeyGsrvWR2x+rmSW7uEti1NrQkqyV5S70PCvnrG79enPNiGHkijD+34XHXVLY8GtbitpdA4Ub/yGdKG+2W7vu5LNsJe3K910OoSe7eYu9YmDi7+akKO1Z7/+R2b4Z+E0PbXkBlCfQe7t1OTPEuE1Zd7n0b3JbCjV7imLe0fZPcvCUQ28Lo1L76tDSTYcdqqKuCbcsPLMmtrfYSmp79W9jnUm/GTeFGSJresNzngx2rYPSp3vOWNQ+y3vE+ILU1OrJ9FYw43vuQtukDWPu693cK/lKjeKv39zzyKhhwBCx90nvdt/S4cXDy3Q1fcASseMaLryOoq4Fdn8OYMyHzVFg/F75c0Hw0q2CD91znLW2e5G5b4X0hfNytzbf/1h3eY20ryQ08F6f+qvkXSMueavv5Peln3mjqe/fs33O6dzfs/rLl99LWVFd4z8P4c733ubWve+8vTe1aCzUV3rqmSW7eEu9YOBSzjYq+9BLcaddCv0mttyvd7n0JseuL5knu9pUw5Gg4/JLQ97vyOe9YaUtlsXesBN5L17zS8t8xWE2l92VLS1/gb1/pjcaddb/3v2bu7V4MoX6+Ksz2/m9NvwEyxsHCR1qOJ2+p9/9z5xfNk9zcJdBrYNv7Kcn1/vfkLQ09yS3f5f2NDrsEhh4Nq57f9/PbVO6S8NWKaU0gxjPv917Lc3/kLQtnkrsnD8p2eM9vW0nuzjVegnvCj73PKfPv3f/nNNj2ldB3Ahz1Te+z/ZLHvc9iA47Y/20VbPAS3KNv/P/tnXuQJEl937+/ee9jpntvX7ePnuWAveM4JBZYnmc7IGTghCIECr0OGQnLWCgsICzLoTBy2BKBbNnhMJItB5LBBusFOiMZpLOMhAABEoKD24PjcXc6uDu007t7ut27ve7Z17y6039kZXd2dmZVVs1U9czs9xMxMTPVlV1ZWVmZ+XumVqTe8xubZz6oiDKF3DMA7BHkKIBzgXPvBDCg9lBKnUt+PyYin4WO133UOef9AN4PACdPngwJ0JuHyR1QYxOYkyv9mNzeFj0+S+68niCXL4W1OItnASjgOd8HvOBN66vftCOkptVt9wH9Y5PlHmkE+tbC5hBy201tLSlcfqH/PahIyDXXfP6dwDP+nvOh0sLe0uL6hVzz7H3u8u0kG/iL36IXAZ/+Zf+k127qxepSy+/OXLQOVy/qhd3x1+g6TO7Q9714dnhhFaLXF5vAjQEht7MGLJ7TQliaoN6rZ46J35R57huA294w+FnzXi3ktprFhFwjtNshCFlCrt0eVdHt6PYdm4hXhJgQirVrWmiyXRLT+mwMi5QxGDEAACAASURBVGcAKH95e+xqWELulfNAZwW4+bW6L45NAN/6U70PuW/cBPTzWG7rRfOL36LH3Yfu1ovW/bcMX/PEj+kF6YW/0Yt+l3YTgAAvf8ewO2vrNHDPb44mrMJl8axeDD7ndcALf0I//0c+pV3zZg/2z2ulvE/tJnDjd/uVSV/49ez+22rq9/nlbx9ujye/BXz194b7oukPr3iHdkO//0P53hMzNuYp0z6jf9/6/VooXL2qlSHXWtod3q1bqM92VrQgNHco/tre+pi++Cbg6IvC5115Sgu57r12VvU7ceLH8nm7LJ4FPv9f0pVGLWcsvXYROP15rSiY2hm4nzODZQc+awKzh7WQAQCf+ZV8Y4rpty/8Ce3VceaUfnaherv9fOUqcPVJraBMvU6B8c5c83k/CNxyhxZ4/+o9w2Np1nWvXRxWypVJO9nl46WJB9nn/2t5O4/Y17R/hzDv98vfpufZb/zB+urWbmqF6YvfopVXpz6gn1sRIdc87xf9Yz23LHxRexBcR5Q5690L4LiI3CQiU9CC7JDfoojcAmAPgC9ax/aIyHTy9z4AtyMcy7t1EEF3ag5zuIop25I7sWPQ7dfQ2ys35YXpZUn2aCTzMuMkjkpzpU4r3+36P1/vInQjWV3Sk//yol5sFcFe+FZFmuXfWHE2IqNumtDTavavL6K10O4zXVvuW8mLCk6hOphFgXk/TF3yPIeYvnjpnF5orF1LjyUrsog15/osCeZYkffETTxljmUxinfz0uM6rnttaTAGKQ0TQqG6iYLPYr2Cul3ejfkcUGh5ypgxMmbMdp99qIy5Zs3q58uLw/kXWk3t2uiL16w1tKBz5Xy4PlXhjl2hft4OvE9GwRGa62JyWLSbOqTDJ/DXGtozxw0FaTW1dd/EWcfmyrCvaf+OKuN59r7vCPX5brcvyG3EO502XtmYnRfcay6e0+9sVnmXWkOPwbZ7rUvbqVsteRfN/XvLLAz+tmk1B+tZbxQb2+1+funx4TjwUD839TYGjqzr5FKeeOZO1dXPJ4aVK/25sEqF6HqfSdFr2r9DtJtaiW8UybV11G31mp4LTR8280rRd7g3jhzt123xbPE17xakNCFXKbUG4O0APgHgIQAfUUo9ICLvFpHvt059I4C7lBpYVdwK4JSIfA3AZ6Bjcre+kAugMzWLWTsmt72gX1ifFaMW0cHzCqJpuJbYVhOY3BVvhZueA6C09c6ls9pflFbt6uLDngDTJpI0esJNlULugo55mjsy/JkRbjYiw7W5J9/k7O7rXJ8fboN2YhWzv6toHdy4VbfP591uyyg4ssrYn4ViZ+3z2mfCCp5QGXvPacOuA8D4dPo1fXQ7iZBrJZ4C4pQeo+rLvr9Ty1ht4pYxn623v61c8gg6gfYx1+z1xWPZdQj2X08/H5sEZm90znPr4Nln3RBTn6rIc9/2b8PVi0mOiJR7zbrP1LYKte9pz3jXzP+uL54LJ7wKlcka40JtdfnvgO6q/7MitE7rEJVd+9PPE/HPB0XXKTFjuzuW5imz1B4eH2PmtzRaC3qnCWNxr88DUImniKcOobYCMpRlVnlfIra0Mj0BPOfcaden6rnCnivzPpOi1zS/09rX118Wz2rvg9zXdJSmO/dqpdF65rSd+/oW9/q8ViynKY22GaX6LymlPq6Uulkp9Syl1L9Pjv2iUupu65x3KaXe6ZT7glLqu5RSz09+f6DMelZJJ7Hk9rIrp066ERaqVuKq5hN68uIKuWb/3th4yrRFtdHkAtVqAEPYGtwils+N1pTH0m7qWB2f65ax3C3lzLQdug6Aocl55Yp2VcrSqtptUqR9lAq3r6spnzusY6hir2MrODLfLc/fQ9+XfNZd1YvLqDqkeHCMjWnNa973xCg3fO7KWZhrLZ4rNjkXociCKe2ZrNcaHeqz3S7QNgq6wDV7ffFIdh16ZZJxf/eNWpj19fPakX623zTLZ8hCFjOHVIW7N3vPAyPwfi+eHRQkXSuUS72hvUfSBEnXIuSWt+tp13tgvJvXsd+x3ge9+1PD3gdpZcYmPAqOlD5vL8Q3WhhpJxb0mLVAzZMws6jHWYwly/WG6z3HAmN7Z00/I7uetfnh9k3D7S9Z/TzkyeD7zL0OoBU/oUSULq2m9vgyitC8lsKBMbKiMUWpfv8z1Bra08pkWy4Dc3+ZnlxO3erG+yDSOu67puk/ZpeVwkKuxwJujl8njDhI5/pjbXJOW3JNTG6a+9WuAzp+KGugC7mq5WWmNphdubWQb1IyA+eSx5K4XqFno7Ff8iJC7pULeqHjflfZpPWXPEJN5nUC2uSegGkpZmoNHUO0cjW9TB6uPNnPCOhb2E3t7nsYjE/qGKrY6+RdRGSdV+ReWykeHID+LO97Yt67adeSm8NduejkXITY5zBQJuWZmLbPEnRChJ6jbRXzXdN2VZucAXYfzLYiTezo5yUYG9PCrK+fu4ttt24mrjnNhddX71Hguv3OzOk+6hMqgX48qV0eyLhXj8XMsLasn2UtoFT2tm+i4HAX2HY9sygy9/XcqhMFx869us8M9T/jfeC4WW/0fJumHHDxjV29Z3d0+Pw0zPmpSkZnLJ09pBUEMYpJ9+9Lj+sx0BUMVq8ObvmVhk/oca9jlMXmfLd87+9YT6NIIcgVwI1SLs+81fu7ojHl2tO6f7vPJI+bdRFinoMRwOvOesgtn/eabv9Zj+LWN4dshvmgIijkVszq5G7M4Sqmx8f8VjGbsbFsLU4rRYufF1/iqTzuRWlClnl59x7fHFok+yUv4t7btu6nfSZey7te3EnKJk3JUOQ6e4/3/7aPA8OWDWDQQtpuauvqnpuKaXxNGdO+tkXHLCJsATHPRBDbF1sLWmCZms1eMPnaKg138nEpEtdj3rshS26EZb9l3UNV72erqd0fp2s5FlmJgmP3jYNlli/rsXTvcaQKOmmEnqPbX+x33fccs2I22029eLf7r69Myxl/d+0bFnRMXHNoTJhOlEGbYsz1zFW1+cG6mbjb1LEny/MpcK9mfAq1lS+e1Cg4vNaQWO+DhfzvlvvsRYa3FOx2kmR7vj5rxs9nb8yzzxqvbGqN4XjS9sKggiOWyR16jMiyytp1GxvX3j1ZiknfM/FZnHtKjaKC5FEA4lei7T2u+5i9x3W7qd+LGANH3nmn1RxU8hilXJ57G5vUfbMqQSn1mZRYh5j2NUkwa771UIG6tZs6HG3WShRXNMbXjKUDArhRGm0Cz56KoJBbMSu2JddnFXPJCrDPM/lkMVPT8Wjdjp6grj2dT4BOiwk1L/z8y6pzc0nDfsmLWD5N+WOv0BbHK09uTL3SMNl+K7HkNoH5l0JPzh6NsW/Ccc+bPaT3U16PRvPYKxLXQCtxjk+xk2ciMAJ446URwkgjXYA2E4nZQiqP223au1Wf1/ecJ/u3664cm3jqWktn+zVbQFW5eMlq37Qydixn2+ovQME+twAcPqEFSV+fP/YK7RpoW3R84SZZY7bv2bsxZmsrWoC13zOT5M37PqbMIXkTJZWFzwvFFdyuPqXH095zdCxHaTkisha+WS6zPtfAkOdK2nV8151/Wf4yPuWJXTej4PC21QKw4wa9hc16n71JhhNtyfVYxNejjM8a232KX1d54itz5IXDuQ98scN5XDyvtfR4az+7iSntdu5TQvTGXCeEpj6fHrLS7WgPgzzjXc/quI6504RQ1I9VqwwF/Ir1supgwtGy2tcXQhHjfRCi1dTWdTscrd7oZ7POgxlL7b44tVPH6G6G+aAiKORWzOrE7iQm14ohTLOWpi1Quh39Im5E0ilgUEjNcg3z0YsJ9VlyT2tN7r7j/mQPVdNqahdXoJjlszdJ3T74f5ksnk1cqQLPe3KndtNab+KpnlXs2VpQdTXddjIcwB8DZRa0RRNEmDJmm6SBOvgEixzJHloLeiK54Sa9eLPdrN3z6vPp92CS4ey/VS8qY+515Yp27057t3zW8Sx6ltzkPZyc0Yu4rHdtSECsSAllFr55+ohJAuRaEkz/6PWXnPdgrGK+Ptt23nXzv09TDvTrFkpM5BOMa41BN2uznZFPGPbdd9ocUEWSlizMojHUVspJUucbV41nUcjFf+6IVl6F7jUm+dHQs/e0r3GzjmlToyzujaURZdZWtDLTpzzxPfteWznjtP1urcfTqNfHPEnyfPgsWWlhNjHfF2o3k+3X169CZUwSzPp8uE1tt+o8yZlCfSw0ppjxyq1D1rxzKfEwOPR8rfiJqVvP7TdHW7n05sSIJG8bhZtYDCjfInn5CR0uceN3JZ5cOcaUyR061DBv4kjzfUPPxyQPzCmYukkRe9+3CeaDCqGQWzHLE7uxW5YwKR2rE2Ysdi8/oTPCulz6u3RXtbzMWEJqjAA+VD5lCxtjvVhPvMJG0m4CNyab2hcRuNtNfb8Hn5v8X8Gg4XMVthEZdjlfz3V8VjY3GQ7gj4EygmhRLWS7qe/l4PP63wdohcRS228Rio0ntQVwwC9I9hbljXRNt63JjXXh6rlNpiwai2yL5LorA/qdzuoP5t72HU8m5wr6skksVp/vt2/MQtweR9pWYiLzHOZfBkDya6p7br+Bhe/Ovf09bE17me2MfBa30LY9Zg/Mof7rZGANCa+uldjdIsKHyQZcVUiFD5/bLzC8bY9p9wO3aouta/1Km+smpoaVcjatxINj7nD4O4aevcdSA/TbNAvbChWbQGbxLIIKjqtP9cdSU8/DJ7Sg4xOUao188aQ+3O2MsnDHrm63L1QWod4YDlkxhLzhQtv2ANZ2RvPDY3t7QY+B9j7zM3Ut6ESN7YE52jVWtBJl8dGTg/dhPDh6Y1yGV0L9WLwnjM8Ly9TVTfIWwrhS1xvDbtZl0fZ4cExMa6NJWeuu2PYNGYOKxtGGLO1A/nnZZwE3/496/V0hFHIrZml8FgAw07nSH+h23xguYDq4LytjOzDAF8VOVBMaEFPLZySeGhAsRviSGbffg7fp/wu5K49AaI9xb3czZK/nOr1FgOMG5/aJsXFtRTHP1CTDqTf8yVxi62CEbLt82iIi9jpt59n5Jsor57WgYuqwHPA+sCe52MkjNPnYFNkr17x3RtkEDCeT82GPI+tJcpGHKxf0/rjmmiuXsmOHl5NzTFvb2axbTR3DNnc0XdAJMSSMOFYx39iVJgDZ32nTU3B4FuV2mZBrbS/J25X++Tv3aTe0ELVGvgysZZAmjAD+NnWfQ0wixCzBYPawTlSXVv7a09qbxVxzxw39LTh658UqtAq8W8Fn7yjlWpaCw3b77mWjnfd72eQlZryy2X1wMJ7UWMUKuyunZLNOnQ8C2ayzlLjud/XioXOM7b5+3j7T35+0nSiLa41B7wOj4DDjTcjAUUR5ktZWbpI3H2sr2rAyMHcWyH2Ql1CSxjKFtbRxyKbdHEyCaSgSR9tZHQ5RMXUA8r/DaXNIlXlkRgyF3IpZGtOT5Uzncn+g821Mb+gtfjyuD3knnyymHUvu+JSesGIZn9Qus+5i1bWKAaPVJF06p61+e27SGsKiiadq83ovvOm5agSD3qCVYrWZmVt/4ilbc9/T8lqTs08jb1s2jFXMFlLzto8RRKdntdDWWwSHFhGRyhM7rjkt1soV9EPn2R4PsVtNxFhGZg/rBBR53hMjhE/P9o/FWPbtbL9Fk1zkxV2k2ceiyjiCZLuZZKMdKyaou8LItYuWoJP0xR17EtfACEEU8C9KQs/ejfNsNeHdGs71PvBp/l3yJkoqg1jlVKuprWYz9UHPCKPgiLnXoGthTFs540iofc0CO+tddxfLbWssDZZJscDYn7eb2sNgategcG+S4WzUfNtuJtsZHco+F9Dv4NwRz3uyDkuu/T02adbJYBlnzL5yoZ/7IJTjpNaIEzLazcHM6Xb57poWEk0dao1kZ4BDg/3N1D/VwOEoOKIsueucO00IxXrm9SKkPpOSrj+kCEkZU9wkmEC690GIxbOJh4Fzr2aLuSKK2+m5/n7NvbrNV5dHZhNAIbdiro3rrSYm1y73X5A00qwCRvDdyMRTQD8mt3Y0XQAPfYcrNBpNbq0B7D6gN5UfZfIpO45iZi7/vrJKDbrOxWpS10vrtFY6TM6Ez9kQS+5CX8HRm5wftzS5nsWK3Qbuws7UPW8dTNm677vdmMbIGJ1eXHPDcrP2lLHfrbSYrNZC35Wq3khcA1P21DNl7D0wfYxPJAvFHP1qeVHXxbZU+d5HX31Mtl+zYMozORdhoH0jhTA7yZJbZuh9zNvfTH2OYmCbBfOu1+aHM9wG4+9S7idUZu4IBpK8mcRt7tZw7nzgi+FyyRNTWBahuaoXb5bUzQiVdhIoE/sMxN3rYkCQLNJWvphrcx8rl7Kt42Ys3XWg731wKWMv7dYCtILDUWa6Y2lwjIwcu2IxOQzsEJUs7Li/kMdDnu8CAor+heEcEQNlUt7BuSODioNuN/y8Y+MYW6cDVsekn7c9762tWLSF9lQDx8KggsPNZu3DuP3uvGH43uxrB+/NN69Xse4JvLf1+fyCZJ5rmq3hao1wHplg3Y4NJ8yMuSYw/H1jY3peyivQp7Wbfb1tDoXcirk2poXcqdVLSSfMSOZgLDq+Dt6OcFXLg52dN8Y1zIfPcmTHN/gyhFaNvWCKced0MQkceguMyPis9RKjFNmImFxbwWEnPbA1uS52DJStMZ4toIU0GSrNYGxncmwv6GRKu/YPlukle8joV7bl1XWz9p5nLRRDVgGTDCd24jcZFLMWjXktkkutfsiAIUbpYVur6sfC8aQbyUD7OgvAzDKWdd0oy+zFaX1eW+uzLGY2ttuvLUiaDJV16123r+lzVZueDW/b02r6FRxuPGnIgmjft4lrjnHhNd85KlpN7fZr9hM2uNv2uM/RxJPGWgNtpZxNZ62fWCyrPNAXro3HjkusJctYoeyxNKaMT8Exe6PuO762st2s7Xdrxx7dR9fz7EOCXxr22FUk9Mkmy5PGzREB+Lft6ZVZ6CuLe2P7grbodpYDgoERdLIUhoE52hamzX7Ndj+3xxQka6RUA4fznoTOGygTcPvNM2+Z6/WSvJU8pixfDu/yUW/EuVkXwX6OqeEngTwBRTwoQvG9QN9zJA9pFnBgtIamCqGQWzFXE3flqaWnkoEuY+Afn9CJMoID3QZZcYFBITfGDS70He6i2tXkVuUSGcJMvnNHigmFrutdVXGMMc9kpr7+7Mr24Ggv5tLc4+0YKNuVamxcL0LytI/bvsYtyVh0Qh4GMc/BddkKKShazUSTO6sF6okZ/yLAnuTyLHxjFo1535Ol9mDSKSA+8VTNamtzrExaTb0/7kxNWyQmdsQt0oyCY3p3ks3aWjT2nmlA0EljQNC3FgHuAt1+JuY98WX7DbnS9dyqPQoOVzDwLVCMoNNq9uOas/qSEXRGPeb6xg132572gmfsWRieQ0KEQhAuPd734EjDjie13X5d8rjY13O+W6EEW0YpZ9yk7WzVtiLOXiz32ncdzz60WE6jZsWTtpt9q1gRTDbrkJLRVzfftj2+MvYzCYUf2MeixnZf+cQq317ohxrY/dwo5dpNXe+J6WwDhyuExSpcXMxe2jHlJXFFN0q5stc9qc+kxPwu9hwdat9QEkxgcOzKc00A3nC02BwANiH5IC1MaxtCIbdirkjirvzUQ/pAzOSRtmDaKFdloB+Te/m8nqCKxND4YkLdgaoqoTBEy9LkxrhzDpW3NJqAvq/lRW2BLAsT15z1vDcq8VRvYWa5AadNOO4ia9f+vodB3kXWkCDa6GdgTRP0Y67jTiQx75bxPshaMEVr1COF3HpDx493VrPPBfR7NyTkZngqmGy/dautgfK1vPYioucmHWGFtxUcZhzpJXMyfbZAsjP7mdgxUG3nXa83tMV8+VJYGDHnZ1lgvGUW+tsZ+c6zvQ/SNP82RtAZtSU3VE/zHI1LoE8obDf7br9phBa+aWOXjR1PmhY7n8cq6xPaY8sMXTdZ7F55cnAPTHvsaTd1XLPxMIh5t0KYZDh5Fd7m/MWzxSzBLqF9b9MUhqEwIrvM7KG+IJmmSIkZ2812Rr5nN7VLK/MGxhSrnxulnK3cChk43K3Loi2xKeNVzNzZaur2MuEwVRgr0sIUyso1EGzfwJiykZbc3YmCw6XnKReZzXqprZNl+vriTE0rmEc5H1QIhdyKuQK98B+/8KA+EDN5+FwVQns0rofxCR2zcf6h+Lq5eC25jibXTfZQNfZEUkQodF3nqkjCYLL9Zj3vmTktEMbsF+vDtYqZybm3CPAkwwEGtYPuIi12ax2DbxFgjmculjNidFoLyRYRM/0yvq0m3HfLN6EvLQ4mw4nZasJsERGr3FJdreWPYandV1QZpmt6MezbSgPAULbfKi259vgSu8jylfEp0YD4PtdzS03KjY31vQ9c7wVX8Ao9R9v7wCarzOLZJKY0ZWs4Iwy3I62b5pxRhYiY9k0VRjxC+4DibCHswTHwXYHY/NiYXqAvdKcJPcbNOq3Pri5pZXHdGkuN90GIbgdon81WnrjP3nZBNO+J8TBYjzBikuHktuRaAshGKON9ivG1ZR3fnKU8sbGTYAJW7gPPOGITY8kNZU63v6O14OnnTlu5Y5x7TRNCYcq72ax9GLffLOVJGkPz+jqUJ7GkKZrKCsNwt4bbtV97ELn36irjbdK8D0KEXJ8B614js1mned2Z47TkkjK4Inr/NTn/TX0gatJNkmnYgovR5G6kkAvoF/OJHHXzlXcto24AvJshtGrsBVeMO6dLa0EvcEwChyoC+UNJCVzs5GFF8E3UZlHdamrNshsrBlgxUAvDGuP6fD4tZGtBuwebuFtTlwvf0sJ+KI49JtmDry+q7mAGy15iMU8b2LhWPjcxkQ8T1xwlmOTsV8sBS675zIfrjjszp4X1MvtyL5mT00eiLBH2MznW72/mOwBrgR2ZfMrn9tvr8wv9bL/mmgBw/sEkVizFKmvv/wpoRcPiuZQyiUWn+eXkPtIsvs3hZ5dGbOKcMrj6VOL2m3I/1y4CF/4m+T9p456btRHcIuajqZ163BgScq0Qiizs8c7879JzA07pY2ljaYhLZj/hFEHp0uPAU48OfrcRdEyfdd+tpVaxrPux846LPXbFJPyK+T4TJ21om7E0pV/Z2/YAg0kw3e9uLej33M1rAPQTZqY976y2MoJka6Hv9gv0+/vTpwdd0O26DVzn9OB1TGKitH7lzlW+urnt69I6PVy39tniCvUYTOI23y4fvZCVDR7Xeu1rKT1983rM885Tt7T3JNYlvay6bWEo5FbMcncMl9UOSPvM4ECXRq2h44kuWRadvBu0xzIzl67RzMLEuA5MRh4NIBC/CN1IXE2ucefMs2eYWUT0NOUF3CPzErugtbeBWs91Qhaz0PVNDFRrYditOrcW0mlfM1AvfHG4bjYxVkifptwcN7iaXHPNq09q995ePT2a3CyrSayLKZB/Yltq+xNPmc98+KyBZYcTLLV0Zlr3mtcu9vd/dVld0soLu63rDa3oO3d/MpYe1senduokUrHvo++ZGPdI0196fTE55/QXBv938bnSmT0wg/13Pu67jaBz8TFtqXe3iAiVMW7WVZM1dtUD923Hk+axBvqsX23jwbEjonwST/rUI4MKjqF6Z7wnvjk6s0yKdciUhwIW7hn8btfN2n237O/OQ5ZFKMTcYf1OPv41reBY7zql1hhWGqW5i5oy9rY9A2WcccR4bYS+q5cwM21sj+jnpi/bicWM4uXMvf2t9+y6LZ4bFCR9zyR23klTnpgkbz66nURB51xTdfLlPshLWg4OoByLpHc+8FwnlASzVybgYu+j29UKgzSvBLtuWWSNI6MOX6kQCrkVs9rp4lLisjwQ35CGr4MXnXyyMItie9GYt3xnRVtGAL9bdVUukT6M26+pw/Sc1pzncZ12BaVd+3TinDIHjawJ3bBuS65ngDcacbM9QohaAzj3VY9VLOciy21fsz+pWQRnTQQhFypfXLP33fIJ+h7vA98zyXLhin2OQF8BFvOeKBVOPAWEt8lqNYf3wMwzORchJFTan7m4cbd2+dNf0Ela7LE0j6AeEvQv/522mNn13HVAWxZ6fTFlEQEM1iFLeegK0CGrY0/Q+VL8+D/KZCMxwgig79v24DBlnnpk0O03C9/CN0+SRnPewj2DCg5fvaMEC4/yJKRUzZrX7bZy98CsN7SHgZsMZz1K2HYT3u2Mshif1O9klsImFt8ckqUw9CkJfYKorTRKy0OSJRi0m/7M6XZ5o5Szrz+5Q/f5Xls5a6UhA4dvji6gcLHJmjsvPe4XwO36lEGWcqsMYS1NEWITI4D7QlZ8XDYeHIF7Ndms81hyffs123UrO4/MJoFCbsWsdrq4JDrDcrxm2jNYr8famoZZJLuLxrzljWuUzypmJ3uoGlejWUQodONCq9gWqdXUFoXp2fTzsix3MddxFRxmcs7aVqreAC54EqrlVWr42tf+7qKWXF9cs3Gzznq3fIsAew9Muw5pW020ciwaJ2e0m1ZM3NPqNb0ICbkrh+rTTlzQ7Wy/eSbnIoSUA/ZnQ2UCVjFA9wu3T+SJQwxp7gHgyYcHv9u4Bmb1RV+imkwBJukTFx7q74HpPc+67/XMIVWRKYzY93N0UKisNfQzSCvvUmtopUiaN1FW+V59Msa7NO+DdlPPc7OHB8usXQvvpW1npg9dM1S32rzl8r1BwkirmWT79YSoZBGaD4rgG9t7AnjAGy5YBsPto7rAU99OF8azrIatZvrWcFnjla+tQgYOV8FhZ7MO1S3k9mtfM3R/IYVNWpmNIEs5Vc9QGhW95uSuwa3hfHlk0pJgAn7vg7Rrmuv4GJ8c3GIuC5OkMU1BZ87b5lDIrZiVtS6uGiE3VrvZS6aRMdBtBMbdtajm1RWyfFax8QmgdmQ0VgXjIt2LQcwpFC5f1gsb16pQtotn1oBq6Fnu1mHJ9VnFfH+7+OKuiRhEvwAAIABJREFUgWQRInHt08v261kEAMOLRpusZA++xXbPzdonjGR4H7jZfu0yQWGt6d8DM0SssGb671DiqQz39VYTQzHOeSbnIvTa17qunagmtYxHEHX/BtCLf4tZ/LSbw26/bky5jblWWrZf430wpDxJUXBM7dJu1r5r2sS+j74yo4jDajf9+wkbTDZrwPMci9zrvBYkrzyp/+9tt5OzrbKuae8h7sPkMBif6B+L6edpCg6jlPPVzY1XNxjvgyLPvp2h2EzD9QZaD16rbMZY6lVMNvtbw/nqmWo1nNeK0pDXV1pytazrhPpcyMARKm/nlrBpLSQCeMjqGDFv2fUBMLAtUhm4STB91BraiLKRc5V5jraA2OtLlidXWhLMgTIR83eMh1etEf8OZyoHchoetjAUcitmpdPFlZ6QGznwG4uOHcO6EckcfBihr+h3B4Vcd6E4PxotkjuY5BVyQwkcyg7kby0MCyM+1m3J9fSrkPDq4tNAA3oRMnc4rn3aHgHIvu7ckcFFo0vac3ATdgyUcd4td1E+eyjZn9Sx5IbaKliHlAyKPmL7lXneQUtuSMj1LGLLTqRmXKl27u0fmzXb9qS0m6vg2LFHx0zadTbU57Xb/JULcfVJExhC7VNrhBeNIsPPrrWQreAw9UhbPA0IOpHj9K4DOn5sFEKueU9CVgVjHQeKjz2+MuZeL59PQigixk+g7xqYdc1MgbXo+JByTbM/qa9uIQXQ2Fi+BXKe+qRhyqUpOGLZuTfJZp0x/tr0tu1xyoTeZ/dvl6yEmVn1SbuO+d9VcPiyhaf2q0CekywB3E7y5sNNxgSEk7xtFFnZqu3PNjK/iy8sy73O6rX0JJgDZSLaxzW+hL4vVqGQ2ReP9c/b5lDIrZjVjsLVsZzuyubcLG3eRmAsgUW/21iOlpNFdcitul5w0l0vriY3y53TVx7wuIo1tAtayHVtPZi45phnsu7EUx4NoC++y4cZVKdrw8JWrEUy1L6mTlkCYlo8aUhbGnq37EW52bPQtST4+oF9Hy5ZLt8u9UaypUw3/Tzjbh+KyfW545vtjIYm9JJdmUxiHLt9x8bR27bHW6Y5rOAwbux2nQ15XOR9zzFN0DH/Z/VFd4yLUXCYesQKOrF9yQiSo3JXzqpn8Dkm7ZDmweHSc8VL2j5vaI+JJ80qkxXHmGZxS+vnsW0VGnt8yXCKeBqZZDhFvbrseoYUHLH0kpBZbZ225YrBnXd8wp7tGh5l/fI877WV9O2MAO0pEvKUM/3cLd8zcDjW6LzjXZZlz07yFiq/a/9w4rY8YSF5SdvCy1CGRTJmXvfliHDJ487daupM0WabTR/1hk7+ZWcL92G84dL64s695eeR2SRQyK2Y1bUuro0lHTmXRccZTPIk0shDz5Jb8LuHLLkBVzWT7KGzWuw6RXEXEdMZiXmGygcG3iwt73owcc0xz2Q6RajJorOmBSp3cLQn57QtOHoLdE896404LWSofc13xywAQ26qobjmekMv5owgGRJGbAHaZPt1F0yhPfWAJENlzkVjraHjiC8/kX5eyJI7NQtA/EoPk+3XF9sHlLh4CSzksxZZ3mcS6BdZAoiNLxTAxED5vju2LxZRTNYDi92h8yKVPm6ZkSSeihFG5gd/G0w51+03DXfhG7NYDn1HmrLBuFn72rSzNpyNFujvpe0r40vS6CM0zvaESk8ynCLCiEmGs1535Y1ap9iCusn2GzsfAGFl8cS0fpZAtmss4BcMYreG640dgX4eGuPMNZfa2oAwpJQ7HE5MFOP2a66dR2HTK1OWMjRCObXRsaXLl/Ra0H0Obh6ZmN0uzF7ase7KMX2nu5adzTrGAh6z3eE2IXLWIBvFaqeLq+OJkJs16NjUGsDffBz4+h/oRa9voNsIzCK56Heb8o99VgsNZ+71a3JNsofFs8CeZwx+dvEx4Mx9/u+f2gncfEc4uUMWrQVg77OH65smFD7+deBCkvzk0c/ohc1uJ4Oiaa+v3QUceG6xuoVYPDN4jTTGJ/QiyhVqFr6UPaAttXQmx9BEe/kJ3f4h0lwtaw3gmx8Fvv4R9FwtfTz6F8PZfoF465mJJ/3q72pNpc3Z+8L31l0F7vtfWph/+jRw9MXD59UbwLc/qd/Bq0/2y9oYi1nzy/o8m+X2cIbKLMx9f/X3ht8TmzP36t+ukDs2pq25Z78yXJ+nvp1cw6mPmZwf+2x4e4T18PR3gMMnho/X54Fv/dlwPQFd12d9j6dMQBgxbfzwn6Xv49hZ1u9+qM9eedJvFfNd01e3a08D939Yjxnts8BtP5BeJlYwqDWA5pcKzCF/4m/fsuisDGf79RFa5Jt40jzvzExNe5N85y/1OPLIp/TxvJ5T+GJ6mbEx7X3Q/NJwm5qx1C1vFpdn7h0us3pVxxJHW3KdZ2+8D7xKxiSe9Gt36cV6DE//bb9sEWIVNrHUGkAzaTczlsYoT779KV1m7VpYWVxv6HFg5w3h7zKCziOf0vH2NmYsjXl25x8YVhaHhF9TZiHpY0bA8SrlDgOnvzjcr0ySs5gxZeEe//hw4WHg6El/mYcDY/Z6eeRT2bt8GDfrxz4Xzo+Qh8vJdlPucxyf0O+XaZ/Tf62Px1jHfWsBlwsPA4een36OudZXPwTc8MyU74pM9lZrAE98M1y3wy8A9j3b/9kWgkJuxax0ujg/cVS/nHk0nAefpxdkH/2n1rENFqYALQCOTwMHbi1WfucNWsj6yu/oHwB43g8On2dnH3UX73/8DuD058PXeNNHgWd7FrxZGE3uM1/VPxYTw/rhHxnUnt34XcOa8n3H9UL287+av16xxD6TmblB9+u1ZeC3vk8LclHXuW342OETg/sN+pjaBew97h+sD96mF30f/ans6x983rASY++z9cIiayI4mNT97nf4P//uO8Nl/t/PWcc879bB24Cv/X72O3jwNuChu/XiN62OMex/DgABPvPvss8dnwJ2eyb6+jHg0U/rHxcZB/bd4hwTXcdvf0L/lIGvjx28Dbj/Q4PtO/C5p60PndBjqc/7YO4o8PW79E8Wvu8+fEL32aF3/Ra91U1mX3ye/v1H/6x/zHffNoeer5U8WYqywyf0vtGhLSJC9fnq74bbt0yy+vyhE1opte/mweNjY7pNstrad71HPql/AN0/3D2k0zh8Avjbv8pW8hx8nlYcmD28ffXwHfvGH+Tr5zaHTuiF/V5noTs+qb87NP4CwMd+Ov27XWQM2H9L9nk+ag39buZ9diEO3qYVkXa7Zb1PB2/Twu1AmcA4MjaR7lY9PqHn4If+r/5xkfHh/uu7zsXHhpXFe56hFTOhZ/fAx7LvwYzZobVT1vrh4G3AqQ+E++WBN3vKeNalG8n+W9N3+Shrrgq177f+tC/gztSzQygO3gY88NG49jnxY+mf73+Ofh8/+yvZ3zU2qdekWXV79NPhur3uP28LIVdUWdtEVMzJkyfVqVOnRl2NTH70fV+EqC7u+icvSLeKuSilg9ONVWJiuhx3ZUDHlYayO8Zw9eLgpuL1+eFkK089Cvy3FwJv+M3hl/s9twJHXwR8z7uc730S+OBrge97D/DiAoPq1YvAf7oJeO1/AF7+M/qYUsAv7wNe8Q7gH75ruMzKVeBXDgEvfzvwop/Ux2Zv9MdOXL5QPBY2i+nd4f33XH7j5VrTd+eH9P+mrV/9buCW70svO7lDWydc1lYAKN3v0li9pgdY17VQKW1JjnFPnz3o3ypp+bLul1nxXa2mFux9+PoioK1sJmvm2Biw56bh63S72gppxsypnX4t89py2DUw1L5pXHpCu1FlsaPuF3qWL4cVFDNzfsF45QqwmOEWVZRQ+yql29cXfyyiy7gCZ7erF7G+8Wqprd/JLEJjaWdVu0VOzgx/Ft0XF5J3B/qdqB/LLrN8OT02C9D1WlvOP4eE2rdMYuYqpXSf89336pJWeuXZ0s7tv7v3D3s5pBHbvqtL4RCVtLE05FUzOZMeEgJktFVg/AUG+2Is07N6PC7KyhWtvAglaMuD239jxlKltEXaxDEWeddtli/p8dhHaCwduM6aVja7sa2AbqvJnRHzzi5g7tBw+bS+GJqrbNy2sgmNv+66dKMJrQVsNnquim3fXXuzE6qlrQVsQu3rcvl8XP6YmZoe89LodvTzDsmAu/Zt/O4tG4iI3KeU8rgXDEJLbsWsdrrYNT2Rb3ECJC/BM0qp0xDrEXABbc1Nc/sB4M0aCPST4Rx47rAWqfvMcAxUDL7YLBE9IAT3EU0GtRu/O1urtXt/9sBSBdNzg8K2iQk5/MLimrnYLW98kzeQ9N/I7KYhshb+hiLKnxjBc2wM2Pus7PMmpjdWAzp7cH0LzendwHTO+kztql6LK5LuhuVjbCw8Xs14EqDlYXwyLFhF98UCrp4x3z02XmwOydu+VSESvu8swcPHevtvbPtOzuS/zsTU+uqW2laB8Rco7na8Hta7lrAp0n9FgBtuyj4v7V23mZ7NFrpSrzMRji0PtVXsvFOkL9rEtpVbpqp1aYiq5qpC7/oGrwV2H8hWpMQyNh7Xr7Y4TDxVMasdhclxNnsv2YMrsJoEDr54AhMDVTRYPpTIYKaWvsUKUJ7VvAxmaoMxxlvxHgghhBBCCCkIpa2KWe10MTm+znT62wVfNj8j9Ia0zvV17K8b2rN3ei6ceKodKLOZcYX2VjNJ4JDTTZYQQgghhJAtCIXcilnpdDE1UTAz8Haj7tnTNLSXqSFtH9QsWk2dvMiNo0i15Db92X43MzMed+XZw/li2gghhBBCCNmiUMitmJU1WnJ71Bo65tVOhNJqAhCdGdVHvaHTvIcSC6Vh9iJzEzu4QqFbZu5w8S2LRoGJMTYJBcraU5kQQgghhJBNCIXcilntdDHFmFxNPdmf9LKV+bXd1FmEQ4mOept/B7IIptFa8LsdpyWeajXz7UW5GZie01ufrFzR/7cXytlTmRBCCCGEkE1IqdKWiNwhIg+LyCMi8k7P578mIvcnP98SkZb12ZtF5NvJj2eDrq0JE09Z1Ky9cg0hQdTQ21+3QPKpdtMv7M3U0xNPbaV4XKCfUXZ5Uaf2b5+lJZcQQgghhFw3lLaFkIiMA3gvgFcDOAPgXhG5Wyn1oDlHKfUvrPPfAeAFyd83APglACcBKAD3JWWfLqu+VbG61qWQazDCY7sJ4KX679YCcPTFKWWMJTdnXO7yJeDa035hb3oOWL2iBUI7vb/ZzmirCYhGyF1q673QVIeWXEIIIYQQct1QprT1EgCPKKUeU0qtALgLwOtTzn8jgN9P/n4tgE8qpS4mgu0nAdxRYl0rQyeeopALoC88GqtstwMsZlgd547oTMF5k0+1AtsHAYOWT5vFswhuZ7SZmZnTv5faViKvLWaNJoQQQgghpCBlSltHANiSyJnk2BAicgzATQD+Ik9ZEXmriJwSkVMXLlzYkEqXiVJKC7lMPKWZ2gXsuKEviF36O6C7li5Ujk/qTMd5Lblpwl5PKGwNHs/K9LxZmanr30uL2VsyEUIIIYQQss0oU8j1SXIqcO6dAP5QKdXJU1Yp9X6l1Eml1Mn9+/cXrGZ1dLoKSoHuyjb1Rt+SG2t1rDXyx+SG9sgFLPdex5Jrymw1S+60bck19xDIVk0IIYQQQsg2o0xp6wwAWzo4CuBc4Nw70XdVzlt2y7Da0XL6JN2V+9QafWtjmiBq49tfN4vWAjA+Bew6MPyZHcM6UCbZzmirCYg99+u2vu9d+4HJHaOtEyGEEEIIIRVRprR1L4DjInKTiExBC7J3uyeJyC0A9gD4onX4EwBeIyJ7RGQPgNckx7Y0Kx29HywtuRb1Y9qCq5RlOc0QKusNHS/bWYu/Trupv3fM0/bG8unG5Pa2M5qOv85mwBbaW4GM0oQQQgghhGxTSpO2lFJrAN4OLZw+BOAjSqkHROTdIvL91qlvBHCXUkpZZS8C+GVoQfleAO9Ojm1pVhMhl4mnLOoNYPUqcPWiFip37tWxumnUGjpj8KXH46+TJuwFLblbdH/ZyRlttTaJp7ZaTDEhhBBCCCHroLQthABAKfVxAB93jv2i8/+7AmU/COCDpVVuBKysJUIuE0/1MUJkeyHe6mhvIxQrwLWbwPFX+z8LCbntJnDkRXHfv9mYqSVC7hnglu8ddW0IIYQQQgipDJoUK2SV7srD2NsItRbihNbafL9MDKtLwOUntGu0j+lZ/dtOPNXtaAFxK1pyAe2C/dSjwNpSv70IIYQQQgi5DqC0VSEUcj3ULYG1fSYsiA6UMYJxZPKp9hn9OySwjo1rodC25JrtjLbq1jszNeCJb+q/6a5MCCGEEEKuIyhtVcjKWpJdmUJun5k6MDULnLsfWLsWZzmd3KEzBrcjLbnmvDRhb3puMPFU7HZGm5WZOeDa0/rvrWqNJoQQQgghpACUtirEWHKnmXiqj4gWPk//tf4/1upobz2UhTkvTdgzMax5ymxmTJwxQEsuIYQQQgi5rqC0VSF0Vw5Qa/QzJccKlfVG39qaRbsJyBgwdzh8jivkxlh/NzNGyJ2uDQq8hBBCCCGEbHMobVWIya48yezKg9iCZF5LbrebfW5rAZg7AoxPhs+ZcWJyWwvAjhuytzParJi9f7equzUhhBBCCCEFoZBbISvGkkt35UGMIDY9p2N0o8ocAzrLwJUL2efGbE3kc1feygKiacetaokmhBBCCCGkIJS2KmS1oxNPTdFdeRAjgNYaOkY3Bnuv3Cxi9tP1JZ7aygLiTGLJ3aoxxYQQQgghhBSE0laFmJjcKVpyBzEW0zxCpRHesvbK7awBi+ciLbmLgFL6p9Xc2vvLmjjcrSyoE0IIIYQQUoCJUVfgeoKJpwLYltxYjPB2z28Aj346fN7qEqA62cLeTE2f90c/A6iu3s5oKwuIRsilJZcQQgghhFxnUMitkGUmnvKz+wBwy+uAm++ILzNTA579auD8g9pSm8YNzwLmX55+TuMlOs73O5/T/++5CTh2e3x9NhuHng80XgrMv2zUNSGEEEIIIaRSKORWSM9dmZbcQUSAN/5+/nJv+sONq8P8y4Cf/frGfd+omTsMvOXPR10LQgghhBBCKofSVoWsrtFdmRBCCCGEEELKhNJWhZjsytxCiBBCCCGEEELKgdJWhazQXZkQQgghhBBCSoXSVoWsMPEUIYQQQgghhJQKhdwKWe10MTkuEKGQSwghhBBCCCFlQCG3QrSQyyYnhBBCCCGEkLKgxFUhqx1FIZcQQgghhBBCSoQSV4WsdLqYYmZlQgghhBBCCCkNSlwVsrLWZWZlQgghhBBCCCkRSlwVYhJPEUIIIYQQQggpBwq5FcLEU4QQQgghhBBSLpS4KmRljYmnCCGEEEIIIaRMKHFVyCoTTxFCCCGEEEJIqVDiqpDVDhNPEUIIIYQQQkiZUOKqkJW1LiYnmHiKEEIIIYQQQsqCQm6FMPEUIYQQQgghhJRLqRKXiNwhIg+LyCMi8s7AOT8iIg+KyAMi8mHreEdE7k9+7i6znlWx0mHiKUIIIYQQQggpk4myvlhExgG8F8CrAZwBcK+I3K2UetA65ziAXwBwu1LqaRE5YH3FNaXUibLqNwqYeIoQQgghhBBCyqVMieslAB5RSj2mlFoBcBeA1zvn/BSA9yqlngYApdT5Euszcph4ihBCCCGEEELKpUyJ6wiApvX/meSYzc0AbhaRvxaRe0TkDuuzGRE5lRx/Q4n1rIyVtS4mx5l4ihBCCCGEEELKojR3ZQA+aU55rn8cwCsBHAXwVyLyPKVUC8C8UuqciDwTwF+IyDeUUo8OXEDkrQDeCgDz8/MbXf8Nh4mnCCGEEEIIIaRcypS4zgBoWP8fBXDOc84fK6VWlVLfAfAwtNALpdS55PdjAD4L4AXuBZRS71dKnVRKndy/f//G38EGoy25FHIJIYQQQgghpCzKlLjuBXBcRG4SkSkAdwJwsyT/EYBXAYCI7IN2X35MRPaIyLR1/HYAD2KLs9pRmGbiKUIIIYQQQggpjdLclZVSayLydgCfADAO4INKqQdE5N0ATiml7k4+e42IPAigA+DnlVJPicgrALxPRLrQgvh/tLMyb1XorkwIIYQQQggh5VJmTC6UUh8H8HHn2C9afysAP5f82Od8AcB3lVm3qul2Fda63CeXEEIIIYQQQsqEEldFrHS6AIDJCWZXJoQQQgghhJCyoJBbEauJkMt9cgkhhBBCCCGkPChxVcRqR++eNMXEU4QQQgghhBBSGpS4KsJYchmTSwghhBBCCCHlQYmrIlbWKOQSQgghhBBCSNlQ4qqIXuKpcSaeIoQQQgghhJCyoJBbEUw8RQghhBBCCCHlQ4mrIlbXmHiKEEIIIYQQQsqGEldFrDDxFCGEEEIIIYSUDiWuimDiKUIIIYQQQggpH0pcFdGLyZ1g4ilCCCGEEEIIKQsKuRXBfXIJIYQQQgghpHwocVVE35LLJieEEEIIIYSQsqDEVRErHZ1dmZZcQgghhBBCCCkPSlwVsbrGfXIJIYQQQgghpGwocVUEtxAihBBCCCGEkPKhxFUR/cRTzK5MCCGEEEIIIWVBIbcizD65TDxFCCGEEEIIIeVBiasiVpl4ihBCCCGEEEJKhxJXRXCfXEIIIYQQQggpH0pcFbGy1sX4mGB8jDG5hBBCCCGEEFIWFHIrYrXTZdIpQgghhBBCCCkZCrkVsdLpco9cQgghhBBCCCkZSl0VsdrpMrMyIYQQQgghhJQMpa6KWF1TTDpFCCGEEEIIISVDqasiVjpdCrmEEEIIIYQQUjKUuipihYmnCCGEEEIIIaR0KORWxOpaF1MT46OuBiGEEEIIIYRsayjkVsRqp4spWnIJIYQQQgghpFRKFXJF5A4ReVhEHhGRdwbO+REReVBEHhCRD1vH3ywi305+3lxmPavguYfn8IL5PaOuBiGEEEIIIYRsaybK+mIRGQfwXgCvBnAGwL0icrdS6kHrnOMAfgHA7Uqpp0XkQHL8BgC/BOAkAAXgvqTs02XVt2x+/rXPGXUVCCGEEEIIIWTbU6Yl9yUAHlFKPaaUWgFwF4DXO+f8FID3GuFVKXU+Of5aAJ9USl1MPvskgDtKrCshhBBCCCGEkG1AmULuEQBN6/8zyTGbmwHcLCJ/LSL3iMgdOcpCRN4qIqdE5NSFCxc2sOqEEEIIIYQQQrYiZQq5vixLyvl/AsBxAK8E8EYA/1NE6pFloZR6v1LqpFLq5P79+9dZXUIIIYQQQgghW50yhdwzABrW/0cBnPOc88dKqVWl1HcAPAwt9MaUJYQQQgghhBBCBihTyL0XwHERuUlEpgDcCeBu55w/AvAqABCRfdDuy48B+ASA14jIHhHZA+A1yTFCCCGEEEIIISRIadmVlVJrIvJ2aOF0HMAHlVIPiMi7AZxSSt2NvjD7IIAOgJ9XSj0FACLyy9CCMgC8Wyl1say6EkIIIYQQQgjZHohSQ6GuW5KTJ0+qU6dOjboahBBCCCGEEEJKQETuU0qdzDqvTHdlQgghhBBCCCGkUijkEkIIIYQQQgjZNlDIJYQQQgghhBCybaCQSwghhBBCCCFk20AhlxBCCCGEEELItoFCLiGEEEIIIYSQbcO22UJIRC4AOD3qemSwD8CTo64EIWBfJJsH9kWyWWBfJJsF9kWyWdiMffGYUmp/1knbRsjdCojIqZh9nQgpG/ZFsllgXySbBfZFsllgXySbha3cF+muTAghhBBCCCFk20AhlxBCCCGEEELItoFCbrW8f9QVICSBfZFsFtgXyWaBfZFsFtgXyWZhy/ZFxuQSQgghhBBCCNk20JJLCCGEEEIIIWTbQCG3IkTkDhF5WEQeEZF3jro+5PpCRP5WRL4hIveLyKnk2A0i8kkR+Xbye8+o60m2HyLyQRE5LyLftI55+55ofj0ZJ78uIi8cXc3JdiPQF98lImeTsfF+EXmd9dkvJH3xYRF57WhqTbYbItIQkc+IyEMi8oCI/PPkOMdFUikpfXFbjIsUcitARMYBvBfA9wJ4LoA3ishzR1srch3yKqXUCSsV/DsBfFopdRzAp5P/CdlofgvAHc6xUN/7XgDHk5+3AvjNiupIrg9+C8N9EQB+LRkbTyilPg4AyRx9J4DbkjK/kczlhKyXNQD/Uil1K4CXAXhb0t84LpKqCfVFYBuMixRyq+ElAB5RSj2mlFoBcBeA14+4ToS8HsBvJ3//NoA3jLAuZJuilPpLABedw6G+93oAv6M09wCoi8ihampKtjuBvhji9QDuUkotK6W+A+AR6LmckHWhlHpcKfWV5O9LAB4CcAQcF0nFpPTFEFtqXKSQWw1HADSt/88gvRMRstEoAH8uIveJyFuTYweVUo8DeqADcGBktSPXG6G+x7GSjIK3J26gH7TCNtgXSemIyDMAvADAl8BxkYwQpy8C22BcpJBbDeI5xrTWpEpuV0q9ENrt6W0i8g9GXSFCPHCsJFXzmwCeBeAEgMcBvCc5zr5ISkVEdgP4PwB+Vim1mHaq5xj7ItkwPH1xW4yLFHKr4QyAhvX/UQDnRlQXch2ilDqX/D4P4GPQ7iVPGJen5Pf50dWQXGeE+h7HSlIpSqknlFIdpVQXwP9A3/WOfZGUhohMQgsVH1JKfTQ5zHGRVI6vL26XcZFCbjXcC+C4iNwkIlPQQdt3j7hO5DpBRHaJyKz5G8BrAHwTug++OTntzQD+eDQ1JNchob53N4CfSLKJvgxA27jvEVIGTmzjD0CPjYDui3eKyLSI3ASd9OfLVdePbD9ERAB8AMBDSqlftT7iuEgqJdQXt8u4ODHqClwPKKXWROTtAD4BYBzAB5VSD4y4WuT64SCAj+mxDBMAPqyU+jMRuRfAR0TkLQAWAPzwCOtItiki8vsAXglgn4icAfBLAP4j/H3v4wBeB53M4iqAn6y8wmTbEuiLrxSRE9Aud38L4KcBQCn1gIh8BMCD0BlI36aU6oyi3mTbcTuAHwfwDRG5Pzn2r8E+vM7mAAACoUlEQVRxkVRPqC++cTuMi6LUpnWlJoQQQgghhBBCckF3ZUIIIYQQQggh2wYKuYQQQgghhBBCtg0UcgkhhBBCCCGEbBso5BJCCCGEEEII2TZQyCWEEEIIIYQQsm2gkEsIIYRsU0TklSLyJ6OuByGEEFIlFHIJIYQQQgghhGwbKOQSQgghI0ZE3iQiXxaR+0XkfSIyLiKXReQ9IvIVEfm0iOxPzj0hIveIyNdF5GMisic5/mwR+ZSIfC0p86zk63eLyB+KyN+IyIdEREZ2o4QQQkgFUMglhBBCRoiI3ArgRwHcrpQ6AaAD4B8B2AXgK0qpFwL4HIBfSor8DoB/pZT6bgDfsI5/CMB7lVLPB/AKAI8nx18A4GcBPBfAMwHcXvpNEUIIISNkYtQVIIQQQq5zvgfAiwDcmxhZdwA4D6AL4H8n5/wegI+KSA1AXSn1ueT4bwP4AxGZBXBEKfUxAFBKLQFA8n1fVkqdSf6/H8AzAHy+/NsihBBCRgOFXEIIIWS0CIDfVkr9wsBBkX/rnKcyviPEsvV3B5z7CSGEbHPorkwIIYSMlk8D+CEROQAAInKDiByDnqN/KDnnxwB8XinVBvC0iPz95PiPA/icUmoRwBkReUPyHdMisrPSuyCEEEI2CdTmEkIIISNEKfWgiPwbAH8uImMAVgG8DcAVALeJyH0A2tBxuwDwZgD/PRFiHwPwk8nxHwfwPhF5d/IdP1zhbRBCCCGbBlEqzfuJEEIIIaNARC4rpXaPuh6EEELIVoPuyoQQQgghhBBCtg205BJCCCGEEEII2TbQkksIIYQQQgghZNtAIZcQQgghhBBCyLaBQi4hhBBCCCGEkG0DhVxCCCGEEEIIIdsGCrmEEEIIIYQQQrYNFHIJIYQQQgghhGwb/j8FTkWqqhOCiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f1db85860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее-3,  добавили reduce lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.7188 - acc: 0.4960 - val_loss: 0.6513 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65131, saving model to test.hdf5\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.6233 - acc: 0.6960 - val_loss: 0.6579 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.65131\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 196us/step - loss: 0.5808 - acc: 0.6960 - val_loss: 0.6395 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65131 to 0.63951, saving model to test.hdf5\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.5484 - acc: 0.7600 - val_loss: 0.6250 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63951 to 0.62495, saving model to test.hdf5\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.5219 - acc: 0.7960 - val_loss: 0.6171 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.62495 to 0.61715, saving model to test.hdf5\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.5000 - acc: 0.7800 - val_loss: 0.6087 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.61715 to 0.60872, saving model to test.hdf5\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.4802 - acc: 0.8160 - val_loss: 0.6065 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60872 to 0.60648, saving model to test.hdf5\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.4617 - acc: 0.8040 - val_loss: 0.6028 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.60648 to 0.60275, saving model to test.hdf5\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.4485 - acc: 0.8160 - val_loss: 0.5991 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60275 to 0.59911, saving model to test.hdf5\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.4359 - acc: 0.8160 - val_loss: 0.6007 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59911\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.4258 - acc: 0.8120 - val_loss: 0.5926 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59911 to 0.59261, saving model to test.hdf5\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.4147 - acc: 0.8320 - val_loss: 0.5905 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59261 to 0.59048, saving model to test.hdf5\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.4073 - acc: 0.8080 - val_loss: 0.5889 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59048 to 0.58888, saving model to test.hdf5\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.3991 - acc: 0.8160 - val_loss: 0.5883 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58888 to 0.58832, saving model to test.hdf5\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.3933 - acc: 0.8120 - val_loss: 0.5853 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58832 to 0.58528, saving model to test.hdf5\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.3860 - acc: 0.8160 - val_loss: 0.5825 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.58528 to 0.58253, saving model to test.hdf5\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.3821 - acc: 0.8200 - val_loss: 0.5825 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.58253 to 0.58252, saving model to test.hdf5\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3763 - acc: 0.8200 - val_loss: 0.5812 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.58252 to 0.58115, saving model to test.hdf5\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.3703 - acc: 0.8160 - val_loss: 0.5800 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.58115 to 0.58001, saving model to test.hdf5\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3659 - acc: 0.8240 - val_loss: 0.5774 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.58001 to 0.57739, saving model to test.hdf5\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3622 - acc: 0.8280 - val_loss: 0.5762 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.57739 to 0.57616, saving model to test.hdf5\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3580 - acc: 0.8280 - val_loss: 0.5753 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.57616 to 0.57525, saving model to test.hdf5\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3536 - acc: 0.8240 - val_loss: 0.5677 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.57525 to 0.56773, saving model to test.hdf5\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3488 - acc: 0.8240 - val_loss: 0.5747 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.56773\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.3443 - acc: 0.8240 - val_loss: 0.5780 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.56773\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 0.3426 - acc: 0.8200 - val_loss: 0.5716 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.999999772640876e-05.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.56773\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.3374 - acc: 0.8200 - val_loss: 0.5639 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.56773 to 0.56390, saving model to test.hdf5\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 0.3352 - acc: 0.8320 - val_loss: 0.5712 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.56390\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.3326 - acc: 0.8320 - val_loss: 0.5717 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.56390\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.3297 - acc: 0.8320 - val_loss: 0.5758 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.56390\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.3254 - acc: 0.8360 - val_loss: 0.5748 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.56390\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.3239 - acc: 0.8360 - val_loss: 0.5652 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.56390\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 0.3215 - acc: 0.8400 - val_loss: 0.5694 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.56390\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.3210 - acc: 0.8480 - val_loss: 0.5708 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.56390\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.3158 - acc: 0.8480 - val_loss: 0.5695 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.56390\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.3114 - acc: 0.8560 - val_loss: 0.5753 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.56390\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.3096 - acc: 0.8520 - val_loss: 0.5753 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.56390\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 0.3081 - acc: 0.8520 - val_loss: 0.5684 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.56390\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.3060 - acc: 0.8560 - val_loss: 0.5651 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.56390\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.3027 - acc: 0.8600 - val_loss: 0.5665 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.56390\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.3003 - acc: 0.8600 - val_loss: 0.5704 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.56390\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2981 - acc: 0.8520 - val_loss: 0.5709 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.56390\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2960 - acc: 0.8560 - val_loss: 0.5730 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.56390\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2940 - acc: 0.8600 - val_loss: 0.5673 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.56390\n",
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2924 - acc: 0.8600 - val_loss: 0.5668 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.56390\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2912 - acc: 0.8600 - val_loss: 0.5763 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.56390\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2897 - acc: 0.8640 - val_loss: 0.5884 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.56390\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2879 - acc: 0.8560 - val_loss: 0.5625 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.56390 to 0.56251, saving model to test.hdf5\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2860 - acc: 0.8680 - val_loss: 0.5639 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.56251\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2847 - acc: 0.8640 - val_loss: 0.5851 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.56251\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2811 - acc: 0.8600 - val_loss: 0.5848 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 8.100000122794882e-05.\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.56251\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.2787 - acc: 0.8680 - val_loss: 0.5924 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.56251\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2751 - acc: 0.8720 - val_loss: 0.5994 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.56251\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2738 - acc: 0.8760 - val_loss: 0.5864 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.56251\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2714 - acc: 0.8800 - val_loss: 0.5855 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.56251\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2699 - acc: 0.8760 - val_loss: 0.5797 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.56251\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2681 - acc: 0.8800 - val_loss: 0.5807 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.56251\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2665 - acc: 0.8800 - val_loss: 0.5884 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.56251\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2646 - acc: 0.8720 - val_loss: 0.5873 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.56251\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2613 - acc: 0.8800 - val_loss: 0.5838 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.56251\n",
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2600 - acc: 0.8880 - val_loss: 0.5872 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.56251\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2586 - acc: 0.8880 - val_loss: 0.5908 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.56251\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2565 - acc: 0.8840 - val_loss: 0.5860 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.56251\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2550 - acc: 0.8840 - val_loss: 0.5931 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.56251\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2531 - acc: 0.8880 - val_loss: 0.5902 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.56251\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2509 - acc: 0.8880 - val_loss: 0.5859 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.56251\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2507 - acc: 0.8920 - val_loss: 0.5964 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.56251\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2489 - acc: 0.8840 - val_loss: 0.6016 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.56251\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2475 - acc: 0.8840 - val_loss: 0.5975 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.56251\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2455 - acc: 0.9000 - val_loss: 0.6000 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.56251\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2437 - acc: 0.8960 - val_loss: 0.6022 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.56251\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2423 - acc: 0.8960 - val_loss: 0.6023 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.56251\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2421 - acc: 0.9040 - val_loss: 0.6045 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.56251\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.2393 - acc: 0.9040 - val_loss: 0.6005 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.56251\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.2375 - acc: 0.9000 - val_loss: 0.5990 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.56251\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2381 - acc: 0.9000 - val_loss: 0.6054 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 7.289999848580919e-05.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.56251\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2349 - acc: 0.9000 - val_loss: 0.6075 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.56251\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2338 - acc: 0.9000 - val_loss: 0.6055 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.56251\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2314 - acc: 0.9080 - val_loss: 0.6054 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.56251\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2300 - acc: 0.9040 - val_loss: 0.6033 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.56251\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2291 - acc: 0.9040 - val_loss: 0.6112 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.56251\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2279 - acc: 0.9080 - val_loss: 0.6121 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00082: val_loss did not improve from 0.56251\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2271 - acc: 0.9040 - val_loss: 0.6075 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.56251\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2251 - acc: 0.9160 - val_loss: 0.6091 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.56251\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2237 - acc: 0.9120 - val_loss: 0.6065 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.56251\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2229 - acc: 0.9080 - val_loss: 0.6053 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.56251\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2212 - acc: 0.9080 - val_loss: 0.6159 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.56251\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2206 - acc: 0.9120 - val_loss: 0.6228 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.56251\n",
      "Epoch 89/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.2197 - acc: 0.9040 - val_loss: 0.6160 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.56251\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2179 - acc: 0.9120 - val_loss: 0.6099 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.56251\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 0.2163 - acc: 0.9120 - val_loss: 0.6163 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.56251\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2162 - acc: 0.9120 - val_loss: 0.6168 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.56251\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2148 - acc: 0.9080 - val_loss: 0.6125 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.56251\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2129 - acc: 0.9120 - val_loss: 0.6172 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.56251\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2116 - acc: 0.9080 - val_loss: 0.6120 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.56251\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.2105 - acc: 0.9120 - val_loss: 0.6056 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.56251\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2099 - acc: 0.9240 - val_loss: 0.6169 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.56251\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.2088 - acc: 0.9120 - val_loss: 0.6229 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.56251\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2071 - acc: 0.9200 - val_loss: 0.6216 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.56251\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 0.2061 - acc: 0.9200 - val_loss: 0.6232 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.56251\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2057 - acc: 0.9160 - val_loss: 0.6118 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 6.56100019114092e-05.\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.56251\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.2032 - acc: 0.9240 - val_loss: 0.6082 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.56251\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.2028 - acc: 0.9240 - val_loss: 0.6088 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.56251\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.2016 - acc: 0.9240 - val_loss: 0.6119 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.56251\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.2001 - acc: 0.9240 - val_loss: 0.6213 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.56251\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1996 - acc: 0.9240 - val_loss: 0.6190 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.56251\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1980 - acc: 0.9320 - val_loss: 0.6142 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.56251\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1968 - acc: 0.9280 - val_loss: 0.6187 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.56251\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 0.1958 - acc: 0.9280 - val_loss: 0.6194 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.56251\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1946 - acc: 0.9280 - val_loss: 0.6152 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.56251\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1938 - acc: 0.9320 - val_loss: 0.6150 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.56251\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1932 - acc: 0.9280 - val_loss: 0.6159 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.56251\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1919 - acc: 0.9320 - val_loss: 0.6185 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.56251\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1919 - acc: 0.9320 - val_loss: 0.6310 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.56251\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 0.1896 - acc: 0.9320 - val_loss: 0.6280 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.56251\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1889 - acc: 0.9320 - val_loss: 0.6281 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.56251\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 172us/step - loss: 0.1886 - acc: 0.9280 - val_loss: 0.6325 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.56251\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 0.1875 - acc: 0.9160 - val_loss: 0.6306 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.56251\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1853 - acc: 0.9320 - val_loss: 0.6311 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.56251\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1841 - acc: 0.9360 - val_loss: 0.6380 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.56251\n",
      "Epoch 121/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1828 - acc: 0.9360 - val_loss: 0.6328 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.56251\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1825 - acc: 0.9320 - val_loss: 0.6388 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.56251\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1810 - acc: 0.9320 - val_loss: 0.6333 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.56251\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1803 - acc: 0.9400 - val_loss: 0.6449 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.56251\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1793 - acc: 0.9320 - val_loss: 0.6502 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.56251\n",
      "Epoch 126/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 191us/step - loss: 0.1778 - acc: 0.9320 - val_loss: 0.6450 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 5.904900172026828e-05.\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.56251\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1770 - acc: 0.9360 - val_loss: 0.6387 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.56251\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1765 - acc: 0.9400 - val_loss: 0.6407 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.56251\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1759 - acc: 0.9400 - val_loss: 0.6425 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.56251\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1745 - acc: 0.9360 - val_loss: 0.6397 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.56251\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1745 - acc: 0.9360 - val_loss: 0.6501 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.56251\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1732 - acc: 0.9320 - val_loss: 0.6448 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.56251\n",
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1739 - acc: 0.9440 - val_loss: 0.6458 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.56251\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1715 - acc: 0.9400 - val_loss: 0.6468 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.56251\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1708 - acc: 0.9360 - val_loss: 0.6491 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.56251\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1693 - acc: 0.9360 - val_loss: 0.6530 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.56251\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1686 - acc: 0.9480 - val_loss: 0.6504 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.56251\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1675 - acc: 0.9400 - val_loss: 0.6532 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.56251\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1664 - acc: 0.9480 - val_loss: 0.6532 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.56251\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1658 - acc: 0.9440 - val_loss: 0.6563 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.56251\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1653 - acc: 0.9440 - val_loss: 0.6550 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.56251\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1643 - acc: 0.9400 - val_loss: 0.6479 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.56251\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1636 - acc: 0.9440 - val_loss: 0.6516 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.56251\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1624 - acc: 0.9440 - val_loss: 0.6563 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.56251\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1624 - acc: 0.9520 - val_loss: 0.6582 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.56251\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1613 - acc: 0.9520 - val_loss: 0.6527 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.56251\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1601 - acc: 0.9520 - val_loss: 0.6565 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.56251\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1600 - acc: 0.9440 - val_loss: 0.6606 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.56251\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1585 - acc: 0.9520 - val_loss: 0.6567 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.56251\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 227us/step - loss: 0.1584 - acc: 0.9520 - val_loss: 0.6642 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.56251\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1573 - acc: 0.9560 - val_loss: 0.6695 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 5.314410154824145e-05.\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.56251\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1566 - acc: 0.9520 - val_loss: 0.6652 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.56251\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1561 - acc: 0.9480 - val_loss: 0.6662 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.56251\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1559 - acc: 0.9480 - val_loss: 0.6637 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.56251\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1542 - acc: 0.9480 - val_loss: 0.6643 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.56251\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1543 - acc: 0.9520 - val_loss: 0.6732 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.56251\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1537 - acc: 0.9480 - val_loss: 0.6692 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.56251\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1529 - acc: 0.9520 - val_loss: 0.6663 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.56251\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1522 - acc: 0.9520 - val_loss: 0.6722 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.56251\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1509 - acc: 0.9600 - val_loss: 0.6836 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.56251\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1503 - acc: 0.9480 - val_loss: 0.6782 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.56251\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1494 - acc: 0.9560 - val_loss: 0.6712 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.56251\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1487 - acc: 0.9560 - val_loss: 0.6716 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.56251\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1478 - acc: 0.9560 - val_loss: 0.6767 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.56251\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1465 - acc: 0.9560 - val_loss: 0.6787 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.56251\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1464 - acc: 0.9600 - val_loss: 0.6761 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.56251\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1455 - acc: 0.9600 - val_loss: 0.6736 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.56251\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1456 - acc: 0.9560 - val_loss: 0.6778 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_loss did not improve from 0.56251\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1446 - acc: 0.9560 - val_loss: 0.6881 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.56251\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1434 - acc: 0.9600 - val_loss: 0.6801 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.56251\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1429 - acc: 0.9600 - val_loss: 0.6802 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.56251\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1424 - acc: 0.9600 - val_loss: 0.6825 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.56251\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1420 - acc: 0.9600 - val_loss: 0.6819 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.56251\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1417 - acc: 0.9560 - val_loss: 0.6858 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.56251\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1405 - acc: 0.9680 - val_loss: 0.6814 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.56251\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1398 - acc: 0.9600 - val_loss: 0.6854 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 4.7829690083744934e-05.\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.56251\n",
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1397 - acc: 0.9600 - val_loss: 0.6892 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.56251\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1389 - acc: 0.9560 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.56251\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1382 - acc: 0.9600 - val_loss: 0.6900 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.56251\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1378 - acc: 0.9640 - val_loss: 0.6846 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.56251\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1372 - acc: 0.9640 - val_loss: 0.6877 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.56251\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1367 - acc: 0.9640 - val_loss: 0.6905 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.56251\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1354 - acc: 0.9680 - val_loss: 0.6992 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.56251\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1348 - acc: 0.9680 - val_loss: 0.6944 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.56251\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1341 - acc: 0.9640 - val_loss: 0.7015 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.56251\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1360 - acc: 0.9600 - val_loss: 0.7016 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.56251\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1325 - acc: 0.9640 - val_loss: 0.7000 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.56251\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1319 - acc: 0.9640 - val_loss: 0.7058 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.56251\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1307 - acc: 0.9640 - val_loss: 0.7102 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.56251\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1300 - acc: 0.9640 - val_loss: 0.7101 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.56251\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1284 - acc: 0.9720 - val_loss: 0.7205 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.56251\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1283 - acc: 0.9720 - val_loss: 0.7115 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.56251\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1278 - acc: 0.9640 - val_loss: 0.7043 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.56251\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1269 - acc: 0.9640 - val_loss: 0.7052 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.56251\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1271 - acc: 0.9640 - val_loss: 0.7081 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.56251\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1258 - acc: 0.9640 - val_loss: 0.7030 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.56251\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1255 - acc: 0.9640 - val_loss: 0.7046 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.56251\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1252 - acc: 0.9640 - val_loss: 0.7117 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.56251\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1246 - acc: 0.9640 - val_loss: 0.7056 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.56251\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 219us/step - loss: 0.1248 - acc: 0.9640 - val_loss: 0.7214 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.56251\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1232 - acc: 0.9640 - val_loss: 0.7082 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 4.304672074795235e-05.\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.56251\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1229 - acc: 0.9640 - val_loss: 0.7121 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.56251\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1222 - acc: 0.9640 - val_loss: 0.7165 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.56251\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1220 - acc: 0.9640 - val_loss: 0.7157 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.56251\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1213 - acc: 0.9680 - val_loss: 0.7129 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.56251\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 235us/step - loss: 0.1207 - acc: 0.9640 - val_loss: 0.7071 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.56251\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 215us/step - loss: 0.1203 - acc: 0.9640 - val_loss: 0.7131 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.56251\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1200 - acc: 0.9640 - val_loss: 0.7100 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.56251\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1195 - acc: 0.9640 - val_loss: 0.7144 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.56251\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1200 - acc: 0.9680 - val_loss: 0.7194 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.56251\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1187 - acc: 0.9720 - val_loss: 0.7184 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.56251\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1183 - acc: 0.9640 - val_loss: 0.7162 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.56251\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1181 - acc: 0.9680 - val_loss: 0.7166 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.56251\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1176 - acc: 0.9720 - val_loss: 0.7165 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.56251\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1171 - acc: 0.9720 - val_loss: 0.7131 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.56251\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 0.1161 - acc: 0.9720 - val_loss: 0.7282 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.56251\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1157 - acc: 0.9720 - val_loss: 0.7268 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.56251\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1156 - acc: 0.9720 - val_loss: 0.7309 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.56251\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1152 - acc: 0.9720 - val_loss: 0.7348 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.56251\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1145 - acc: 0.9760 - val_loss: 0.7403 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.56251\n",
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1141 - acc: 0.9760 - val_loss: 0.7369 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.56251\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1139 - acc: 0.9800 - val_loss: 0.7377 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.56251\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1135 - acc: 0.9720 - val_loss: 0.7333 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.56251\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1130 - acc: 0.9760 - val_loss: 0.7310 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.56251\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1124 - acc: 0.9760 - val_loss: 0.7383 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.56251\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1120 - acc: 0.9760 - val_loss: 0.7374 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 3.8742047036066654e-05.\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.56251\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 0.1112 - acc: 0.9760 - val_loss: 0.7330 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.56251\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1111 - acc: 0.9800 - val_loss: 0.7328 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.56251\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 0.1105 - acc: 0.9800 - val_loss: 0.7360 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.56251\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1101 - acc: 0.9800 - val_loss: 0.7355 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.56251\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1096 - acc: 0.9760 - val_loss: 0.7363 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.56251\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1092 - acc: 0.9800 - val_loss: 0.7353 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.56251\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 0.1088 - acc: 0.9800 - val_loss: 0.7355 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.56251\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1085 - acc: 0.9800 - val_loss: 0.7332 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.56251\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1082 - acc: 0.9800 - val_loss: 0.7368 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.56251\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1080 - acc: 0.9800 - val_loss: 0.7340 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.56251\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1078 - acc: 0.9800 - val_loss: 0.7368 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.56251\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1069 - acc: 0.9800 - val_loss: 0.7289 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.56251\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1067 - acc: 0.9800 - val_loss: 0.7368 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.56251\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1061 - acc: 0.9800 - val_loss: 0.7356 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.56251\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1056 - acc: 0.9800 - val_loss: 0.7411 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.56251\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 199us/step - loss: 0.1051 - acc: 0.9840 - val_loss: 0.7400 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.56251\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 191us/step - loss: 0.1048 - acc: 0.9800 - val_loss: 0.7394 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.56251\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1047 - acc: 0.9800 - val_loss: 0.7384 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.56251\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1040 - acc: 0.9800 - val_loss: 0.7483 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.56251\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1039 - acc: 0.9840 - val_loss: 0.7397 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.56251\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 207us/step - loss: 0.1034 - acc: 0.9800 - val_loss: 0.7315 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.56251\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 203us/step - loss: 0.1032 - acc: 0.9800 - val_loss: 0.7350 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.56251\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 195us/step - loss: 0.1028 - acc: 0.9800 - val_loss: 0.7464 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.56251\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 0.1022 - acc: 0.9840 - val_loss: 0.7409 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.56251\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VGX2wPHvSe8JaSQkQELvvQsoKlJUsCIiltUV3bVt0d/q7rrrus1dy1rWVVGxY0NRVBTEBkoNCAgJvSUEQgjpvby/P95JCCFAgEwmyZzP88yTmTv33jkvo/fMfasYY1BKKaUAPFwdgFJKqeZDk4JSSqkamhSUUkrV0KSglFKqhiYFpZRSNTQpKKWUqqFJQakGEpFXReRvDdx3j4hceLbnUaqpaVJQSilVQ5OCUkqpGpoUVKviqLa5T0Q2ikihiLwsIm1F5HMRyReRJSLSptb+U0Rks4jkiMi3ItKz1nsDRWSd47h3Ab86n3WJiKx3HLtcRPqdYcy3isgOETkiIgtEpJ1ju4jIf0TkkIjkOsrUx/HeZBFJdsS2X0TuPaN/MKXq0KSgWqMrgfFAN+BS4HPg90Ak9r/5uwFEpBvwNvArIApYCHwiIj4i4gN8BLwBhAPvO86L49hBwBzgNiACeAFYICK+pxOoiJwP/BOYBsQCe4F3HG9fBIx1lCMMuAbIcrz3MnCbMSYY6AN8fTqfq9SJaFJQrdEzxpgMY8x+YBmwyhjzozGmFJgPDHTsdw3wmTHmS2NMOfAY4A+MAkYA3sCTxphyY8w8YE2tz7gVeMEYs8oYU2mMeQ0odRx3Oq4D5hhj1jniewAYKSIJQDkQDPQAxBiTYow54DiuHOglIiHGmGxjzLrT/Fyl6qVJQbVGGbWeF9fzOsjxvB32lzkAxpgqIBWIc7y33xw7Y+TeWs87Ar91VB3liEgO0N5x3OmoG0MB9m4gzhjzNfBf4FkgQ0Rmi0iIY9crgcnAXhH5TkRGnubnKlUvTQrKnaVjL+6ArcPHXtj3AweAOMe2ah1qPU8F/m6MCav1CDDGvH2WMQRiq6P2AxhjnjbGDAZ6Y6uR7nNsX2OMmQpEY6u53jvNz1WqXpoUlDt7D7hYRC4QEW/gt9gqoOXACqACuFtEvETkCmBYrWNfBG4XkeGOBuFAEblYRIJPM4a5wM9EZICjPeIf2OquPSIy1HF+b6AQKAEqHW0e14lIqKPaKw+oPIt/B6VqaFJQbssYsxWYCTwDHMY2Sl9qjCkzxpQBVwA3AdnY9ocPax2bhG1X+K/j/R2OfU83hq+AB4EPsHcnnYHpjrdDsMknG1vFlIVt9wC4HtgjInnA7Y5yKHXWRBfZUUopVU3vFJRSStXQpKCUUqqGJgWllFI1NCkopZSq4eXqAE5XZGSkSUhIcHUYSinVoqxdu/awMSbqVPu1uKSQkJBAUlKSq8NQSqkWRUT2nnovrT5SSilViyYFpZRSNTQpKKWUqqFJQSmlVA1NCkoppWpoUlBKKVVDk4JSSqkamhSUUqq5qCyHNS9DWaHLQtCkoJRSzcVP78Nnv4HlzxzddmAjPD8aMrc1SQiaFJRSqi5j7MPZDmyA/FpLiCe9Yv+ueh5KCxzb5sDBn2Dez6C82OkhaVJQSqnaKsvh9Snw8njI2HzsL/TD22Hj+5Cbdvafs2UhvDAWHu8GTw2At2dA2mrofQUUZ8O616CiDJI/gqgekLEJVj539p97Ci1u7iOllHKqb/8Ju5eClx88N8puG/9XGPELePtayNoOHt4w4x1IPA+WPWYv2J4+NllE97THdhgJh1LgxzdgyM3w45sw8g6bdJY/bdsNYvpC36shLQnS10NQW7j4cSjMtFVIoe1tgrjsecBA5wucXvwWtxznkCFDjE6Ip5RyitUvwsJ7YeD1MOou2PUd7P4OtnwKiefa55MehXWvQ9YOCI6B7N3QJhFMJQS3g8wUe+EvL7LnDIyGwkMgnuAbbKul/MPs86tfhciuRz/fGBCBHV/Bm1fYRBMQAfdsBC+fsyqaiKw1xgw51X56p6CUcm/5ByF7j623X3gvdJ8MFz9hL8JR3WHwjfDZb+0v/g6jYNit0GsqLHnIXuzH/QH6XX3sOasqYf1cezcw9BbY+Y1NAq9MtO//bCHE9Dk+FhH7t/P50H4E5B+AmR+cdUI4HXqnoJRyb3OvgW1f2OfdJ8PVr9V/Ec7cBoGREBB+5p/1ya/A0xsmP3rqfcuLwcPL7t8I9E5BKdV6ZSTbuvvqX9ZnqqIMdi+DxLH2MeqeE/8qj+p2dp8FcOmTDd/X2//sP+8MuE3vo7V7j/Dkkm1UVrWsOyOl3MLhHfBYd0hdc+p9U1fDcyNhy2cNO3dVJXz1MHz7iG34rW3/WigvhGGzYOx9TVpN01y5zZ3C2r3ZPLlkO7eMTiTYr3Fux5RSjWTtK1BwEL5/Aq59++T77vza/k35BHpeAps+tIO+YgfAiNvBL/TY/b/5Oyx7HBCbGBJG26oZTx/7a1w87DYFuFFS8PexRS0ur9SkoFRzUlEGG94BT1/Y+jlk7YSIzsfvV5JrB3TtXmZfb18MG9+DD2dBYJQ99sc34br3bRfRgxshvJNNCINugAv+DD88aY8PCLeNy0d2QbuB4N+mSYvcnLlNUgjw9gSguKzSxZEopQDb/XLpo7aXTtFhmPosfPobWPYEXPasfb/gEAS3haoqeP0yOLITyktsF9Ds3fDhrdDxHLhunh1o9s618O51kJMKlaX2cxLHwuTHwMsXLvrb0c8vLYAlf4aEMa4pfzPl1KQgIhOBpwBP4CVjzCN13v8PMM7xMgCINsaEOSMWfx+bFIo0KSjVPCx/2lbtdBgJnc6DftNtnf+KZ6HHZDsWYNsXcNUrUFEK6euOHjvuD/DJ3baxeca74BMA7YfaxDJ3GviHw8RnYN8KuOivNiHU5RtkB4qpYzgtKYiIJ/AsMB5IA9aIyAJjTHL1PsaYX9fa/y5goLPi0aSglItVVdlqHQ9PKM23/fx7Xw5XzgEPR5+XMY7xAO/MsHX+4Z3ho1+AqbLVPH2vtncX3SbAL1faEcDefkc/o9sEmxgiukCHEdD/GpcUtSVz5p3CMGCHMWYXgIi8A0wFkk+w/7XAn50VTHX1UUm5JgWlmtSOr+wv+m//aX/9gx3dGxoPlz59NCGAreuf8Z5tV+h0nu1y+t6NENsfRv8aQuNg+O02sfiF1P95A2c6u0StmjOTQhyQWut1GjC8vh1FpCOQCHx9gvdnAbMAOnTocEbBBDgamvVOQakmlJFsp2sIiYe8/TBgJnQYbieDG3tv/Rf2DiPso9rPvzz2fQ9P58bs5pyZFOobVXKiQQLTgXnGmHqv2MaY2cBssCOazyQYfx/7a6SorOJMDldKnYnlz4CXv50Owr8NTPi7nfdn0A2ujkydgDOTQhrQvtbreCD9BPtOB+5wYiw1XVK1+kip01BZAZ6nuEyUFdpZRbteZCeUi+pm5+7Zu9yOHxhyM/S5wk7X4O+UfiSqETkzKawBuopIIrAfe+GfUXcnEekOtAFWODGWmjYFrT5SqoHy0uG/w+w8PQOuPfa9vSvsZHEeXvDW1ZC60k4Wt285eAfaSeRWPQ9hHWH0ryCknWvKoE6b05KCMaZCRO4EFmG7pM4xxmwWkYeBJGPMAseu1wLvGCfPzKe9j5TCTun87T+h7zSI7nHyfde/BWX5tttonyvt4LG9P8DhbXZbdC/wCYT96+w8/zu/gvihdkDYyv/ZLqYXP2ZnB1UthlPHKRhjFgIL62z7U53XDzkzhmq+Xh6I6OA15ea2f2lH+G6eD7O+O7aht/Aw+IbY+X+qquzo4KAYyE21jcUHNkBpnt03YQzsW2mfT3vNzi668T1bhZSfbu8yuk1o+vKps+Y2I5pFhABvT4q1TUG5s03zwCcYsvfCot/D1P/aO4BP7rGJIqILXPqUvahn74ErXrTTSaT/aEcGj/ilHTPQYaRdOtLDC9oPs+eurmIKjLAriqkWyW2SAtjGZq0+Um5l0wcQ0x8iu9hpHbYshAEz7ERwK561C8B892974R/+C9i6EF692I4jaD/cLibTb1r95+44qmnLopqEmyUFD4q1S6pqbYyxvX/iBtupG6qlr4d5N9spH25cYGcXrSi2o4Lb9rKT0M0eBxiY+C87w+gFf4Lv/mUXqL/8ufqnh1CtmlslhQBvvVNQrdDaV+DTX9veP+f+n20XiB9s7wR8guxdwcsToKoCelxiB4aJwJUvwY4lENPv6N2ATwCM/4try6Ncyq2Sgr+PtimoVuZQCnx+P0T1tJO/vXGZ3d5xtO0mOmyWXYD+w1l26ohLnqy1DvA4+1CqFvdKCt6e2vtItXzGQNLLdsK4lE/shHA3fWoXnq8osdVGKQug+yQ7X1BQtH2/srzR1vtVrZdbJYWOksE1WY9D7lw7GZdSzU1BJhxKto281bN/Zu+1K4Yd/AlmzrOjhpc9dvSYCx+yC8pX/+rvPgnGPXD8uTUhqAZwn6RgDDdmP03Pig12jvahP3d1RMrdlebDgY22F8/Wz+2gr+//YxecCYiEWxaDdwC8MgmKjgAGXjjXLls56AZ7x5CWBMNuc3VJVCviPkkh+WN6FiXZ52lJmhRU49r5NYR2sF0/6yo8bOv+E2ut8FV0BN64HA6sh7AOkLPPbo/qARMfseMGFt4HBRl2HMEtjrECn9xt5xKa/LidctqYo20ESjUC90kK3gFsDTmHg3nFnJuW5OpoVGuy61t44wq74Mvty2wdfm2f3ANbPrXrBET1sD1+lj4GRVl2MFjyApjwD9tVNCDCTg2dswe+/pudYfTauRDbzz46nWvnE6pOBJoQVCNzn6TQ7SLm9+yA9/InODfrXSjO1sW61dkrzYcPboU2CZB/ED74Odzwsb1Yl5fYX/nbvrCDwd6ebkcDg1005po3bdfRif88/rwj77TrE/e5yq4/UK1NQlOUSrkx90kKQICPJysqu9jp+favhS4Xujok1dKlfGrXCpj2OWRuhU9/ZQd/Ze+Fn94Dv1A7PmDG+7ZHUEw/SBhtVyI72a98b387O6lSTcytkoK/tycbqzphxAPZt0qTgjo9VZWw6A/QfaJtl0r5xDYEh3awcwG1H2HXD/j2n7bap981NmkkjIFuF9mHUs2ceyUFH08K8ac8ZiA+u76B8//g6pBUc1flqO7x8IB1r8Gq5+zC8uVFR6uCzvmV/dUvYieQS1lg2wcCI23VkHic+PxKNTNu9V9rQPWaCvFjbfVRcbaLI1LNTtERO0FcQSZUlMJbV8JjXeGze+Grv0K7gXbQWHA7OPd+e8GvPWFcaByM+IVNCGCrj3Q9AdWCuNedgmP1tezYMYSZ/8Cu76D3ZS6OSjUra162C8isftH2Jsr4yVYNrXvdNvJO/Z+9yHt4QUis7docFOXqqJVqNO6VFBx3Ckfa9CXRNwR2fKlJoTlqyLrAtZUV2ou0MVB85OyWfkxZAJHd7TlK8+xcQUN+duL9NSGoVsatkkKgry1uQblAzynw0wdwwZ+P71euXCdzK8yZAOP/CoOuP/X+RUfg+dFQkmf791eUwD0bIDjm6D75GbDiv3YUcGRXu80Y+/CoVYOavQcObrSffc7djVospVoKt2pTiAyyc8NnFZTaicIqS2H5My6OStUwBj7/nW3rWfxHx9QO2NG+BzfZ9zO3wZHdR4/54n476rfHxdDpPJsUNs8/9rzfPwHLn4b/jYCN78M3/4B/J9q2grS1dp+KMvj+Sfu85yXOLqlSzZZb3SlEBdukkJlfaqcj6HMVrHkJzrnnaMOgcp2dX8Oub+w0DmtfgyV/hvBOsOQh+37faXZlMC8/uG2pTR4b34Wx/3e0J9nzY2y30BG/sK9L82H9XLuGcEkezJ9lew11m2QnnnvjMrt0ZOYWO8J44PX2M5VyU26VFAJ9PPH39rRJAWDsvfYCsuJZuPDPrg3OXexbaatyjIFLn7br+VZb95qd5mHiv+ziMMuftm0F3Sba6qC1r0JwrL3Qv3+THenr4QXDbz96jr5Xw5cP2t5l7QbZX/+leTDmt/Zi/9oUO13ElP/aBekX/9HOTdRtIvS+HLqOb+p/EaWaFacmBRGZCDyFHUP8kjHmkXr2mQY8BBhggzFmhhPjISrYl8wCR1KI6m4vBKtn29Woul6kc8k0psyttuqn8/m2vr+8xF7MK8vthf3Vi+32hNF2Woetn9vePF4+MO739nXhIZjyjJ01NKafHQh2YD18eKtjVPoFxyaW/tfCyufg9cshopOdRK73FRA/xL5/+7Kj33GbjnDNG03+z6JUc+a0pCAinsCzwHggDVgjIguMMcm19ukKPACcY4zJFhGnt/hGBfsevVMAuOBBOLAB5k6zq1RN/NexjY+qYTI228Vd+l9r//2WPOSoozcQEmd/4YfEQv4BuGEBlOTYeYKie8Gq521iNlV2UXmw0zzcvMj+yq/uCDD0Fvs3squtEtr1ja0CrC0oCn7+JXx8hx1nMOEfdkH6apr0lTopZ94pDAN2GGN2AYjIO8BUILnWPrcCzxpjsgGMMYecGA8AUUG+7MwsOLohvBPcscpexFb81zZuXvCgnYys/TBnh9PypK2F1FW2yubITvjqYbvIe+YWwNglIXteatcF6DfdVsckfwS5++20EB3PgcSx9uLc/WLb9TR1DWx42w4Ki+l79LMCI469C6gmAlOettV+vaYc/35ovJ2UTil12pyZFOKA1Fqv04DhdfbpBiAiP2CrmB4yxnzhxJiICvZlxa6sYzd6esOEv9vG5iUPwaZ5dvtty2z9c0tXVQlvXQVdxsPIX575eXL22fMUH7EX+LQ19hd94ljb+6eqAn540k4D0SYRLn3Svt/3KseCMGuOnfa5eixC+6H2cTrCOsCkf515WZRS9XJmUqjvPt3U8/ldgfOAeGCZiPQxxuQccyKRWcAsgA4dOpxVUFHBvuQWl1NaUYmvl+exb47+NYTEQ2aKHdG69NHWUee8fq7t2ZO91/bKOdMqlAV32faAgdfbC/+AmbaBvvY4j67jbZfQ/jNsQqgmondeSrUAzkwKaUD7Wq/jgfR69llpjCkHdovIVmySWFN7J2PMbGA2wJAhQ+omltNS3S31cEEZcWH+x+/Q72r7VzxsUlj+jG389K5n35agrNBO2+Dpa6t7Dm+zDewnk7XT9gLa8il8/Xc7qVtMX7uYzPkP2l5bF/0N/MOOPzZhtH0opVokZ7aorgG6ikiiiPgA04EFdfb5CBgHICKR2OqkXU6MiejaYxVOZtRd0PkC22Xx8e7w3o2w8nk7BUNzVF5i6/HLio7dvvJ/tnH38ufs6y2fHft+yif2uMPb7ev1b8Ozw2DOREd3zUx4/0Z47wabKKsbgutLCEqpFs9pdwrGmAoRuRNYhG0vmGOM2SwiDwNJxpgFjvcuEpFkoBK4zxiTdeKznr2ohiYFv1C4/kPYuwKS5kDaattgunk+XPmirdNuTjbNs+0hbRJsN9uMzXZg15o50OMS6HMl/PC07RGUsxcmPWrbBj64FSqK7Sjf3pfbY9oNtAvKY+DWr23SSP7Ydtk9m3mFlFLNnlPHKRhjFgIL62z7U63nBviN49EkGpwUqnUcaR8AG9+DT38Dz51jq2CietgLbqfzwNvPKfE2WLKjt83hHfbvD0/ZC7xvKFz4kN025WlY9rgdBBYQaZNCZRn87HO7HvDGd22X0kuftpMFFh2xCeKKFyGym00aSqlWza1GNANEBPoiAhl5Jad/cL9pdhDU13+31SrJH9sGV78w23up7zQ78KpaVZXtS99xlHPbJIpzYOc39nmWoxro4E/QdQLMePdow3Jsf5j2Osy/HZY9ZrcNvsnGN/ND2J9ku4yK2N5E1bx84fw/Oi9+pVSz4XZJwcfLg+hgX9Jzis/sBOGd4KqX7fOKMtizFJY+ZgdLLbzPXlRH3QXxQ+2o2y2fwqAb7a/0aqUFdl4f8bCN2HUbfvcuh80fQUQXGHbrqXsLbV0IVeUQGG0bksuL7Wji7pPrP3bSv+xgsqgeR3/9e/tpA7FSyv2SAkBcmD9p2WeYFGrz8rHrPHc6H7Yvst0+Uz61Uzn0vsw26rYfbuf06T8d4gbbht2kOXaQl6evPebOJHu+7D12VO/ca+xsn5VlEBBu+/mD7eufsw/2fG/PccGDtuoqaY5NIJ3Ptw3Fh5LBVB47EKw2v1Cd60kpVS+3TArxbQJYn5pz6h0bysMDuk+yj/7Xwovj7IV6wEyY/G94djgs+r2du2fdazYZXD7bXrjn32andt7wjv2Vj4BPoB1l/f7PbA+gLhfa6qd5N9s7DwAPb/hwlp0XKG0NTPq3vfMoy4ftS+w+J0oKSil1Am6ZFOLa+LPwpwNUVhk8PRp5Lpy4Qbanz/Yv7S95n0A4735bvZT+o50WesI/7EW+vMQmi68etr2ZJvzDThfRdYKtppr8GLwyEV4ebxNJxk9w7u/spHB+ofDSBXbOJp8gm4zS19kYNn8IPsF2VLFSSp0Gt0wK8W38qagyHMovITbUCQ3Al79g5/qvHunbb7rtClqQAeP+eLTR2dvPTun845u2QbhuN9f2Q+H6+TD/F+DvC1fNsQmn2s1fwO6ldlI5vxCIcKwqlrnFtm3oxH5KqdPklkmheiRzWnaxc5KCp/exUz94esENH9lFXupO8DbyDvs4kcSx8JvN9b8XN9g+qoW0sw3HXv52yg6llDpNbpkU4tsEALA/u5ihCU30oaHxEOrkzxCBq1918ocopVozt6xfiG9TfadQdIo9lVLKvbhlUvDz9iQyyIf9ZzpWQSmlWim3TAoAcW0C2HdE7xSUUqo2t00KnSID2Z1Z6OowlFKqWXHrpJCeW0JxWaWrQ1FKqWbDbZNCYlQgALsP692CUkpVc9uk0CkyCIBdhwtcHIlSSjUfbpsUEiMddwrarqCUUjXcNin4+3jSLtSPXVp9pJRSNdw2KQB0igpiV6ZWHymlVDU3TwqB7MwsxK4KqpRSyq2TQveYYApKKxpnwR2llGoF3Dop9IwNASDlQJ6LI1FKqebBrZNC97bBiMCWg/muDkUppZoFpyYFEZkoIltFZIeI3F/P+zeJSKaIrHc8fu7MeOoK9PWiY3iA3ikopZSD09ZTEBFP4FlgPJAGrBGRBcaY5Dq7vmuMudNZcZxKj5gQTQpKKeXgzDuFYcAOY8wuY0wZ8A4w1Ymfd0Z6xoaw90gRhaUVrg5FKaVczplJIQ5IrfU6zbGtritFZKOIzBOR9vWdSERmiUiSiCRlZmY2apC92oVgjDY2K6UUODcpSD3b6g4I+ARIMMb0A5YAr9V3ImPMbGPMEGPMkKioqEYNsn+8XSNzQ1puo55XKaVaImcmhTSg9i//eCC99g7GmCxjTKnj5YvAYJpYdIgfsaF+bEjNaeqPVkqpZseZSWEN0FVEEkXEB5gOLKi9g4jE1no5BUhxYjwn1C8+lI1pmhSUUsppScEYUwHcCSzCXuzfM8ZsFpGHRWSKY7e7RWSziGwA7gZuclY8J9O/fRh7sorIKSpzxccrpVSz4bQuqQDGmIXAwjrb/lTr+QPAA86MoSH6x4cBsDEtl7HdGrfNQimlWhK3HtFcrW91Y7O2Kyil3JwmBSDEz5tOUYHaA0kp5fY0KTgMiA9jQ1qOTqOtlHJrmhQc+sWHkplfysG8EleHopRSLqNJwaF/e9vYrO0KSil3pknBoWdsCN6ewo+aFJRSbkyTgoOftycD27fhu62NO7eSUkq1JJoUarmwVzRbDuaTeqTI1aEopZRLaFKoZXyvGAC+TM5wcSRKKeUamhRqSYwMpGt0kCYFpZTb0qRQx/hebVm954jOg6SUcksNSgoico+IhIj1soisE5GLnB2cK4zv1ZbKKsM3Ww+5OhSllGpyDb1TuNkYkwdcBEQBPwMecVpULtQ/PozoYF+tQlJKuaWGJoXqVdQmA68YYzZQ/8pqLZ6Hh3Bhr7Z8tzWTkvJKV4ejlFJNqqFJYa2ILMYmhUUiEgxUOS8s17qkbyyFZZUs2nzQ1aEopVSTamhSuAW4HxhqjCkCvLFVSK3SiE4RxIX5M29tmqtDUUqpJtXQpDAS2GqMyRGRmcAfgVY7z7SHh3Dl4Hi+33GY9JxiV4ejlFJNpqFJ4TmgSET6A/8H7AVed1pUzcBVg+IxBub/uN/VoSilVJNpaFKoMHahganAU8aYp4Bg54Xleh0iAhieGM77Sam6xoJSym00NCnki8gDwPXAZyLiiW1XaNWuHtKePVlFrN2b7epQlFKqSTQ0KVwDlGLHKxwE4oBHnRZVMzGpTwzBvl68tGy3q0NRSqkm0aCk4EgEbwGhInIJUGKMadVtCgCBvl7cPDqRLzYfZNP+VtuurpRSNRo6zcU0YDVwNTANWCUiVzXguIkislVEdojI/SfZ7yoRMSIypKGBN5VbxiQS6u/NE19uc3UoSinldA2tPvoDdozCjcaYG4BhwIMnO8DR7vAsMAnoBVwrIr3q2S8YuBtYdTqBN5UQP29mje3E11sOaduCUqrVa2hS8DDG1J4hLqsBxw4DdhhjdhljyoB3sL2X6vor8G+gpIGxNLmbRiUQEejD44u3ak8kpVSr1tCk8IWILBKRm0TkJuAzYOEpjokDUmu9TnNsqyEiA4H2xphPT3YiEZklIkkikpSZ2fTLZQb6enHPhV1ZvjOL93WUs1KqFWtoQ/N9wGygH9AfmG2M+d0pDqtvwryan9ki4gH8B/htAz5/tjFmiDFmSFRUVENCbnQzh3dkeGI4D3+STEZes72pUUqps9LgRXaMMR8YY35jjPm1MWZ+Aw5JA9rXeh0PpNd6HQz0Ab4VkT3ACGBBc2xsBjv1xb+v6kdpRSX/0UZnpVQrddKkICL5IpJXzyNfRPJOce41QFcRSRQRH2A6sKD6TWNMrjEm0hiTYIxJAFYCU4wxSWdZJqfpGBHI9SMSeC8plZ/StIuqUqr1OWlSMMYEG2NC6nkEG2NCTnFsBXAnsAhIAd4zxmwWkYdFZErjFaFp3XV+F6KD/Zj58iodu6CUanWkpfWmGTJkiElKcu3NROqRIqbPXomHB3xxz1gCfb1cGo9SSp2KiKw1xpyyer7BbQrqqPbhATw5fQBmQCleAAAbVElEQVRp2cX8Y2GKq8NRSqlGo0nhDA1NCOfnoxN5a9U+lm1v+m6ySinlDJoUzsJvL+pO56hA/m/eRg7lazdVpVTLp0nhLPh5e/LU9IHkFpdz05w15JWUuzokpZQ6K5oUzlKfuFD+d90gtmXkc/3Lq8kt1sSglGq5NCk0gvO6R/PczMEkp+dy/curyC3SxKCUapk0KTSS8b3a8vzMwWw5kM+Nr6ymuKzS1SEppdRp06TQiC7o2ZZnZgxkQ1oOd7/zI5VVLWsMiFJKaVJoZBN6x/DQpb35MjmDv3yyWafaVkq1KDoU1wluHJXA/pxiZi/dRVyYP7ed29nVISmlVINoUnCS+yf2ID2nmH9+voVdmYXcfWFX4sL8XR2WUkqdlCYFJ/HwEB67uj/hgT68uyaVNXuO8PGd5xDs5+3q0JRS6oS0TcGJ/Lw9eXhqH16/eRh7jxQx6/W17MoscHVYSil1QpoUmsDwThH88/K+bEzLYcKTS3n+u53aM0kp1SxpUmgi04a259v7xnFBj7Y88vkWrn1xJQdzdb4kpVTzokmhCUUF+/LczEE8dnV/Nu/P5doXV+pEekqpZkWTQhMTEa4aHM/rtwzjYG4J4x79lj9+9BNHCstcHZpSSmlScJXBHcP54BejmNQ3lndWpzLmX19zxf9+YENqjqtDU0q5MU0KLtSrXQiPXd2fz+4ew+WD4kjPKWHWG0lk5pe6OjSllJvSpNAMdI8J5m+X9eXlm4aQU1TOrDeSdEI9pZRLaFJoRnq3C+Wp6QNYn5rDjJdWsmx7ps6dpJRqUk5NCiIyUUS2isgOEbm/nvdvF5GfRGS9iHwvIr2cGU9LMLFPLE9eM4C07GKuf3k1k5/+nvk/plFRWeXq0JRSbkCc9UtURDyBbcB4IA1YA1xrjEmutU+IMSbP8XwK8EtjzMSTnXfIkCEmKSnJKTE3J6UVlXy8Pp0Xl+5i+6EChiWG89x1g4gI8nV1aEqpFkhE1hpjhpxqP2feKQwDdhhjdhljyoB3gKm1d6hOCA6BgNaVOPh6eTJtSHsW/Wosj13dnw2pOVz4xHe8+sNuyir0rkEp5RzOTApxQGqt12mObccQkTtEZCfwb+Du+k4kIrNEJElEkjIzM50SbHPl4WHHNXx85zn0ahfCQ58kM+HJpXyx6aC2NyilGp0zk4LUs+24q5gx5lljTGfgd8Af6zuRMWa2MWaIMWZIVFRUI4fZMvSICeHNW4bzyk1D8fQQbn9zLZOeWsa8tWmUVmhPJaVU43BmUkgD2td6HQ+kn2T/d4DLnBhPiycijOsRzRf3jOHRq/phDNz7/gZG/OMrfj//J1buytK7B6XUWXHmegprgK4ikgjsB6YDM2rvICJdjTHbHS8vBrajTsnL04Orh7TnqsHxLNt+mPfXpjF/3X7mrtpHj5hgfnFeZy7uG4uXp/Y4VkqdHqf1PgIQkcnAk4AnMMcY83cReRhIMsYsEJGngAuBciAbuNMYs/lk53SX3kenq6isgk83HmD20l3sOFRAeKAPlw2I43eTuuPr5enq8JRSLtbQ3kdOTQrOoEnh5KqqDF9vOcRH6/fz6cYDjOocwX+uGUDbED9Xh6aUcqHm0CVVuYCHh3Bhr7b8d8YgnpjWn6S92Vzw+Hd8semAq0NTSrUAmhRasSsGxfPlr8fStW0Qv3hrHQ9+tIlN+3NdHZZSqhnTpNDKdYwIZO7PR3DloHjeTUrlkme+5zfvrSflQN6pD1ZKuR1tU3AjeSXlPPv1Dl5dvofSiiqGdGzD9SM7MrFPjDZGK9XKaUOzOqHswjLmrU3jzVV72ZtVRNsQX+4Y14XrR3REpL4xh0qplk6TgjqlqirD0u2ZPPftTlbtPsLE3jHceX4XercL0eSgVCvT0KTgzMFrqpnz8BDO6x7Nud2ieHHZLh5dtJUvNh+kU2QgM4Z3YOaIjvh5a7WSUu5E7xRUjZyiMr7YdJAP1+1n9Z4jRAT6cPnAOGaN7US0jnNQqkXT6iN1VpbvPMybK/eyeHMGnh7CzBEdGdU5gp6xIbQL83d1eEqp06RJQTWKfVlFPP31dj5cl0aVAQ+B83u05YaRHRndJRIPD217UKol0KSgGtWhvBL25xTzVcoh3l69j6zCMjpFBjJzREeuHBxPqL+3q0NUSp2EJgXlNKUVlXz+00FeX7GHdfty8Pf2ZFTnCBIjA7nz/C6EBfi4OkSlVB2aFFST2LQ/lzdW7GVDWk7N7Kx3nt+FUH9vurUNpmdsiKtDVEqhSUG5wKb9ufzxo02sT80BwNtTuPei7lw+ME57LynlYpoUlEsYY0g+kIcx8PjirXyzNRMPgRtGJjBrbCftuaSUi2hSUC5njGFrRj5vrtzLW6v2YQz0ig1hWGI4wxLDGZoQTlSwr6vDVMotaFJQzcrerEI+3XiA5TsPs3ZvNiXlVYjAxX1juXl0IgPbh+nUGko5kSYF1WyVVVSxKT2XxZszeH3FHorKKmkT4M2QhHCuHdaewR3DtYurUo1Mk4JqEfJKyvlycwardx/hqy2HOFxQCkBcmD/ndo/iplEJdGsb7OIolWr5NCmoFqe0opIVO7NIOZDPpv25LEnJoLSiiv7xoUQE+XJe9yimDojTuwilzoAmBdXiHSks4+3V+1i6LZPMglJ2ZRYS6OPJ1IFxXNgzmlGdI3UWV6UaSJOCanU27c/lpWW7WJycQVFZJT6eHnSKCmR4YjiT+8YyLDFcG6uVOoFmkRREZCLwFOAJvGSMeaTO+78Bfg5UAJnAzcaYvSc7pyYFVVpRyapdR/hh52GS0/NYs+cIJeVVtA/3Z0jHcDqEB3Dd8A46YE6pWlyeFETEE9gGjAfSgDXAtcaY5Fr7jANWGWOKROQXwHnGmGtOdl5NCqqu4rJKPtmQzpKUDDbtz+VgXgmBvl6M7RZFj7bBjO0WRd+4UJ3RVbm15pAURgIPGWMmOF4/AGCM+ecJ9h8I/NcYc87JzqtJQZ3KrswC/v3FVrYczGNPVhEA4YE+jO4SybndohjTLZLoYL2LUO6lOSzHGQek1nqdBgw/yf63AJ/X94aIzAJmAXTo0KGx4lOtVKeoIJ6/fjAAWQWlfL/jMN9tzWTp9kwWbEgH7Mjqc7tHMbZrFIM7tsHHy8OVISvVbDgzKdR3r17vbYmIzASGAOfW974xZjYwG+ydQmMFqFq/iCBfpg6IY+qAOKqq7LxM323LZOm2TF5cuovnvt1JoI8nvduFMrBjGMMTwwnw8WJYQrhWNym35MykkAa0r/U6Hkivu5OIXAj8ATjXGFN6Jh9UXl5OWloaJSUlZxRoS+Hn50d8fDze3tpP/0x4eAh94kLpExfKHeO6kF9SzvKdWXy//TCb03N5edluXvhuFwD924dxab9YuscE0yMmROdoUm7DmW0KXtiG5guA/diG5hnGmM219hkIzAMmGmO2N+S89bUp7N69m+DgYCIiIlptl0RjDFlZWeTn55OYmOjqcFql3KJydmQWsPNQAU9/vZ207OKa9+LC/Ln7gi5MHRCnYyNUi+TyhmZHEJOBJ7FdUucYY/4uIg8DScaYBSKyBOgLHHAcss8YM+Vk56wvKaSkpNCjR49WmxCqGWPYsmULPXv2dHUobiGroJStB/PZcjCfBRvSWZ9qV5kb0zWSgR3akBARwLge0ZokVIvQHBqaMcYsBBbW2fanWs8vbKzPau0JAdyjjM1JRJAvo7r4MqpLJD87J4EfdmSxOPkgXyZnsDg5A4AgXy/6tw+lf3wY53aLYqi2RagWzqlJQanWQkQY3TWS0V0j+cuU3hSXV7Jubw4LNx1gQ2oOs5fu4n/f7iQ80IdubYPo1jaYjhGBjOwUQc/YYE3oqsXQpNAIcnJymDt3Lr/85S9P67jJkyczd+5cwsLCnBSZcgYRIcDHqyZJABSVVbBo80FW7TrC1ox85q/bT35pBQA+nh5EBPkwLDGcnKJyJvWJ4eoh7fHUOwrVDLWKuY9SUlJcWs++Z88eLrnkEjZt2nTM9srKSjw9G7e+2dVlVQ1jjCEzv5QlKYfYd6SI3YcL+HFfDv4+nuzNKiLQx5PBCeFM7d+O/u1D6RQZpNVOyqmaRZuCK/zlk80kp+c16jl7tQvhz5f2PuH7999/Pzt37mTAgAF4e3sTFBREbGws69evJzk5mcsuu4zU1FRKSkq45557mDVrFgAJCQkkJSVRUFDApEmTGD16NMuXLycuLo6PP/4Yf39dz7ilEhGiQ/yYMfzYwZbGGBZtzmDFzsMsSTnEb9/fAEBkkA/ndIlkaEI4PWKC6R4TTLCfdj1WTa/VJQVXeOSRR9i0aRPr16/n22+/5eKLL2bTpk01XUfnzJlDeHg4xcXFDB06lCuvvJKIiIhjzrF9+3befvttXnzxRaZNm8YHH3zAzJkzXVEc5UQiwsQ+MUzsE8OfLjWkHMgj+UAey3cc5vsdh/l4/dGhPHFh/vSMDWZwx3D6x4cS4u9Nz9gQrXZSTtXqksLJftE3lWHDhh0zluDpp59m/vz5AKSmprJ9+/bjkkJiYiIDBgwAYPDgwezZs6fJ4lWu4VlrMN20Ie0xxpCeW8KWA3lscXSFTTmQx5KUQzXHhPjZtoz4NgF0jQ7i/B7RBPt56zQdqtG0uqTQHAQGBtY8//bbb1myZAkrVqwgICCA8847r96R176+R0fMenp6UlxcfNw+qnUTEeLC/IkL8+eCnm1rth/ILWbP4SIyC0r5fnsmP+zIYknKIcoqqgDwEDsCu3e7EDpFBtEuzJ/oEF8Gtg/TXk/qtGlSaATBwcHk5+fX+15ubi5t2rQhICCALVu2sHLlyiaOTrV0saH+xIba9qUp/dsBtm1i3b5sftyXw5HCMlbtPsLH69PJL6moOa5TZCBtAn2ICfGjW9tgurUNomdsCAmRgfV+jlKgSaFRREREcM4559CnTx/8/f1p2/bor7yJEyfy/PPP069fP7p3786IESNcGKlqLUSEwR3DGdwxvGabMYbDBWVk5JWQfCCPTzceoLyiik3puSzcdIDqjoadowIZlhhBr3Yh9GkXQs/YEB2VrWpol9QWxp3KqhpPUVkFOw4VsD41hy+TM9iYlktucTlg2zaq2ycSIwNpF+ZPYmQg3p4eOhFgK+K2XVKVUscL8PGiX3wY/eLDuGFkAsYY9ucUszk9j837c0nam80LS3dRWXXsj8SEiADGdI2id7sQ2ob6ERvqR0yIH6H+3tpe0UppUlDKDYkI8W0CiG8TwITeMQDkl5STXVjO3iOFpB4ppqisghU7s/hgXRpvrKw85nh/b08GdgjjnC6RdIwIINDHi65tg4gL89dk0cJpUlBKARDs502wnzcdIgJqtv18TCcqKqvIyC/lYG4xB3JLOJhbQlp2Md/vOMyji7Yec46wAG86RQYS1yaAuDB/OoQHMKZrJO3D7TmrqgyH8kuJCdXlUJsrTQpKqZPy8vSo6SpbV15JOQdySigoLSflQD6b0/PYm1XIxrQcvth0gPJKWx3VNsSXrtHBZOaXsjUjn19f2I07xnXGy1PHVzQ3mhSUUmcsxM+bkBg7HUftnlBg7wr2Hini6y2HSE7PY8ehfPy8PRjfqy3/WbKNZ7/ZQb/4UMb1iOa87lH0ig3RqqdmQJOCUsopPDyExMhAbhl97EqBxhi+2HSQ9ak5rNiVxaOLtvLooq1EBPrQJtCH6GBfurUNplNUIMbAqM4RdI7SCQObiiaFRnCmU2cDPPnkk8yaNYuAgIBT76xUKyAiTOoby6S+sQBk5pfy3bZMVu3KoqC0goN5Jby7JpXi8qON214eQlSwL21D/AgL8KayyjCuezTDEsOJDvElMtBXk0Yj0XEKjeBEU2c3RPVMqZGRkQ3a39VlVaoplFdWkV1URnmlYdm2TFKziziYW8qh/BJyi8spLa9ia8bRWQS8PIToYF86RASQEBFIQmQg8W38iQ72o02AN1mFZXSKDCQ6xH0buN13nMLn98PBnxr3nDF9YdIjJ3y79tTZ48ePJzo6mvfee4/S0lIuv/xy/vKXv1BYWMi0adNIS0ujsrKSBx98kIyMDNLT0xk3bhyRkZF88803jRu3Ui2Ut6cH0cH2Aj59WId699lxKJ+dmYUcyivhYF4JB3JK2HukiCUpGRwuKKv3mA7hAcSE+BEdYu862ob40rVtMAPiwwgL0LEX0BqTggvUnjp78eLFzJs3j9WrV2OMYcqUKSxdupTMzEzatWvHZ599Btg5kUJDQ3niiSf45ptvGnynoJSyukQH0yU6uN738kvKSc8p4VB+CUcKywgL8GHT/ly2HswnI6+Ezel5fL3lEEVlR6uovD3FkYx8aRfmX/OIC/M7+jrUH3+f1j0lSOtLCif5Rd8UFi9ezOLFixk4cCAABQUFbN++nTFjxnDvvffyu9/9jksuuYQxY8a4NE6lWrNgP2+6x3jTPeZo0ji3W9Rx++WVlLMxNZctB/PIKiyjtLyKjPwS0nOK+X77YTLyS6hbw94mwLtWwvCnnSNpxIba5+GBPvh6tdzE4dSkICITgacAT+AlY8wjdd4fCzwJ9AOmG2PmOTOepmCM4YEHHuC222477r21a9eycOFCHnjgAS666CL+9Kc/uSBCpVS1ED/vY9barqusooqMPJsk0nOLSc8pYX9OMek5xezLKmLFTts4XlegjyfhQT6EB9geVW0CfAj196ZzdBA9YoJrqrCaY/JwWlIQEU/gWWA8kAasEZEFxpjkWrvtA24C7nVWHE2h9tTZEyZM4MEHH+S6664jKCiI/fv34+3tTUVFBeHh4cycOZOgoCBeffXVY47V6iOlmh8fLw/ahwfUjMiuT15JuU0aOXbEd3ZhGUcKy8kuKuNIoX3sOFRATlH5cQkkLMCbqCBfooIdjyBfokOqn/sREeRDWIA3bQJ8mmwmW2feKQwDdhhjdgGIyDvAVKAmKRhj9jjeq3JiHE5Xe+rsSZMmMWPGDEaOHAlAUFAQb775Jjt27OC+++7Dw8MDb29vnnvuOQBmzZrFpEmTiI2N1YZmpVqg6gF8PWJCTrqfMYa07GJ2Hy7kYJ6dLuRwQSmZ+fbx474cDuWXUFJe/+Uwvo0/903oztQBcc4oRg1nJoU4ILXW6zRguBM/z6Xmzp17zOt77rnnmNedO3dmwoQJxx131113cddddzk1NqWU64nIKe86jDEUllWSmV/KobwSsovKyC4qJzO/lO2HCogKcv5U5s5MCvX17TqjQREiMguYBdChQ/3d05RSqqUTEYJ8vQjy9SLRRSvkOXM2qjSgfa3X8UD6mZzIGDPbGDPEGDMkKur4HgRKKaUahzOTwhqgq4gkiogPMB1Y4KwPa2kjs8+EO5RRKeVaTksKxpgK4E5gEZACvGeM2SwiD4vIFAARGSoiacDVwAsisvlMPsvPz4+srKxWfdE0xpCVlYWfn/sO01dKOV+rmPuovLyctLQ0SkpKXBRV0/Dz8yM+Ph5vb29Xh6KUamHcau4jb29vEhMTT72jUkqpk9Jlj5RSStXQpKCUUqqGJgWllFI1WlxDs4hkAnvP8PBI4HAjhtMSuGOZwT3LrWV2D2da5o7GmFMO9GpxSeFsiEhSQ1rfWxN3LDO4Z7m1zO7B2WXW6iOllFI1NCkopZSq4W5JYbarA3ABdywzuGe5tczuwalldqs2BaWUUifnbncKSimlTkKTglJKqRpukxREZKKIbBWRHSJyv6vjcRYR2SMiP4nIehFJcmwLF5EvRWS7428bV8d5NkRkjogcEpFNtbbVW0axnnZ87xtFZJDrIj9zJyjzQyKy3/FdrxeRybXee8BR5q0icvySfy2AiLQXkW9EJEVENovIPY7trfa7PkmZm+67Nsa0+gfgCewEOgE+wAagl6vjclJZ9wCRdbb9G7jf8fx+4F+ujvMsyzgWGARsOlUZgcnA59iVAEcAq1wdfyOW+SHg3nr27eX4b9wXSHT8t+/p6jKcQZljgUGO58HANkfZWu13fZIyN9l37S53CsOAHcaYXcaYMuAdYKqLY2pKU4HXHM9fAy5zYSxnzRizFDhSZ/OJyjgVeN1YK4EwEYltmkgbzwnKfCJTgXeMMaXGmN3ADuz/Ay2KMeaAMWad43k+dl2WOFrxd32SMp9Io3/X7pIU4oDUWq/TOPk/dEtmgMUistaxtjVAW2PMAbD/0QHRLovOeU5Uxtb+3d/pqCqZU6tasNWVWUQSgIHAKtzku65TZmii79pdkoLUs6219sU9xxgzCJgE3CEiY10dkIu15u/+OaAzMAA4ADzu2N6qyiwiQcAHwK+MMXkn27WebS2y3PWUucm+a3dJCmlA+1qv44F0F8XiVMaYdMffQ8B87K1kRvVttOPvIddF6DQnKmOr/e6NMRnGmEpjTBXwIkerDVpNmUXEG3txfMsY86Fjc6v+rusrc1N+1+6SFNYAXUUkUUR8gOnAAhfH1OhEJFBEgqufAxcBm7BlvdGx243Ax66J0KlOVMYFwA2OnikjgNzqqoeWrk59+eXY7xpsmaeLiK+IJAJdgdVNHd/ZEhEBXgZSjDFP1Hqr1X7XJypzk37Xrm5tb8JW/cnYlvydwB9cHY+TytgJ2xNhA7C5upxABPAVsN3xN9zVsZ5lOd/G3kKXY38p3XKiMmJvr591fO8/AUNcHX8jlvkNR5k2Oi4OsbX2/4OjzFuBSa6O/wzLPBpbFbIRWO94TG7N3/VJytxk37VOc6GUUqqGu1QfKaWUagBNCkoppWpoUlBKKVVDk4JSSqkamhSUUkrV0KSgVBMSkfNE5FNXx6HUiWhSUEopVUOTglL1EJGZIrLaMXf9CyLiKSIFIvK4iKwTka9EJMqx7wARWemYrGx+rfn9u4jIEhHZ4Dims+P0QSIyT0S2iMhbjlGsSjULmhSUqkNEegLXYCcXHABUAtcBgcA6Yycc/A74s+OQ14HfGWP6YUedVm9/C3jWGNMfGIUdkQx25stfYefC7wSc4/RCKdVAXq4OQKlm6AJgMLDG8SPeHzvpWhXwrmOfN4EPRSQUCDPGfOfY/hrwvmMOqjhjzHwAY0wJgON8q40xaY7X64EE4HvnF0upU9OkoNTxBHjNGPPAMRtFHqyz38nmiDlZlVBpreeV6P+HqhnR6iOljvcVcJWIREPNmsAdsf+/XOXYZwbwvTEmF8gWkTGO7dcD3xk7B36aiFzmOIeviAQ0aSmUOgP6C0WpOowxySLyR+wKdh7YmUnvAAqB3iKyFsjFtjuAnb75ecdFfxfwM8f264EXRORhxzmubsJiKHVGdJZUpRpIRAqMMUGujkMpZ9LqI6WUUjX0TkEppVQNvVNQSilVQ5OCUkqpGpoUlFJK1dCkoJRSqoYmBaWUUjX+HwZdrZ5QsfuAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f2cbc0a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f2dba0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 4 увеличили шаг, добавили регуляризацию, заменили сигмоид на релу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 174670.2789 - acc: 0.6000 - val_loss: 55200.7882 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 55200.78816, saving model to test.hdf5\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 79475.3370 - acc: 0.5600 - val_loss: 34019.5198 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00002: val_loss improved from 55200.78816 to 34019.51981, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 45818.3389 - acc: 0.5760 - val_loss: 24043.3508 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss improved from 34019.51981 to 24043.35080, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 30891.2125 - acc: 0.6640 - val_loss: 18408.5673 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00004: val_loss improved from 24043.35080 to 18408.56735, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 23239.4550 - acc: 0.6920 - val_loss: 14873.9454 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00005: val_loss improved from 18408.56735 to 14873.94542, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 18839.4218 - acc: 0.6600 - val_loss: 12451.9654 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00006: val_loss improved from 14873.94542 to 12451.96544, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 15921.7854 - acc: 0.7080 - val_loss: 10769.1491 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00007: val_loss improved from 12451.96544 to 10769.14908, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 13923.6258 - acc: 0.7000 - val_loss: 9368.6198 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00008: val_loss improved from 10769.14908 to 9368.61984, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 12554.9303 - acc: 0.6960 - val_loss: 8385.9021 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00009: val_loss improved from 9368.61984 to 8385.90209, saving model to test.hdf5\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 11389.7445 - acc: 0.7120 - val_loss: 7458.8545 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00010: val_loss improved from 8385.90209 to 7458.85453, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 10471.8616 - acc: 0.7320 - val_loss: 6802.8233 - val_acc: 0.3214\n",
      "\n",
      "Epoch 00011: val_loss improved from 7458.85453 to 6802.82326, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 9689.2217 - acc: 0.7160 - val_loss: 6260.4102 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00012: val_loss improved from 6802.82326 to 6260.41022, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 9020.7201 - acc: 0.7480 - val_loss: 5773.4524 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00013: val_loss improved from 6260.41022 to 5773.45245, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 8511.4564 - acc: 0.7480 - val_loss: 5417.9259 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00014: val_loss improved from 5773.45245 to 5417.92586, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 8022.9824 - acc: 0.7640 - val_loss: 5087.5055 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00015: val_loss improved from 5417.92586 to 5087.50553, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 7586.6012 - acc: 0.7560 - val_loss: 4762.3933 - val_acc: 0.3571\n",
      "\n",
      "Epoch 00016: val_loss improved from 5087.50553 to 4762.39334, saving model to test.hdf5\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 7246.8353 - acc: 0.7440 - val_loss: 4496.6971 - val_acc: 0.3929\n",
      "\n",
      "Epoch 00017: val_loss improved from 4762.39334 to 4496.69707, saving model to test.hdf5\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 6866.5507 - acc: 0.7840 - val_loss: 4303.8405 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00018: val_loss improved from 4496.69707 to 4303.84052, saving model to test.hdf5\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 6567.7743 - acc: 0.7640 - val_loss: 4100.2833 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00019: val_loss improved from 4303.84052 to 4100.28326, saving model to test.hdf5\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 6226.7974 - acc: 0.8080 - val_loss: 3923.8982 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00020: val_loss improved from 4100.28326 to 3923.89823, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 6042.6210 - acc: 0.7760 - val_loss: 3745.8378 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00021: val_loss improved from 3923.89823 to 3745.83784, saving model to test.hdf5\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 5796.4330 - acc: 0.7640 - val_loss: 3589.4114 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00022: val_loss improved from 3745.83784 to 3589.41136, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 5545.3229 - acc: 0.8120 - val_loss: 3459.2289 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00023: val_loss improved from 3589.41136 to 3459.22889, saving model to test.hdf5\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 5331.8184 - acc: 0.7600 - val_loss: 3317.6774 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00024: val_loss improved from 3459.22889 to 3317.67741, saving model to test.hdf5\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 5116.4433 - acc: 0.7960 - val_loss: 3212.7724 - val_acc: 0.4643\n",
      "\n",
      "Epoch 00025: val_loss improved from 3317.67741 to 3212.77242, saving model to test.hdf5\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 4952.3126 - acc: 0.7920 - val_loss: 3102.5112 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00026: val_loss improved from 3212.77242 to 3102.51118, saving model to test.hdf5\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 4790.0765 - acc: 0.8160 - val_loss: 2985.7708 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00027: val_loss improved from 3102.51118 to 2985.77080, saving model to test.hdf5\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 4591.6409 - acc: 0.8280 - val_loss: 2886.0776 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00028: val_loss improved from 2985.77080 to 2886.07762, saving model to test.hdf5\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 4444.2352 - acc: 0.8240 - val_loss: 2787.8106 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00029: val_loss improved from 2886.07762 to 2787.81062, saving model to test.hdf5\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 4276.5975 - acc: 0.8640 - val_loss: 2707.1797 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00030: val_loss improved from 2787.81062 to 2707.17966, saving model to test.hdf5\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 4180.1489 - acc: 0.7960 - val_loss: 2620.9874 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00031: val_loss improved from 2707.17966 to 2620.98744, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 4008.8087 - acc: 0.8240 - val_loss: 2532.9337 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00032: val_loss improved from 2620.98744 to 2532.93374, saving model to test.hdf5\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 3891.0316 - acc: 0.8440 - val_loss: 2460.3505 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00033: val_loss improved from 2532.93374 to 2460.35047, saving model to test.hdf5\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 3762.1117 - acc: 0.8480 - val_loss: 2374.8579 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00034: val_loss improved from 2460.35047 to 2374.85795, saving model to test.hdf5\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 3636.1439 - acc: 0.8560 - val_loss: 2335.7650 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00035: val_loss improved from 2374.85795 to 2335.76498, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 3548.6222 - acc: 0.8440 - val_loss: 2248.2021 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00036: val_loss improved from 2335.76498 to 2248.20209, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 3446.2535 - acc: 0.8640 - val_loss: 2188.4987 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00037: val_loss improved from 2248.20209 to 2188.49866, saving model to test.hdf5\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 3363.2697 - acc: 0.8680 - val_loss: 2118.1502 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00038: val_loss improved from 2188.49866 to 2118.15021, saving model to test.hdf5\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 3221.8850 - acc: 0.8920 - val_loss: 2063.1936 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00039: val_loss improved from 2118.15021 to 2063.19358, saving model to test.hdf5\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 3138.9048 - acc: 0.8680 - val_loss: 2008.7122 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00040: val_loss improved from 2063.19358 to 2008.71217, saving model to test.hdf5\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 3064.5019 - acc: 0.9080 - val_loss: 1963.5706 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00041: val_loss improved from 2008.71217 to 1963.57062, saving model to test.hdf5\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 2961.6206 - acc: 0.8920 - val_loss: 1902.0889 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00042: val_loss improved from 1963.57062 to 1902.08886, saving model to test.hdf5\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 2893.3078 - acc: 0.9000 - val_loss: 1850.9765 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00043: val_loss improved from 1902.08886 to 1850.97653, saving model to test.hdf5\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 2816.7910 - acc: 0.9000 - val_loss: 1805.0600 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00044: val_loss improved from 1850.97653 to 1805.05995, saving model to test.hdf5\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 2746.1507 - acc: 0.8960 - val_loss: 1746.4239 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00045: val_loss improved from 1805.05995 to 1746.42389, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 2668.0006 - acc: 0.8880 - val_loss: 1701.5435 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00046: val_loss improved from 1746.42389 to 1701.54352, saving model to test.hdf5\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2577.1056 - acc: 0.8920 - val_loss: 1669.3218 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00047: val_loss improved from 1701.54352 to 1669.32180, saving model to test.hdf5\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 2510.9668 - acc: 0.9280 - val_loss: 1620.5151 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00048: val_loss improved from 1669.32180 to 1620.51509, saving model to test.hdf5\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 2453.1630 - acc: 0.9040 - val_loss: 1578.1573 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00049: val_loss improved from 1620.51509 to 1578.15733, saving model to test.hdf5\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 2385.1496 - acc: 0.9320 - val_loss: 1552.2978 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00050: val_loss improved from 1578.15733 to 1552.29776, saving model to test.hdf5\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 2308.6516 - acc: 0.9160 - val_loss: 1502.3693 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00051: val_loss improved from 1552.29776 to 1502.36931, saving model to test.hdf5\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 2246.1611 - acc: 0.8920 - val_loss: 1466.5755 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00052: val_loss improved from 1502.36931 to 1466.57552, saving model to test.hdf5\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 2196.4935 - acc: 0.9240 - val_loss: 1443.8696 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00053: val_loss improved from 1466.57552 to 1443.86963, saving model to test.hdf5\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2136.6163 - acc: 0.9240 - val_loss: 1400.7401 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00054: val_loss improved from 1443.86963 to 1400.74013, saving model to test.hdf5\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 2097.1971 - acc: 0.9200 - val_loss: 1362.0151 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00055: val_loss improved from 1400.74013 to 1362.01511, saving model to test.hdf5\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 2014.3077 - acc: 0.9120 - val_loss: 1329.8807 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00056: val_loss improved from 1362.01511 to 1329.88074, saving model to test.hdf5\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1961.4164 - acc: 0.8960 - val_loss: 1299.6085 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00057: val_loss improved from 1329.88074 to 1299.60854, saving model to test.hdf5\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1931.3177 - acc: 0.8960 - val_loss: 1275.7843 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00058: val_loss improved from 1299.60854 to 1275.78431, saving model to test.hdf5\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1866.9837 - acc: 0.9160 - val_loss: 1237.4500 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00059: val_loss improved from 1275.78431 to 1237.44996, saving model to test.hdf5\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 1810.0477 - acc: 0.9240 - val_loss: 1200.9550 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00060: val_loss improved from 1237.44996 to 1200.95498, saving model to test.hdf5\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1768.6133 - acc: 0.9320 - val_loss: 1184.2598 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00061: val_loss improved from 1200.95498 to 1184.25977, saving model to test.hdf5\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1719.7754 - acc: 0.9440 - val_loss: 1141.7524 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00062: val_loss improved from 1184.25977 to 1141.75242, saving model to test.hdf5\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 1684.6078 - acc: 0.9320 - val_loss: 1121.3849 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00063: val_loss improved from 1141.75242 to 1121.38494, saving model to test.hdf5\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1617.3845 - acc: 0.9360 - val_loss: 1087.7296 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00064: val_loss improved from 1121.38494 to 1087.72959, saving model to test.hdf5\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1584.7290 - acc: 0.9320 - val_loss: 1060.3701 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00065: val_loss improved from 1087.72959 to 1060.37013, saving model to test.hdf5\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1547.6639 - acc: 0.9080 - val_loss: 1033.1398 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00066: val_loss improved from 1060.37013 to 1033.13982, saving model to test.hdf5\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1494.9083 - acc: 0.9240 - val_loss: 1013.3327 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00067: val_loss improved from 1033.13982 to 1013.33272, saving model to test.hdf5\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1465.5130 - acc: 0.9520 - val_loss: 991.6327 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00068: val_loss improved from 1013.33272 to 991.63275, saving model to test.hdf5\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1421.0186 - acc: 0.9400 - val_loss: 960.7076 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00069: val_loss improved from 991.63275 to 960.70762, saving model to test.hdf5\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 1387.1471 - acc: 0.9280 - val_loss: 944.4650 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00070: val_loss improved from 960.70762 to 944.46502, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1345.7779 - acc: 0.9160 - val_loss: 921.8177 - val_acc: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_loss improved from 944.46502 to 921.81772, saving model to test.hdf5\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 1310.4344 - acc: 0.9360 - val_loss: 896.0377 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00072: val_loss improved from 921.81772 to 896.03769, saving model to test.hdf5\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1277.4023 - acc: 0.9360 - val_loss: 877.5101 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00073: val_loss improved from 896.03769 to 877.51013, saving model to test.hdf5\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1245.2305 - acc: 0.8880 - val_loss: 859.1318 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00074: val_loss improved from 877.51013 to 859.13184, saving model to test.hdf5\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1220.3388 - acc: 0.9280 - val_loss: 830.7625 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00075: val_loss improved from 859.13184 to 830.76248, saving model to test.hdf5\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1180.2918 - acc: 0.9160 - val_loss: 814.7816 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00076: val_loss improved from 830.76248 to 814.78157, saving model to test.hdf5\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1150.9718 - acc: 0.9320 - val_loss: 790.8927 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00077: val_loss improved from 814.78157 to 790.89270, saving model to test.hdf5\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1115.9129 - acc: 0.9400 - val_loss: 774.2617 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00078: val_loss improved from 790.89270 to 774.26167, saving model to test.hdf5\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1097.7088 - acc: 0.9240 - val_loss: 757.6259 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00079: val_loss improved from 774.26167 to 757.62588, saving model to test.hdf5\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1060.9527 - acc: 0.9320 - val_loss: 737.4616 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00080: val_loss improved from 757.62588 to 737.46158, saving model to test.hdf5\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1031.5385 - acc: 0.9240 - val_loss: 716.3953 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00081: val_loss improved from 737.46158 to 716.39534, saving model to test.hdf5\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 1002.6242 - acc: 0.9360 - val_loss: 701.4877 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00082: val_loss improved from 716.39534 to 701.48770, saving model to test.hdf5\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 982.2592 - acc: 0.9400 - val_loss: 681.2757 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00083: val_loss improved from 701.48770 to 681.27569, saving model to test.hdf5\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 949.6529 - acc: 0.9240 - val_loss: 666.0070 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00084: val_loss improved from 681.27569 to 666.00702, saving model to test.hdf5\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 928.1821 - acc: 0.9440 - val_loss: 654.4668 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00085: val_loss improved from 666.00702 to 654.46679, saving model to test.hdf5\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 902.0965 - acc: 0.9160 - val_loss: 636.9669 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00086: val_loss improved from 654.46679 to 636.96686, saving model to test.hdf5\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 875.8507 - acc: 0.9600 - val_loss: 624.9222 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00087: val_loss improved from 636.96686 to 624.92220, saving model to test.hdf5\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 854.0504 - acc: 0.9360 - val_loss: 603.8758 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00088: val_loss improved from 624.92220 to 603.87577, saving model to test.hdf5\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 822.0487 - acc: 0.9320 - val_loss: 586.4623 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00089: val_loss improved from 603.87577 to 586.46227, saving model to test.hdf5\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 805.8427 - acc: 0.9400 - val_loss: 573.5870 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00090: val_loss improved from 586.46227 to 573.58697, saving model to test.hdf5\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 784.4596 - acc: 0.9440 - val_loss: 560.8094 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00091: val_loss improved from 573.58697 to 560.80944, saving model to test.hdf5\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 765.0222 - acc: 0.9280 - val_loss: 546.8338 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00092: val_loss improved from 560.80944 to 546.83377, saving model to test.hdf5\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 736.7783 - acc: 0.9400 - val_loss: 533.4702 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00093: val_loss improved from 546.83377 to 533.47022, saving model to test.hdf5\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 719.7619 - acc: 0.9440 - val_loss: 520.6239 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00094: val_loss improved from 533.47022 to 520.62392, saving model to test.hdf5\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 700.8348 - acc: 0.9640 - val_loss: 507.1086 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00095: val_loss improved from 520.62392 to 507.10857, saving model to test.hdf5\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 682.4236 - acc: 0.9400 - val_loss: 492.0689 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00096: val_loss improved from 507.10857 to 492.06893, saving model to test.hdf5\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 658.4393 - acc: 0.9360 - val_loss: 483.0612 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00097: val_loss improved from 492.06893 to 483.06118, saving model to test.hdf5\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 642.6625 - acc: 0.9520 - val_loss: 470.3480 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00098: val_loss improved from 483.06118 to 470.34800, saving model to test.hdf5\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 627.3321 - acc: 0.9480 - val_loss: 459.0266 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00099: val_loss improved from 470.34800 to 459.02661, saving model to test.hdf5\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 606.1863 - acc: 0.9480 - val_loss: 447.1341 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00100: val_loss improved from 459.02661 to 447.13406, saving model to test.hdf5\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 589.8295 - acc: 0.9520 - val_loss: 438.3502 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00101: val_loss improved from 447.13406 to 438.35019, saving model to test.hdf5\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 575.6367 - acc: 0.9240 - val_loss: 420.5503 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00102: val_loss improved from 438.35019 to 420.55034, saving model to test.hdf5\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 557.1699 - acc: 0.9480 - val_loss: 415.1797 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00103: val_loss improved from 420.55034 to 415.17972, saving model to test.hdf5\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 546.4230 - acc: 0.9400 - val_loss: 400.2053 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00104: val_loss improved from 415.17972 to 400.20533, saving model to test.hdf5\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 528.3030 - acc: 0.9520 - val_loss: 389.8684 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00105: val_loss improved from 400.20533 to 389.86841, saving model to test.hdf5\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 513.5196 - acc: 0.9520 - val_loss: 381.8934 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00106: val_loss improved from 389.86841 to 381.89340, saving model to test.hdf5\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 498.6889 - acc: 0.9480 - val_loss: 373.0270 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00107: val_loss improved from 381.89340 to 373.02699, saving model to test.hdf5\n",
      "Epoch 108/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 207us/step - loss: 487.8870 - acc: 0.9520 - val_loss: 363.7907 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00108: val_loss improved from 373.02699 to 363.79071, saving model to test.hdf5\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 468.7193 - acc: 0.9600 - val_loss: 352.2182 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00109: val_loss improved from 363.79071 to 352.21825, saving model to test.hdf5\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 456.3550 - acc: 0.9520 - val_loss: 343.8018 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00110: val_loss improved from 352.21825 to 343.80177, saving model to test.hdf5\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 445.3446 - acc: 0.9360 - val_loss: 338.0871 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00111: val_loss improved from 343.80177 to 338.08710, saving model to test.hdf5\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 431.0617 - acc: 0.9400 - val_loss: 324.2426 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00112: val_loss improved from 338.08710 to 324.24258, saving model to test.hdf5\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 420.4713 - acc: 0.9520 - val_loss: 318.4599 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00113: val_loss improved from 324.24258 to 318.45994, saving model to test.hdf5\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 408.8822 - acc: 0.9520 - val_loss: 311.1302 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00114: val_loss improved from 318.45994 to 311.13019, saving model to test.hdf5\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 392.7110 - acc: 0.9440 - val_loss: 301.2477 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00115: val_loss improved from 311.13019 to 301.24773, saving model to test.hdf5\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 383.4462 - acc: 0.9480 - val_loss: 296.6283 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00116: val_loss improved from 301.24773 to 296.62832, saving model to test.hdf5\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 371.7603 - acc: 0.9480 - val_loss: 285.1902 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00117: val_loss improved from 296.62832 to 285.19025, saving model to test.hdf5\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 363.8115 - acc: 0.9400 - val_loss: 279.6408 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00118: val_loss improved from 285.19025 to 279.64084, saving model to test.hdf5\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 352.7943 - acc: 0.9520 - val_loss: 270.8320 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00119: val_loss improved from 279.64084 to 270.83197, saving model to test.hdf5\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 341.3765 - acc: 0.9480 - val_loss: 265.2897 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00120: val_loss improved from 270.83197 to 265.28971, saving model to test.hdf5\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 331.2457 - acc: 0.9600 - val_loss: 259.7340 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00121: val_loss improved from 265.28971 to 259.73403, saving model to test.hdf5\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 322.5669 - acc: 0.9560 - val_loss: 251.6193 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00122: val_loss improved from 259.73403 to 251.61931, saving model to test.hdf5\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 311.0945 - acc: 0.9640 - val_loss: 242.6961 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00123: val_loss improved from 251.61931 to 242.69606, saving model to test.hdf5\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 303.9360 - acc: 0.9360 - val_loss: 237.1920 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00124: val_loss improved from 242.69606 to 237.19197, saving model to test.hdf5\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 294.2330 - acc: 0.9600 - val_loss: 234.1045 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00125: val_loss improved from 237.19197 to 234.10453, saving model to test.hdf5\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 285.6772 - acc: 0.9360 - val_loss: 225.8195 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00126: val_loss improved from 234.10453 to 225.81951, saving model to test.hdf5\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 277.7589 - acc: 0.9480 - val_loss: 218.2407 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00127: val_loss improved from 225.81951 to 218.24069, saving model to test.hdf5\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 271.3470 - acc: 0.9560 - val_loss: 212.1181 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00128: val_loss improved from 218.24069 to 212.11811, saving model to test.hdf5\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 259.8307 - acc: 0.9440 - val_loss: 206.7478 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00129: val_loss improved from 212.11811 to 206.74778, saving model to test.hdf5\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 252.1796 - acc: 0.9400 - val_loss: 201.4504 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00130: val_loss improved from 206.74778 to 201.45037, saving model to test.hdf5\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 243.1155 - acc: 0.9400 - val_loss: 196.7052 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00131: val_loss improved from 201.45037 to 196.70520, saving model to test.hdf5\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 237.2214 - acc: 0.9520 - val_loss: 193.9077 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00132: val_loss improved from 196.70520 to 193.90773, saving model to test.hdf5\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 207us/step - loss: 230.0520 - acc: 0.9480 - val_loss: 185.5232 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00133: val_loss improved from 193.90773 to 185.52322, saving model to test.hdf5\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 222.9066 - acc: 0.9280 - val_loss: 181.4514 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00134: val_loss improved from 185.52322 to 181.45143, saving model to test.hdf5\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 217.8470 - acc: 0.9480 - val_loss: 177.7482 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00135: val_loss improved from 181.45143 to 177.74823, saving model to test.hdf5\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 210.2105 - acc: 0.9560 - val_loss: 169.5727 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00136: val_loss improved from 177.74823 to 169.57271, saving model to test.hdf5\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 202.3773 - acc: 0.9480 - val_loss: 165.6086 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00137: val_loss improved from 169.57271 to 165.60861, saving model to test.hdf5\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 198.7856 - acc: 0.9280 - val_loss: 161.8086 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00138: val_loss improved from 165.60861 to 161.80858, saving model to test.hdf5\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 191.8293 - acc: 0.9280 - val_loss: 158.1626 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00139: val_loss improved from 161.80858 to 158.16263, saving model to test.hdf5\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 185.8155 - acc: 0.9240 - val_loss: 153.3804 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00140: val_loss improved from 158.16263 to 153.38039, saving model to test.hdf5\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 179.5302 - acc: 0.9360 - val_loss: 149.0126 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00141: val_loss improved from 153.38039 to 149.01256, saving model to test.hdf5\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 176.8701 - acc: 0.9360 - val_loss: 145.1648 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00142: val_loss improved from 149.01256 to 145.16476, saving model to test.hdf5\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 171.3114 - acc: 0.9400 - val_loss: 143.9461 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00143: val_loss improved from 145.16476 to 143.94609, saving model to test.hdf5\n",
      "Epoch 144/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 211us/step - loss: 165.9600 - acc: 0.9480 - val_loss: 138.6551 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00144: val_loss improved from 143.94609 to 138.65512, saving model to test.hdf5\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 159.8637 - acc: 0.9320 - val_loss: 135.9459 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00145: val_loss improved from 138.65512 to 135.94594, saving model to test.hdf5\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 155.8473 - acc: 0.9400 - val_loss: 131.8580 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00146: val_loss improved from 135.94594 to 131.85804, saving model to test.hdf5\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 151.2370 - acc: 0.9320 - val_loss: 128.2242 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00147: val_loss improved from 131.85804 to 128.22424, saving model to test.hdf5\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 148.1690 - acc: 0.9400 - val_loss: 124.1546 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00148: val_loss improved from 128.22424 to 124.15457, saving model to test.hdf5\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 144.8932 - acc: 0.9440 - val_loss: 122.3044 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00149: val_loss improved from 124.15457 to 122.30436, saving model to test.hdf5\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 139.0215 - acc: 0.9160 - val_loss: 120.3793 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00150: val_loss improved from 122.30436 to 120.37935, saving model to test.hdf5\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 137.7300 - acc: 0.9240 - val_loss: 115.8037 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00151: val_loss improved from 120.37935 to 115.80368, saving model to test.hdf5\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 131.5640 - acc: 0.9400 - val_loss: 113.5501 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00152: val_loss improved from 115.80368 to 113.55009, saving model to test.hdf5\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 128.9696 - acc: 0.9320 - val_loss: 109.5708 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00153: val_loss improved from 113.55009 to 109.57077, saving model to test.hdf5\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 124.2371 - acc: 0.9360 - val_loss: 107.9336 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00154: val_loss improved from 109.57077 to 107.93363, saving model to test.hdf5\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 120.6179 - acc: 0.9400 - val_loss: 104.5444 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00155: val_loss improved from 107.93363 to 104.54436, saving model to test.hdf5\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 117.3682 - acc: 0.9240 - val_loss: 101.2667 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00156: val_loss improved from 104.54436 to 101.26673, saving model to test.hdf5\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 114.5387 - acc: 0.9320 - val_loss: 99.5581 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00157: val_loss improved from 101.26673 to 99.55813, saving model to test.hdf5\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 111.5519 - acc: 0.9280 - val_loss: 97.0219 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00158: val_loss improved from 99.55813 to 97.02188, saving model to test.hdf5\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 108.5576 - acc: 0.9440 - val_loss: 93.8754 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00159: val_loss improved from 97.02188 to 93.87542, saving model to test.hdf5\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 104.8668 - acc: 0.9440 - val_loss: 92.8707 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00160: val_loss improved from 93.87542 to 92.87068, saving model to test.hdf5\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 101.9141 - acc: 0.9160 - val_loss: 90.8432 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00161: val_loss improved from 92.87068 to 90.84320, saving model to test.hdf5\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 97.9349 - acc: 0.9480 - val_loss: 87.3633 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00162: val_loss improved from 90.84320 to 87.36330, saving model to test.hdf5\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 95.1265 - acc: 0.9120 - val_loss: 85.7966 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00163: val_loss improved from 87.36330 to 85.79655, saving model to test.hdf5\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 93.2049 - acc: 0.8960 - val_loss: 82.5548 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00164: val_loss improved from 85.79655 to 82.55477, saving model to test.hdf5\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 90.2294 - acc: 0.9080 - val_loss: 80.6294 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00165: val_loss improved from 82.55477 to 80.62937, saving model to test.hdf5\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 87.2679 - acc: 0.9160 - val_loss: 77.8647 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00166: val_loss improved from 80.62937 to 77.86473, saving model to test.hdf5\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 85.1877 - acc: 0.9160 - val_loss: 76.3216 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00167: val_loss improved from 77.86473 to 76.32164, saving model to test.hdf5\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 81.9125 - acc: 0.9080 - val_loss: 74.0621 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00168: val_loss improved from 76.32164 to 74.06208, saving model to test.hdf5\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 79.4900 - acc: 0.9120 - val_loss: 72.6043 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00169: val_loss improved from 74.06208 to 72.60434, saving model to test.hdf5\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 77.4711 - acc: 0.9160 - val_loss: 70.0156 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00170: val_loss improved from 72.60434 to 70.01560, saving model to test.hdf5\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 74.4409 - acc: 0.9080 - val_loss: 68.6296 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00171: val_loss improved from 70.01560 to 68.62958, saving model to test.hdf5\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 73.7427 - acc: 0.9200 - val_loss: 66.3344 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00172: val_loss improved from 68.62958 to 66.33436, saving model to test.hdf5\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 71.6318 - acc: 0.9160 - val_loss: 64.6715 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00173: val_loss improved from 66.33436 to 64.67151, saving model to test.hdf5\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 69.3522 - acc: 0.9120 - val_loss: 64.2187 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00174: val_loss improved from 64.67151 to 64.21874, saving model to test.hdf5\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 66.1425 - acc: 0.9200 - val_loss: 60.8948 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00175: val_loss improved from 64.21874 to 60.89476, saving model to test.hdf5\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 64.3308 - acc: 0.9120 - val_loss: 58.9763 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00176: val_loss improved from 60.89476 to 58.97634, saving model to test.hdf5\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 62.2466 - acc: 0.9080 - val_loss: 57.8663 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00177: val_loss improved from 58.97634 to 57.86626, saving model to test.hdf5\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 60.5795 - acc: 0.9120 - val_loss: 56.6702 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00178: val_loss improved from 57.86626 to 56.67022, saving model to test.hdf5\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 59.0210 - acc: 0.8960 - val_loss: 54.9797 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00179: val_loss improved from 56.67022 to 54.97969, saving model to test.hdf5\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 58.2851 - acc: 0.9200 - val_loss: 53.5635 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00180: val_loss improved from 54.97969 to 53.56347, saving model to test.hdf5\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 55.1776 - acc: 0.8800 - val_loss: 51.4246 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00181: val_loss improved from 53.56347 to 51.42460, saving model to test.hdf5\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 53.7218 - acc: 0.9240 - val_loss: 50.1698 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00182: val_loss improved from 51.42460 to 50.16977, saving model to test.hdf5\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 52.0179 - acc: 0.9120 - val_loss: 49.2450 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00183: val_loss improved from 50.16977 to 49.24505, saving model to test.hdf5\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 50.5238 - acc: 0.8840 - val_loss: 47.5904 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00184: val_loss improved from 49.24505 to 47.59041, saving model to test.hdf5\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 48.7341 - acc: 0.9040 - val_loss: 46.4936 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00185: val_loss improved from 47.59041 to 46.49360, saving model to test.hdf5\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 47.5169 - acc: 0.9040 - val_loss: 45.2956 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00186: val_loss improved from 46.49360 to 45.29558, saving model to test.hdf5\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 46.2208 - acc: 0.8920 - val_loss: 44.4005 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00187: val_loss improved from 45.29558 to 44.40051, saving model to test.hdf5\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 44.6855 - acc: 0.9000 - val_loss: 42.6428 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00188: val_loss improved from 44.40051 to 42.64283, saving model to test.hdf5\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 42.8806 - acc: 0.8880 - val_loss: 41.2508 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00189: val_loss improved from 42.64283 to 41.25080, saving model to test.hdf5\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 41.0199 - acc: 0.9040 - val_loss: 41.2627 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 41.25080\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 40.8611 - acc: 0.8960 - val_loss: 39.3841 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00191: val_loss improved from 41.25080 to 39.38414, saving model to test.hdf5\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 38.7436 - acc: 0.8800 - val_loss: 38.1098 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00192: val_loss improved from 39.38414 to 38.10976, saving model to test.hdf5\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 37.5823 - acc: 0.8960 - val_loss: 36.9770 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00193: val_loss improved from 38.10976 to 36.97703, saving model to test.hdf5\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 36.7954 - acc: 0.9080 - val_loss: 35.5851 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00194: val_loss improved from 36.97703 to 35.58512, saving model to test.hdf5\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 35.6167 - acc: 0.8840 - val_loss: 34.5212 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00195: val_loss improved from 35.58512 to 34.52122, saving model to test.hdf5\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 34.4388 - acc: 0.8960 - val_loss: 34.0194 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00196: val_loss improved from 34.52122 to 34.01936, saving model to test.hdf5\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 33.3099 - acc: 0.8920 - val_loss: 33.0636 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00197: val_loss improved from 34.01936 to 33.06359, saving model to test.hdf5\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 32.0214 - acc: 0.8880 - val_loss: 31.9886 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00198: val_loss improved from 33.06359 to 31.98861, saving model to test.hdf5\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 31.4668 - acc: 0.8840 - val_loss: 30.8515 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00199: val_loss improved from 31.98861 to 30.85149, saving model to test.hdf5\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 30.1830 - acc: 0.8680 - val_loss: 30.0232 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00200: val_loss improved from 30.85149 to 30.02324, saving model to test.hdf5\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 29.6438 - acc: 0.8480 - val_loss: 29.3348 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00201: val_loss improved from 30.02324 to 29.33483, saving model to test.hdf5\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 28.0055 - acc: 0.8680 - val_loss: 28.4106 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00202: val_loss improved from 29.33483 to 28.41062, saving model to test.hdf5\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 27.6854 - acc: 0.8800 - val_loss: 27.4702 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00203: val_loss improved from 28.41062 to 27.47016, saving model to test.hdf5\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 26.6169 - acc: 0.8680 - val_loss: 26.8269 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00204: val_loss improved from 27.47016 to 26.82690, saving model to test.hdf5\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 25.5899 - acc: 0.8840 - val_loss: 25.7948 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00205: val_loss improved from 26.82690 to 25.79480, saving model to test.hdf5\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 24.7687 - acc: 0.8720 - val_loss: 25.8536 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 25.79480\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 24.5841 - acc: 0.8840 - val_loss: 24.5832 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00207: val_loss improved from 25.79480 to 24.58322, saving model to test.hdf5\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 23.5510 - acc: 0.9000 - val_loss: 23.8681 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00208: val_loss improved from 24.58322 to 23.86812, saving model to test.hdf5\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 22.7307 - acc: 0.8840 - val_loss: 23.7653 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00209: val_loss improved from 23.86812 to 23.76534, saving model to test.hdf5\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 21.7834 - acc: 0.9120 - val_loss: 22.9702 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00210: val_loss improved from 23.76534 to 22.97024, saving model to test.hdf5\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 21.2853 - acc: 0.8840 - val_loss: 22.2412 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00211: val_loss improved from 22.97024 to 22.24122, saving model to test.hdf5\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 20.7535 - acc: 0.8680 - val_loss: 21.6415 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00212: val_loss improved from 22.24122 to 21.64146, saving model to test.hdf5\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 20.3035 - acc: 0.8640 - val_loss: 20.9797 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00213: val_loss improved from 21.64146 to 20.97973, saving model to test.hdf5\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 19.8085 - acc: 0.8840 - val_loss: 20.7476 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00214: val_loss improved from 20.97973 to 20.74760, saving model to test.hdf5\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 19.2674 - acc: 0.8800 - val_loss: 19.9488 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00215: val_loss improved from 20.74760 to 19.94884, saving model to test.hdf5\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 18.5902 - acc: 0.8840 - val_loss: 19.3315 - val_acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: val_loss improved from 19.94884 to 19.33146, saving model to test.hdf5\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 18.0930 - acc: 0.8880 - val_loss: 18.9179 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00217: val_loss improved from 19.33146 to 18.91789, saving model to test.hdf5\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 17.2116 - acc: 0.8640 - val_loss: 18.1619 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00218: val_loss improved from 18.91789 to 18.16188, saving model to test.hdf5\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 16.8688 - acc: 0.8680 - val_loss: 17.6059 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00219: val_loss improved from 18.16188 to 17.60585, saving model to test.hdf5\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 16.3376 - acc: 0.8800 - val_loss: 17.5774 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00220: val_loss improved from 17.60585 to 17.57744, saving model to test.hdf5\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 15.8557 - acc: 0.8720 - val_loss: 16.8917 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00221: val_loss improved from 17.57744 to 16.89169, saving model to test.hdf5\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 15.5129 - acc: 0.8520 - val_loss: 16.5723 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00222: val_loss improved from 16.89169 to 16.57232, saving model to test.hdf5\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 15.1145 - acc: 0.8760 - val_loss: 15.8467 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00223: val_loss improved from 16.57232 to 15.84671, saving model to test.hdf5\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 14.5555 - acc: 0.8560 - val_loss: 15.6024 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00224: val_loss improved from 15.84671 to 15.60240, saving model to test.hdf5\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 14.2923 - acc: 0.8400 - val_loss: 15.0933 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00225: val_loss improved from 15.60240 to 15.09335, saving model to test.hdf5\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 13.7192 - acc: 0.8680 - val_loss: 14.6276 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00226: val_loss improved from 15.09335 to 14.62762, saving model to test.hdf5\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 13.0742 - acc: 0.8760 - val_loss: 14.4035 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00227: val_loss improved from 14.62762 to 14.40346, saving model to test.hdf5\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 12.9278 - acc: 0.8760 - val_loss: 13.9640 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00228: val_loss improved from 14.40346 to 13.96400, saving model to test.hdf5\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 12.4658 - acc: 0.8720 - val_loss: 13.3671 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00229: val_loss improved from 13.96400 to 13.36708, saving model to test.hdf5\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 12.0912 - acc: 0.8920 - val_loss: 13.4909 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 13.36708\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 11.7571 - acc: 0.8720 - val_loss: 12.9015 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00231: val_loss improved from 13.36708 to 12.90146, saving model to test.hdf5\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 11.3921 - acc: 0.8960 - val_loss: 12.5570 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00232: val_loss improved from 12.90146 to 12.55701, saving model to test.hdf5\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 11.0928 - acc: 0.8640 - val_loss: 12.3122 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00233: val_loss improved from 12.55701 to 12.31217, saving model to test.hdf5\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 10.6573 - acc: 0.8640 - val_loss: 11.6367 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00234: val_loss improved from 12.31217 to 11.63673, saving model to test.hdf5\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 10.3882 - acc: 0.8400 - val_loss: 11.5522 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00235: val_loss improved from 11.63673 to 11.55225, saving model to test.hdf5\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 10.5038 - acc: 0.8520 - val_loss: 10.9955 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00236: val_loss improved from 11.55225 to 10.99554, saving model to test.hdf5\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 9.9562 - acc: 0.8360 - val_loss: 10.7103 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00237: val_loss improved from 10.99554 to 10.71034, saving model to test.hdf5\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 9.5278 - acc: 0.8520 - val_loss: 10.3494 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00238: val_loss improved from 10.71034 to 10.34943, saving model to test.hdf5\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 9.1383 - acc: 0.8360 - val_loss: 10.2046 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00239: val_loss improved from 10.34943 to 10.20460, saving model to test.hdf5\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 8.9622 - acc: 0.8760 - val_loss: 10.0272 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00240: val_loss improved from 10.20460 to 10.02716, saving model to test.hdf5\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 8.5151 - acc: 0.8480 - val_loss: 9.7617 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00241: val_loss improved from 10.02716 to 9.76175, saving model to test.hdf5\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 8.3524 - acc: 0.8960 - val_loss: 9.1775 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00242: val_loss improved from 9.76175 to 9.17751, saving model to test.hdf5\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 7.9350 - acc: 0.8760 - val_loss: 9.0557 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00243: val_loss improved from 9.17751 to 9.05567, saving model to test.hdf5\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 7.9618 - acc: 0.8360 - val_loss: 8.8448 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00244: val_loss improved from 9.05567 to 8.84484, saving model to test.hdf5\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 7.8643 - acc: 0.8400 - val_loss: 8.3903 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00245: val_loss improved from 8.84484 to 8.39025, saving model to test.hdf5\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 7.4626 - acc: 0.8360 - val_loss: 8.1911 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00246: val_loss improved from 8.39025 to 8.19109, saving model to test.hdf5\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 7.1687 - acc: 0.8480 - val_loss: 8.2220 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 8.19109\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 6.9681 - acc: 0.8560 - val_loss: 7.8424 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00248: val_loss improved from 8.19109 to 7.84240, saving model to test.hdf5\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 7.0367 - acc: 0.8440 - val_loss: 7.6305 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00249: val_loss improved from 7.84240 to 7.63046, saving model to test.hdf5\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 6.7257 - acc: 0.8280 - val_loss: 7.3073 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00250: val_loss improved from 7.63046 to 7.30728, saving model to test.hdf5\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 6.2253 - acc: 0.8800 - val_loss: 7.0916 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00251: val_loss improved from 7.30728 to 7.09165, saving model to test.hdf5\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 6.1298 - acc: 0.8600 - val_loss: 6.9678 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00252: val_loss improved from 7.09165 to 6.96784, saving model to test.hdf5\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 5.9390 - acc: 0.8640 - val_loss: 7.1033 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00253: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 6.96784\n",
      "Epoch 254/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 223us/step - loss: 5.8247 - acc: 0.8520 - val_loss: 6.4634 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00254: val_loss improved from 6.96784 to 6.46344, saving model to test.hdf5\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 5.6067 - acc: 0.8560 - val_loss: 6.3781 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00255: val_loss improved from 6.46344 to 6.37813, saving model to test.hdf5\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 5.4396 - acc: 0.8560 - val_loss: 6.2885 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00256: val_loss improved from 6.37813 to 6.28846, saving model to test.hdf5\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 5.4222 - acc: 0.8360 - val_loss: 5.9809 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00257: val_loss improved from 6.28846 to 5.98088, saving model to test.hdf5\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 5.1081 - acc: 0.8600 - val_loss: 6.0824 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 5.98088\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 5.0335 - acc: 0.8920 - val_loss: 5.6754 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00259: val_loss improved from 5.98088 to 5.67542, saving model to test.hdf5\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 4.8245 - acc: 0.8400 - val_loss: 5.8281 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 5.67542\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 5.0204 - acc: 0.8480 - val_loss: 5.3624 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00261: val_loss improved from 5.67542 to 5.36241, saving model to test.hdf5\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 4.8382 - acc: 0.8280 - val_loss: 5.2222 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00262: val_loss improved from 5.36241 to 5.22223, saving model to test.hdf5\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 4.4965 - acc: 0.8440 - val_loss: 5.1345 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00263: val_loss improved from 5.22223 to 5.13446, saving model to test.hdf5\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 4.4075 - acc: 0.8520 - val_loss: 4.9977 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00264: val_loss improved from 5.13446 to 4.99771, saving model to test.hdf5\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 4.1971 - acc: 0.8240 - val_loss: 5.0176 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 4.99771\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 4.4495 - acc: 0.8600 - val_loss: 4.8916 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00266: val_loss improved from 4.99771 to 4.89158, saving model to test.hdf5\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 4.1767 - acc: 0.8560 - val_loss: 4.7097 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00267: val_loss improved from 4.89158 to 4.70970, saving model to test.hdf5\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 4.1159 - acc: 0.8240 - val_loss: 4.5735 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00268: val_loss improved from 4.70970 to 4.57350, saving model to test.hdf5\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 4.2203 - acc: 0.8560 - val_loss: 4.4362 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00269: val_loss improved from 4.57350 to 4.43616, saving model to test.hdf5\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.8981 - acc: 0.8400 - val_loss: 4.5421 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 4.43616\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 3.7330 - acc: 0.8480 - val_loss: 4.1659 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00271: val_loss improved from 4.43616 to 4.16586, saving model to test.hdf5\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.7330 - acc: 0.8480 - val_loss: 4.0680 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00272: val_loss improved from 4.16586 to 4.06799, saving model to test.hdf5\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.6189 - acc: 0.8320 - val_loss: 3.9111 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00273: val_loss improved from 4.06799 to 3.91112, saving model to test.hdf5\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.4558 - acc: 0.8840 - val_loss: 3.9060 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00274: val_loss improved from 3.91112 to 3.90599, saving model to test.hdf5\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.5314 - acc: 0.8640 - val_loss: 3.6409 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00275: val_loss improved from 3.90599 to 3.64090, saving model to test.hdf5\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.1988 - acc: 0.8560 - val_loss: 3.5847 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00276: val_loss improved from 3.64090 to 3.58466, saving model to test.hdf5\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 3.0810 - acc: 0.8480 - val_loss: 4.0370 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 3.58466\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.3995 - acc: 0.8120 - val_loss: 3.4522 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00278: val_loss improved from 3.58466 to 3.45222, saving model to test.hdf5\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.9841 - acc: 0.8520 - val_loss: 3.2259 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00279: val_loss improved from 3.45222 to 3.22591, saving model to test.hdf5\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.0914 - acc: 0.8440 - val_loss: 3.4616 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 3.22591\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.4679 - acc: 0.8400 - val_loss: 3.8761 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 3.22591\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.2730 - acc: 0.8280 - val_loss: 3.1842 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00282: val_loss improved from 3.22591 to 3.18423, saving model to test.hdf5\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.7206 - acc: 0.8480 - val_loss: 3.2111 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 3.18423\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.0843 - acc: 0.8520 - val_loss: 3.0607 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00284: val_loss improved from 3.18423 to 3.06072, saving model to test.hdf5\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.7287 - acc: 0.8320 - val_loss: 3.1080 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 3.06072\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 3.3672 - acc: 0.8480 - val_loss: 2.9509 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00286: val_loss improved from 3.06072 to 2.95088, saving model to test.hdf5\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 2.5162 - acc: 0.8760 - val_loss: 2.7816 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00287: val_loss improved from 2.95088 to 2.78155, saving model to test.hdf5\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.7149 - acc: 0.8080 - val_loss: 2.7690 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00288: val_loss improved from 2.78155 to 2.76903, saving model to test.hdf5\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.7816 - acc: 0.8280 - val_loss: 2.7707 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.76903\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.6559 - acc: 0.8360 - val_loss: 2.4925 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00290: val_loss improved from 2.76903 to 2.49249, saving model to test.hdf5\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 2.7741 - acc: 0.8400 - val_loss: 2.6210 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.49249\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 2.4676 - acc: 0.8400 - val_loss: 2.4173 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00292: val_loss improved from 2.49249 to 2.41726, saving model to test.hdf5\n",
      "Epoch 293/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 259us/step - loss: 2.7703 - acc: 0.8480 - val_loss: 2.8360 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.41726\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 2.3989 - acc: 0.8360 - val_loss: 2.8391 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.41726\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 2.5822 - acc: 0.8520 - val_loss: 2.2062 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00295: val_loss improved from 2.41726 to 2.20620, saving model to test.hdf5\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 2.4638 - acc: 0.8360 - val_loss: 2.3634 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.20620\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 267us/step - loss: 3.2041 - acc: 0.8280 - val_loss: 2.2031 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00297: val_loss improved from 2.20620 to 2.20306, saving model to test.hdf5\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 2.6162 - acc: 0.8400 - val_loss: 2.2584 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.20306\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 2.2728 - acc: 0.8120 - val_loss: 2.0494 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00299: val_loss improved from 2.20306 to 2.04943, saving model to test.hdf5\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 2.3575 - acc: 0.8160 - val_loss: 2.2864 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.04943\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 2.4568 - acc: 0.8160 - val_loss: 1.9262 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00301: val_loss improved from 2.04943 to 1.92619, saving model to test.hdf5\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 2.1703 - acc: 0.8360 - val_loss: 2.7073 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1.92619\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 1.9031 - acc: 0.8200 - val_loss: 2.2149 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00303: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1.92619\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 3.1019 - acc: 0.8240 - val_loss: 1.7951 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00304: val_loss improved from 1.92619 to 1.79509, saving model to test.hdf5\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 1.7529 - acc: 0.8440 - val_loss: 1.6794 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00305: val_loss improved from 1.79509 to 1.67937, saving model to test.hdf5\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 1.6222 - acc: 0.8560 - val_loss: 1.7320 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 1.67937\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.8961 - acc: 0.8520 - val_loss: 1.9934 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 1.67937\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 1.7968 - acc: 0.8080 - val_loss: 1.7455 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 1.67937\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.8080 - acc: 0.8200 - val_loss: 1.6227 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00309: val_loss improved from 1.67937 to 1.62271, saving model to test.hdf5\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 271us/step - loss: 1.9305 - acc: 0.8160 - val_loss: 2.1827 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 1.62271\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 1.7671 - acc: 0.8240 - val_loss: 1.4799 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00311: val_loss improved from 1.62271 to 1.47991, saving model to test.hdf5\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 1.5856 - acc: 0.8080 - val_loss: 1.8084 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1.47991\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 1.7433 - acc: 0.8440 - val_loss: 1.4858 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1.47991\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.5557 - acc: 0.8440 - val_loss: 1.5684 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 1.47991\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 1.7956 - acc: 0.8680 - val_loss: 1.6745 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 1.47991\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 275us/step - loss: 1.8862 - acc: 0.8240 - val_loss: 1.8381 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1.47991\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.6248 - acc: 0.8360 - val_loss: 1.3698 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00317: val_loss improved from 1.47991 to 1.36978, saving model to test.hdf5\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 1.5346 - acc: 0.8240 - val_loss: 1.6629 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1.36978\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 3.0180 - acc: 0.8360 - val_loss: 1.3961 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1.36978\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 1.6590 - acc: 0.8120 - val_loss: 2.4721 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1.36978\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 2.3168 - acc: 0.7760 - val_loss: 1.9354 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.36978\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.9940 - acc: 0.8520 - val_loss: 1.4292 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1.36978\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 279us/step - loss: 1.9399 - acc: 0.8600 - val_loss: 2.1793 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.36978\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 271us/step - loss: 1.8608 - acc: 0.8280 - val_loss: 1.6137 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1.36978\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 1.7308 - acc: 0.7960 - val_loss: 1.4148 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1.36978\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 1.8521 - acc: 0.7880 - val_loss: 1.2135 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00326: val_loss improved from 1.36978 to 1.21352, saving model to test.hdf5\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.7228 - acc: 0.8280 - val_loss: 1.4944 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1.21352\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.5730 - acc: 0.8280 - val_loss: 1.2836 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.21352\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5715 - acc: 0.8360 - val_loss: 1.0186 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00329: val_loss improved from 1.21352 to 1.01859, saving model to test.hdf5\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.5808 - acc: 0.7800 - val_loss: 1.1934 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.01859\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.0188 - acc: 0.7880 - val_loss: 1.1785 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1.01859\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.4401 - acc: 0.8200 - val_loss: 2.0270 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1.01859\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7212 - acc: 0.8360 - val_loss: 1.0376 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1.01859\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.3880 - acc: 0.8280 - val_loss: 1.4741 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.01859\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.3592 - acc: 0.8160 - val_loss: 1.3495 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 1.01859\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.4989 - acc: 0.8280 - val_loss: 1.0320 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.01859\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 1.4933 - acc: 0.8440 - val_loss: 0.9597 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00337: val_loss improved from 1.01859 to 0.95968, saving model to test.hdf5\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.5165 - acc: 0.8120 - val_loss: 1.0467 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.95968\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.0106 - acc: 0.8360 - val_loss: 0.9963 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.95968\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.7412 - acc: 0.8200 - val_loss: 1.3747 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.95968\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 5.8578 - acc: 0.7960 - val_loss: 1.9750 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.95968\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.9936 - acc: 0.8360 - val_loss: 1.2887 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.95968\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.8778 - acc: 0.8080 - val_loss: 2.0637 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.95968\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6071 - acc: 0.8120 - val_loss: 1.4782 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.95968\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9610 - acc: 0.8120 - val_loss: 0.9240 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.95968 to 0.92400, saving model to test.hdf5\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.5127 - acc: 0.8400 - val_loss: 0.9567 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.92400\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 2.1736 - acc: 0.7840 - val_loss: 1.3188 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.92400\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.6082 - acc: 0.8200 - val_loss: 2.1505 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.92400\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.5662 - acc: 0.7800 - val_loss: 1.2809 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.92400\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.4383 - acc: 0.8440 - val_loss: 1.4563 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.92400\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.3039 - acc: 0.7920 - val_loss: 1.1317 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.92400\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.4834 - acc: 0.7960 - val_loss: 1.1805 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.92400\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 4.3498 - acc: 0.7520 - val_loss: 1.1642 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.92400\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5895 - acc: 0.8200 - val_loss: 0.8537 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.92400 to 0.85366, saving model to test.hdf5\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9656 - acc: 0.7960 - val_loss: 0.9873 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.85366\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.7515 - acc: 0.7840 - val_loss: 0.8979 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.85366\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.6190 - acc: 0.7480 - val_loss: 1.4040 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.85366\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.8089 - acc: 0.8160 - val_loss: 1.9104 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.85366\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 5.4305 - acc: 0.7840 - val_loss: 0.9350 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.85366\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.0195 - acc: 0.8360 - val_loss: 1.0002 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.85366\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.8533 - acc: 0.8000 - val_loss: 1.1749 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.85366\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 1.6800 - acc: 0.7960 - val_loss: 0.8478 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.85366 to 0.84776, saving model to test.hdf5\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.3351 - acc: 0.8160 - val_loss: 0.8709 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.84776\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5705 - acc: 0.7880 - val_loss: 0.9157 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.84776\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.5972 - acc: 0.8040 - val_loss: 1.0854 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.84776\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.6437 - acc: 0.8120 - val_loss: 1.4429 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.84776\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.0279 - acc: 0.7680 - val_loss: 1.0716 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.84776\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.7372 - acc: 0.8320 - val_loss: 0.7188 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.84776 to 0.71877, saving model to test.hdf5\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.3822 - acc: 0.8040 - val_loss: 0.9533 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.71877\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 7.6051 - acc: 0.7920 - val_loss: 1.1666 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.71877\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.3494 - acc: 0.7920 - val_loss: 0.7979 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.71877\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.8689 - acc: 0.7800 - val_loss: 1.2346 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.71877\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.8768 - acc: 0.7960 - val_loss: 0.7391 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.71877\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.7464 - acc: 0.8120 - val_loss: 2.1856 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.71877\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.1656 - acc: 0.8160 - val_loss: 0.8927 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.71877\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.8107 - acc: 0.8240 - val_loss: 2.2213 - val_acc: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00376: val_loss did not improve from 0.71877\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.0977 - acc: 0.8120 - val_loss: 1.7513 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.71877\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 4.5244 - acc: 0.7760 - val_loss: 1.4615 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.71877\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.1216 - acc: 0.8000 - val_loss: 1.7588 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00379: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.71877\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5132 - acc: 0.7880 - val_loss: 1.8818 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.71877\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7283 - acc: 0.8120 - val_loss: 0.6940 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.71877 to 0.69398, saving model to test.hdf5\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.6356 - acc: 0.7520 - val_loss: 0.7586 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.69398\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.6117 - acc: 0.7920 - val_loss: 0.9582 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.69398\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.4764 - acc: 0.7920 - val_loss: 0.6774 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.69398 to 0.67736, saving model to test.hdf5\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.2628 - acc: 0.8080 - val_loss: 0.6651 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.67736 to 0.66511, saving model to test.hdf5\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.9910 - acc: 0.7800 - val_loss: 0.6567 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00386: val_loss improved from 0.66511 to 0.65666, saving model to test.hdf5\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.3403 - acc: 0.7880 - val_loss: 1.1844 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.65666\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.8492 - acc: 0.7960 - val_loss: 0.9122 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.65666\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.2366 - acc: 0.8240 - val_loss: 1.6237 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.65666\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9454 - acc: 0.7920 - val_loss: 1.0815 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.65666\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6953 - acc: 0.8080 - val_loss: 0.7682 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.65666\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.6861 - acc: 0.8280 - val_loss: 0.7997 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.65666\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.7914 - acc: 0.7800 - val_loss: 0.8477 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.65666\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.1308 - acc: 0.7840 - val_loss: 1.1959 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.65666\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7129 - acc: 0.8160 - val_loss: 0.9048 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.65666\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.4691 - acc: 0.8040 - val_loss: 0.7584 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.65666\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5107 - acc: 0.8080 - val_loss: 0.7770 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.65666\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.2581 - acc: 0.8120 - val_loss: 0.9897 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.65666\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.5525 - acc: 0.7960 - val_loss: 0.9694 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.65666\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.7686 - acc: 0.7920 - val_loss: 0.7517 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.65666\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.7956 - acc: 0.7920 - val_loss: 0.7766 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.65666\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.8836 - acc: 0.7920 - val_loss: 0.9841 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.65666\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.8450 - acc: 0.7800 - val_loss: 0.6095 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.65666 to 0.60947, saving model to test.hdf5\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.0684 - acc: 0.7760 - val_loss: 1.0612 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.60947\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 4.9635 - acc: 0.7920 - val_loss: 1.0126 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.60947\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6567 - acc: 0.7760 - val_loss: 1.5150 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.60947\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9208 - acc: 0.7720 - val_loss: 0.7980 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.60947\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 3.9614 - acc: 0.7960 - val_loss: 0.8645 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.60947\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5289 - acc: 0.8160 - val_loss: 1.1387 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.60947\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.8873 - acc: 0.7880 - val_loss: 1.7028 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.60947\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.6377 - acc: 0.8160 - val_loss: 0.8813 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.60947\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.3566 - acc: 0.7960 - val_loss: 3.8278 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.60947\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 3.6866 - acc: 0.8000 - val_loss: 1.2638 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.60947\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.6481 - acc: 0.7920 - val_loss: 0.9900 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.60947\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7273 - acc: 0.8160 - val_loss: 1.3616 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.60947\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.0556 - acc: 0.7840 - val_loss: 0.7479 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.60947\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.8327 - acc: 0.8160 - val_loss: 1.1067 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.60947\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 1.6649 - acc: 0.8000 - val_loss: 1.4865 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.60947\n",
      "Epoch 419/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 227us/step - loss: 1.9397 - acc: 0.7640 - val_loss: 0.8176 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.60947\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.3745 - acc: 0.8120 - val_loss: 0.7991 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.60947\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 3.1223 - acc: 0.7920 - val_loss: 1.2316 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.60947\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 295us/step - loss: 2.1323 - acc: 0.7600 - val_loss: 4.7852 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.60947\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 287us/step - loss: 3.6966 - acc: 0.7920 - val_loss: 0.8580 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.60947\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 2.4292 - acc: 0.7840 - val_loss: 1.7944 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.60947\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 4.8228 - acc: 0.8080 - val_loss: 0.9517 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.60947\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 1.8760 - acc: 0.7960 - val_loss: 0.7302 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.60947\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 5.6202 - acc: 0.8160 - val_loss: 1.6116 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.60947\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9080 - acc: 0.7560 - val_loss: 0.7208 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.60947\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9885 - acc: 0.7920 - val_loss: 0.8821 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00429: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.60947\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.3518 - acc: 0.8120 - val_loss: 0.6213 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.60947\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.7693 - acc: 0.7840 - val_loss: 0.6577 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.60947\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.1734 - acc: 0.8040 - val_loss: 1.2407 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.60947\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.7914 - acc: 0.7960 - val_loss: 1.5450 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.60947\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.0528 - acc: 0.7720 - val_loss: 0.8856 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.60947\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.6384 - acc: 0.8200 - val_loss: 0.7381 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.60947\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.4696 - acc: 0.7800 - val_loss: 1.6135 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.60947\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.5178 - acc: 0.8080 - val_loss: 0.6499 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.60947\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.3520 - acc: 0.8240 - val_loss: 0.6252 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.60947\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.6316 - acc: 0.7520 - val_loss: 1.4825 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.60947\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.3126 - acc: 0.8120 - val_loss: 0.8778 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.60947\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.1554 - acc: 0.8240 - val_loss: 0.7683 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.60947\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.4112 - acc: 0.8440 - val_loss: 1.2008 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.60947\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.7743 - acc: 0.7880 - val_loss: 1.1770 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.60947\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7505 - acc: 0.8000 - val_loss: 0.6392 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.60947\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.0149 - acc: 0.8280 - val_loss: 0.6365 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.60947\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.4927 - acc: 0.7800 - val_loss: 1.4847 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.60947\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.7608 - acc: 0.8160 - val_loss: 2.5502 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.60947\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.5209 - acc: 0.8200 - val_loss: 0.6817 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.60947\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 1.6105 - acc: 0.8120 - val_loss: 0.9041 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.60947\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 2.0927 - acc: 0.8320 - val_loss: 1.0272 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.60947\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 2.2662 - acc: 0.8120 - val_loss: 0.9522 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.60947\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.4557 - acc: 0.8040 - val_loss: 0.9566 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.60947\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.7531 - acc: 0.8160 - val_loss: 0.7130 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.60947\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5180 - acc: 0.8400 - val_loss: 1.3625 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.60947\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5544 - acc: 0.8160 - val_loss: 0.6234 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.60947\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.3568 - acc: 0.8080 - val_loss: 0.7440 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.60947\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.9314 - acc: 0.7840 - val_loss: 0.8292 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.60947\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.4457 - acc: 0.8440 - val_loss: 0.7357 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.60947\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.7605 - acc: 0.7600 - val_loss: 0.7667 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.60947\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 1.9217 - acc: 0.8120 - val_loss: 0.5775 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.60947 to 0.57752, saving model to test.hdf5\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.8882 - acc: 0.7760 - val_loss: 1.5642 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.57752\n",
      "Epoch 462/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 211us/step - loss: 5.2770 - acc: 0.7720 - val_loss: 0.8790 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.57752\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.8025 - acc: 0.7720 - val_loss: 0.9110 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.57752\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.0408 - acc: 0.7640 - val_loss: 0.6939 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.57752\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.3732 - acc: 0.8040 - val_loss: 0.9013 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.57752\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.9752 - acc: 0.7800 - val_loss: 0.9379 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.57752\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.8352 - acc: 0.7800 - val_loss: 0.7347 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.57752\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.8325 - acc: 0.7360 - val_loss: 0.9639 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.57752\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.3919 - acc: 0.7920 - val_loss: 1.1080 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.57752\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.8484 - acc: 0.7840 - val_loss: 0.8091 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.57752\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.7384 - acc: 0.7960 - val_loss: 1.2619 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.57752\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.3232 - acc: 0.7840 - val_loss: 0.8876 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.57752\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.3191 - acc: 0.7840 - val_loss: 0.9770 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.57752\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 2.1012 - acc: 0.8120 - val_loss: 1.2405 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.57752\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 7.4571 - acc: 0.7480 - val_loss: 0.9711 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.57752\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.3268 - acc: 0.7840 - val_loss: 1.0860 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.57752\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.7512 - acc: 0.7800 - val_loss: 1.6592 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.57752\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 1.7158 - acc: 0.7880 - val_loss: 1.5188 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.57752\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.2022 - acc: 0.7800 - val_loss: 0.7149 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00479: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.57752\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 1.2110 - acc: 0.8000 - val_loss: 1.0514 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.57752\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.3684 - acc: 0.8080 - val_loss: 0.8380 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.57752\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.8245 - acc: 0.7960 - val_loss: 0.9416 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.57752\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.2703 - acc: 0.7960 - val_loss: 1.0801 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.57752\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.2735 - acc: 0.7960 - val_loss: 0.6766 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.57752\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.4856 - acc: 0.7840 - val_loss: 1.2127 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.57752\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.2939 - acc: 0.7920 - val_loss: 0.8469 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.57752\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5106 - acc: 0.8080 - val_loss: 1.0197 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.57752\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.4251 - acc: 0.8040 - val_loss: 0.8852 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.57752\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.9897 - acc: 0.8120 - val_loss: 1.1339 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.57752\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 6.4756 - acc: 0.7840 - val_loss: 1.2058 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.57752\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 3.4031 - acc: 0.7680 - val_loss: 1.2639 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.57752\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.7341 - acc: 0.7840 - val_loss: 0.7185 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.57752\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.1227 - acc: 0.8200 - val_loss: 0.6298 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.57752\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.6998 - acc: 0.7840 - val_loss: 0.7160 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.57752\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.3425 - acc: 0.7880 - val_loss: 0.8063 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.57752\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.4096 - acc: 0.8040 - val_loss: 1.0621 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.57752\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 3.6877 - acc: 0.7640 - val_loss: 1.0519 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.57752\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6390 - acc: 0.8440 - val_loss: 0.8191 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.57752\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5505 - acc: 0.8160 - val_loss: 0.8617 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.57752\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.7798 - acc: 0.8160 - val_loss: 0.8090 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.57752\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.3694 - acc: 0.8080 - val_loss: 0.8422 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.57752\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.8805 - acc: 0.7920 - val_loss: 0.8435 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.57752\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 1.3047 - acc: 0.8160 - val_loss: 0.8318 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.57752\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.8595 - acc: 0.8000 - val_loss: 0.8975 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.57752\n",
      "Epoch 505/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 227us/step - loss: 1.3124 - acc: 0.7880 - val_loss: 0.8431 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.57752\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.3166 - acc: 0.7480 - val_loss: 1.0048 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.57752\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.9261 - acc: 0.8120 - val_loss: 0.8257 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.57752\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.3596 - acc: 0.7880 - val_loss: 1.2960 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.57752\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.5218 - acc: 0.8080 - val_loss: 0.7545 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.57752\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 2.2690 - acc: 0.7720 - val_loss: 1.3837 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.57752\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6050 - acc: 0.8040 - val_loss: 1.0084 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.57752\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.4609 - acc: 0.8240 - val_loss: 1.1558 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.57752\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6574 - acc: 0.7840 - val_loss: 2.0096 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.57752\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.4640 - acc: 0.7920 - val_loss: 0.6614 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.57752\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 2.4205 - acc: 0.7920 - val_loss: 1.0465 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.57752\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.2229 - acc: 0.8080 - val_loss: 0.6596 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.57752\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.6144 - acc: 0.8240 - val_loss: 0.7800 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.57752\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.5384 - acc: 0.7920 - val_loss: 1.6221 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.57752\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.5989 - acc: 0.7720 - val_loss: 0.7958 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.57752\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.7523 - acc: 0.7840 - val_loss: 0.9591 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.57752\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6245 - acc: 0.7840 - val_loss: 0.7987 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.57752\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5053 - acc: 0.7720 - val_loss: 0.7842 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.57752\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.5983 - acc: 0.8200 - val_loss: 1.5521 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.57752\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.0129 - acc: 0.8120 - val_loss: 0.8969 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.57752\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 2.1420 - acc: 0.7960 - val_loss: 0.7846 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.57752\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.9948 - acc: 0.8040 - val_loss: 1.8437 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.57752\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 3.7715 - acc: 0.8080 - val_loss: 2.0394 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.57752\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 3.4446 - acc: 0.7520 - val_loss: 0.7542 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.57752\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.7720 - acc: 0.7880 - val_loss: 0.7074 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00529: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.57752\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.2147 - acc: 0.7960 - val_loss: 1.1569 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.57752\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.6629 - acc: 0.8000 - val_loss: 1.0977 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.57752\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.0211 - acc: 0.8280 - val_loss: 0.8114 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.57752\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.6722 - acc: 0.8160 - val_loss: 0.6591 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.57752\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.6896 - acc: 0.7680 - val_loss: 0.7921 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.57752\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.6508 - acc: 0.7960 - val_loss: 1.4872 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.57752\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.4246 - acc: 0.8200 - val_loss: 0.6415 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.57752\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.9964 - acc: 0.7560 - val_loss: 0.6000 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.57752\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.7958 - acc: 0.7560 - val_loss: 1.2400 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.57752\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.3252 - acc: 0.8040 - val_loss: 0.6569 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.57752\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 219us/step - loss: 1.5097 - acc: 0.8000 - val_loss: 1.1313 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.57752\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.3675 - acc: 0.7800 - val_loss: 0.7627 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.57752\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.2468 - acc: 0.8240 - val_loss: 0.7187 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.57752\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.5795 - acc: 0.7840 - val_loss: 0.8719 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.57752\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 1.8312 - acc: 0.8040 - val_loss: 1.9131 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.57752\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.7932 - acc: 0.7920 - val_loss: 0.9357 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.57752\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 1.4764 - acc: 0.8000 - val_loss: 0.6382 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.57752\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 1.9038 - acc: 0.7680 - val_loss: 0.8253 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.57752\n",
      "Epoch 548/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 255us/step - loss: 1.4055 - acc: 0.7840 - val_loss: 0.8115 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.57752\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.2641 - acc: 0.7960 - val_loss: 0.6914 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.57752\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 1.2897 - acc: 0.8080 - val_loss: 1.0560 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.57752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f416226d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f1c353f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 5 добавили batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 156246.5394 - acc: 0.7920 - val_loss: 55269.3090 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 55269.30901, saving model to test.hdf5\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 80826.9934 - acc: 0.8080 - val_loss: 35115.2372 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00002: val_loss improved from 55269.30901 to 35115.23717, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 44922.0451 - acc: 0.8320 - val_loss: 23809.9027 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00003: val_loss improved from 35115.23717 to 23809.90273, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 28654.7505 - acc: 0.8440 - val_loss: 17392.1666 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from 23809.90273 to 17392.16657, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 20775.0473 - acc: 0.8400 - val_loss: 13534.0719 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00005: val_loss improved from 17392.16657 to 13534.07190, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 16585.9928 - acc: 0.8720 - val_loss: 10932.9481 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00006: val_loss improved from 13534.07190 to 10932.94805, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 13853.5915 - acc: 0.9080 - val_loss: 9174.4043 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00007: val_loss improved from 10932.94805 to 9174.40427, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 12171.5897 - acc: 0.9120 - val_loss: 7892.6942 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00008: val_loss improved from 9174.40427 to 7892.69421, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 10914.1269 - acc: 0.8520 - val_loss: 6918.9003 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00009: val_loss improved from 7892.69421 to 6918.90026, saving model to test.hdf5\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 9786.9662 - acc: 0.8920 - val_loss: 6161.9252 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00010: val_loss improved from 6918.90026 to 6161.92516, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 9028.9586 - acc: 0.8960 - val_loss: 5582.0213 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00011: val_loss improved from 6161.92516 to 5582.02129, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 8369.9281 - acc: 0.8840 - val_loss: 5069.0604 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00012: val_loss improved from 5582.02129 to 5069.06036, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 7864.9699 - acc: 0.8840 - val_loss: 4668.4612 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00013: val_loss improved from 5069.06036 to 4668.46117, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 7341.8081 - acc: 0.9200 - val_loss: 4312.3315 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00014: val_loss improved from 4668.46117 to 4312.33147, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 6992.6785 - acc: 0.9200 - val_loss: 4045.8897 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss improved from 4312.33147 to 4045.88974, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 6567.7541 - acc: 0.9360 - val_loss: 3829.5061 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00016: val_loss improved from 4045.88974 to 3829.50612, saving model to test.hdf5\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 6277.7647 - acc: 0.9320 - val_loss: 3655.4689 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00017: val_loss improved from 3829.50612 to 3655.46889, saving model to test.hdf5\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 5970.1671 - acc: 0.9280 - val_loss: 3439.9292 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00018: val_loss improved from 3655.46889 to 3439.92916, saving model to test.hdf5\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 5723.8462 - acc: 0.9440 - val_loss: 3302.3326 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00019: val_loss improved from 3439.92916 to 3302.33264, saving model to test.hdf5\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 5433.6336 - acc: 0.9120 - val_loss: 3125.3121 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00020: val_loss improved from 3302.33264 to 3125.31209, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 5230.1741 - acc: 0.9240 - val_loss: 3010.2967 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00021: val_loss improved from 3125.31209 to 3010.29672, saving model to test.hdf5\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 5072.2441 - acc: 0.9240 - val_loss: 2900.4852 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00022: val_loss improved from 3010.29672 to 2900.48521, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 4869.2020 - acc: 0.9000 - val_loss: 2779.5422 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00023: val_loss improved from 2900.48521 to 2779.54218, saving model to test.hdf5\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 4701.7980 - acc: 0.9200 - val_loss: 2693.5957 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00024: val_loss improved from 2779.54218 to 2693.59566, saving model to test.hdf5\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 4494.4783 - acc: 0.8960 - val_loss: 2592.9162 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00025: val_loss improved from 2693.59566 to 2592.91617, saving model to test.hdf5\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 4363.3086 - acc: 0.9000 - val_loss: 2510.6294 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00026: val_loss improved from 2592.91617 to 2510.62941, saving model to test.hdf5\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 4178.9595 - acc: 0.9360 - val_loss: 2420.1743 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00027: val_loss improved from 2510.62941 to 2420.17434, saving model to test.hdf5\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 4047.6914 - acc: 0.9120 - val_loss: 2349.8120 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00028: val_loss improved from 2420.17434 to 2349.81197, saving model to test.hdf5\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 3894.6354 - acc: 0.9360 - val_loss: 2280.0256 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00029: val_loss improved from 2349.81197 to 2280.02564, saving model to test.hdf5\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 3778.5609 - acc: 0.9320 - val_loss: 2217.9012 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00030: val_loss improved from 2280.02564 to 2217.90117, saving model to test.hdf5\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 3647.9823 - acc: 0.9320 - val_loss: 2149.1124 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00031: val_loss improved from 2217.90117 to 2149.11236, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 3552.7168 - acc: 0.9160 - val_loss: 2093.6986 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00032: val_loss improved from 2149.11236 to 2093.69857, saving model to test.hdf5\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 3410.2513 - acc: 0.9520 - val_loss: 2022.9658 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00033: val_loss improved from 2093.69857 to 2022.96577, saving model to test.hdf5\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 3323.1608 - acc: 0.9440 - val_loss: 1970.3171 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00034: val_loss improved from 2022.96577 to 1970.31709, saving model to test.hdf5\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 3221.3818 - acc: 0.9280 - val_loss: 1915.9265 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00035: val_loss improved from 1970.31709 to 1915.92654, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 3128.4706 - acc: 0.9320 - val_loss: 1856.0030 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00036: val_loss improved from 1915.92654 to 1856.00295, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 3036.6246 - acc: 0.9040 - val_loss: 1818.9050 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00037: val_loss improved from 1856.00295 to 1818.90500, saving model to test.hdf5\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 2968.2389 - acc: 0.9320 - val_loss: 1775.9153 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00038: val_loss improved from 1818.90500 to 1775.91529, saving model to test.hdf5\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 2856.8220 - acc: 0.9480 - val_loss: 1704.4789 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00039: val_loss improved from 1775.91529 to 1704.47886, saving model to test.hdf5\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 2746.5285 - acc: 0.9440 - val_loss: 1672.6528 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00040: val_loss improved from 1704.47886 to 1672.65284, saving model to test.hdf5\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 2690.1819 - acc: 0.9320 - val_loss: 1626.2423 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00041: val_loss improved from 1672.65284 to 1626.24231, saving model to test.hdf5\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 2595.1084 - acc: 0.9360 - val_loss: 1587.6252 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00042: val_loss improved from 1626.24231 to 1587.62520, saving model to test.hdf5\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 2559.6464 - acc: 0.9000 - val_loss: 1543.4245 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00043: val_loss improved from 1587.62520 to 1543.42449, saving model to test.hdf5\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 2479.7209 - acc: 0.9280 - val_loss: 1510.2826 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00044: val_loss improved from 1543.42449 to 1510.28261, saving model to test.hdf5\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 2376.7653 - acc: 0.9200 - val_loss: 1460.1361 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00045: val_loss improved from 1510.28261 to 1460.13612, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 2341.9777 - acc: 0.9480 - val_loss: 1429.5050 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00046: val_loss improved from 1460.13612 to 1429.50505, saving model to test.hdf5\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 2287.5451 - acc: 0.9480 - val_loss: 1390.4012 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00047: val_loss improved from 1429.50505 to 1390.40116, saving model to test.hdf5\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 2207.6159 - acc: 0.9320 - val_loss: 1362.2562 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00048: val_loss improved from 1390.40116 to 1362.25619, saving model to test.hdf5\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 2144.6500 - acc: 0.9320 - val_loss: 1321.9680 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00049: val_loss improved from 1362.25619 to 1321.96799, saving model to test.hdf5\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 2101.8329 - acc: 0.9560 - val_loss: 1290.2332 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00050: val_loss improved from 1321.96799 to 1290.23321, saving model to test.hdf5\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 2023.8091 - acc: 0.9120 - val_loss: 1258.1929 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00051: val_loss improved from 1290.23321 to 1258.19292, saving model to test.hdf5\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 1971.2686 - acc: 0.9320 - val_loss: 1222.7884 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00052: val_loss improved from 1258.19292 to 1222.78836, saving model to test.hdf5\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 1912.3941 - acc: 0.9240 - val_loss: 1186.4727 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00053: val_loss improved from 1222.78836 to 1186.47266, saving model to test.hdf5\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 1855.9900 - acc: 0.9560 - val_loss: 1164.4959 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00054: val_loss improved from 1186.47266 to 1164.49589, saving model to test.hdf5\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 1793.5690 - acc: 0.9360 - val_loss: 1126.5558 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00055: val_loss improved from 1164.49589 to 1126.55581, saving model to test.hdf5\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 1752.6824 - acc: 0.9520 - val_loss: 1107.3894 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00056: val_loss improved from 1126.55581 to 1107.38943, saving model to test.hdf5\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 1714.0646 - acc: 0.9360 - val_loss: 1079.0499 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00057: val_loss improved from 1107.38943 to 1079.04986, saving model to test.hdf5\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 1648.8292 - acc: 0.9080 - val_loss: 1049.6832 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00058: val_loss improved from 1079.04986 to 1049.68324, saving model to test.hdf5\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 146us/step - loss: 1617.2181 - acc: 0.9320 - val_loss: 1023.4533 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00059: val_loss improved from 1049.68324 to 1023.45330, saving model to test.hdf5\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 1560.7398 - acc: 0.9200 - val_loss: 996.0522 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00060: val_loss improved from 1023.45330 to 996.05220, saving model to test.hdf5\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 1529.8936 - acc: 0.9360 - val_loss: 973.4698 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00061: val_loss improved from 996.05220 to 973.46978, saving model to test.hdf5\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 1508.4315 - acc: 0.9280 - val_loss: 951.6653 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00062: val_loss improved from 973.46978 to 951.66525, saving model to test.hdf5\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 1435.6804 - acc: 0.9040 - val_loss: 930.7808 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00063: val_loss improved from 951.66525 to 930.78076, saving model to test.hdf5\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 1400.8453 - acc: 0.9560 - val_loss: 909.2722 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00064: val_loss improved from 930.78076 to 909.27216, saving model to test.hdf5\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 1370.6388 - acc: 0.9480 - val_loss: 880.3429 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00065: val_loss improved from 909.27216 to 880.34292, saving model to test.hdf5\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 1316.2110 - acc: 0.9280 - val_loss: 858.9701 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00066: val_loss improved from 880.34292 to 858.97011, saving model to test.hdf5\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 1295.8797 - acc: 0.9080 - val_loss: 836.2632 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00067: val_loss improved from 858.97011 to 836.26315, saving model to test.hdf5\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 1250.9109 - acc: 0.9120 - val_loss: 816.8628 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00068: val_loss improved from 836.26315 to 816.86285, saving model to test.hdf5\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 1221.3888 - acc: 0.9320 - val_loss: 801.5784 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00069: val_loss improved from 816.86285 to 801.57839, saving model to test.hdf5\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 1193.2316 - acc: 0.9160 - val_loss: 781.6909 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00070: val_loss improved from 801.57839 to 781.69094, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 1157.9108 - acc: 0.9200 - val_loss: 759.1124 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00071: val_loss improved from 781.69094 to 759.11237, saving model to test.hdf5\n",
      "Epoch 72/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 155us/step - loss: 1123.1473 - acc: 0.9320 - val_loss: 736.3109 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00072: val_loss improved from 759.11237 to 736.31086, saving model to test.hdf5\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 168us/step - loss: 1091.1041 - acc: 0.9160 - val_loss: 720.4715 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00073: val_loss improved from 736.31086 to 720.47147, saving model to test.hdf5\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 1054.0055 - acc: 0.9240 - val_loss: 699.1894 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00074: val_loss improved from 720.47147 to 699.18943, saving model to test.hdf5\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 1032.9861 - acc: 0.9240 - val_loss: 683.9057 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00075: val_loss improved from 699.18943 to 683.90570, saving model to test.hdf5\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 994.0536 - acc: 0.9320 - val_loss: 669.2091 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00076: val_loss improved from 683.90570 to 669.20908, saving model to test.hdf5\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 966.5421 - acc: 0.9400 - val_loss: 656.0063 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00077: val_loss improved from 669.20908 to 656.00632, saving model to test.hdf5\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 942.9486 - acc: 0.9520 - val_loss: 645.0103 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00078: val_loss improved from 656.00632 to 645.01035, saving model to test.hdf5\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 923.9940 - acc: 0.9240 - val_loss: 620.2500 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00079: val_loss improved from 645.01035 to 620.25004, saving model to test.hdf5\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 897.0707 - acc: 0.9360 - val_loss: 608.5195 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00080: val_loss improved from 620.25004 to 608.51952, saving model to test.hdf5\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 879.6691 - acc: 0.9520 - val_loss: 593.3593 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00081: val_loss improved from 608.51952 to 593.35931, saving model to test.hdf5\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 856.9473 - acc: 0.9360 - val_loss: 577.5459 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00082: val_loss improved from 593.35931 to 577.54588, saving model to test.hdf5\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 830.3328 - acc: 0.9120 - val_loss: 567.7178 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00083: val_loss improved from 577.54588 to 567.71779, saving model to test.hdf5\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 816.0707 - acc: 0.9240 - val_loss: 554.4495 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00084: val_loss improved from 567.71779 to 554.44948, saving model to test.hdf5\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 795.7512 - acc: 0.9320 - val_loss: 547.4132 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00085: val_loss improved from 554.44948 to 547.41323, saving model to test.hdf5\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 767.9907 - acc: 0.9360 - val_loss: 529.4204 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00086: val_loss improved from 547.41323 to 529.42037, saving model to test.hdf5\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 750.7542 - acc: 0.9280 - val_loss: 516.6632 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00087: val_loss improved from 529.42037 to 516.66324, saving model to test.hdf5\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 727.7647 - acc: 0.9520 - val_loss: 508.6102 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00088: val_loss improved from 516.66324 to 508.61019, saving model to test.hdf5\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 711.3635 - acc: 0.9600 - val_loss: 493.5129 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00089: val_loss improved from 508.61019 to 493.51291, saving model to test.hdf5\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 692.8846 - acc: 0.9640 - val_loss: 485.8454 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00090: val_loss improved from 493.51291 to 485.84538, saving model to test.hdf5\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 676.4551 - acc: 0.9320 - val_loss: 474.0685 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00091: val_loss improved from 485.84538 to 474.06854, saving model to test.hdf5\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 657.0288 - acc: 0.9440 - val_loss: 461.6759 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00092: val_loss improved from 474.06854 to 461.67587, saving model to test.hdf5\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 640.8288 - acc: 0.9560 - val_loss: 447.1575 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00093: val_loss improved from 461.67587 to 447.15751, saving model to test.hdf5\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 622.1317 - acc: 0.9600 - val_loss: 438.2833 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00094: val_loss improved from 447.15751 to 438.28330, saving model to test.hdf5\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 607.9662 - acc: 0.9280 - val_loss: 432.3466 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00095: val_loss improved from 438.28330 to 432.34665, saving model to test.hdf5\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 597.4783 - acc: 0.9280 - val_loss: 418.5293 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00096: val_loss improved from 432.34665 to 418.52935, saving model to test.hdf5\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 571.4773 - acc: 0.9400 - val_loss: 407.9036 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00097: val_loss improved from 418.52935 to 407.90361, saving model to test.hdf5\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 559.3733 - acc: 0.9240 - val_loss: 398.5755 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00098: val_loss improved from 407.90361 to 398.57551, saving model to test.hdf5\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 545.5682 - acc: 0.9240 - val_loss: 385.8237 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00099: val_loss improved from 398.57551 to 385.82368, saving model to test.hdf5\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 528.9501 - acc: 0.9200 - val_loss: 378.5258 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00100: val_loss improved from 385.82368 to 378.52582, saving model to test.hdf5\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 519.2438 - acc: 0.9360 - val_loss: 374.6879 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00101: val_loss improved from 378.52582 to 374.68790, saving model to test.hdf5\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 502.5933 - acc: 0.9520 - val_loss: 363.4571 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00102: val_loss improved from 374.68790 to 363.45712, saving model to test.hdf5\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 488.7826 - acc: 0.9400 - val_loss: 354.8013 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00103: val_loss improved from 363.45712 to 354.80129, saving model to test.hdf5\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 474.8169 - acc: 0.9320 - val_loss: 344.4316 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00104: val_loss improved from 354.80129 to 344.43157, saving model to test.hdf5\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 464.7493 - acc: 0.9480 - val_loss: 337.5718 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00105: val_loss improved from 344.43157 to 337.57181, saving model to test.hdf5\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 453.1136 - acc: 0.9280 - val_loss: 327.8835 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00106: val_loss improved from 337.57181 to 327.88351, saving model to test.hdf5\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 146us/step - loss: 439.6411 - acc: 0.9160 - val_loss: 324.9056 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00107: val_loss improved from 327.88351 to 324.90563, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 429.0010 - acc: 0.9600 - val_loss: 314.7873 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00108: val_loss improved from 324.90563 to 314.78729, saving model to test.hdf5\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 415.5760 - acc: 0.9320 - val_loss: 305.6519 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00109: val_loss improved from 314.78729 to 305.65187, saving model to test.hdf5\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 404.0382 - acc: 0.9480 - val_loss: 297.3708 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00110: val_loss improved from 305.65187 to 297.37084, saving model to test.hdf5\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 395.9379 - acc: 0.9320 - val_loss: 290.7747 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00111: val_loss improved from 297.37084 to 290.77472, saving model to test.hdf5\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 382.1654 - acc: 0.9360 - val_loss: 287.0815 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00112: val_loss improved from 290.77472 to 287.08153, saving model to test.hdf5\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 370.1682 - acc: 0.9240 - val_loss: 274.5714 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00113: val_loss improved from 287.08153 to 274.57140, saving model to test.hdf5\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 362.0227 - acc: 0.9240 - val_loss: 270.6724 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00114: val_loss improved from 274.57140 to 270.67237, saving model to test.hdf5\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 350.4968 - acc: 0.9440 - val_loss: 266.6808 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00115: val_loss improved from 270.67237 to 266.68085, saving model to test.hdf5\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 342.6152 - acc: 0.8960 - val_loss: 256.7297 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00116: val_loss improved from 266.68085 to 256.72970, saving model to test.hdf5\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 332.4731 - acc: 0.9520 - val_loss: 252.3376 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00117: val_loss improved from 256.72970 to 252.33758, saving model to test.hdf5\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 322.6025 - acc: 0.9440 - val_loss: 243.5572 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00118: val_loss improved from 252.33758 to 243.55720, saving model to test.hdf5\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 314.5821 - acc: 0.9160 - val_loss: 238.0100 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00119: val_loss improved from 243.55720 to 238.00996, saving model to test.hdf5\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 307.0540 - acc: 0.9320 - val_loss: 230.8681 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00120: val_loss improved from 238.00996 to 230.86814, saving model to test.hdf5\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 296.6145 - acc: 0.9320 - val_loss: 226.7649 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00121: val_loss improved from 230.86814 to 226.76489, saving model to test.hdf5\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 288.1996 - acc: 0.9120 - val_loss: 221.0380 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00122: val_loss improved from 226.76489 to 221.03802, saving model to test.hdf5\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 281.1443 - acc: 0.9280 - val_loss: 219.1403 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00123: val_loss improved from 221.03802 to 219.14035, saving model to test.hdf5\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 275.2341 - acc: 0.9200 - val_loss: 208.6783 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00124: val_loss improved from 219.14035 to 208.67831, saving model to test.hdf5\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 265.7741 - acc: 0.9240 - val_loss: 203.3193 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00125: val_loss improved from 208.67831 to 203.31926, saving model to test.hdf5\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 257.6153 - acc: 0.9520 - val_loss: 201.1646 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00126: val_loss improved from 203.31926 to 201.16457, saving model to test.hdf5\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 249.8827 - acc: 0.9520 - val_loss: 194.8219 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00127: val_loss improved from 201.16457 to 194.82194, saving model to test.hdf5\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 146us/step - loss: 243.4343 - acc: 0.9240 - val_loss: 192.9622 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00128: val_loss improved from 194.82194 to 192.96215, saving model to test.hdf5\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 238.6985 - acc: 0.9440 - val_loss: 186.9246 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00129: val_loss improved from 192.96215 to 186.92461, saving model to test.hdf5\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 233.1092 - acc: 0.9600 - val_loss: 181.5043 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00130: val_loss improved from 186.92461 to 181.50428, saving model to test.hdf5\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 224.2821 - acc: 0.9320 - val_loss: 177.2843 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00131: val_loss improved from 181.50428 to 177.28429, saving model to test.hdf5\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 221.2133 - acc: 0.9400 - val_loss: 174.4028 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00132: val_loss improved from 177.28429 to 174.40278, saving model to test.hdf5\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 213.8048 - acc: 0.9200 - val_loss: 169.3594 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00133: val_loss improved from 174.40278 to 169.35938, saving model to test.hdf5\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 209.2840 - acc: 0.9320 - val_loss: 165.0995 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00134: val_loss improved from 169.35938 to 165.09947, saving model to test.hdf5\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 202.3161 - acc: 0.9480 - val_loss: 160.9981 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00135: val_loss improved from 165.09947 to 160.99810, saving model to test.hdf5\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 197.8313 - acc: 0.9480 - val_loss: 157.8842 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00136: val_loss improved from 160.99810 to 157.88416, saving model to test.hdf5\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 194.1156 - acc: 0.9160 - val_loss: 154.4310 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00137: val_loss improved from 157.88416 to 154.43096, saving model to test.hdf5\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 188.3148 - acc: 0.9320 - val_loss: 151.3580 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00138: val_loss improved from 154.43096 to 151.35800, saving model to test.hdf5\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 180.5960 - acc: 0.9240 - val_loss: 146.6092 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00139: val_loss improved from 151.35800 to 146.60918, saving model to test.hdf5\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 177.8825 - acc: 0.9360 - val_loss: 143.2619 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00140: val_loss improved from 146.60918 to 143.26185, saving model to test.hdf5\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 173.5375 - acc: 0.9200 - val_loss: 140.1398 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00141: val_loss improved from 143.26185 to 140.13975, saving model to test.hdf5\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 169.5907 - acc: 0.9640 - val_loss: 137.4853 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00142: val_loss improved from 140.13975 to 137.48526, saving model to test.hdf5\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 164.9855 - acc: 0.9400 - val_loss: 134.3835 - val_acc: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00143: val_loss improved from 137.48526 to 134.38349, saving model to test.hdf5\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 160.4968 - acc: 0.9200 - val_loss: 130.2756 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00144: val_loss improved from 134.38349 to 130.27559, saving model to test.hdf5\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 154.1497 - acc: 0.9320 - val_loss: 127.5239 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00145: val_loss improved from 130.27559 to 127.52388, saving model to test.hdf5\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 152.7457 - acc: 0.9600 - val_loss: 124.1102 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00146: val_loss improved from 127.52388 to 124.11022, saving model to test.hdf5\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 146.6005 - acc: 0.9160 - val_loss: 122.9497 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00147: val_loss improved from 124.11022 to 122.94969, saving model to test.hdf5\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 143.1335 - acc: 0.9080 - val_loss: 118.4315 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00148: val_loss improved from 122.94969 to 118.43151, saving model to test.hdf5\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 138.9086 - acc: 0.8800 - val_loss: 114.9618 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00149: val_loss improved from 118.43151 to 114.96181, saving model to test.hdf5\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 135.7938 - acc: 0.9400 - val_loss: 112.5033 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00150: val_loss improved from 114.96181 to 112.50329, saving model to test.hdf5\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 131.2070 - acc: 0.9280 - val_loss: 108.6964 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00151: val_loss improved from 112.50329 to 108.69641, saving model to test.hdf5\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 128.9209 - acc: 0.9400 - val_loss: 106.2071 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00152: val_loss improved from 108.69641 to 106.20709, saving model to test.hdf5\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 124.9214 - acc: 0.9360 - val_loss: 104.5484 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00153: val_loss improved from 106.20709 to 104.54836, saving model to test.hdf5\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 121.4144 - acc: 0.9400 - val_loss: 101.4612 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00154: val_loss improved from 104.54836 to 101.46123, saving model to test.hdf5\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 117.7239 - acc: 0.9120 - val_loss: 100.3547 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00155: val_loss improved from 101.46123 to 100.35474, saving model to test.hdf5\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 116.0785 - acc: 0.9160 - val_loss: 96.2610 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00156: val_loss improved from 100.35474 to 96.26096, saving model to test.hdf5\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 112.4431 - acc: 0.9200 - val_loss: 94.3965 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00157: val_loss improved from 96.26096 to 94.39652, saving model to test.hdf5\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 108.6495 - acc: 0.9200 - val_loss: 92.0536 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00158: val_loss improved from 94.39652 to 92.05359, saving model to test.hdf5\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 105.7255 - acc: 0.9240 - val_loss: 89.3236 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00159: val_loss improved from 92.05359 to 89.32357, saving model to test.hdf5\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 101.9098 - acc: 0.9280 - val_loss: 87.5364 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00160: val_loss improved from 89.32357 to 87.53635, saving model to test.hdf5\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 98.9195 - acc: 0.9400 - val_loss: 86.1960 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00161: val_loss improved from 87.53635 to 86.19602, saving model to test.hdf5\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 96.8345 - acc: 0.9320 - val_loss: 84.5494 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00162: val_loss improved from 86.19602 to 84.54944, saving model to test.hdf5\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 94.4952 - acc: 0.9280 - val_loss: 81.2980 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00163: val_loss improved from 84.54944 to 81.29797, saving model to test.hdf5\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 92.1446 - acc: 0.9200 - val_loss: 79.7860 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00164: val_loss improved from 81.29797 to 79.78597, saving model to test.hdf5\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 89.4875 - acc: 0.8800 - val_loss: 76.5373 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00165: val_loss improved from 79.78597 to 76.53733, saving model to test.hdf5\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 86.6019 - acc: 0.9320 - val_loss: 75.7024 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00166: val_loss improved from 76.53733 to 75.70238, saving model to test.hdf5\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 83.5061 - acc: 0.9440 - val_loss: 73.2904 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00167: val_loss improved from 75.70238 to 73.29037, saving model to test.hdf5\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 81.7680 - acc: 0.9280 - val_loss: 71.2347 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00168: val_loss improved from 73.29037 to 71.23466, saving model to test.hdf5\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 78.5147 - acc: 0.9480 - val_loss: 69.6716 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00169: val_loss improved from 71.23466 to 69.67161, saving model to test.hdf5\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 76.7946 - acc: 0.9200 - val_loss: 67.9893 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00170: val_loss improved from 69.67161 to 67.98928, saving model to test.hdf5\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 74.5245 - acc: 0.9280 - val_loss: 66.4267 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00171: val_loss improved from 67.98928 to 66.42673, saving model to test.hdf5\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 72.7406 - acc: 0.9240 - val_loss: 64.0010 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00172: val_loss improved from 66.42673 to 64.00100, saving model to test.hdf5\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 70.5520 - acc: 0.9280 - val_loss: 62.7898 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00173: val_loss improved from 64.00100 to 62.78980, saving model to test.hdf5\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 68.9153 - acc: 0.9480 - val_loss: 60.8415 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00174: val_loss improved from 62.78980 to 60.84151, saving model to test.hdf5\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 65.7582 - acc: 0.9080 - val_loss: 59.2183 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00175: val_loss improved from 60.84151 to 59.21826, saving model to test.hdf5\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 64.5783 - acc: 0.9360 - val_loss: 57.9471 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00176: val_loss improved from 59.21826 to 57.94714, saving model to test.hdf5\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 62.7982 - acc: 0.9320 - val_loss: 57.0843 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00177: val_loss improved from 57.94714 to 57.08425, saving model to test.hdf5\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 60.6709 - acc: 0.9160 - val_loss: 55.3696 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00178: val_loss improved from 57.08425 to 55.36961, saving model to test.hdf5\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 59.2814 - acc: 0.9000 - val_loss: 54.6667 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00179: val_loss improved from 55.36961 to 54.66669, saving model to test.hdf5\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 57.0914 - acc: 0.9040 - val_loss: 53.5970 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00180: val_loss improved from 54.66669 to 53.59695, saving model to test.hdf5\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 56.0991 - acc: 0.9440 - val_loss: 52.5144 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00181: val_loss improved from 53.59695 to 52.51443, saving model to test.hdf5\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 55.3901 - acc: 0.9040 - val_loss: 50.1425 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00182: val_loss improved from 52.51443 to 50.14249, saving model to test.hdf5\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 53.1522 - acc: 0.9160 - val_loss: 49.2649 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00183: val_loss improved from 50.14249 to 49.26485, saving model to test.hdf5\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 52.6521 - acc: 0.9280 - val_loss: 48.0321 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00184: val_loss improved from 49.26485 to 48.03208, saving model to test.hdf5\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 49.9058 - acc: 0.9520 - val_loss: 47.3558 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00185: val_loss improved from 48.03208 to 47.35578, saving model to test.hdf5\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 49.6507 - acc: 0.9160 - val_loss: 45.7080 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00186: val_loss improved from 47.35578 to 45.70803, saving model to test.hdf5\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 48.0161 - acc: 0.8800 - val_loss: 44.8122 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00187: val_loss improved from 45.70803 to 44.81217, saving model to test.hdf5\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 46.8598 - acc: 0.8840 - val_loss: 43.9319 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00188: val_loss improved from 44.81217 to 43.93186, saving model to test.hdf5\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 44.7037 - acc: 0.9480 - val_loss: 43.1889 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00189: val_loss improved from 43.93186 to 43.18890, saving model to test.hdf5\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 44.1562 - acc: 0.9160 - val_loss: 41.1520 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00190: val_loss improved from 43.18890 to 41.15202, saving model to test.hdf5\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 42.7638 - acc: 0.9120 - val_loss: 40.2981 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00191: val_loss improved from 41.15202 to 40.29809, saving model to test.hdf5\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 41.7953 - acc: 0.9320 - val_loss: 39.9401 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00192: val_loss improved from 40.29809 to 39.94014, saving model to test.hdf5\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 40.1820 - acc: 0.9400 - val_loss: 38.5041 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00193: val_loss improved from 39.94014 to 38.50408, saving model to test.hdf5\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 39.5006 - acc: 0.9160 - val_loss: 37.5998 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00194: val_loss improved from 38.50408 to 37.59981, saving model to test.hdf5\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 38.6600 - acc: 0.8840 - val_loss: 36.7483 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00195: val_loss improved from 37.59981 to 36.74832, saving model to test.hdf5\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 37.6962 - acc: 0.9160 - val_loss: 35.3351 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00196: val_loss improved from 36.74832 to 35.33512, saving model to test.hdf5\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 36.2038 - acc: 0.9080 - val_loss: 34.8209 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00197: val_loss improved from 35.33512 to 34.82093, saving model to test.hdf5\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 35.3304 - acc: 0.9160 - val_loss: 33.9418 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00198: val_loss improved from 34.82093 to 33.94182, saving model to test.hdf5\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 34.2857 - acc: 0.8600 - val_loss: 34.0079 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 33.94182\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 33.5138 - acc: 0.8800 - val_loss: 32.9001 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00200: val_loss improved from 33.94182 to 32.90009, saving model to test.hdf5\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 32.6208 - acc: 0.8960 - val_loss: 31.1783 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00201: val_loss improved from 32.90009 to 31.17830, saving model to test.hdf5\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 31.8817 - acc: 0.8960 - val_loss: 30.4952 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00202: val_loss improved from 31.17830 to 30.49516, saving model to test.hdf5\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 30.4377 - acc: 0.9040 - val_loss: 29.9287 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00203: val_loss improved from 30.49516 to 29.92865, saving model to test.hdf5\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 29.7181 - acc: 0.8960 - val_loss: 29.0546 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00204: val_loss improved from 29.92865 to 29.05462, saving model to test.hdf5\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 28.9997 - acc: 0.9280 - val_loss: 28.3858 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00205: val_loss improved from 29.05462 to 28.38585, saving model to test.hdf5\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 27.7881 - acc: 0.9080 - val_loss: 27.5409 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00206: val_loss improved from 28.38585 to 27.54092, saving model to test.hdf5\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 27.1458 - acc: 0.9040 - val_loss: 27.1373 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00207: val_loss improved from 27.54092 to 27.13726, saving model to test.hdf5\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 26.9695 - acc: 0.8920 - val_loss: 26.6636 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00208: val_loss improved from 27.13726 to 26.66360, saving model to test.hdf5\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 25.5736 - acc: 0.9040 - val_loss: 26.0784 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00209: val_loss improved from 26.66360 to 26.07838, saving model to test.hdf5\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 25.2400 - acc: 0.9200 - val_loss: 24.9841 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00210: val_loss improved from 26.07838 to 24.98410, saving model to test.hdf5\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 24.2141 - acc: 0.9240 - val_loss: 24.1858 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00211: val_loss improved from 24.98410 to 24.18581, saving model to test.hdf5\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 23.9583 - acc: 0.9000 - val_loss: 24.8744 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 24.18581\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 23.5302 - acc: 0.8800 - val_loss: 23.2195 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00213: val_loss improved from 24.18581 to 23.21955, saving model to test.hdf5\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 22.1923 - acc: 0.8960 - val_loss: 22.5844 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00214: val_loss improved from 23.21955 to 22.58445, saving model to test.hdf5\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 22.1229 - acc: 0.8880 - val_loss: 21.9594 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00215: val_loss improved from 22.58445 to 21.95935, saving model to test.hdf5\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 21.0082 - acc: 0.8960 - val_loss: 21.2361 - val_acc: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00216: val_loss improved from 21.95935 to 21.23608, saving model to test.hdf5\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 20.4655 - acc: 0.8720 - val_loss: 21.1380 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00217: val_loss improved from 21.23608 to 21.13796, saving model to test.hdf5\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 20.3387 - acc: 0.8840 - val_loss: 20.0492 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00218: val_loss improved from 21.13796 to 20.04924, saving model to test.hdf5\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 19.3954 - acc: 0.8880 - val_loss: 20.0898 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 20.04924\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 18.6509 - acc: 0.9160 - val_loss: 19.3309 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00220: val_loss improved from 20.04924 to 19.33086, saving model to test.hdf5\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 18.3592 - acc: 0.8960 - val_loss: 19.0047 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00221: val_loss improved from 19.33086 to 19.00467, saving model to test.hdf5\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 17.8643 - acc: 0.8960 - val_loss: 18.7971 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00222: val_loss improved from 19.00467 to 18.79706, saving model to test.hdf5\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 17.0644 - acc: 0.9040 - val_loss: 18.3121 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00223: val_loss improved from 18.79706 to 18.31207, saving model to test.hdf5\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 16.8137 - acc: 0.9040 - val_loss: 17.5986 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00224: val_loss improved from 18.31207 to 17.59865, saving model to test.hdf5\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 16.4693 - acc: 0.8800 - val_loss: 16.8192 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00225: val_loss improved from 17.59865 to 16.81924, saving model to test.hdf5\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 15.6120 - acc: 0.8960 - val_loss: 16.3454 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00226: val_loss improved from 16.81924 to 16.34541, saving model to test.hdf5\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 15.2970 - acc: 0.9000 - val_loss: 16.4223 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 16.34541\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 15.1492 - acc: 0.8640 - val_loss: 15.3386 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00228: val_loss improved from 16.34541 to 15.33864, saving model to test.hdf5\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 14.2870 - acc: 0.9080 - val_loss: 15.7102 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 15.33864\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 14.1526 - acc: 0.9120 - val_loss: 14.7690 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00230: val_loss improved from 15.33864 to 14.76898, saving model to test.hdf5\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 13.6664 - acc: 0.9200 - val_loss: 14.6298 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00231: val_loss improved from 14.76898 to 14.62982, saving model to test.hdf5\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 13.2163 - acc: 0.8880 - val_loss: 14.5166 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00232: val_loss improved from 14.62982 to 14.51656, saving model to test.hdf5\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 13.3193 - acc: 0.8400 - val_loss: 14.0381 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00233: val_loss improved from 14.51656 to 14.03812, saving model to test.hdf5\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13.1275 - acc: 0.8720 - val_loss: 13.6247 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00234: val_loss improved from 14.03812 to 13.62466, saving model to test.hdf5\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 12.6116 - acc: 0.8640 - val_loss: 13.0723 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00235: val_loss improved from 13.62466 to 13.07235, saving model to test.hdf5\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 11.7615 - acc: 0.8760 - val_loss: 12.9113 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00236: val_loss improved from 13.07235 to 12.91125, saving model to test.hdf5\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 11.5315 - acc: 0.8680 - val_loss: 12.6021 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00237: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 00237: val_loss improved from 12.91125 to 12.60207, saving model to test.hdf5\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 11.4555 - acc: 0.8920 - val_loss: 11.9585 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00238: val_loss improved from 12.60207 to 11.95852, saving model to test.hdf5\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 10.6972 - acc: 0.9000 - val_loss: 11.4838 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00239: val_loss improved from 11.95852 to 11.48376, saving model to test.hdf5\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 10.4789 - acc: 0.8840 - val_loss: 11.4052 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00240: val_loss improved from 11.48376 to 11.40523, saving model to test.hdf5\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 10.1507 - acc: 0.8920 - val_loss: 11.5970 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 11.40523\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 10.1242 - acc: 0.8960 - val_loss: 10.8175 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00242: val_loss improved from 11.40523 to 10.81750, saving model to test.hdf5\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 9.8196 - acc: 0.8680 - val_loss: 11.1983 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 10.81750\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 9.4824 - acc: 0.9040 - val_loss: 11.6596 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 10.81750\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 9.2539 - acc: 0.9040 - val_loss: 9.7809 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00245: val_loss improved from 10.81750 to 9.78087, saving model to test.hdf5\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 8.9068 - acc: 0.8960 - val_loss: 9.7005 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00246: val_loss improved from 9.78087 to 9.70053, saving model to test.hdf5\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 8.7204 - acc: 0.8960 - val_loss: 9.5959 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00247: val_loss improved from 9.70053 to 9.59594, saving model to test.hdf5\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 8.5615 - acc: 0.8800 - val_loss: 9.3670 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00248: val_loss improved from 9.59594 to 9.36699, saving model to test.hdf5\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 8.2706 - acc: 0.9080 - val_loss: 9.5158 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 9.36699\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 8.3509 - acc: 0.8920 - val_loss: 9.0187 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00250: val_loss improved from 9.36699 to 9.01873, saving model to test.hdf5\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 7.9867 - acc: 0.8920 - val_loss: 8.9175 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00251: val_loss improved from 9.01873 to 8.91750, saving model to test.hdf5\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 7.7244 - acc: 0.8800 - val_loss: 8.6535 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00252: val_loss improved from 8.91750 to 8.65347, saving model to test.hdf5\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 7.6296 - acc: 0.8560 - val_loss: 8.4387 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00253: val_loss improved from 8.65347 to 8.43874, saving model to test.hdf5\n",
      "Epoch 254/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 185us/step - loss: 7.3500 - acc: 0.8800 - val_loss: 7.9553 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00254: val_loss improved from 8.43874 to 7.95531, saving model to test.hdf5\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 7.4154 - acc: 0.8480 - val_loss: 8.8886 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 7.95531\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 7.5335 - acc: 0.8720 - val_loss: 7.7220 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00256: val_loss improved from 7.95531 to 7.72204, saving model to test.hdf5\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 6.9677 - acc: 0.8760 - val_loss: 7.4700 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00257: val_loss improved from 7.72204 to 7.46997, saving model to test.hdf5\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 6.7758 - acc: 0.8760 - val_loss: 7.3361 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00258: val_loss improved from 7.46997 to 7.33607, saving model to test.hdf5\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 6.8755 - acc: 0.8480 - val_loss: 7.1269 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00259: val_loss improved from 7.33607 to 7.12689, saving model to test.hdf5\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 6.3459 - acc: 0.9000 - val_loss: 6.9124 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00260: val_loss improved from 7.12689 to 6.91244, saving model to test.hdf5\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 6.2777 - acc: 0.8680 - val_loss: 7.4541 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 6.91244\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 5.9997 - acc: 0.9120 - val_loss: 6.6399 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00262: val_loss improved from 6.91244 to 6.63988, saving model to test.hdf5\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 6.0512 - acc: 0.8640 - val_loss: 6.7276 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 6.63988\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 5.6977 - acc: 0.9080 - val_loss: 6.4828 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00264: val_loss improved from 6.63988 to 6.48281, saving model to test.hdf5\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 5.9104 - acc: 0.8520 - val_loss: 6.7668 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 6.48281\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 5.7582 - acc: 0.8600 - val_loss: 6.6633 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 6.48281\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 5.6896 - acc: 0.8480 - val_loss: 6.3216 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00267: val_loss improved from 6.48281 to 6.32159, saving model to test.hdf5\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 5.4165 - acc: 0.8640 - val_loss: 5.7382 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00268: val_loss improved from 6.32159 to 5.73819, saving model to test.hdf5\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 5.3193 - acc: 0.8720 - val_loss: 5.5189 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00269: val_loss improved from 5.73819 to 5.51892, saving model to test.hdf5\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 5.2039 - acc: 0.8520 - val_loss: 6.6263 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 5.51892\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 5.5290 - acc: 0.8560 - val_loss: 5.6153 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 5.51892\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 4.7337 - acc: 0.8840 - val_loss: 7.0919 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 5.51892\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 5.0658 - acc: 0.8480 - val_loss: 5.0422 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00273: val_loss improved from 5.51892 to 5.04223, saving model to test.hdf5\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 4.9719 - acc: 0.8400 - val_loss: 5.0928 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 5.04223\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 4.4394 - acc: 0.9000 - val_loss: 4.7812 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00275: val_loss improved from 5.04223 to 4.78125, saving model to test.hdf5\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 4.4101 - acc: 0.8520 - val_loss: 5.1959 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 4.78125\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 4.4545 - acc: 0.8440 - val_loss: 5.4048 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 4.78125\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 4.1272 - acc: 0.9120 - val_loss: 4.9507 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 4.78125\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 4.2469 - acc: 0.8800 - val_loss: 5.0255 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 4.78125\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 4.2800 - acc: 0.8400 - val_loss: 6.0038 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 4.78125\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 4.7249 - acc: 0.8360 - val_loss: 4.6222 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00281: val_loss improved from 4.78125 to 4.62221, saving model to test.hdf5\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 4.0824 - acc: 0.8800 - val_loss: 4.5462 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00282: val_loss improved from 4.62221 to 4.54619, saving model to test.hdf5\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 3.8607 - acc: 0.8760 - val_loss: 6.1895 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 4.54619\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 3.8883 - acc: 0.8680 - val_loss: 4.2417 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00284: val_loss improved from 4.54619 to 4.24168, saving model to test.hdf5\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 3.8632 - acc: 0.8520 - val_loss: 4.4177 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 4.24168\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 3.7101 - acc: 0.8840 - val_loss: 3.6577 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00286: val_loss improved from 4.24168 to 3.65774, saving model to test.hdf5\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 3.9487 - acc: 0.8160 - val_loss: 4.0169 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 3.65774\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 3.5261 - acc: 0.8360 - val_loss: 4.1487 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 3.65774\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 4.0807 - acc: 0.8400 - val_loss: 3.5987 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00289: val_loss improved from 3.65774 to 3.59869, saving model to test.hdf5\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 3.4286 - acc: 0.8720 - val_loss: 3.8034 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 3.59869\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 3.6617 - acc: 0.8240 - val_loss: 4.5197 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 3.59869\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 3.6825 - acc: 0.8400 - val_loss: 3.3471 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00292: val_loss improved from 3.59869 to 3.34710, saving model to test.hdf5\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 3.4339 - acc: 0.8560 - val_loss: 3.3074 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00293: val_loss improved from 3.34710 to 3.30738, saving model to test.hdf5\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 3.2545 - acc: 0.8680 - val_loss: 3.3184 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 3.30738\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 3.2477 - acc: 0.8440 - val_loss: 3.2017 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00295: val_loss improved from 3.30738 to 3.20171, saving model to test.hdf5\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 3.3589 - acc: 0.8360 - val_loss: 3.3513 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 3.20171\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 3.1529 - acc: 0.8640 - val_loss: 3.6222 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 3.20171\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 3.3024 - acc: 0.8680 - val_loss: 3.0318 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00298: val_loss improved from 3.20171 to 3.03176, saving model to test.hdf5\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 3.1731 - acc: 0.8240 - val_loss: 3.2700 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 3.03176\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 3.0446 - acc: 0.8120 - val_loss: 3.3712 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 3.03176\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 2.9497 - acc: 0.8520 - val_loss: 3.1007 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 3.03176\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.8777 - acc: 0.8640 - val_loss: 3.5580 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 3.03176\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 3.1884 - acc: 0.8560 - val_loss: 2.4912 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00303: val_loss improved from 3.03176 to 2.49122, saving model to test.hdf5\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.8349 - acc: 0.8760 - val_loss: 2.6499 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.49122\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.8466 - acc: 0.8640 - val_loss: 2.5868 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.49122\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.4170 - acc: 0.8880 - val_loss: 2.6781 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.49122\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 3.0238 - acc: 0.8360 - val_loss: 3.5520 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 2.49122\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.6660 - acc: 0.8680 - val_loss: 2.7783 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.49122\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.8993 - acc: 0.8200 - val_loss: 3.4146 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.49122\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.7089 - acc: 0.8480 - val_loss: 2.5580 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.49122\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 3.1433 - acc: 0.8040 - val_loss: 3.1118 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.49122\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 3.0655 - acc: 0.7960 - val_loss: 3.4240 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 2.49122\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.5515 - acc: 0.8480 - val_loss: 3.5064 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.49122\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.4531 - acc: 0.8520 - val_loss: 2.1382 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00314: val_loss improved from 2.49122 to 2.13818, saving model to test.hdf5\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.2475 - acc: 0.9000 - val_loss: 1.9714 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00315: val_loss improved from 2.13818 to 1.97141, saving model to test.hdf5\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 209us/step - loss: 2.2991 - acc: 0.8440 - val_loss: 2.6817 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 1.97141\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 2.6585 - acc: 0.8480 - val_loss: 2.0968 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1.97141\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.5957 - acc: 0.8240 - val_loss: 3.0535 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1.97141\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.5692 - acc: 0.8480 - val_loss: 2.5167 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 1.97141\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.5071 - acc: 0.8360 - val_loss: 2.1339 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 1.97141\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 2.4845 - acc: 0.8160 - val_loss: 2.5600 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.97141\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.6553 - acc: 0.8400 - val_loss: 2.1966 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 1.97141\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 2.2885 - acc: 0.8600 - val_loss: 4.5903 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.97141\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.9713 - acc: 0.8240 - val_loss: 2.1456 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 1.97141\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 2.2671 - acc: 0.8440 - val_loss: 4.3200 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 1.97141\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 209us/step - loss: 2.5272 - acc: 0.8640 - val_loss: 1.7495 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00326: val_loss improved from 1.97141 to 1.74945, saving model to test.hdf5\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 2.1586 - acc: 0.8280 - val_loss: 2.1887 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 1.74945\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 1.9886 - acc: 0.8400 - val_loss: 1.9745 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.74945\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.0788 - acc: 0.8520 - val_loss: 2.0904 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 1.74945\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 2.5805 - acc: 0.8440 - val_loss: 1.9894 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.74945\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 2.1686 - acc: 0.8360 - val_loss: 2.0057 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 1.74945\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 2.4450 - acc: 0.8200 - val_loss: 1.9628 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 1.74945\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.2981 - acc: 0.8040 - val_loss: 2.5628 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 1.74945\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 2.1482 - acc: 0.8440 - val_loss: 1.8579 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.74945\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 2.1182 - acc: 0.8280 - val_loss: 1.7290 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00335: val_loss improved from 1.74945 to 1.72896, saving model to test.hdf5\n",
      "Epoch 336/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 202us/step - loss: 1.9450 - acc: 0.8440 - val_loss: 4.5128 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.72896\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 2.8192 - acc: 0.8400 - val_loss: 3.1609 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 1.72896\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 2.5403 - acc: 0.8480 - val_loss: 1.7796 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 1.72896\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 1.8543 - acc: 0.8800 - val_loss: 2.2865 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1.72896\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 2.6253 - acc: 0.8240 - val_loss: 1.7551 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1.72896\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 2.0425 - acc: 0.8360 - val_loss: 2.1915 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 1.72896\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.5257 - acc: 0.8160 - val_loss: 2.3036 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1.72896\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 2.4253 - acc: 0.8040 - val_loss: 1.8431 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1.72896\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.1193 - acc: 0.8480 - val_loss: 3.3692 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 1.72896\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 2.6028 - acc: 0.8080 - val_loss: 1.5676 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00345: val_loss improved from 1.72896 to 1.56765, saving model to test.hdf5\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.1121 - acc: 0.8440 - val_loss: 2.4674 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 1.56765\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 2.3896 - acc: 0.8000 - val_loss: 1.7313 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 1.56765\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 2.3163 - acc: 0.8560 - val_loss: 1.6221 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 1.56765\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 2.3024 - acc: 0.8080 - val_loss: 2.5691 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 1.56765\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 2.2253 - acc: 0.8360 - val_loss: 1.6003 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1.56765\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.2163 - acc: 0.8480 - val_loss: 1.3025 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00351: val_loss improved from 1.56765 to 1.30249, saving model to test.hdf5\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 213us/step - loss: 2.3099 - acc: 0.8040 - val_loss: 1.6823 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 1.30249\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.1669 - acc: 0.8400 - val_loss: 1.9098 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1.30249\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.5088 - acc: 0.8440 - val_loss: 2.3251 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 1.30249\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.3671 - acc: 0.8160 - val_loss: 1.8187 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1.30249\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.5566 - acc: 0.8160 - val_loss: 1.9567 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 1.30249\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.0974 - acc: 0.8280 - val_loss: 1.1769 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00357: val_loss improved from 1.30249 to 1.17690, saving model to test.hdf5\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 2.4304 - acc: 0.8080 - val_loss: 1.3546 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1.17690\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.0136 - acc: 0.8480 - val_loss: 1.4845 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 1.17690\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.2897 - acc: 0.8400 - val_loss: 2.0226 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 1.17690\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 209us/step - loss: 2.4726 - acc: 0.8360 - val_loss: 1.7834 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 1.17690\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 2.8805 - acc: 0.8080 - val_loss: 1.5875 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1.17690\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 2.0917 - acc: 0.7920 - val_loss: 1.4145 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1.17690\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 2.0769 - acc: 0.8320 - val_loss: 1.3163 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 1.17690\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 1.9861 - acc: 0.8080 - val_loss: 1.3989 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 1.17690\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 1.9976 - acc: 0.8240 - val_loss: 2.1395 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1.17690\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 1.9937 - acc: 0.8520 - val_loss: 1.2943 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 1.17690\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.0276 - acc: 0.8320 - val_loss: 1.1766 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00368: val_loss improved from 1.17690 to 1.17663, saving model to test.hdf5\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 1.8695 - acc: 0.8440 - val_loss: 1.5527 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1.17663\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.3364 - acc: 0.8000 - val_loss: 1.5709 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1.17663\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.0648 - acc: 0.8280 - val_loss: 1.5961 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1.17663\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.7514 - acc: 0.8480 - val_loss: 1.7981 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1.17663\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 2.0816 - acc: 0.8360 - val_loss: 1.3893 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 1.17663\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.8830 - acc: 0.8280 - val_loss: 1.1815 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 1.17663\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 1.8648 - acc: 0.8640 - val_loss: 2.2241 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 1.17663\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2020 - acc: 0.8200 - val_loss: 1.8186 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1.17663\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.1449 - acc: 0.8200 - val_loss: 1.9838 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1.17663\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.0793 - acc: 0.8440 - val_loss: 1.5350 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 1.17663\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.1528 - acc: 0.8120 - val_loss: 1.8482 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 1.17663\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.0872 - acc: 0.8400 - val_loss: 1.4752 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 1.17663\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.0910 - acc: 0.8000 - val_loss: 1.8450 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1.17663\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 2.2681 - acc: 0.8360 - val_loss: 1.1929 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1.17663\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1.9563 - acc: 0.8400 - val_loss: 1.4747 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1.17663\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1.9068 - acc: 0.8400 - val_loss: 1.2135 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 1.17663\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.5520 - acc: 0.8560 - val_loss: 1.1586 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00385: val_loss improved from 1.17663 to 1.15858, saving model to test.hdf5\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.8703 - acc: 0.8520 - val_loss: 1.2188 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1.15858\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.0683 - acc: 0.8200 - val_loss: 1.3222 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1.15858\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2056 - acc: 0.7920 - val_loss: 2.6838 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1.15858\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.2597 - acc: 0.8080 - val_loss: 1.5440 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 1.15858\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.9303 - acc: 0.8080 - val_loss: 1.1736 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1.15858\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 2.1785 - acc: 0.8000 - val_loss: 1.8401 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1.15858\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.2312 - acc: 0.8200 - val_loss: 1.5919 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1.15858\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 2.2246 - acc: 0.8400 - val_loss: 1.2585 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1.15858\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.1938 - acc: 0.8160 - val_loss: 2.3855 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 1.15858\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2128 - acc: 0.8200 - val_loss: 2.0106 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 1.15858\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1.9803 - acc: 0.8400 - val_loss: 2.0287 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1.15858\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.6454 - acc: 0.7960 - val_loss: 1.4783 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1.15858\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.5280 - acc: 0.8080 - val_loss: 1.2603 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 1.15858\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.8119 - acc: 0.8360 - val_loss: 1.1547 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00399: val_loss improved from 1.15858 to 1.15474, saving model to test.hdf5\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.1519 - acc: 0.8160 - val_loss: 1.7320 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 1.15474\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.1426 - acc: 0.8400 - val_loss: 1.5867 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 1.15474\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2085 - acc: 0.8200 - val_loss: 2.2986 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1.15474\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 2.5790 - acc: 0.8000 - val_loss: 2.1152 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 1.15474\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 2.2209 - acc: 0.8400 - val_loss: 1.9415 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 1.15474\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 2.3782 - acc: 0.7880 - val_loss: 2.0804 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1.15474\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.2391 - acc: 0.7920 - val_loss: 6.4696 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 1.15474\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.9219 - acc: 0.8200 - val_loss: 1.8481 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1.15474\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1.9771 - acc: 0.8400 - val_loss: 1.1517 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00408: val_loss improved from 1.15474 to 1.15170, saving model to test.hdf5\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.3048 - acc: 0.8040 - val_loss: 1.6556 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1.15170\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.0943 - acc: 0.8120 - val_loss: 1.7629 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1.15170\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.1193 - acc: 0.8240 - val_loss: 1.5524 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 1.15170\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.0244 - acc: 0.8240 - val_loss: 2.3368 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1.15170\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.8905 - acc: 0.8600 - val_loss: 1.2334 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1.15170\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1.9856 - acc: 0.8200 - val_loss: 8.7287 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 1.15170\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.4950 - acc: 0.8280 - val_loss: 0.9677 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00415: val_loss improved from 1.15170 to 0.96772, saving model to test.hdf5\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.0521 - acc: 0.8280 - val_loss: 1.7369 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.96772\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.8381 - acc: 0.8360 - val_loss: 1.3980 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.96772\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.1879 - acc: 0.8200 - val_loss: 1.0946 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.96772\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 1.8007 - acc: 0.8320 - val_loss: 1.4141 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.96772\n",
      "Epoch 420/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 194us/step - loss: 2.1423 - acc: 0.8120 - val_loss: 1.5427 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.96772\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.0590 - acc: 0.8240 - val_loss: 1.4897 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.96772\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.1079 - acc: 0.8040 - val_loss: 3.8548 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.96772\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.4873 - acc: 0.8120 - val_loss: 1.2951 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.96772\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.7416 - acc: 0.8200 - val_loss: 1.2112 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.96772\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 1.5958 - acc: 0.8320 - val_loss: 1.6603 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.96772\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.0447 - acc: 0.8280 - val_loss: 1.6552 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.96772\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.8945 - acc: 0.8320 - val_loss: 3.3234 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.96772\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.4434 - acc: 0.7760 - val_loss: 2.1561 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.96772\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.3443 - acc: 0.8120 - val_loss: 1.2038 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.96772\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.2090 - acc: 0.8240 - val_loss: 1.4021 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.96772\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.1799 - acc: 0.7880 - val_loss: 1.7015 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.96772\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.4252 - acc: 0.7800 - val_loss: 1.1249 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.96772\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.8938 - acc: 0.8280 - val_loss: 1.6497 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.96772\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.6073 - acc: 0.8160 - val_loss: 1.2474 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.96772\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.8746 - acc: 0.8080 - val_loss: 2.0059 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.96772\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.9977 - acc: 0.8120 - val_loss: 1.6251 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.96772\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.4818 - acc: 0.7760 - val_loss: 2.4386 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.96772\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.2044 - acc: 0.8080 - val_loss: 1.6904 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.96772\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.1879 - acc: 0.8480 - val_loss: 1.2060 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.96772\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 2.0226 - acc: 0.7920 - val_loss: 1.4161 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.96772\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 2.4608 - acc: 0.8040 - val_loss: 1.7665 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.96772\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.9287 - acc: 0.8480 - val_loss: 1.4782 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.96772\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.9687 - acc: 0.8120 - val_loss: 1.2135 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.96772\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.9939 - acc: 0.8000 - val_loss: 1.5013 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.96772\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.1992 - acc: 0.8240 - val_loss: 1.5965 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.96772\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2537 - acc: 0.7960 - val_loss: 1.6886 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.96772\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.2038 - acc: 0.8040 - val_loss: 1.1779 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.96772\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.0170 - acc: 0.8200 - val_loss: 1.9870 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.96772\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.2220 - acc: 0.8200 - val_loss: 2.2097 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.96772\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 2.4854 - acc: 0.7840 - val_loss: 2.0255 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.96772\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1.8645 - acc: 0.8280 - val_loss: 1.0468 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.96772\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.7776 - acc: 0.8480 - val_loss: 1.1850 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.96772\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.2568 - acc: 0.7760 - val_loss: 2.1729 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.96772\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.3932 - acc: 0.7640 - val_loss: 1.1568 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.96772\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.0886 - acc: 0.8080 - val_loss: 1.4147 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.96772\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.9801 - acc: 0.8480 - val_loss: 3.0298 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.96772\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 2.1392 - acc: 0.8200 - val_loss: 1.0919 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.96772\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2.0632 - acc: 0.8240 - val_loss: 1.7811 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.96772\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.3328 - acc: 0.7720 - val_loss: 2.4236 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.96772\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.0975 - acc: 0.8480 - val_loss: 1.5247 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.96772\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.2318 - acc: 0.8440 - val_loss: 1.2253 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.96772\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.7380 - acc: 0.7720 - val_loss: 1.1375 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00462: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.96772\n",
      "Epoch 463/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 205us/step - loss: 1.8341 - acc: 0.8120 - val_loss: 1.2441 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.96772\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 1.8001 - acc: 0.8480 - val_loss: 1.1787 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.96772\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.6199 - acc: 0.8200 - val_loss: 1.4339 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.96772\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.0364 - acc: 0.8320 - val_loss: 0.9515 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00466: val_loss improved from 0.96772 to 0.95153, saving model to test.hdf5\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 1.6347 - acc: 0.8600 - val_loss: 1.8085 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.95153\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 1.7665 - acc: 0.8520 - val_loss: 4.5675 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.95153\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 2.8149 - acc: 0.7560 - val_loss: 1.5079 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.95153\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.1363 - acc: 0.8080 - val_loss: 1.8326 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.95153\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.1288 - acc: 0.8000 - val_loss: 2.4382 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.95153\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2.3733 - acc: 0.7640 - val_loss: 1.8683 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.95153\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 1.9578 - acc: 0.8680 - val_loss: 0.9609 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.95153\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.7272 - acc: 0.8680 - val_loss: 1.3614 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.95153\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.9932 - acc: 0.8280 - val_loss: 1.1531 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.95153\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 2.0509 - acc: 0.8000 - val_loss: 1.6720 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.95153\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.9971 - acc: 0.8320 - val_loss: 1.3777 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.95153\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1.9562 - acc: 0.8440 - val_loss: 1.3154 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.95153\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.7333 - acc: 0.8320 - val_loss: 1.3508 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.95153\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 1.6371 - acc: 0.8600 - val_loss: 1.4927 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.95153\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.8727 - acc: 0.8080 - val_loss: 0.9838 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.95153\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.8479 - acc: 0.8360 - val_loss: 1.0892 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.95153\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.3198 - acc: 0.8000 - val_loss: 1.4780 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.95153\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.1700 - acc: 0.8120 - val_loss: 1.6184 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.95153\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.1034 - acc: 0.8320 - val_loss: 1.1900 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.95153\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.0375 - acc: 0.8160 - val_loss: 1.3182 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.95153\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 2.2669 - acc: 0.8160 - val_loss: 1.1669 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.95153\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.9977 - acc: 0.8440 - val_loss: 1.2434 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.95153\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.0410 - acc: 0.8080 - val_loss: 1.4019 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.95153\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.0323 - acc: 0.8240 - val_loss: 1.3205 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.95153\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.0042 - acc: 0.8520 - val_loss: 1.0698 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.95153\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.8517 - acc: 0.8240 - val_loss: 1.4588 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.95153\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.1404 - acc: 0.8080 - val_loss: 1.2067 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.95153\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 2.2388 - acc: 0.8240 - val_loss: 1.5984 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.95153\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1.9218 - acc: 0.8120 - val_loss: 1.0794 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.95153\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.0592 - acc: 0.8080 - val_loss: 1.3307 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.95153\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.2040 - acc: 0.8440 - val_loss: 3.6922 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.95153\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 3.0656 - acc: 0.8040 - val_loss: 1.5538 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.95153\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.7256 - acc: 0.8440 - val_loss: 2.3176 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.95153\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.1848 - acc: 0.8480 - val_loss: 1.5259 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.95153\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.1601 - acc: 0.7920 - val_loss: 2.2755 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.95153\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 2.4393 - acc: 0.8000 - val_loss: 1.4597 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.95153\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.1779 - acc: 0.7920 - val_loss: 0.9567 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.95153\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.7285 - acc: 0.8480 - val_loss: 1.2796 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.95153\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 2.0599 - acc: 0.8040 - val_loss: 1.5112 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.95153\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2.3163 - acc: 0.8080 - val_loss: 1.4614 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.95153\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 2.0210 - acc: 0.8080 - val_loss: 1.1370 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.95153\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2.2687 - acc: 0.7960 - val_loss: 2.0646 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.95153\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 2.4154 - acc: 0.8160 - val_loss: 1.1658 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.95153\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2.0009 - acc: 0.8000 - val_loss: 0.9835 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.95153\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2.3068 - acc: 0.7760 - val_loss: 2.5826 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.95153\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.1114 - acc: 0.8440 - val_loss: 1.6666 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00512: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.95153\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 1.8622 - acc: 0.8160 - val_loss: 1.3491 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.95153\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.8362 - acc: 0.8240 - val_loss: 1.2297 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.95153\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1.9243 - acc: 0.8320 - val_loss: 1.0021 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.95153\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.6582 - acc: 0.8280 - val_loss: 1.0933 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.95153\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1.7183 - acc: 0.8440 - val_loss: 2.0784 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.95153\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1.8003 - acc: 0.8400 - val_loss: 1.3632 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.95153\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 2.0092 - acc: 0.8400 - val_loss: 2.2103 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.95153\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 2.1413 - acc: 0.7960 - val_loss: 1.3137 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.95153\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.1288 - acc: 0.8240 - val_loss: 1.2769 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.95153\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2.5920 - acc: 0.7800 - val_loss: 1.9749 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.95153\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 2.0230 - acc: 0.8600 - val_loss: 1.4236 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.95153\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 1.9709 - acc: 0.8200 - val_loss: 1.1309 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.95153\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1.9735 - acc: 0.8080 - val_loss: 1.8846 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.95153\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.1429 - acc: 0.8280 - val_loss: 1.2103 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.95153\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.6875 - acc: 0.8360 - val_loss: 1.2036 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.95153\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 1.8547 - acc: 0.8160 - val_loss: 0.8812 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.95153 to 0.88121, saving model to test.hdf5\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 1.5782 - acc: 0.8160 - val_loss: 1.4933 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.88121\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 2.2443 - acc: 0.8280 - val_loss: 1.3256 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.88121\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.8947 - acc: 0.8480 - val_loss: 1.1352 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.88121\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 1.7912 - acc: 0.8160 - val_loss: 1.3379 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.88121\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1.7538 - acc: 0.8280 - val_loss: 1.8070 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.88121\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.2831 - acc: 0.8360 - val_loss: 1.1025 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.88121\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1.6265 - acc: 0.8240 - val_loss: 1.5826 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.88121\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 2.0523 - acc: 0.8440 - val_loss: 1.0548 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.88121\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 2.0779 - acc: 0.8240 - val_loss: 1.6547 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.88121\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.1848 - acc: 0.8240 - val_loss: 1.1914 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.88121\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.2746 - acc: 0.8000 - val_loss: 1.2649 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.88121\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 1.7054 - acc: 0.8480 - val_loss: 1.0646 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.88121\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.7182 - acc: 0.8560 - val_loss: 1.9890 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.88121\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 1.6531 - acc: 0.8560 - val_loss: 2.4028 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.88121\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2.0217 - acc: 0.8240 - val_loss: 1.2945 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.88121\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 2.0620 - acc: 0.8080 - val_loss: 1.6520 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.88121\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1.8946 - acc: 0.8520 - val_loss: 1.5805 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.88121\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 1.9044 - acc: 0.8240 - val_loss: 1.9133 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.88121\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 2.0177 - acc: 0.8320 - val_loss: 1.2710 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.88121\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 1.9287 - acc: 0.8120 - val_loss: 1.2800 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.88121\n",
      "Epoch 549/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 218us/step - loss: 1.8904 - acc: 0.8320 - val_loss: 1.2776 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.88121\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.8035 - acc: 0.8520 - val_loss: 0.9258 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.88121\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2141f1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b214224dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 6, заменили relu на leaky relu, увеличили вес регуляризаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 8458523.4300 - acc: 0.5520 - val_loss: 2879389.9821 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2879389.98214, saving model to test.hdf5\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 4414737.5950 - acc: 0.6000 - val_loss: 1831249.1473 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00002: val_loss improved from 2879389.98214 to 1831249.14732, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 2415060.6900 - acc: 0.5560 - val_loss: 1259849.4163 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00003: val_loss improved from 1831249.14732 to 1259849.41629, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 1489410.6875 - acc: 0.6120 - val_loss: 948121.4051 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00004: val_loss improved from 1259849.41629 to 948121.40513, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 1072363.0112 - acc: 0.6440 - val_loss: 734421.7427 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00005: val_loss improved from 948121.40513 to 734421.74275, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 845132.7969 - acc: 0.6680 - val_loss: 598813.0279 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00006: val_loss improved from 734421.74275 to 598813.02790, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 701339.8550 - acc: 0.6720 - val_loss: 501421.2277 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00007: val_loss improved from 598813.02790 to 501421.22768, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 614930.6719 - acc: 0.6480 - val_loss: 431992.0592 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00008: val_loss improved from 501421.22768 to 431992.05915, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 548313.0925 - acc: 0.7120 - val_loss: 378909.6077 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00009: val_loss improved from 431992.05915 to 378909.60770, saving model to test.hdf5\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 500413.0013 - acc: 0.7480 - val_loss: 337937.2171 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00010: val_loss improved from 378909.60770 to 337937.21708, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 459780.0094 - acc: 0.7520 - val_loss: 306371.5876 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00011: val_loss improved from 337937.21708 to 306371.58761, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 424166.5059 - acc: 0.7520 - val_loss: 279935.2165 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00012: val_loss improved from 306371.58761 to 279935.21652, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 398967.6605 - acc: 0.6960 - val_loss: 258119.1415 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00013: val_loss improved from 279935.21652 to 258119.14146, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 377435.7800 - acc: 0.7360 - val_loss: 240832.9763 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00014: val_loss improved from 258119.14146 to 240832.97628, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 350728.4825 - acc: 0.7200 - val_loss: 226741.2829 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00015: val_loss improved from 240832.97628 to 226741.28292, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 336285.0675 - acc: 0.7440 - val_loss: 213263.4803 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00016: val_loss improved from 226741.28292 to 213263.48033, saving model to test.hdf5\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 321910.1487 - acc: 0.7480 - val_loss: 203430.1998 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00017: val_loss improved from 213263.48033 to 203430.19978, saving model to test.hdf5\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 304845.9669 - acc: 0.8120 - val_loss: 192656.1037 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00018: val_loss improved from 203430.19978 to 192656.10366, saving model to test.hdf5\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 291605.7606 - acc: 0.7360 - val_loss: 183232.1007 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00019: val_loss improved from 192656.10366 to 183232.10073, saving model to test.hdf5\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 146us/step - loss: 278858.4319 - acc: 0.7160 - val_loss: 175437.4226 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00020: val_loss improved from 183232.10073 to 175437.42257, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 269634.8672 - acc: 0.7400 - val_loss: 169885.8514 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00021: val_loss improved from 175437.42257 to 169885.85142, saving model to test.hdf5\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 255327.0912 - acc: 0.7560 - val_loss: 162570.9876 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00022: val_loss improved from 169885.85142 to 162570.98758, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 245133.3978 - acc: 0.7600 - val_loss: 156284.2154 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00023: val_loss improved from 162570.98758 to 156284.21540, saving model to test.hdf5\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 238873.7484 - acc: 0.7120 - val_loss: 150308.7983 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00024: val_loss improved from 156284.21540 to 150308.79827, saving model to test.hdf5\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 229670.0303 - acc: 0.7120 - val_loss: 144934.3375 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00025: val_loss improved from 150308.79827 to 144934.33747, saving model to test.hdf5\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 220962.4133 - acc: 0.7480 - val_loss: 139824.8592 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00026: val_loss improved from 144934.33747 to 139824.85924, saving model to test.hdf5\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 212095.3809 - acc: 0.7360 - val_loss: 134317.5778 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00027: val_loss improved from 139824.85924 to 134317.57785, saving model to test.hdf5\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 206250.8897 - acc: 0.7000 - val_loss: 130288.1987 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00028: val_loss improved from 134317.57785 to 130288.19866, saving model to test.hdf5\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 199687.0645 - acc: 0.7400 - val_loss: 126828.1390 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00029: val_loss improved from 130288.19866 to 126828.13895, saving model to test.hdf5\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 194643.9773 - acc: 0.7440 - val_loss: 123364.4485 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00030: val_loss improved from 126828.13895 to 123364.44852, saving model to test.hdf5\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 186450.4825 - acc: 0.7400 - val_loss: 119149.1676 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00031: val_loss improved from 123364.44852 to 119149.16755, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 181745.9919 - acc: 0.7200 - val_loss: 116162.7726 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00032: val_loss improved from 119149.16755 to 116162.77260, saving model to test.hdf5\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 177735.1245 - acc: 0.7400 - val_loss: 112887.3083 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00033: val_loss improved from 116162.77260 to 112887.30831, saving model to test.hdf5\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 170578.0286 - acc: 0.7120 - val_loss: 110109.4849 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00034: val_loss improved from 112887.30831 to 110109.48493, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 167837.8311 - acc: 0.7040 - val_loss: 107487.8992 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00035: val_loss improved from 110109.48493 to 107487.89920, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 162us/step - loss: 163640.5880 - acc: 0.7320 - val_loss: 104717.5228 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00036: val_loss improved from 107487.89920 to 104717.52281, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 158494.1336 - acc: 0.6960 - val_loss: 101900.1857 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00037: val_loss improved from 104717.52281 to 101900.18569, saving model to test.hdf5\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 153608.2752 - acc: 0.7480 - val_loss: 99311.7027 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00038: val_loss improved from 101900.18569 to 99311.70271, saving model to test.hdf5\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 149670.2619 - acc: 0.7040 - val_loss: 96551.4584 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00039: val_loss improved from 99311.70271 to 96551.45836, saving model to test.hdf5\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 145902.2237 - acc: 0.6920 - val_loss: 94292.5446 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00040: val_loss improved from 96551.45836 to 94292.54457, saving model to test.hdf5\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 141723.0445 - acc: 0.7400 - val_loss: 91973.1498 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00041: val_loss improved from 94292.54457 to 91973.14976, saving model to test.hdf5\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 138676.2755 - acc: 0.6960 - val_loss: 89344.7847 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00042: val_loss improved from 91973.14976 to 89344.78467, saving model to test.hdf5\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 134000.5788 - acc: 0.7200 - val_loss: 86680.2753 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00043: val_loss improved from 89344.78467 to 86680.27532, saving model to test.hdf5\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 130895.9755 - acc: 0.7160 - val_loss: 84824.9049 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00044: val_loss improved from 86680.27532 to 84824.90485, saving model to test.hdf5\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 128350.3334 - acc: 0.7120 - val_loss: 83037.9586 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00045: val_loss improved from 84824.90485 to 83037.95864, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 124038.3067 - acc: 0.7040 - val_loss: 80517.8094 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00046: val_loss improved from 83037.95864 to 80517.80943, saving model to test.hdf5\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 122020.4512 - acc: 0.7240 - val_loss: 78878.5259 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00047: val_loss improved from 80517.80943 to 78878.52588, saving model to test.hdf5\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 118334.7522 - acc: 0.7080 - val_loss: 76522.2683 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00048: val_loss improved from 78878.52588 to 76522.26828, saving model to test.hdf5\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 114833.9839 - acc: 0.6800 - val_loss: 75731.2069 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00049: val_loss improved from 76522.26828 to 75731.20689, saving model to test.hdf5\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 112142.6319 - acc: 0.7320 - val_loss: 73353.4418 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00050: val_loss improved from 75731.20689 to 73353.44176, saving model to test.hdf5\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 109154.0345 - acc: 0.6960 - val_loss: 71597.2217 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00051: val_loss improved from 73353.44176 to 71597.22175, saving model to test.hdf5\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 106585.7421 - acc: 0.7280 - val_loss: 69680.1744 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00052: val_loss improved from 71597.22175 to 69680.17439, saving model to test.hdf5\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 103488.2410 - acc: 0.7280 - val_loss: 68538.8161 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00053: val_loss improved from 69680.17439 to 68538.81613, saving model to test.hdf5\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 101027.6012 - acc: 0.7360 - val_loss: 66894.1465 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00054: val_loss improved from 68538.81613 to 66894.14652, saving model to test.hdf5\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 97965.8855 - acc: 0.7040 - val_loss: 65722.1615 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00055: val_loss improved from 66894.14652 to 65722.16148, saving model to test.hdf5\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 96256.2673 - acc: 0.7080 - val_loss: 64504.0518 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00056: val_loss improved from 65722.16148 to 64504.05179, saving model to test.hdf5\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 94047.0784 - acc: 0.7560 - val_loss: 62623.5931 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00057: val_loss improved from 64504.05179 to 62623.59309, saving model to test.hdf5\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 92530.6545 - acc: 0.7440 - val_loss: 61280.0427 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00058: val_loss improved from 62623.59309 to 61280.04269, saving model to test.hdf5\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 90436.2288 - acc: 0.7560 - val_loss: 60171.3041 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00059: val_loss improved from 61280.04269 to 60171.30413, saving model to test.hdf5\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 88536.3842 - acc: 0.7200 - val_loss: 58956.9346 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00060: val_loss improved from 60171.30413 to 58956.93461, saving model to test.hdf5\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 85809.1326 - acc: 0.6920 - val_loss: 57674.8556 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00061: val_loss improved from 58956.93461 to 57674.85561, saving model to test.hdf5\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 83620.0601 - acc: 0.7000 - val_loss: 56545.4263 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00062: val_loss improved from 57674.85561 to 56545.42627, saving model to test.hdf5\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 81780.2867 - acc: 0.7040 - val_loss: 55384.5582 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00063: val_loss improved from 56545.42627 to 55384.55821, saving model to test.hdf5\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 79540.9929 - acc: 0.7160 - val_loss: 54348.8542 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00064: val_loss improved from 55384.55821 to 54348.85425, saving model to test.hdf5\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 78646.7863 - acc: 0.7080 - val_loss: 52951.4890 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00065: val_loss improved from 54348.85425 to 52951.48905, saving model to test.hdf5\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 76407.0643 - acc: 0.7120 - val_loss: 51513.0766 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00066: val_loss improved from 52951.48905 to 51513.07659, saving model to test.hdf5\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 74761.8234 - acc: 0.7240 - val_loss: 50530.9042 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00067: val_loss improved from 51513.07659 to 50530.90419, saving model to test.hdf5\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 73536.4241 - acc: 0.7280 - val_loss: 49819.0085 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00068: val_loss improved from 50530.90419 to 49819.00848, saving model to test.hdf5\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 71375.4884 - acc: 0.7040 - val_loss: 48184.2490 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00069: val_loss improved from 49819.00848 to 48184.24895, saving model to test.hdf5\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 70081.9704 - acc: 0.7280 - val_loss: 47060.3418 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00070: val_loss improved from 48184.24895 to 47060.34180, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 67531.9962 - acc: 0.7240 - val_loss: 46507.4724 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00071: val_loss improved from 47060.34180 to 46507.47238, saving model to test.hdf5\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 67076.8173 - acc: 0.6680 - val_loss: 45747.4792 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00072: val_loss improved from 46507.47238 to 45747.47918, saving model to test.hdf5\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 65128.7017 - acc: 0.6960 - val_loss: 44392.5816 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00073: val_loss improved from 45747.47918 to 44392.58165, saving model to test.hdf5\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 63897.4204 - acc: 0.6840 - val_loss: 43394.8090 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00074: val_loss improved from 44392.58165 to 43394.80901, saving model to test.hdf5\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 162us/step - loss: 62291.2945 - acc: 0.6520 - val_loss: 42654.8699 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00075: val_loss improved from 43394.80901 to 42654.86994, saving model to test.hdf5\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 61224.5859 - acc: 0.7240 - val_loss: 41947.0049 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00076: val_loss improved from 42654.86994 to 41947.00488, saving model to test.hdf5\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 59078.4809 - acc: 0.7280 - val_loss: 40839.9574 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00077: val_loss improved from 41947.00488 to 40839.95745, saving model to test.hdf5\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 57717.2995 - acc: 0.7360 - val_loss: 39832.5637 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00078: val_loss improved from 40839.95745 to 39832.56365, saving model to test.hdf5\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 56544.6244 - acc: 0.7360 - val_loss: 39032.4934 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00079: val_loss improved from 39832.56365 to 39032.49341, saving model to test.hdf5\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 54858.8744 - acc: 0.6880 - val_loss: 38234.6448 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00080: val_loss improved from 39032.49341 to 38234.64481, saving model to test.hdf5\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 53809.7324 - acc: 0.7240 - val_loss: 37194.8600 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00081: val_loss improved from 38234.64481 to 37194.86004, saving model to test.hdf5\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 52549.2588 - acc: 0.7560 - val_loss: 36639.8614 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00082: val_loss improved from 37194.86004 to 36639.86143, saving model to test.hdf5\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 51321.3157 - acc: 0.6880 - val_loss: 35576.9136 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00083: val_loss improved from 36639.86143 to 35576.91364, saving model to test.hdf5\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 50216.8796 - acc: 0.7280 - val_loss: 35218.2771 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00084: val_loss improved from 35576.91364 to 35218.27706, saving model to test.hdf5\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 49187.9859 - acc: 0.7000 - val_loss: 34257.6599 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00085: val_loss improved from 35218.27706 to 34257.65988, saving model to test.hdf5\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 48071.5461 - acc: 0.7000 - val_loss: 33507.8312 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00086: val_loss improved from 34257.65988 to 33507.83125, saving model to test.hdf5\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 46536.4742 - acc: 0.6840 - val_loss: 32669.3978 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00087: val_loss improved from 33507.83125 to 32669.39781, saving model to test.hdf5\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 45837.8787 - acc: 0.6840 - val_loss: 32120.0721 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00088: val_loss improved from 32669.39781 to 32120.07207, saving model to test.hdf5\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 44321.4168 - acc: 0.7200 - val_loss: 31613.5207 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00089: val_loss improved from 32120.07207 to 31613.52070, saving model to test.hdf5\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 44062.3809 - acc: 0.6680 - val_loss: 30637.3257 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00090: val_loss improved from 31613.52070 to 30637.32570, saving model to test.hdf5\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 42515.7255 - acc: 0.7160 - val_loss: 30114.4423 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00091: val_loss improved from 30637.32570 to 30114.44231, saving model to test.hdf5\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 41483.0409 - acc: 0.7440 - val_loss: 29292.4505 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00092: val_loss improved from 30114.44231 to 29292.45053, saving model to test.hdf5\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 40490.6681 - acc: 0.6720 - val_loss: 28677.9282 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00093: val_loss improved from 29292.45053 to 28677.92822, saving model to test.hdf5\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 39439.4350 - acc: 0.7120 - val_loss: 28226.1533 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00094: val_loss improved from 28677.92822 to 28226.15325, saving model to test.hdf5\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 38340.3382 - acc: 0.7240 - val_loss: 27522.9587 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00095: val_loss improved from 28226.15325 to 27522.95865, saving model to test.hdf5\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 37679.3013 - acc: 0.6760 - val_loss: 26927.5757 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00096: val_loss improved from 27522.95865 to 26927.57567, saving model to test.hdf5\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 36689.0755 - acc: 0.7280 - val_loss: 26489.6436 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00097: val_loss improved from 26927.57567 to 26489.64361, saving model to test.hdf5\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 35549.2568 - acc: 0.6840 - val_loss: 25581.9807 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00098: val_loss improved from 26489.64361 to 25581.98073, saving model to test.hdf5\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 34930.1337 - acc: 0.7160 - val_loss: 25089.3360 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00099: val_loss improved from 25581.98073 to 25089.33599, saving model to test.hdf5\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 33956.5093 - acc: 0.6880 - val_loss: 24610.1111 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00100: val_loss improved from 25089.33599 to 24610.11114, saving model to test.hdf5\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 32965.5913 - acc: 0.6840 - val_loss: 24138.5782 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00101: val_loss improved from 24610.11114 to 24138.57821, saving model to test.hdf5\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 32280.0320 - acc: 0.7120 - val_loss: 23853.5178 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00102: val_loss improved from 24138.57821 to 23853.51779, saving model to test.hdf5\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 31884.2318 - acc: 0.6960 - val_loss: 23185.4666 - val_acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00103: val_loss improved from 23853.51779 to 23185.46662, saving model to test.hdf5\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 148us/step - loss: 31172.7313 - acc: 0.7080 - val_loss: 22726.8128 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00104: val_loss improved from 23185.46662 to 22726.81281, saving model to test.hdf5\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 30320.1283 - acc: 0.7120 - val_loss: 22295.9078 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00105: val_loss improved from 22726.81281 to 22295.90780, saving model to test.hdf5\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 29805.6294 - acc: 0.6960 - val_loss: 21859.2520 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00106: val_loss improved from 22295.90780 to 21859.25199, saving model to test.hdf5\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 29060.8235 - acc: 0.7320 - val_loss: 21397.5945 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00107: val_loss improved from 21859.25199 to 21397.59450, saving model to test.hdf5\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 28315.2814 - acc: 0.7080 - val_loss: 20809.6358 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00108: val_loss improved from 21397.59450 to 20809.63579, saving model to test.hdf5\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 27942.8908 - acc: 0.6760 - val_loss: 20456.9700 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00109: val_loss improved from 20809.63579 to 20456.96999, saving model to test.hdf5\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 27216.3375 - acc: 0.6640 - val_loss: 20026.6415 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00110: val_loss improved from 20456.96999 to 20026.64148, saving model to test.hdf5\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 26493.7247 - acc: 0.7200 - val_loss: 19741.4266 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00111: val_loss improved from 20026.64148 to 19741.42657, saving model to test.hdf5\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 26160.9161 - acc: 0.7120 - val_loss: 19333.9728 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00112: val_loss improved from 19741.42657 to 19333.97285, saving model to test.hdf5\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 25534.2276 - acc: 0.7120 - val_loss: 18759.2085 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00113: val_loss improved from 19333.97285 to 18759.20850, saving model to test.hdf5\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 25101.1071 - acc: 0.7040 - val_loss: 18356.1087 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00114: val_loss improved from 18759.20850 to 18356.10869, saving model to test.hdf5\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 24177.9058 - acc: 0.7240 - val_loss: 18021.9987 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00115: val_loss improved from 18356.10869 to 18021.99866, saving model to test.hdf5\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 23683.4609 - acc: 0.6800 - val_loss: 17775.7957 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00116: val_loss improved from 18021.99866 to 17775.79572, saving model to test.hdf5\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 23125.6425 - acc: 0.7040 - val_loss: 17294.1896 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00117: val_loss improved from 17775.79572 to 17294.18959, saving model to test.hdf5\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 22592.7266 - acc: 0.7200 - val_loss: 17082.3927 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00118: val_loss improved from 17294.18959 to 17082.39274, saving model to test.hdf5\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 22168.7252 - acc: 0.6720 - val_loss: 16607.5408 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00119: val_loss improved from 17082.39274 to 16607.54082, saving model to test.hdf5\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 21612.5545 - acc: 0.7160 - val_loss: 16329.4547 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00120: val_loss improved from 16607.54082 to 16329.45470, saving model to test.hdf5\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 21228.2912 - acc: 0.6920 - val_loss: 15937.5877 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00121: val_loss improved from 16329.45470 to 15937.58770, saving model to test.hdf5\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 20565.1492 - acc: 0.7200 - val_loss: 15706.9233 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00122: val_loss improved from 15937.58770 to 15706.92333, saving model to test.hdf5\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 20259.3948 - acc: 0.6360 - val_loss: 15201.5543 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00123: val_loss improved from 15706.92333 to 15201.55430, saving model to test.hdf5\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 19807.9496 - acc: 0.6960 - val_loss: 14874.0387 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00124: val_loss improved from 15201.55430 to 14874.03868, saving model to test.hdf5\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 19345.7694 - acc: 0.7440 - val_loss: 14646.4000 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00125: val_loss improved from 14874.03868 to 14646.40004, saving model to test.hdf5\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 18860.9225 - acc: 0.6760 - val_loss: 14363.4934 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00126: val_loss improved from 14646.40004 to 14363.49338, saving model to test.hdf5\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 18316.0884 - acc: 0.6760 - val_loss: 14013.1003 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00127: val_loss improved from 14363.49338 to 14013.10026, saving model to test.hdf5\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 17873.1838 - acc: 0.6920 - val_loss: 13806.4284 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00128: val_loss improved from 14013.10026 to 13806.42838, saving model to test.hdf5\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 17602.9858 - acc: 0.7120 - val_loss: 13417.1479 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00129: val_loss improved from 13806.42838 to 13417.14790, saving model to test.hdf5\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 17100.2839 - acc: 0.6560 - val_loss: 13133.0696 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00130: val_loss improved from 13417.14790 to 13133.06962, saving model to test.hdf5\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 16723.5847 - acc: 0.6880 - val_loss: 12877.4941 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00131: val_loss improved from 13133.06962 to 12877.49415, saving model to test.hdf5\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 209us/step - loss: 16249.8083 - acc: 0.7080 - val_loss: 12752.9369 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00132: val_loss improved from 12877.49415 to 12752.93689, saving model to test.hdf5\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 15895.9908 - acc: 0.7760 - val_loss: 12411.1159 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00133: val_loss improved from 12752.93689 to 12411.11588, saving model to test.hdf5\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 15515.7026 - acc: 0.6880 - val_loss: 12084.5635 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00134: val_loss improved from 12411.11588 to 12084.56352, saving model to test.hdf5\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 15015.8111 - acc: 0.7560 - val_loss: 11848.4364 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00135: val_loss improved from 12084.56352 to 11848.43639, saving model to test.hdf5\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14741.2389 - acc: 0.6960 - val_loss: 11556.6982 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00136: val_loss improved from 11848.43639 to 11556.69823, saving model to test.hdf5\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 14343.3014 - acc: 0.7080 - val_loss: 11296.3203 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00137: val_loss improved from 11556.69823 to 11296.32030, saving model to test.hdf5\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13967.3890 - acc: 0.6960 - val_loss: 11060.2127 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00138: val_loss improved from 11296.32030 to 11060.21274, saving model to test.hdf5\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13773.4959 - acc: 0.6960 - val_loss: 10934.8545 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00139: val_loss improved from 11060.21274 to 10934.85449, saving model to test.hdf5\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13353.5281 - acc: 0.6880 - val_loss: 10588.8197 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00140: val_loss improved from 10934.85449 to 10588.81973, saving model to test.hdf5\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 13074.1266 - acc: 0.6600 - val_loss: 10408.6313 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00141: val_loss improved from 10588.81973 to 10408.63130, saving model to test.hdf5\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 12687.7643 - acc: 0.7400 - val_loss: 10278.0764 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00142: val_loss improved from 10408.63130 to 10278.07642, saving model to test.hdf5\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 12409.2462 - acc: 0.6880 - val_loss: 9870.5924 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00143: val_loss improved from 10278.07642 to 9870.59241, saving model to test.hdf5\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 12210.2026 - acc: 0.6960 - val_loss: 9689.9921 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00144: val_loss improved from 9870.59241 to 9689.99206, saving model to test.hdf5\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 11887.9219 - acc: 0.7080 - val_loss: 9490.2274 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 00145: val_loss improved from 9689.99206 to 9490.22740, saving model to test.hdf5\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 11521.2933 - acc: 0.7280 - val_loss: 9318.1054 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00146: val_loss improved from 9490.22740 to 9318.10537, saving model to test.hdf5\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 11193.4646 - acc: 0.7200 - val_loss: 9048.7885 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00147: val_loss improved from 9318.10537 to 9048.78851, saving model to test.hdf5\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 10889.3285 - acc: 0.6880 - val_loss: 8931.3930 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00148: val_loss improved from 9048.78851 to 8931.39301, saving model to test.hdf5\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 10835.4993 - acc: 0.7720 - val_loss: 8775.8618 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00149: val_loss improved from 8931.39301 to 8775.86179, saving model to test.hdf5\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 10549.4075 - acc: 0.7040 - val_loss: 8532.4110 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00150: val_loss improved from 8775.86179 to 8532.41099, saving model to test.hdf5\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 10139.5381 - acc: 0.6840 - val_loss: 8348.0286 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00151: val_loss improved from 8532.41099 to 8348.02856, saving model to test.hdf5\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 10043.6689 - acc: 0.7160 - val_loss: 8162.0815 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00152: val_loss improved from 8348.02856 to 8162.08151, saving model to test.hdf5\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 9787.3441 - acc: 0.6760 - val_loss: 8057.5554 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00153: val_loss improved from 8162.08151 to 8057.55545, saving model to test.hdf5\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 9541.8921 - acc: 0.7160 - val_loss: 7898.5649 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00154: val_loss improved from 8057.55545 to 7898.56492, saving model to test.hdf5\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 9350.0090 - acc: 0.7080 - val_loss: 7691.8967 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00155: val_loss improved from 7898.56492 to 7691.89669, saving model to test.hdf5\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 9237.1033 - acc: 0.6760 - val_loss: 7581.4682 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00156: val_loss improved from 7691.89669 to 7581.46818, saving model to test.hdf5\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 8932.2410 - acc: 0.7360 - val_loss: 7469.3413 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00157: val_loss improved from 7581.46818 to 7469.34134, saving model to test.hdf5\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 8790.9847 - acc: 0.7080 - val_loss: 7228.1305 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00158: val_loss improved from 7469.34134 to 7228.13047, saving model to test.hdf5\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 8485.2109 - acc: 0.6880 - val_loss: 7140.2116 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00159: val_loss improved from 7228.13047 to 7140.21156, saving model to test.hdf5\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 8284.9025 - acc: 0.7560 - val_loss: 7008.0123 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00160: val_loss improved from 7140.21156 to 7008.01230, saving model to test.hdf5\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 8153.1798 - acc: 0.6960 - val_loss: 6749.0129 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00161: val_loss improved from 7008.01230 to 6749.01293, saving model to test.hdf5\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 7921.4573 - acc: 0.7200 - val_loss: 6724.6681 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00162: val_loss improved from 6749.01293 to 6724.66813, saving model to test.hdf5\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 7783.8544 - acc: 0.7000 - val_loss: 6539.9790 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00163: val_loss improved from 6724.66813 to 6539.97902, saving model to test.hdf5\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 7548.9476 - acc: 0.7120 - val_loss: 6358.6296 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00164: val_loss improved from 6539.97902 to 6358.62963, saving model to test.hdf5\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 7376.1331 - acc: 0.7120 - val_loss: 6255.1290 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00165: val_loss improved from 6358.62963 to 6255.12902, saving model to test.hdf5\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 7222.8430 - acc: 0.6880 - val_loss: 6127.0906 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00166: val_loss improved from 6255.12902 to 6127.09063, saving model to test.hdf5\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 7075.2967 - acc: 0.7120 - val_loss: 5944.0281 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00167: val_loss improved from 6127.09063 to 5944.02807, saving model to test.hdf5\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 6932.5326 - acc: 0.6520 - val_loss: 5841.5372 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00168: val_loss improved from 5944.02807 to 5841.53717, saving model to test.hdf5\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6757.4264 - acc: 0.7000 - val_loss: 5745.0145 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00169: val_loss improved from 5841.53717 to 5745.01454, saving model to test.hdf5\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 6578.4960 - acc: 0.6880 - val_loss: 5590.0247 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "\n",
      "Epoch 00170: val_loss improved from 5745.01454 to 5590.02466, saving model to test.hdf5\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 6342.3357 - acc: 0.7400 - val_loss: 5501.4016 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00171: val_loss improved from 5590.02466 to 5501.40161, saving model to test.hdf5\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 6247.0748 - acc: 0.7080 - val_loss: 5413.6729 - val_acc: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00172: val_loss improved from 5501.40161 to 5413.67290, saving model to test.hdf5\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6128.1323 - acc: 0.6640 - val_loss: 5309.0898 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00173: val_loss improved from 5413.67290 to 5309.08976, saving model to test.hdf5\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6042.8232 - acc: 0.6720 - val_loss: 5166.4763 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00174: val_loss improved from 5309.08976 to 5166.47635, saving model to test.hdf5\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 5896.1146 - acc: 0.7000 - val_loss: 5060.4559 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00175: val_loss improved from 5166.47635 to 5060.45589, saving model to test.hdf5\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 5795.7000 - acc: 0.6880 - val_loss: 4959.7387 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00176: val_loss improved from 5060.45589 to 4959.73873, saving model to test.hdf5\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 5572.7909 - acc: 0.6960 - val_loss: 4863.4458 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00177: val_loss improved from 4959.73873 to 4863.44580, saving model to test.hdf5\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 5441.7607 - acc: 0.6520 - val_loss: 4789.5656 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00178: val_loss improved from 4863.44580 to 4789.56557, saving model to test.hdf5\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 5420.7178 - acc: 0.7040 - val_loss: 4669.7024 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00179: val_loss improved from 4789.56557 to 4669.70240, saving model to test.hdf5\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 5194.1586 - acc: 0.6840 - val_loss: 4586.8058 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00180: val_loss improved from 4669.70240 to 4586.80576, saving model to test.hdf5\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 5087.4351 - acc: 0.7680 - val_loss: 4554.5414 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00181: val_loss improved from 4586.80576 to 4554.54136, saving model to test.hdf5\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 5022.1896 - acc: 0.6720 - val_loss: 4438.0131 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00182: val_loss improved from 4554.54136 to 4438.01313, saving model to test.hdf5\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 4896.9068 - acc: 0.6960 - val_loss: 4317.1265 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00183: val_loss improved from 4438.01313 to 4317.12651, saving model to test.hdf5\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 4798.3468 - acc: 0.7400 - val_loss: 4216.1064 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00184: val_loss improved from 4317.12651 to 4216.10638, saving model to test.hdf5\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 4677.4741 - acc: 0.7560 - val_loss: 4152.4604 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00185: val_loss improved from 4216.10638 to 4152.46039, saving model to test.hdf5\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 4544.2240 - acc: 0.7040 - val_loss: 4037.5492 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00186: val_loss improved from 4152.46039 to 4037.54921, saving model to test.hdf5\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 4465.9737 - acc: 0.7080 - val_loss: 3957.6739 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00187: val_loss improved from 4037.54921 to 3957.67388, saving model to test.hdf5\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 4340.9942 - acc: 0.6760 - val_loss: 3904.3001 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00188: val_loss improved from 3957.67388 to 3904.30007, saving model to test.hdf5\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 4273.7138 - acc: 0.6960 - val_loss: 3780.8176 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00189: val_loss improved from 3904.30007 to 3780.81762, saving model to test.hdf5\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 4187.8154 - acc: 0.6760 - val_loss: 3759.5154 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00190: val_loss improved from 3780.81762 to 3759.51541, saving model to test.hdf5\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 4048.3332 - acc: 0.6800 - val_loss: 3648.9659 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00191: val_loss improved from 3759.51541 to 3648.96593, saving model to test.hdf5\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 3937.8562 - acc: 0.6760 - val_loss: 3568.2266 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00192: val_loss improved from 3648.96593 to 3568.22662, saving model to test.hdf5\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 3869.7033 - acc: 0.7240 - val_loss: 3494.6229 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00193: val_loss improved from 3568.22662 to 3494.62287, saving model to test.hdf5\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 3805.8982 - acc: 0.7080 - val_loss: 3420.6686 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00194: val_loss improved from 3494.62287 to 3420.66856, saving model to test.hdf5\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 3685.3951 - acc: 0.7080 - val_loss: 3359.1296 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "\n",
      "Epoch 00195: val_loss improved from 3420.66856 to 3359.12957, saving model to test.hdf5\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 3616.0187 - acc: 0.7160 - val_loss: 3297.5774 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00196: val_loss improved from 3359.12957 to 3297.57739, saving model to test.hdf5\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 3528.3205 - acc: 0.6840 - val_loss: 3209.8195 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00197: val_loss improved from 3297.57739 to 3209.81945, saving model to test.hdf5\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 3468.3520 - acc: 0.6560 - val_loss: 3199.3356 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00198: val_loss improved from 3209.81945 to 3199.33558, saving model to test.hdf5\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 3396.0419 - acc: 0.7120 - val_loss: 3090.1192 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00199: val_loss improved from 3199.33558 to 3090.11918, saving model to test.hdf5\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 3251.2291 - acc: 0.7280 - val_loss: 3020.5096 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00200: val_loss improved from 3090.11918 to 3020.50964, saving model to test.hdf5\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 3261.3269 - acc: 0.6800 - val_loss: 2969.5939 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00201: val_loss improved from 3020.50964 to 2969.59388, saving model to test.hdf5\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 3129.1742 - acc: 0.6920 - val_loss: 2950.1558 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00202: val_loss improved from 2969.59388 to 2950.15576, saving model to test.hdf5\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 3098.3375 - acc: 0.7000 - val_loss: 2870.9493 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00203: val_loss improved from 2950.15576 to 2870.94933, saving model to test.hdf5\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 3013.1833 - acc: 0.7160 - val_loss: 2797.0491 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00204: val_loss improved from 2870.94933 to 2797.04905, saving model to test.hdf5\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2953.0993 - acc: 0.7280 - val_loss: 2761.1554 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00205: val_loss improved from 2797.04905 to 2761.15541, saving model to test.hdf5\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2867.2766 - acc: 0.6800 - val_loss: 2709.6490 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00206: val_loss improved from 2761.15541 to 2709.64902, saving model to test.hdf5\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 2813.3621 - acc: 0.7080 - val_loss: 2634.9010 - val_acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00207: val_loss improved from 2709.64902 to 2634.90097, saving model to test.hdf5\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2726.7185 - acc: 0.7280 - val_loss: 2592.3558 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00208: val_loss improved from 2634.90097 to 2592.35582, saving model to test.hdf5\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 2690.1520 - acc: 0.7440 - val_loss: 2533.9774 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00209: val_loss improved from 2592.35582 to 2533.97745, saving model to test.hdf5\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 2624.6671 - acc: 0.6840 - val_loss: 2494.6741 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00210: val_loss improved from 2533.97745 to 2494.67406, saving model to test.hdf5\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2570.2183 - acc: 0.7120 - val_loss: 2435.1648 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00211: val_loss improved from 2494.67406 to 2435.16478, saving model to test.hdf5\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 2512.4138 - acc: 0.7320 - val_loss: 2393.3996 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00212: val_loss improved from 2435.16478 to 2393.39964, saving model to test.hdf5\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 2459.5263 - acc: 0.6400 - val_loss: 2306.5709 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00213: val_loss improved from 2393.39964 to 2306.57087, saving model to test.hdf5\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 2408.9123 - acc: 0.7160 - val_loss: 2302.6055 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00214: val_loss improved from 2306.57087 to 2302.60555, saving model to test.hdf5\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 2345.8109 - acc: 0.7080 - val_loss: 2245.3892 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00215: val_loss improved from 2302.60555 to 2245.38917, saving model to test.hdf5\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2274.8421 - acc: 0.7080 - val_loss: 2197.4945 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00216: val_loss improved from 2245.38917 to 2197.49446, saving model to test.hdf5\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 2212.7424 - acc: 0.7320 - val_loss: 2182.3365 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00217: val_loss improved from 2197.49446 to 2182.33654, saving model to test.hdf5\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 2185.7353 - acc: 0.6760 - val_loss: 2099.7858 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00218: val_loss improved from 2182.33654 to 2099.78583, saving model to test.hdf5\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2139.5779 - acc: 0.7440 - val_loss: 2060.2255 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00219: val_loss improved from 2099.78583 to 2060.22546, saving model to test.hdf5\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 2080.8775 - acc: 0.6920 - val_loss: 2030.1600 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "\n",
      "Epoch 00220: val_loss improved from 2060.22546 to 2030.15999, saving model to test.hdf5\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 2045.6351 - acc: 0.7120 - val_loss: 1999.3429 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00221: val_loss improved from 2030.15999 to 1999.34294, saving model to test.hdf5\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1996.9820 - acc: 0.7240 - val_loss: 1945.2827 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00222: val_loss improved from 1999.34294 to 1945.28269, saving model to test.hdf5\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1932.0429 - acc: 0.6920 - val_loss: 1917.1270 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00223: val_loss improved from 1945.28269 to 1917.12699, saving model to test.hdf5\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1903.8440 - acc: 0.7440 - val_loss: 1866.6715 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00224: val_loss improved from 1917.12699 to 1866.67147, saving model to test.hdf5\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1857.4264 - acc: 0.6680 - val_loss: 1820.8760 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00225: val_loss improved from 1866.67147 to 1820.87604, saving model to test.hdf5\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1813.1207 - acc: 0.6920 - val_loss: 1786.1871 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00226: val_loss improved from 1820.87604 to 1786.18709, saving model to test.hdf5\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 1780.7120 - acc: 0.7200 - val_loss: 1751.9278 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00227: val_loss improved from 1786.18709 to 1751.92782, saving model to test.hdf5\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1748.5471 - acc: 0.7400 - val_loss: 1718.0382 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00228: val_loss improved from 1751.92782 to 1718.03820, saving model to test.hdf5\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1691.0472 - acc: 0.7200 - val_loss: 1714.1650 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00229: val_loss improved from 1718.03820 to 1714.16502, saving model to test.hdf5\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1678.3878 - acc: 0.6920 - val_loss: 1658.0597 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00230: val_loss improved from 1714.16502 to 1658.05973, saving model to test.hdf5\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1635.5376 - acc: 0.6800 - val_loss: 1627.1122 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00231: val_loss improved from 1658.05973 to 1627.11218, saving model to test.hdf5\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 1593.3168 - acc: 0.7000 - val_loss: 1597.8528 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00232: val_loss improved from 1627.11218 to 1597.85282, saving model to test.hdf5\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1563.5958 - acc: 0.7240 - val_loss: 1550.9652 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00233: val_loss improved from 1597.85282 to 1550.96522, saving model to test.hdf5\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1517.5998 - acc: 0.7400 - val_loss: 1528.2684 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00234: val_loss improved from 1550.96522 to 1528.26841, saving model to test.hdf5\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1488.0724 - acc: 0.7520 - val_loss: 1503.1211 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00235: val_loss improved from 1528.26841 to 1503.12112, saving model to test.hdf5\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1462.8298 - acc: 0.7240 - val_loss: 1473.4058 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00236: val_loss improved from 1503.12112 to 1473.40583, saving model to test.hdf5\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1404.1979 - acc: 0.7640 - val_loss: 1440.3439 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00237: val_loss improved from 1473.40583 to 1440.34393, saving model to test.hdf5\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1381.8110 - acc: 0.7760 - val_loss: 1422.6840 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00238: val_loss improved from 1440.34393 to 1422.68403, saving model to test.hdf5\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1348.4513 - acc: 0.7360 - val_loss: 1373.2210 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00239: val_loss improved from 1422.68403 to 1373.22103, saving model to test.hdf5\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1338.9680 - acc: 0.7120 - val_loss: 1346.9782 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00240: val_loss improved from 1373.22103 to 1346.97821, saving model to test.hdf5\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1276.6309 - acc: 0.7360 - val_loss: 1323.6829 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00241: val_loss improved from 1346.97821 to 1323.68289, saving model to test.hdf5\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 1266.8486 - acc: 0.7400 - val_loss: 1294.0226 - val_acc: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00242: val_loss improved from 1323.68289 to 1294.02261, saving model to test.hdf5\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 1209.7507 - acc: 0.7480 - val_loss: 1275.8521 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00243: val_loss improved from 1294.02261 to 1275.85207, saving model to test.hdf5\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1198.8213 - acc: 0.7440 - val_loss: 1243.5170 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00244: val_loss improved from 1275.85207 to 1243.51696, saving model to test.hdf5\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 1168.9481 - acc: 0.7720 - val_loss: 1217.0204 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "\n",
      "Epoch 00245: val_loss improved from 1243.51696 to 1217.02038, saving model to test.hdf5\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1146.5785 - acc: 0.6960 - val_loss: 1195.1792 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00246: val_loss improved from 1217.02038 to 1195.17919, saving model to test.hdf5\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 1121.5130 - acc: 0.7520 - val_loss: 1167.4622 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00247: val_loss improved from 1195.17919 to 1167.46218, saving model to test.hdf5\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1103.0591 - acc: 0.7240 - val_loss: 1162.2848 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00248: val_loss improved from 1167.46218 to 1162.28483, saving model to test.hdf5\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1054.2664 - acc: 0.7760 - val_loss: 1122.4301 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00249: val_loss improved from 1162.28483 to 1122.43012, saving model to test.hdf5\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 1052.7314 - acc: 0.7640 - val_loss: 1098.4297 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00250: val_loss improved from 1122.43012 to 1098.42968, saving model to test.hdf5\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1037.4515 - acc: 0.7480 - val_loss: 1080.8596 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00251: val_loss improved from 1098.42968 to 1080.85960, saving model to test.hdf5\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1006.2293 - acc: 0.7480 - val_loss: 1066.2600 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00252: val_loss improved from 1080.85960 to 1066.25997, saving model to test.hdf5\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 982.1114 - acc: 0.7680 - val_loss: 1037.9094 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00253: val_loss improved from 1066.25997 to 1037.90937, saving model to test.hdf5\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 970.5630 - acc: 0.7040 - val_loss: 1019.2980 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00254: val_loss improved from 1037.90937 to 1019.29803, saving model to test.hdf5\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 949.2439 - acc: 0.7440 - val_loss: 1003.8898 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00255: val_loss improved from 1019.29803 to 1003.88983, saving model to test.hdf5\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 916.0391 - acc: 0.7600 - val_loss: 980.8295 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00256: val_loss improved from 1003.88983 to 980.82949, saving model to test.hdf5\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 896.5057 - acc: 0.7520 - val_loss: 968.2572 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00257: val_loss improved from 980.82949 to 968.25716, saving model to test.hdf5\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 878.4165 - acc: 0.6760 - val_loss: 945.3774 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00258: val_loss improved from 968.25716 to 945.37740, saving model to test.hdf5\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 860.0721 - acc: 0.7720 - val_loss: 929.0311 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00259: val_loss improved from 945.37740 to 929.03113, saving model to test.hdf5\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 832.8980 - acc: 0.7640 - val_loss: 918.9040 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00260: val_loss improved from 929.03113 to 918.90402, saving model to test.hdf5\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 822.0646 - acc: 0.7000 - val_loss: 886.7357 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00261: val_loss improved from 918.90402 to 886.73567, saving model to test.hdf5\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 809.8806 - acc: 0.7120 - val_loss: 865.3753 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00262: val_loss improved from 886.73567 to 865.37531, saving model to test.hdf5\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 790.6812 - acc: 0.7720 - val_loss: 851.1039 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00263: val_loss improved from 865.37531 to 851.10393, saving model to test.hdf5\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 762.2365 - acc: 0.7440 - val_loss: 836.4921 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00264: val_loss improved from 851.10393 to 836.49209, saving model to test.hdf5\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 753.8294 - acc: 0.7720 - val_loss: 812.2584 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00265: val_loss improved from 836.49209 to 812.25841, saving model to test.hdf5\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 731.8090 - acc: 0.7440 - val_loss: 814.6401 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 812.25841\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 716.8963 - acc: 0.7520 - val_loss: 787.4012 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00267: val_loss improved from 812.25841 to 787.40119, saving model to test.hdf5\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 692.7551 - acc: 0.7240 - val_loss: 766.0359 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00268: val_loss improved from 787.40119 to 766.03585, saving model to test.hdf5\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 683.5904 - acc: 0.7800 - val_loss: 756.6950 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00269: val_loss improved from 766.03585 to 756.69497, saving model to test.hdf5\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 662.0723 - acc: 0.7320 - val_loss: 742.9197 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00270: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "\n",
      "Epoch 00270: val_loss improved from 756.69497 to 742.91967, saving model to test.hdf5\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 653.2941 - acc: 0.7520 - val_loss: 717.7753 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00271: val_loss improved from 742.91967 to 717.77531, saving model to test.hdf5\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 635.7867 - acc: 0.7680 - val_loss: 707.9069 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00272: val_loss improved from 717.77531 to 707.90687, saving model to test.hdf5\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 608.1114 - acc: 0.7360 - val_loss: 705.5375 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00273: val_loss improved from 707.90687 to 705.53754, saving model to test.hdf5\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 604.0858 - acc: 0.7880 - val_loss: 684.9500 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00274: val_loss improved from 705.53754 to 684.95002, saving model to test.hdf5\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 596.3675 - acc: 0.7680 - val_loss: 677.1385 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00275: val_loss improved from 684.95002 to 677.13848, saving model to test.hdf5\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 577.8325 - acc: 0.7600 - val_loss: 654.6928 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00276: val_loss improved from 677.13848 to 654.69278, saving model to test.hdf5\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 570.1160 - acc: 0.7280 - val_loss: 642.6379 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00277: val_loss improved from 654.69278 to 642.63791, saving model to test.hdf5\n",
      "Epoch 278/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 181us/step - loss: 549.1996 - acc: 0.7560 - val_loss: 626.6968 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00278: val_loss improved from 642.63791 to 626.69677, saving model to test.hdf5\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 546.2747 - acc: 0.7360 - val_loss: 620.6289 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00279: val_loss improved from 626.69677 to 620.62894, saving model to test.hdf5\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 531.4758 - acc: 0.7440 - val_loss: 599.3723 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00280: val_loss improved from 620.62894 to 599.37227, saving model to test.hdf5\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 523.6794 - acc: 0.7520 - val_loss: 591.3804 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00281: val_loss improved from 599.37227 to 591.38043, saving model to test.hdf5\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 508.4045 - acc: 0.7800 - val_loss: 582.9939 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00282: val_loss improved from 591.38043 to 582.99391, saving model to test.hdf5\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 493.8708 - acc: 0.7720 - val_loss: 575.7718 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00283: val_loss improved from 582.99391 to 575.77184, saving model to test.hdf5\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 488.7110 - acc: 0.7440 - val_loss: 552.4531 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00284: val_loss improved from 575.77184 to 552.45312, saving model to test.hdf5\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 475.4324 - acc: 0.7560 - val_loss: 551.4806 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00285: val_loss improved from 552.45312 to 551.48060, saving model to test.hdf5\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 201us/step - loss: 467.0049 - acc: 0.7800 - val_loss: 533.5405 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00286: val_loss improved from 551.48060 to 533.54054, saving model to test.hdf5\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 453.7035 - acc: 0.7720 - val_loss: 523.1966 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00287: val_loss improved from 533.54054 to 523.19663, saving model to test.hdf5\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 444.0196 - acc: 0.7480 - val_loss: 512.1105 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00288: val_loss improved from 523.19663 to 512.11046, saving model to test.hdf5\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 439.3009 - acc: 0.7480 - val_loss: 507.6674 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00289: val_loss improved from 512.11046 to 507.66744, saving model to test.hdf5\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 414.0000 - acc: 0.7800 - val_loss: 487.7216 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00290: val_loss improved from 507.66744 to 487.72162, saving model to test.hdf5\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 414.8689 - acc: 0.7880 - val_loss: 476.5270 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00291: val_loss improved from 487.72162 to 476.52703, saving model to test.hdf5\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 405.7433 - acc: 0.7840 - val_loss: 472.3468 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00292: val_loss improved from 476.52703 to 472.34679, saving model to test.hdf5\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 395.2657 - acc: 0.7400 - val_loss: 461.4150 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00293: val_loss improved from 472.34679 to 461.41500, saving model to test.hdf5\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 381.4896 - acc: 0.7680 - val_loss: 448.0529 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00294: val_loss improved from 461.41500 to 448.05289, saving model to test.hdf5\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 372.8386 - acc: 0.7600 - val_loss: 446.0652 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00295: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "\n",
      "Epoch 00295: val_loss improved from 448.05289 to 446.06525, saving model to test.hdf5\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 365.2112 - acc: 0.7880 - val_loss: 439.8318 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00296: val_loss improved from 446.06525 to 439.83176, saving model to test.hdf5\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 359.6030 - acc: 0.7720 - val_loss: 427.0040 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00297: val_loss improved from 439.83176 to 427.00405, saving model to test.hdf5\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 349.3922 - acc: 0.7800 - val_loss: 415.7650 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00298: val_loss improved from 427.00405 to 415.76497, saving model to test.hdf5\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 346.2835 - acc: 0.7640 - val_loss: 407.2425 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00299: val_loss improved from 415.76497 to 407.24252, saving model to test.hdf5\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 334.7686 - acc: 0.8320 - val_loss: 406.4259 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00300: val_loss improved from 407.24252 to 406.42592, saving model to test.hdf5\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 328.4456 - acc: 0.8000 - val_loss: 392.4017 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00301: val_loss improved from 406.42592 to 392.40174, saving model to test.hdf5\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 321.4813 - acc: 0.7520 - val_loss: 387.3875 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00302: val_loss improved from 392.40174 to 387.38753, saving model to test.hdf5\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 309.8090 - acc: 0.7760 - val_loss: 375.0028 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00303: val_loss improved from 387.38753 to 375.00283, saving model to test.hdf5\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 306.4070 - acc: 0.7880 - val_loss: 368.9947 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00304: val_loss improved from 375.00283 to 368.99465, saving model to test.hdf5\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 294.6372 - acc: 0.7480 - val_loss: 364.9947 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00305: val_loss improved from 368.99465 to 364.99470, saving model to test.hdf5\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 288.3222 - acc: 0.7360 - val_loss: 359.4572 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00306: val_loss improved from 364.99470 to 359.45725, saving model to test.hdf5\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 288.2437 - acc: 0.7760 - val_loss: 344.7546 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00307: val_loss improved from 359.45725 to 344.75465, saving model to test.hdf5\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 282.5840 - acc: 0.7720 - val_loss: 341.1731 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00308: val_loss improved from 344.75465 to 341.17306, saving model to test.hdf5\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 274.9446 - acc: 0.7760 - val_loss: 332.0681 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00309: val_loss improved from 341.17306 to 332.06805, saving model to test.hdf5\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 265.4072 - acc: 0.8000 - val_loss: 329.5151 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00310: val_loss improved from 332.06805 to 329.51508, saving model to test.hdf5\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 260.4528 - acc: 0.7480 - val_loss: 319.5756 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00311: val_loss improved from 329.51508 to 319.57558, saving model to test.hdf5\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 256.1657 - acc: 0.7360 - val_loss: 312.2283 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00312: val_loss improved from 319.57558 to 312.22827, saving model to test.hdf5\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 250.8986 - acc: 0.7600 - val_loss: 312.8959 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 312.22827\n",
      "Epoch 314/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 208us/step - loss: 245.5344 - acc: 0.7760 - val_loss: 299.9450 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00314: val_loss improved from 312.22827 to 299.94505, saving model to test.hdf5\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 238.1576 - acc: 0.8120 - val_loss: 291.4627 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00315: val_loss improved from 299.94505 to 291.46269, saving model to test.hdf5\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 235.2275 - acc: 0.7960 - val_loss: 287.7122 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00316: val_loss improved from 291.46269 to 287.71217, saving model to test.hdf5\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 222.8020 - acc: 0.7920 - val_loss: 284.2660 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00317: val_loss improved from 287.71217 to 284.26600, saving model to test.hdf5\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 219.9604 - acc: 0.7800 - val_loss: 278.3867 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00318: val_loss improved from 284.26600 to 278.38670, saving model to test.hdf5\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 214.0107 - acc: 0.7640 - val_loss: 268.0822 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00319: val_loss improved from 278.38670 to 268.08221, saving model to test.hdf5\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 212.6151 - acc: 0.7720 - val_loss: 265.3880 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00320: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "\n",
      "Epoch 00320: val_loss improved from 268.08221 to 265.38797, saving model to test.hdf5\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 208.1266 - acc: 0.7680 - val_loss: 259.9509 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00321: val_loss improved from 265.38797 to 259.95094, saving model to test.hdf5\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 200.0558 - acc: 0.7880 - val_loss: 250.2563 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00322: val_loss improved from 259.95094 to 250.25633, saving model to test.hdf5\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 196.4367 - acc: 0.7560 - val_loss: 250.1501 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00323: val_loss improved from 250.25633 to 250.15008, saving model to test.hdf5\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 194.0756 - acc: 0.7760 - val_loss: 241.5048 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00324: val_loss improved from 250.15008 to 241.50475, saving model to test.hdf5\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 189.9985 - acc: 0.7320 - val_loss: 237.1371 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00325: val_loss improved from 241.50475 to 237.13710, saving model to test.hdf5\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 185.1313 - acc: 0.8000 - val_loss: 234.6758 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00326: val_loss improved from 237.13710 to 234.67579, saving model to test.hdf5\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 181.6933 - acc: 0.7680 - val_loss: 229.0545 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00327: val_loss improved from 234.67579 to 229.05453, saving model to test.hdf5\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 174.8244 - acc: 0.7680 - val_loss: 227.7357 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00328: val_loss improved from 229.05453 to 227.73569, saving model to test.hdf5\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 173.5749 - acc: 0.8000 - val_loss: 218.2516 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00329: val_loss improved from 227.73569 to 218.25160, saving model to test.hdf5\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 169.1073 - acc: 0.7480 - val_loss: 213.7626 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00330: val_loss improved from 218.25160 to 213.76263, saving model to test.hdf5\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 165.1344 - acc: 0.7760 - val_loss: 211.1785 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00331: val_loss improved from 213.76263 to 211.17854, saving model to test.hdf5\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 161.9043 - acc: 0.7720 - val_loss: 206.9960 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00332: val_loss improved from 211.17854 to 206.99597, saving model to test.hdf5\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 156.7669 - acc: 0.7960 - val_loss: 201.9133 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00333: val_loss improved from 206.99597 to 201.91332, saving model to test.hdf5\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 153.5003 - acc: 0.7520 - val_loss: 198.6711 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00334: val_loss improved from 201.91332 to 198.67106, saving model to test.hdf5\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 149.8582 - acc: 0.7880 - val_loss: 195.3019 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00335: val_loss improved from 198.67106 to 195.30194, saving model to test.hdf5\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 144.5861 - acc: 0.7800 - val_loss: 190.2205 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00336: val_loss improved from 195.30194 to 190.22055, saving model to test.hdf5\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 142.0669 - acc: 0.7640 - val_loss: 185.0022 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00337: val_loss improved from 190.22055 to 185.00217, saving model to test.hdf5\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 139.5897 - acc: 0.7800 - val_loss: 179.2185 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00338: val_loss improved from 185.00217 to 179.21853, saving model to test.hdf5\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 137.4586 - acc: 0.7640 - val_loss: 177.6967 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00339: val_loss improved from 179.21853 to 177.69672, saving model to test.hdf5\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 134.6947 - acc: 0.7800 - val_loss: 175.3368 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00340: val_loss improved from 177.69672 to 175.33678, saving model to test.hdf5\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 127.3649 - acc: 0.7840 - val_loss: 169.4279 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00341: val_loss improved from 175.33678 to 169.42794, saving model to test.hdf5\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 126.1549 - acc: 0.7720 - val_loss: 168.4771 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00342: val_loss improved from 169.42794 to 168.47711, saving model to test.hdf5\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 124.2662 - acc: 0.7640 - val_loss: 162.3686 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00343: val_loss improved from 168.47711 to 162.36862, saving model to test.hdf5\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 120.6096 - acc: 0.7920 - val_loss: 158.8733 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00344: val_loss improved from 162.36862 to 158.87335, saving model to test.hdf5\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 119.2027 - acc: 0.7920 - val_loss: 155.5087 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00345: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "\n",
      "Epoch 00345: val_loss improved from 158.87335 to 155.50869, saving model to test.hdf5\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 113.2082 - acc: 0.7880 - val_loss: 151.1555 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00346: val_loss improved from 155.50869 to 151.15549, saving model to test.hdf5\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 114.1132 - acc: 0.7960 - val_loss: 147.3820 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00347: val_loss improved from 151.15549 to 147.38198, saving model to test.hdf5\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 108.4157 - acc: 0.8280 - val_loss: 145.7813 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00348: val_loss improved from 147.38198 to 145.78127, saving model to test.hdf5\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 108.4553 - acc: 0.7960 - val_loss: 141.3886 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00349: val_loss improved from 145.78127 to 141.38856, saving model to test.hdf5\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 105.8299 - acc: 0.7960 - val_loss: 139.8992 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00350: val_loss improved from 141.38856 to 139.89922, saving model to test.hdf5\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 103.5048 - acc: 0.7880 - val_loss: 137.8410 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00351: val_loss improved from 139.89922 to 137.84103, saving model to test.hdf5\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 100.8007 - acc: 0.7640 - val_loss: 133.2683 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00352: val_loss improved from 137.84103 to 133.26826, saving model to test.hdf5\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 99.5984 - acc: 0.7400 - val_loss: 131.1963 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00353: val_loss improved from 133.26826 to 131.19633, saving model to test.hdf5\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 95.2570 - acc: 0.7440 - val_loss: 128.9742 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00354: val_loss improved from 131.19633 to 128.97424, saving model to test.hdf5\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 93.4325 - acc: 0.7800 - val_loss: 125.1341 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00355: val_loss improved from 128.97424 to 125.13406, saving model to test.hdf5\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 92.0082 - acc: 0.8040 - val_loss: 122.2572 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00356: val_loss improved from 125.13406 to 122.25716, saving model to test.hdf5\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 90.3153 - acc: 0.7760 - val_loss: 120.5929 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00357: val_loss improved from 122.25716 to 120.59288, saving model to test.hdf5\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 87.3065 - acc: 0.8120 - val_loss: 117.0135 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00358: val_loss improved from 120.59288 to 117.01355, saving model to test.hdf5\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 85.4864 - acc: 0.7680 - val_loss: 114.6475 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00359: val_loss improved from 117.01355 to 114.64748, saving model to test.hdf5\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 84.0403 - acc: 0.7840 - val_loss: 113.0133 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00360: val_loss improved from 114.64748 to 113.01333, saving model to test.hdf5\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 81.6171 - acc: 0.7480 - val_loss: 109.5529 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00361: val_loss improved from 113.01333 to 109.55289, saving model to test.hdf5\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 78.2134 - acc: 0.8240 - val_loss: 108.1566 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00362: val_loss improved from 109.55289 to 108.15660, saving model to test.hdf5\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 77.6004 - acc: 0.7800 - val_loss: 104.2603 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00363: val_loss improved from 108.15660 to 104.26028, saving model to test.hdf5\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 74.6873 - acc: 0.7760 - val_loss: 103.0055 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00364: val_loss improved from 104.26028 to 103.00550, saving model to test.hdf5\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 73.8104 - acc: 0.7680 - val_loss: 100.2807 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00365: val_loss improved from 103.00550 to 100.28069, saving model to test.hdf5\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 72.5109 - acc: 0.7680 - val_loss: 98.3249 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00366: val_loss improved from 100.28069 to 98.32493, saving model to test.hdf5\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 70.9534 - acc: 0.7880 - val_loss: 97.6288 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00367: val_loss improved from 98.32493 to 97.62882, saving model to test.hdf5\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 68.1078 - acc: 0.7760 - val_loss: 92.7851 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00368: val_loss improved from 97.62882 to 92.78509, saving model to test.hdf5\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 67.6993 - acc: 0.8000 - val_loss: 92.3488 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00369: val_loss improved from 92.78509 to 92.34882, saving model to test.hdf5\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 65.7988 - acc: 0.8200 - val_loss: 90.7225 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00370: val_loss improved from 92.34882 to 90.72254, saving model to test.hdf5\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 63.7857 - acc: 0.7680 - val_loss: 86.0419 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00371: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "\n",
      "Epoch 00371: val_loss improved from 90.72254 to 86.04187, saving model to test.hdf5\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 62.4389 - acc: 0.7880 - val_loss: 84.6491 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00372: val_loss improved from 86.04187 to 84.64907, saving model to test.hdf5\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 60.9304 - acc: 0.7720 - val_loss: 84.8033 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 84.64907\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 59.3453 - acc: 0.7880 - val_loss: 81.1068 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00374: val_loss improved from 84.64907 to 81.10679, saving model to test.hdf5\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 58.0852 - acc: 0.7960 - val_loss: 80.0827 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00375: val_loss improved from 81.10679 to 80.08272, saving model to test.hdf5\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 56.2543 - acc: 0.8160 - val_loss: 77.4953 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00376: val_loss improved from 80.08272 to 77.49530, saving model to test.hdf5\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 55.3316 - acc: 0.7880 - val_loss: 77.2193 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00377: val_loss improved from 77.49530 to 77.21926, saving model to test.hdf5\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 53.8880 - acc: 0.8000 - val_loss: 75.8904 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00378: val_loss improved from 77.21926 to 75.89042, saving model to test.hdf5\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 52.2095 - acc: 0.7840 - val_loss: 74.0254 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00379: val_loss improved from 75.89042 to 74.02542, saving model to test.hdf5\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 52.2383 - acc: 0.7720 - val_loss: 71.7483 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00380: val_loss improved from 74.02542 to 71.74826, saving model to test.hdf5\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 49.9067 - acc: 0.8080 - val_loss: 69.8711 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00381: val_loss improved from 71.74826 to 69.87110, saving model to test.hdf5\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 48.7859 - acc: 0.8000 - val_loss: 70.1347 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 69.87110\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 47.8666 - acc: 0.8000 - val_loss: 67.0091 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00383: val_loss improved from 69.87110 to 67.00908, saving model to test.hdf5\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 46.5172 - acc: 0.7840 - val_loss: 65.3730 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00384: val_loss improved from 67.00908 to 65.37297, saving model to test.hdf5\n",
      "Epoch 385/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 204us/step - loss: 45.3586 - acc: 0.7800 - val_loss: 63.5758 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00385: val_loss improved from 65.37297 to 63.57576, saving model to test.hdf5\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 43.8270 - acc: 0.7680 - val_loss: 63.3130 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00386: val_loss improved from 63.57576 to 63.31295, saving model to test.hdf5\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 43.5872 - acc: 0.7720 - val_loss: 61.7697 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00387: val_loss improved from 63.31295 to 61.76968, saving model to test.hdf5\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 42.1501 - acc: 0.7840 - val_loss: 59.0884 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00388: val_loss improved from 61.76968 to 59.08836, saving model to test.hdf5\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 41.4206 - acc: 0.7920 - val_loss: 58.4180 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00389: val_loss improved from 59.08836 to 58.41804, saving model to test.hdf5\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 39.6411 - acc: 0.7680 - val_loss: 57.1153 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00390: val_loss improved from 58.41804 to 57.11534, saving model to test.hdf5\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 39.7849 - acc: 0.7680 - val_loss: 55.3310 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00391: val_loss improved from 57.11534 to 55.33098, saving model to test.hdf5\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 39.2885 - acc: 0.7880 - val_loss: 54.6586 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00392: val_loss improved from 55.33098 to 54.65864, saving model to test.hdf5\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 37.2892 - acc: 0.7920 - val_loss: 52.9900 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00393: val_loss improved from 54.65864 to 52.98996, saving model to test.hdf5\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 35.3981 - acc: 0.7640 - val_loss: 51.3471 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00394: val_loss improved from 52.98996 to 51.34709, saving model to test.hdf5\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 35.7385 - acc: 0.8040 - val_loss: 51.2735 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00395: val_loss improved from 51.34709 to 51.27355, saving model to test.hdf5\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 34.5447 - acc: 0.8000 - val_loss: 50.3355 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00396: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "\n",
      "Epoch 00396: val_loss improved from 51.27355 to 50.33549, saving model to test.hdf5\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 34.2578 - acc: 0.8080 - val_loss: 48.1931 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00397: val_loss improved from 50.33549 to 48.19308, saving model to test.hdf5\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 32.8500 - acc: 0.8160 - val_loss: 46.9022 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00398: val_loss improved from 48.19308 to 46.90225, saving model to test.hdf5\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 32.2954 - acc: 0.8200 - val_loss: 45.7629 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00399: val_loss improved from 46.90225 to 45.76288, saving model to test.hdf5\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 31.2390 - acc: 0.8160 - val_loss: 44.7482 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00400: val_loss improved from 45.76288 to 44.74815, saving model to test.hdf5\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 30.9846 - acc: 0.8000 - val_loss: 44.7325 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00401: val_loss improved from 44.74815 to 44.73254, saving model to test.hdf5\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 30.1358 - acc: 0.7400 - val_loss: 42.5886 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00402: val_loss improved from 44.73254 to 42.58862, saving model to test.hdf5\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 29.0185 - acc: 0.7600 - val_loss: 42.4305 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00403: val_loss improved from 42.58862 to 42.43051, saving model to test.hdf5\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 28.5134 - acc: 0.7600 - val_loss: 40.9539 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00404: val_loss improved from 42.43051 to 40.95392, saving model to test.hdf5\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 27.7847 - acc: 0.7560 - val_loss: 40.0145 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00405: val_loss improved from 40.95392 to 40.01453, saving model to test.hdf5\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 27.1202 - acc: 0.7840 - val_loss: 39.0813 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00406: val_loss improved from 40.01453 to 39.08126, saving model to test.hdf5\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 26.3382 - acc: 0.8040 - val_loss: 38.3786 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00407: val_loss improved from 39.08126 to 38.37864, saving model to test.hdf5\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 25.4057 - acc: 0.8160 - val_loss: 38.0704 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00408: val_loss improved from 38.37864 to 38.07044, saving model to test.hdf5\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 25.9078 - acc: 0.7720 - val_loss: 36.1874 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00409: val_loss improved from 38.07044 to 36.18744, saving model to test.hdf5\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 24.9761 - acc: 0.7920 - val_loss: 35.4974 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00410: val_loss improved from 36.18744 to 35.49738, saving model to test.hdf5\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 23.8299 - acc: 0.8040 - val_loss: 34.6308 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00411: val_loss improved from 35.49738 to 34.63081, saving model to test.hdf5\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 23.3310 - acc: 0.7920 - val_loss: 33.9992 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00412: val_loss improved from 34.63081 to 33.99916, saving model to test.hdf5\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 22.7537 - acc: 0.7320 - val_loss: 33.5123 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00413: val_loss improved from 33.99916 to 33.51229, saving model to test.hdf5\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 22.5892 - acc: 0.7840 - val_loss: 32.0634 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00414: val_loss improved from 33.51229 to 32.06341, saving model to test.hdf5\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 22.1063 - acc: 0.8120 - val_loss: 31.6843 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00415: val_loss improved from 32.06341 to 31.68429, saving model to test.hdf5\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 21.1821 - acc: 0.8200 - val_loss: 30.3473 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00416: val_loss improved from 31.68429 to 30.34728, saving model to test.hdf5\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 20.8554 - acc: 0.7600 - val_loss: 30.2413 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00417: val_loss improved from 30.34728 to 30.24134, saving model to test.hdf5\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 20.0548 - acc: 0.7760 - val_loss: 28.8853 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00418: val_loss improved from 30.24134 to 28.88534, saving model to test.hdf5\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 19.4900 - acc: 0.7840 - val_loss: 28.9652 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 28.88534\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 19.1660 - acc: 0.7480 - val_loss: 27.7132 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00420: val_loss improved from 28.88534 to 27.71324, saving model to test.hdf5\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 18.6289 - acc: 0.8160 - val_loss: 26.7431 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00421: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "\n",
      "Epoch 00421: val_loss improved from 27.71324 to 26.74309, saving model to test.hdf5\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 17.8892 - acc: 0.7920 - val_loss: 26.5252 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00422: val_loss improved from 26.74309 to 26.52522, saving model to test.hdf5\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 17.5447 - acc: 0.8080 - val_loss: 25.7918 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00423: val_loss improved from 26.52522 to 25.79177, saving model to test.hdf5\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 17.0167 - acc: 0.7920 - val_loss: 25.3025 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00424: val_loss improved from 25.79177 to 25.30249, saving model to test.hdf5\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 16.6491 - acc: 0.8200 - val_loss: 24.6807 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00425: val_loss improved from 25.30249 to 24.68068, saving model to test.hdf5\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 16.3714 - acc: 0.7800 - val_loss: 23.8748 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00426: val_loss improved from 24.68068 to 23.87480, saving model to test.hdf5\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16.5055 - acc: 0.7680 - val_loss: 23.2226 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00427: val_loss improved from 23.87480 to 23.22265, saving model to test.hdf5\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 15.5306 - acc: 0.8200 - val_loss: 23.0126 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00428: val_loss improved from 23.22265 to 23.01259, saving model to test.hdf5\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 15.2618 - acc: 0.7840 - val_loss: 22.5668 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00429: val_loss improved from 23.01259 to 22.56681, saving model to test.hdf5\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 15.0321 - acc: 0.8120 - val_loss: 21.8148 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00430: val_loss improved from 22.56681 to 21.81478, saving model to test.hdf5\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 14.3895 - acc: 0.8200 - val_loss: 21.6666 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00431: val_loss improved from 21.81478 to 21.66660, saving model to test.hdf5\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 14.1915 - acc: 0.8360 - val_loss: 20.7473 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00432: val_loss improved from 21.66660 to 20.74729, saving model to test.hdf5\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13.9391 - acc: 0.8120 - val_loss: 20.5543 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00433: val_loss improved from 20.74729 to 20.55428, saving model to test.hdf5\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 13.3738 - acc: 0.7640 - val_loss: 19.6239 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00434: val_loss improved from 20.55428 to 19.62393, saving model to test.hdf5\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 12.9452 - acc: 0.8360 - val_loss: 19.0563 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00435: val_loss improved from 19.62393 to 19.05631, saving model to test.hdf5\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 12.6694 - acc: 0.8160 - val_loss: 18.7858 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00436: val_loss improved from 19.05631 to 18.78583, saving model to test.hdf5\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 12.5766 - acc: 0.8080 - val_loss: 18.2567 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00437: val_loss improved from 18.78583 to 18.25674, saving model to test.hdf5\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 12.0987 - acc: 0.8120 - val_loss: 17.6537 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00438: val_loss improved from 18.25674 to 17.65373, saving model to test.hdf5\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 11.3324 - acc: 0.8240 - val_loss: 17.3705 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00439: val_loss improved from 17.65373 to 17.37046, saving model to test.hdf5\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 11.7854 - acc: 0.8120 - val_loss: 17.2307 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00440: val_loss improved from 17.37046 to 17.23072, saving model to test.hdf5\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 11.3097 - acc: 0.7680 - val_loss: 16.4536 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00441: val_loss improved from 17.23072 to 16.45358, saving model to test.hdf5\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 10.7875 - acc: 0.7880 - val_loss: 16.6021 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 16.45358\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 10.7233 - acc: 0.8040 - val_loss: 15.6149 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00443: val_loss improved from 16.45358 to 15.61491, saving model to test.hdf5\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 10.5318 - acc: 0.8080 - val_loss: 15.3164 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00444: val_loss improved from 15.61491 to 15.31643, saving model to test.hdf5\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 10.1729 - acc: 0.7880 - val_loss: 15.0721 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00445: val_loss improved from 15.31643 to 15.07213, saving model to test.hdf5\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 9.7920 - acc: 0.8240 - val_loss: 14.5072 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00446: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "\n",
      "Epoch 00446: val_loss improved from 15.07213 to 14.50724, saving model to test.hdf5\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 9.4311 - acc: 0.8000 - val_loss: 14.3913 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00447: val_loss improved from 14.50724 to 14.39130, saving model to test.hdf5\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 9.4589 - acc: 0.8240 - val_loss: 13.9549 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00448: val_loss improved from 14.39130 to 13.95487, saving model to test.hdf5\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 195us/step - loss: 9.2599 - acc: 0.8240 - val_loss: 13.7604 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00449: val_loss improved from 13.95487 to 13.76037, saving model to test.hdf5\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 8.9932 - acc: 0.7880 - val_loss: 13.4879 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00450: val_loss improved from 13.76037 to 13.48790, saving model to test.hdf5\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 8.7491 - acc: 0.7680 - val_loss: 12.7160 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00451: val_loss improved from 13.48790 to 12.71603, saving model to test.hdf5\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 8.4701 - acc: 0.8040 - val_loss: 12.6291 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00452: val_loss improved from 12.71603 to 12.62910, saving model to test.hdf5\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 8.2674 - acc: 0.7920 - val_loss: 12.2495 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00453: val_loss improved from 12.62910 to 12.24952, saving model to test.hdf5\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 8.0824 - acc: 0.8040 - val_loss: 11.8596 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00454: val_loss improved from 12.24952 to 11.85962, saving model to test.hdf5\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 7.8872 - acc: 0.8320 - val_loss: 12.4364 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 11.85962\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 7.8072 - acc: 0.7640 - val_loss: 11.3777 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00456: val_loss improved from 11.85962 to 11.37774, saving model to test.hdf5\n",
      "Epoch 457/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 192us/step - loss: 7.5539 - acc: 0.8000 - val_loss: 11.1125 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00457: val_loss improved from 11.37774 to 11.11247, saving model to test.hdf5\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 7.2907 - acc: 0.8160 - val_loss: 11.4807 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 11.11247\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 7.2351 - acc: 0.7880 - val_loss: 11.3221 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 11.11247\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 7.2504 - acc: 0.7760 - val_loss: 10.5121 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00460: val_loss improved from 11.11247 to 10.51215, saving model to test.hdf5\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6.8665 - acc: 0.7960 - val_loss: 9.8834 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00461: val_loss improved from 10.51215 to 9.88335, saving model to test.hdf5\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 6.4897 - acc: 0.8360 - val_loss: 9.4601 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00462: val_loss improved from 9.88335 to 9.46007, saving model to test.hdf5\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6.4860 - acc: 0.7960 - val_loss: 9.3601 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00463: val_loss improved from 9.46007 to 9.36008, saving model to test.hdf5\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 6.2608 - acc: 0.8200 - val_loss: 9.7449 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 9.36008\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 6.1885 - acc: 0.8040 - val_loss: 8.9936 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00465: val_loss improved from 9.36008 to 8.99365, saving model to test.hdf5\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 6.0759 - acc: 0.7800 - val_loss: 8.7515 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00466: val_loss improved from 8.99365 to 8.75153, saving model to test.hdf5\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 5.9963 - acc: 0.8080 - val_loss: 8.3312 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00467: val_loss improved from 8.75153 to 8.33120, saving model to test.hdf5\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 5.8195 - acc: 0.8200 - val_loss: 8.1258 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00468: val_loss improved from 8.33120 to 8.12582, saving model to test.hdf5\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 5.5975 - acc: 0.8080 - val_loss: 8.1227 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00469: val_loss improved from 8.12582 to 8.12267, saving model to test.hdf5\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 5.3212 - acc: 0.7760 - val_loss: 7.9372 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00470: val_loss improved from 8.12267 to 7.93721, saving model to test.hdf5\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 5.4066 - acc: 0.8000 - val_loss: 7.5519 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00471: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "\n",
      "Epoch 00471: val_loss improved from 7.93721 to 7.55189, saving model to test.hdf5\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 5.1688 - acc: 0.7800 - val_loss: 7.2706 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00472: val_loss improved from 7.55189 to 7.27063, saving model to test.hdf5\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 5.1038 - acc: 0.8160 - val_loss: 7.2700 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00473: val_loss improved from 7.27063 to 7.26998, saving model to test.hdf5\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 4.8960 - acc: 0.8160 - val_loss: 6.9812 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00474: val_loss improved from 7.26998 to 6.98115, saving model to test.hdf5\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 4.7649 - acc: 0.7960 - val_loss: 6.8238 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00475: val_loss improved from 6.98115 to 6.82381, saving model to test.hdf5\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 4.6783 - acc: 0.7800 - val_loss: 6.6499 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00476: val_loss improved from 6.82381 to 6.64986, saving model to test.hdf5\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 4.6122 - acc: 0.8000 - val_loss: 6.6878 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 6.64986\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 4.5005 - acc: 0.8000 - val_loss: 6.2613 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00478: val_loss improved from 6.64986 to 6.26127, saving model to test.hdf5\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 4.3240 - acc: 0.7760 - val_loss: 6.1383 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00479: val_loss improved from 6.26127 to 6.13830, saving model to test.hdf5\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 4.2727 - acc: 0.8120 - val_loss: 6.4937 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 6.13830\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 4.2745 - acc: 0.7920 - val_loss: 5.8651 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00481: val_loss improved from 6.13830 to 5.86510, saving model to test.hdf5\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 4.0998 - acc: 0.8000 - val_loss: 6.0632 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 5.86510\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 3.9671 - acc: 0.7840 - val_loss: 5.6264 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00483: val_loss improved from 5.86510 to 5.62644, saving model to test.hdf5\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 3.9698 - acc: 0.8120 - val_loss: 6.2807 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 5.62644\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 3.8823 - acc: 0.8160 - val_loss: 5.5759 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00485: val_loss improved from 5.62644 to 5.57594, saving model to test.hdf5\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 3.8059 - acc: 0.8160 - val_loss: 5.3307 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00486: val_loss improved from 5.57594 to 5.33071, saving model to test.hdf5\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 3.8030 - acc: 0.7840 - val_loss: 5.0208 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00487: val_loss improved from 5.33071 to 5.02076, saving model to test.hdf5\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 3.5819 - acc: 0.8240 - val_loss: 5.1277 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 5.02076\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 3.4512 - acc: 0.8360 - val_loss: 4.6946 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00489: val_loss improved from 5.02076 to 4.69456, saving model to test.hdf5\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 3.3671 - acc: 0.7760 - val_loss: 4.6202 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00490: val_loss improved from 4.69456 to 4.62024, saving model to test.hdf5\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 3.2913 - acc: 0.8400 - val_loss: 4.6320 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 4.62024\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 3.3065 - acc: 0.7560 - val_loss: 4.2984 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00492: val_loss improved from 4.62024 to 4.29844, saving model to test.hdf5\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 3.0622 - acc: 0.8200 - val_loss: 4.2829 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00493: val_loss improved from 4.29844 to 4.28293, saving model to test.hdf5\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 3.2356 - acc: 0.8320 - val_loss: 3.9817 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00494: val_loss improved from 4.28293 to 3.98172, saving model to test.hdf5\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 3.2211 - acc: 0.8040 - val_loss: 4.4446 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 3.98172\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 3.1159 - acc: 0.8000 - val_loss: 3.9236 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00496: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "\n",
      "Epoch 00496: val_loss improved from 3.98172 to 3.92356, saving model to test.hdf5\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 213us/step - loss: 3.0192 - acc: 0.7640 - val_loss: 4.0449 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 3.92356\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 2.7793 - acc: 0.7920 - val_loss: 3.6214 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00498: val_loss improved from 3.92356 to 3.62142, saving model to test.hdf5\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.7208 - acc: 0.8080 - val_loss: 3.7508 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 3.62142\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 2.7780 - acc: 0.8040 - val_loss: 3.4698 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00500: val_loss improved from 3.62142 to 3.46977, saving model to test.hdf5\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 2.6261 - acc: 0.7920 - val_loss: 3.4481 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00501: val_loss improved from 3.46977 to 3.44808, saving model to test.hdf5\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 2.5936 - acc: 0.8040 - val_loss: 3.3669 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00502: val_loss improved from 3.44808 to 3.36687, saving model to test.hdf5\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 2.5117 - acc: 0.8240 - val_loss: 3.3833 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 3.36687\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 213us/step - loss: 2.4987 - acc: 0.8280 - val_loss: 3.2044 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00504: val_loss improved from 3.36687 to 3.20442, saving model to test.hdf5\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 2.5305 - acc: 0.7680 - val_loss: 3.1387 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00505: val_loss improved from 3.20442 to 3.13870, saving model to test.hdf5\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 2.2795 - acc: 0.8320 - val_loss: 3.1535 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 3.13870\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 2.4609 - acc: 0.8040 - val_loss: 3.2001 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 3.13870\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.3149 - acc: 0.8040 - val_loss: 2.9441 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00508: val_loss improved from 3.13870 to 2.94413, saving model to test.hdf5\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 2.3180 - acc: 0.8040 - val_loss: 2.9683 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 2.94413\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 2.2816 - acc: 0.8200 - val_loss: 3.3207 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 2.94413\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 2.2835 - acc: 0.7600 - val_loss: 3.0938 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 2.94413\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 2.3334 - acc: 0.7840 - val_loss: 2.8242 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00512: val_loss improved from 2.94413 to 2.82418, saving model to test.hdf5\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 2.1287 - acc: 0.8000 - val_loss: 2.5728 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00513: val_loss improved from 2.82418 to 2.57275, saving model to test.hdf5\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 2.0617 - acc: 0.7680 - val_loss: 2.6621 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 2.57275\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 2.1936 - acc: 0.7920 - val_loss: 2.5593 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00515: val_loss improved from 2.57275 to 2.55925, saving model to test.hdf5\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 1.9401 - acc: 0.8320 - val_loss: 2.9406 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 2.55925\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 2.0382 - acc: 0.8000 - val_loss: 2.3196 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00517: val_loss improved from 2.55925 to 2.31963, saving model to test.hdf5\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1.9775 - acc: 0.7960 - val_loss: 2.3483 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 2.31963\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 1.9703 - acc: 0.7800 - val_loss: 2.3244 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 2.31963\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 1.9120 - acc: 0.8160 - val_loss: 2.2545 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00520: val_loss improved from 2.31963 to 2.25447, saving model to test.hdf5\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 1.9617 - acc: 0.7800 - val_loss: 2.1484 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00521: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "\n",
      "Epoch 00521: val_loss improved from 2.25447 to 2.14844, saving model to test.hdf5\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 1.7921 - acc: 0.8200 - val_loss: 2.1886 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 2.14844\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 211us/step - loss: 1.8821 - acc: 0.8000 - val_loss: 2.2236 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 2.14844\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 1.8134 - acc: 0.7880 - val_loss: 2.0487 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00524: val_loss improved from 2.14844 to 2.04871, saving model to test.hdf5\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 1.6797 - acc: 0.8000 - val_loss: 2.0156 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00525: val_loss improved from 2.04871 to 2.01561, saving model to test.hdf5\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 1.6354 - acc: 0.8080 - val_loss: 2.0312 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 2.01561\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 197us/step - loss: 1.9315 - acc: 0.7520 - val_loss: 2.0615 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 2.01561\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1.6149 - acc: 0.8240 - val_loss: 1.8229 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00528: val_loss improved from 2.01561 to 1.82289, saving model to test.hdf5\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 1.7330 - acc: 0.7800 - val_loss: 1.8997 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 1.82289\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 215us/step - loss: 1.6782 - acc: 0.7960 - val_loss: 1.9698 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 1.82289\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 205us/step - loss: 1.9402 - acc: 0.7560 - val_loss: 1.7947 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00531: val_loss improved from 1.82289 to 1.79472, saving model to test.hdf5\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 1.6247 - acc: 0.8200 - val_loss: 1.7226 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00532: val_loss improved from 1.79472 to 1.72263, saving model to test.hdf5\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 1.5447 - acc: 0.8160 - val_loss: 1.6914 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00533: val_loss improved from 1.72263 to 1.69140, saving model to test.hdf5\n",
      "Epoch 534/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 204us/step - loss: 1.5722 - acc: 0.7720 - val_loss: 1.7585 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 1.69140\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 1.5705 - acc: 0.8160 - val_loss: 1.9164 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 1.69140\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1.6278 - acc: 0.7800 - val_loss: 1.6010 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00536: val_loss improved from 1.69140 to 1.60098, saving model to test.hdf5\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 1.4845 - acc: 0.8040 - val_loss: 1.6965 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 1.60098\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1.6009 - acc: 0.8000 - val_loss: 2.3266 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 1.60098\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 1.8178 - acc: 0.8040 - val_loss: 1.5484 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00539: val_loss improved from 1.60098 to 1.54845, saving model to test.hdf5\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.5198 - acc: 0.8160 - val_loss: 1.6998 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 1.54845\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.5666 - acc: 0.8120 - val_loss: 1.5103 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00541: val_loss improved from 1.54845 to 1.51033, saving model to test.hdf5\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 1.5659 - acc: 0.7960 - val_loss: 1.4860 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00542: val_loss improved from 1.51033 to 1.48598, saving model to test.hdf5\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 1.3533 - acc: 0.8280 - val_loss: 1.4011 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00543: val_loss improved from 1.48598 to 1.40112, saving model to test.hdf5\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 1.4408 - acc: 0.8160 - val_loss: 1.5094 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 1.40112\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 1.4514 - acc: 0.8080 - val_loss: 1.3931 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00545: val_loss improved from 1.40112 to 1.39311, saving model to test.hdf5\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 1.3748 - acc: 0.8040 - val_loss: 1.4085 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00546: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 1.39311\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 191us/step - loss: 1.3453 - acc: 0.8000 - val_loss: 1.3425 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00547: val_loss improved from 1.39311 to 1.34250, saving model to test.hdf5\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 1.3810 - acc: 0.8120 - val_loss: 1.4350 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 1.34250\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 1.4265 - acc: 0.7760 - val_loss: 1.2953 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00549: val_loss improved from 1.34250 to 1.29533, saving model to test.hdf5\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 1.4438 - acc: 0.8240 - val_loss: 1.2465 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00550: val_loss improved from 1.29533 to 1.24653, saving model to test.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b21e21b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b21e1d93c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 6, модель переобучилась, уменьшили кол-во эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. непонятно на что влияет параметр verbose, но изменение его с 1 на 2 увеличило стабильность\n",
    "2. почитать про reducelronPlateau\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/350\n",
      " - 1s - loss: 6588264.5100 - acc: 0.4960 - val_loss: 2433305.2232 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2433305.22321, saving model to test.hdf5\n",
      "Epoch 2/350\n",
      " - 0s - loss: 3334743.5088 - acc: 0.5400 - val_loss: 1529263.9040 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00002: val_loss improved from 2433305.22321 to 1529263.90402, saving model to test.hdf5\n",
      "Epoch 3/350\n",
      " - 0s - loss: 1820536.1375 - acc: 0.5560 - val_loss: 1041588.0156 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00003: val_loss improved from 1529263.90402 to 1041588.01562, saving model to test.hdf5\n",
      "Epoch 4/350\n",
      " - 0s - loss: 1196674.2675 - acc: 0.6560 - val_loss: 761294.2879 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00004: val_loss improved from 1041588.01562 to 761294.28795, saving model to test.hdf5\n",
      "Epoch 5/350\n",
      " - 0s - loss: 887723.4062 - acc: 0.6360 - val_loss: 585224.9431 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00005: val_loss improved from 761294.28795 to 585224.94308, saving model to test.hdf5\n",
      "Epoch 6/350\n",
      " - 0s - loss: 716951.2825 - acc: 0.6880 - val_loss: 483382.5943 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00006: val_loss improved from 585224.94308 to 483382.59431, saving model to test.hdf5\n",
      "Epoch 7/350\n",
      " - 0s - loss: 614846.4525 - acc: 0.6240 - val_loss: 412353.5173 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00007: val_loss improved from 483382.59431 to 412353.51730, saving model to test.hdf5\n",
      "Epoch 8/350\n",
      " - 0s - loss: 542550.9587 - acc: 0.6960 - val_loss: 356917.8990 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00008: val_loss improved from 412353.51730 to 356917.89900, saving model to test.hdf5\n",
      "Epoch 9/350\n",
      " - 0s - loss: 492252.3463 - acc: 0.6840 - val_loss: 318182.4350 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00009: val_loss improved from 356917.89900 to 318182.43499, saving model to test.hdf5\n",
      "Epoch 10/350\n",
      " - 0s - loss: 447592.4725 - acc: 0.7280 - val_loss: 285343.4986 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00010: val_loss improved from 318182.43499 to 285343.49860, saving model to test.hdf5\n",
      "Epoch 11/350\n",
      " - 0s - loss: 414331.5719 - acc: 0.7360 - val_loss: 262692.3666 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00011: val_loss improved from 285343.49860 to 262692.36663, saving model to test.hdf5\n",
      "Epoch 12/350\n",
      " - 0s - loss: 386315.4247 - acc: 0.6960 - val_loss: 243766.5968 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00012: val_loss improved from 262692.36663 to 243766.59682, saving model to test.hdf5\n",
      "Epoch 13/350\n",
      " - 0s - loss: 363996.3744 - acc: 0.7440 - val_loss: 226538.2441 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00013: val_loss improved from 243766.59682 to 226538.24414, saving model to test.hdf5\n",
      "Epoch 14/350\n",
      " - 0s - loss: 342992.6987 - acc: 0.7560 - val_loss: 213032.2815 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00014: val_loss improved from 226538.24414 to 213032.28153, saving model to test.hdf5\n",
      "Epoch 15/350\n",
      " - 0s - loss: 322693.9719 - acc: 0.7480 - val_loss: 200105.8859 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00015: val_loss improved from 213032.28153 to 200105.88588, saving model to test.hdf5\n",
      "Epoch 16/350\n",
      " - 0s - loss: 306576.4763 - acc: 0.7480 - val_loss: 189360.6576 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00016: val_loss improved from 200105.88588 to 189360.65765, saving model to test.hdf5\n",
      "Epoch 17/350\n",
      " - 0s - loss: 292398.7800 - acc: 0.7680 - val_loss: 179854.4693 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00017: val_loss improved from 189360.65765 to 179854.46931, saving model to test.hdf5\n",
      "Epoch 18/350\n",
      " - 0s - loss: 277753.2003 - acc: 0.7520 - val_loss: 170727.9897 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00018: val_loss improved from 179854.46931 to 170727.98968, saving model to test.hdf5\n",
      "Epoch 19/350\n",
      " - 0s - loss: 265527.3547 - acc: 0.7480 - val_loss: 163546.5665 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00019: val_loss improved from 170727.98968 to 163546.56655, saving model to test.hdf5\n",
      "Epoch 20/350\n",
      " - 0s - loss: 253306.5636 - acc: 0.7640 - val_loss: 157392.2719 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00020: val_loss improved from 163546.56655 to 157392.27190, saving model to test.hdf5\n",
      "Epoch 21/350\n",
      " - 0s - loss: 242631.3641 - acc: 0.7960 - val_loss: 149781.1119 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00021: val_loss improved from 157392.27190 to 149781.11189, saving model to test.hdf5\n",
      "Epoch 22/350\n",
      " - 0s - loss: 235486.6125 - acc: 0.7360 - val_loss: 143318.5301 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00022: val_loss improved from 149781.11189 to 143318.53013, saving model to test.hdf5\n",
      "Epoch 23/350\n",
      " - 0s - loss: 225382.6691 - acc: 0.7320 - val_loss: 139294.9533 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00023: val_loss improved from 143318.53013 to 139294.95326, saving model to test.hdf5\n",
      "Epoch 24/350\n",
      " - 0s - loss: 215781.7563 - acc: 0.7480 - val_loss: 133700.3013 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00024: val_loss improved from 139294.95326 to 133700.30127, saving model to test.hdf5\n",
      "Epoch 25/350\n",
      " - 0s - loss: 208739.2337 - acc: 0.7760 - val_loss: 128277.1019 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00025: val_loss improved from 133700.30127 to 128277.10191, saving model to test.hdf5\n",
      "Epoch 26/350\n",
      " - 0s - loss: 200833.0550 - acc: 0.7160 - val_loss: 123652.5107 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00026: val_loss improved from 128277.10191 to 123652.51074, saving model to test.hdf5\n",
      "Epoch 27/350\n",
      " - 0s - loss: 195249.7806 - acc: 0.7120 - val_loss: 120180.4636 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00027: val_loss improved from 123652.51074 to 120180.46359, saving model to test.hdf5\n",
      "Epoch 28/350\n",
      " - 0s - loss: 188385.0537 - acc: 0.7400 - val_loss: 116401.1313 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00028: val_loss improved from 120180.46359 to 116401.13135, saving model to test.hdf5\n",
      "Epoch 29/350\n",
      " - 0s - loss: 181126.4641 - acc: 0.7280 - val_loss: 112712.7912 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00029: val_loss improved from 116401.13135 to 112712.79116, saving model to test.hdf5\n",
      "Epoch 30/350\n",
      " - 0s - loss: 173445.8056 - acc: 0.7240 - val_loss: 107955.5966 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00030: val_loss improved from 112712.79116 to 107955.59661, saving model to test.hdf5\n",
      "Epoch 31/350\n",
      " - 0s - loss: 167092.6811 - acc: 0.7480 - val_loss: 106328.7481 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00031: val_loss improved from 107955.59661 to 106328.74812, saving model to test.hdf5\n",
      "Epoch 32/350\n",
      " - 0s - loss: 162790.2339 - acc: 0.7320 - val_loss: 102268.3408 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00032: val_loss improved from 106328.74812 to 102268.34082, saving model to test.hdf5\n",
      "Epoch 33/350\n",
      " - 0s - loss: 157965.4323 - acc: 0.7160 - val_loss: 98820.8203 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00033: val_loss improved from 102268.34082 to 98820.82031, saving model to test.hdf5\n",
      "Epoch 34/350\n",
      " - 0s - loss: 151976.3942 - acc: 0.7000 - val_loss: 95553.5804 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00034: val_loss improved from 98820.82031 to 95553.58043, saving model to test.hdf5\n",
      "Epoch 35/350\n",
      " - 0s - loss: 148715.0417 - acc: 0.7440 - val_loss: 92730.1041 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00035: val_loss improved from 95553.58043 to 92730.10414, saving model to test.hdf5\n",
      "Epoch 36/350\n",
      " - 0s - loss: 143151.0392 - acc: 0.7520 - val_loss: 90396.9615 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00036: val_loss improved from 92730.10414 to 90396.96150, saving model to test.hdf5\n",
      "Epoch 37/350\n",
      " - 0s - loss: 138943.6959 - acc: 0.6720 - val_loss: 87476.4345 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00037: val_loss improved from 90396.96150 to 87476.43450, saving model to test.hdf5\n",
      "Epoch 38/350\n",
      " - 0s - loss: 134382.9916 - acc: 0.7520 - val_loss: 85291.6947 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00038: val_loss improved from 87476.43450 to 85291.69468, saving model to test.hdf5\n",
      "Epoch 39/350\n",
      " - 0s - loss: 130713.3394 - acc: 0.7320 - val_loss: 81764.5956 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00039: val_loss improved from 85291.69468 to 81764.59556, saving model to test.hdf5\n",
      "Epoch 40/350\n",
      " - 0s - loss: 126767.5658 - acc: 0.6760 - val_loss: 80511.5022 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00040: val_loss improved from 81764.59556 to 80511.50223, saving model to test.hdf5\n",
      "Epoch 41/350\n",
      " - 0s - loss: 122397.6001 - acc: 0.7200 - val_loss: 78133.7095 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00041: val_loss improved from 80511.50223 to 78133.70947, saving model to test.hdf5\n",
      "Epoch 42/350\n",
      " - 0s - loss: 119178.5975 - acc: 0.7600 - val_loss: 76171.0921 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00042: val_loss improved from 78133.70947 to 76171.09208, saving model to test.hdf5\n",
      "Epoch 43/350\n",
      " - 0s - loss: 116450.2134 - acc: 0.7160 - val_loss: 73245.2748 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00043: val_loss improved from 76171.09208 to 73245.27476, saving model to test.hdf5\n",
      "Epoch 44/350\n",
      " - 0s - loss: 111183.8914 - acc: 0.7160 - val_loss: 71264.2977 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00044: val_loss improved from 73245.27476 to 71264.29771, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/350\n",
      " - 0s - loss: 108136.5063 - acc: 0.7360 - val_loss: 69532.4099 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00045: val_loss improved from 71264.29771 to 69532.40988, saving model to test.hdf5\n",
      "Epoch 46/350\n",
      " - 0s - loss: 105759.7741 - acc: 0.7040 - val_loss: 67187.1814 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00046: val_loss improved from 69532.40988 to 67187.18136, saving model to test.hdf5\n",
      "Epoch 47/350\n",
      " - 0s - loss: 102230.0392 - acc: 0.7320 - val_loss: 65241.0498 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00047: val_loss improved from 67187.18136 to 65241.04980, saving model to test.hdf5\n",
      "Epoch 48/350\n",
      " - 0s - loss: 99442.0998 - acc: 0.7080 - val_loss: 63530.3632 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00048: val_loss improved from 65241.04980 to 63530.36325, saving model to test.hdf5\n",
      "Epoch 49/350\n",
      " - 0s - loss: 96233.3336 - acc: 0.7240 - val_loss: 61985.0981 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00049: val_loss improved from 63530.36325 to 61985.09807, saving model to test.hdf5\n",
      "Epoch 50/350\n",
      " - 0s - loss: 92881.4997 - acc: 0.7040 - val_loss: 59844.6455 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00050: val_loss improved from 61985.09807 to 59844.64554, saving model to test.hdf5\n",
      "Epoch 51/350\n",
      " - 0s - loss: 90826.1705 - acc: 0.7320 - val_loss: 58434.7615 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00051: val_loss improved from 59844.64554 to 58434.76154, saving model to test.hdf5\n",
      "Epoch 52/350\n",
      " - 0s - loss: 88845.8317 - acc: 0.6960 - val_loss: 56709.9144 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00052: val_loss improved from 58434.76154 to 56709.91438, saving model to test.hdf5\n",
      "Epoch 53/350\n",
      " - 0s - loss: 85723.5470 - acc: 0.7360 - val_loss: 54852.9265 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00053: val_loss improved from 56709.91438 to 54852.92648, saving model to test.hdf5\n",
      "Epoch 54/350\n",
      " - 0s - loss: 83127.3316 - acc: 0.7360 - val_loss: 53837.9850 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00054: val_loss improved from 54852.92648 to 53837.98497, saving model to test.hdf5\n",
      "Epoch 55/350\n",
      " - 0s - loss: 80272.1418 - acc: 0.7040 - val_loss: 52211.2987 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00055: val_loss improved from 53837.98497 to 52211.29869, saving model to test.hdf5\n",
      "Epoch 56/350\n",
      " - 0s - loss: 78260.6812 - acc: 0.7200 - val_loss: 50598.5206 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00056: val_loss improved from 52211.29869 to 50598.52065, saving model to test.hdf5\n",
      "Epoch 57/350\n",
      " - 0s - loss: 75266.9181 - acc: 0.7280 - val_loss: 49345.4445 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00057: val_loss improved from 50598.52065 to 49345.44448, saving model to test.hdf5\n",
      "Epoch 58/350\n",
      " - 0s - loss: 73830.5433 - acc: 0.7400 - val_loss: 47523.1644 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00058: val_loss improved from 49345.44448 to 47523.16441, saving model to test.hdf5\n",
      "Epoch 59/350\n",
      " - 0s - loss: 71794.4142 - acc: 0.7480 - val_loss: 46250.0883 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00059: val_loss improved from 47523.16441 to 46250.08831, saving model to test.hdf5\n",
      "Epoch 60/350\n",
      " - 0s - loss: 69347.7632 - acc: 0.7120 - val_loss: 44823.1545 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00060: val_loss improved from 46250.08831 to 44823.15454, saving model to test.hdf5\n",
      "Epoch 61/350\n",
      " - 0s - loss: 67692.7237 - acc: 0.6800 - val_loss: 43777.3064 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00061: val_loss improved from 44823.15454 to 43777.30643, saving model to test.hdf5\n",
      "Epoch 62/350\n",
      " - 0s - loss: 65304.0773 - acc: 0.7160 - val_loss: 43042.0433 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00062: val_loss improved from 43777.30643 to 43042.04332, saving model to test.hdf5\n",
      "Epoch 63/350\n",
      " - 0s - loss: 63356.1420 - acc: 0.7040 - val_loss: 41263.5929 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00063: val_loss improved from 43042.04332 to 41263.59291, saving model to test.hdf5\n",
      "Epoch 64/350\n",
      " - 0s - loss: 62134.7118 - acc: 0.6760 - val_loss: 40546.4675 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00064: val_loss improved from 41263.59291 to 40546.46746, saving model to test.hdf5\n",
      "Epoch 65/350\n",
      " - 0s - loss: 59894.6718 - acc: 0.7280 - val_loss: 39568.0291 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00065: val_loss improved from 40546.46746 to 39568.02905, saving model to test.hdf5\n",
      "Epoch 66/350\n",
      " - 0s - loss: 57910.6009 - acc: 0.7240 - val_loss: 38023.3597 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00066: val_loss improved from 39568.02905 to 38023.35972, saving model to test.hdf5\n",
      "Epoch 67/350\n",
      " - 0s - loss: 56115.6343 - acc: 0.7320 - val_loss: 36857.7433 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00067: val_loss improved from 38023.35972 to 36857.74327, saving model to test.hdf5\n",
      "Epoch 68/350\n",
      " - 0s - loss: 54717.0627 - acc: 0.7320 - val_loss: 36076.3455 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00068: val_loss improved from 36857.74327 to 36076.34546, saving model to test.hdf5\n",
      "Epoch 69/350\n",
      " - 0s - loss: 52795.7977 - acc: 0.7160 - val_loss: 35352.6797 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00069: val_loss improved from 36076.34546 to 35352.67972, saving model to test.hdf5\n",
      "Epoch 70/350\n",
      " - 0s - loss: 51851.8408 - acc: 0.6800 - val_loss: 34314.3107 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00070: val_loss improved from 35352.67972 to 34314.31067, saving model to test.hdf5\n",
      "Epoch 71/350\n",
      " - 0s - loss: 50144.1702 - acc: 0.7280 - val_loss: 33099.9401 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00071: val_loss improved from 34314.31067 to 33099.94008, saving model to test.hdf5\n",
      "Epoch 72/350\n",
      " - 0s - loss: 48976.9070 - acc: 0.7160 - val_loss: 32202.3171 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00072: val_loss improved from 33099.94008 to 32202.31710, saving model to test.hdf5\n",
      "Epoch 73/350\n",
      " - 0s - loss: 47074.2850 - acc: 0.7080 - val_loss: 31712.5574 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00073: val_loss improved from 32202.31710 to 31712.55743, saving model to test.hdf5\n",
      "Epoch 74/350\n",
      " - 0s - loss: 45590.8393 - acc: 0.7160 - val_loss: 30608.0331 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00074: val_loss improved from 31712.55743 to 30608.03310, saving model to test.hdf5\n",
      "Epoch 75/350\n",
      " - 0s - loss: 44322.8557 - acc: 0.7040 - val_loss: 29548.2151 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00075: val_loss improved from 30608.03310 to 29548.21507, saving model to test.hdf5\n",
      "Epoch 76/350\n",
      " - 0s - loss: 43397.7004 - acc: 0.7280 - val_loss: 28717.1232 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00076: val_loss improved from 29548.21507 to 28717.12324, saving model to test.hdf5\n",
      "Epoch 77/350\n",
      " - 0s - loss: 41811.0240 - acc: 0.6840 - val_loss: 27757.0421 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00077: val_loss improved from 28717.12324 to 27757.04215, saving model to test.hdf5\n",
      "Epoch 78/350\n",
      " - 0s - loss: 40984.6907 - acc: 0.6720 - val_loss: 27199.5407 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00078: val_loss improved from 27757.04215 to 27199.54067, saving model to test.hdf5\n",
      "Epoch 79/350\n",
      " - 0s - loss: 39451.4148 - acc: 0.7160 - val_loss: 26365.0697 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00079: val_loss improved from 27199.54067 to 26365.06967, saving model to test.hdf5\n",
      "Epoch 80/350\n",
      " - 0s - loss: 38362.2663 - acc: 0.6480 - val_loss: 25804.5385 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00080: val_loss improved from 26365.06967 to 25804.53852, saving model to test.hdf5\n",
      "Epoch 81/350\n",
      " - 0s - loss: 36980.6066 - acc: 0.7040 - val_loss: 24861.1421 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00081: val_loss improved from 25804.53852 to 24861.14205, saving model to test.hdf5\n",
      "Epoch 82/350\n",
      " - 0s - loss: 36116.1496 - acc: 0.7040 - val_loss: 24073.8973 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00082: val_loss improved from 24861.14205 to 24073.89727, saving model to test.hdf5\n",
      "Epoch 83/350\n",
      " - 0s - loss: 34433.0259 - acc: 0.7240 - val_loss: 23660.9998 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00083: val_loss improved from 24073.89727 to 23660.99984, saving model to test.hdf5\n",
      "Epoch 84/350\n",
      " - 0s - loss: 33870.0821 - acc: 0.7280 - val_loss: 23029.6213 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00084: val_loss improved from 23660.99984 to 23029.62125, saving model to test.hdf5\n",
      "Epoch 85/350\n",
      " - 0s - loss: 32953.4554 - acc: 0.6920 - val_loss: 22341.0912 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00085: val_loss improved from 23029.62125 to 22341.09124, saving model to test.hdf5\n",
      "Epoch 86/350\n",
      " - 0s - loss: 31903.0948 - acc: 0.6960 - val_loss: 21732.2864 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00086: val_loss improved from 22341.09124 to 21732.28639, saving model to test.hdf5\n",
      "Epoch 87/350\n",
      " - 0s - loss: 30733.5810 - acc: 0.6720 - val_loss: 20967.2804 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00087: val_loss improved from 21732.28639 to 20967.28036, saving model to test.hdf5\n",
      "Epoch 88/350\n",
      " - 0s - loss: 29893.0566 - acc: 0.6720 - val_loss: 20552.0261 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00088: val_loss improved from 20967.28036 to 20552.02605, saving model to test.hdf5\n",
      "Epoch 89/350\n",
      " - 0s - loss: 29036.1591 - acc: 0.7000 - val_loss: 20040.3863 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00089: val_loss improved from 20552.02605 to 20040.38632, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/350\n",
      " - 0s - loss: 28091.0401 - acc: 0.7240 - val_loss: 19136.3602 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00090: val_loss improved from 20040.38632 to 19136.36018, saving model to test.hdf5\n",
      "Epoch 91/350\n",
      " - 0s - loss: 27543.9150 - acc: 0.7520 - val_loss: 18661.7382 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00091: val_loss improved from 19136.36018 to 18661.73816, saving model to test.hdf5\n",
      "Epoch 92/350\n",
      " - 0s - loss: 26460.5330 - acc: 0.7320 - val_loss: 18356.9222 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00092: val_loss improved from 18661.73816 to 18356.92217, saving model to test.hdf5\n",
      "Epoch 93/350\n",
      " - 0s - loss: 25686.4588 - acc: 0.7400 - val_loss: 17702.4271 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00093: val_loss improved from 18356.92217 to 17702.42705, saving model to test.hdf5\n",
      "Epoch 94/350\n",
      " - 0s - loss: 24902.7263 - acc: 0.6760 - val_loss: 17039.0095 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00094: val_loss improved from 17702.42705 to 17039.00951, saving model to test.hdf5\n",
      "Epoch 95/350\n",
      " - 0s - loss: 24102.2061 - acc: 0.6960 - val_loss: 16940.7878 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00095: val_loss improved from 17039.00951 to 16940.78783, saving model to test.hdf5\n",
      "Epoch 96/350\n",
      " - 0s - loss: 23325.9876 - acc: 0.6640 - val_loss: 16418.3979 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00096: val_loss improved from 16940.78783 to 16418.39793, saving model to test.hdf5\n",
      "Epoch 97/350\n",
      " - 0s - loss: 22494.2334 - acc: 0.7320 - val_loss: 15925.4261 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00097: val_loss improved from 16418.39793 to 15925.42612, saving model to test.hdf5\n",
      "Epoch 98/350\n",
      " - 0s - loss: 21918.8706 - acc: 0.7200 - val_loss: 15476.9989 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00098: val_loss improved from 15925.42612 to 15476.99891, saving model to test.hdf5\n",
      "Epoch 99/350\n",
      " - 0s - loss: 21189.6258 - acc: 0.6920 - val_loss: 14863.8021 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00099: val_loss improved from 15476.99891 to 14863.80206, saving model to test.hdf5\n",
      "Epoch 100/350\n",
      " - 0s - loss: 20481.9489 - acc: 0.7160 - val_loss: 14754.6429 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00100: val_loss improved from 14863.80206 to 14754.64294, saving model to test.hdf5\n",
      "Epoch 101/350\n",
      " - 0s - loss: 19999.0386 - acc: 0.7080 - val_loss: 14357.1656 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00101: val_loss improved from 14754.64294 to 14357.16558, saving model to test.hdf5\n",
      "Epoch 102/350\n",
      " - 0s - loss: 19579.3853 - acc: 0.6520 - val_loss: 13624.0020 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00102: val_loss improved from 14357.16558 to 13624.00203, saving model to test.hdf5\n",
      "Epoch 103/350\n",
      " - 0s - loss: 18670.6635 - acc: 0.7040 - val_loss: 13299.2406 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00103: val_loss improved from 13624.00203 to 13299.24056, saving model to test.hdf5\n",
      "Epoch 104/350\n",
      " - 0s - loss: 18227.3017 - acc: 0.7000 - val_loss: 12891.8264 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00104: val_loss improved from 13299.24056 to 12891.82635, saving model to test.hdf5\n",
      "Epoch 105/350\n",
      " - 0s - loss: 17503.6912 - acc: 0.6600 - val_loss: 12847.1523 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00105: val_loss improved from 12891.82635 to 12847.15232, saving model to test.hdf5\n",
      "Epoch 106/350\n",
      " - 0s - loss: 17107.0930 - acc: 0.7040 - val_loss: 12229.1251 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00106: val_loss improved from 12847.15232 to 12229.12505, saving model to test.hdf5\n",
      "Epoch 107/350\n",
      " - 0s - loss: 16502.0466 - acc: 0.7160 - val_loss: 11837.5827 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00107: val_loss improved from 12229.12505 to 11837.58266, saving model to test.hdf5\n",
      "Epoch 108/350\n",
      " - 0s - loss: 15812.4570 - acc: 0.7080 - val_loss: 11555.5895 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00108: val_loss improved from 11837.58266 to 11555.58954, saving model to test.hdf5\n",
      "Epoch 109/350\n",
      " - 0s - loss: 15507.0204 - acc: 0.6840 - val_loss: 11368.0227 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00109: val_loss improved from 11555.58954 to 11368.02269, saving model to test.hdf5\n",
      "Epoch 110/350\n",
      " - 0s - loss: 14966.5503 - acc: 0.6800 - val_loss: 10869.1528 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00110: val_loss improved from 11368.02269 to 10869.15281, saving model to test.hdf5\n",
      "Epoch 111/350\n",
      " - 0s - loss: 14511.1752 - acc: 0.6880 - val_loss: 10608.1794 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00111: val_loss improved from 10869.15281 to 10608.17936, saving model to test.hdf5\n",
      "Epoch 112/350\n",
      " - 0s - loss: 14247.2244 - acc: 0.7000 - val_loss: 10236.7679 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00112: val_loss improved from 10608.17936 to 10236.76794, saving model to test.hdf5\n",
      "Epoch 113/350\n",
      " - 0s - loss: 13610.0155 - acc: 0.7080 - val_loss: 10031.9178 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00113: val_loss improved from 10236.76794 to 10031.91778, saving model to test.hdf5\n",
      "Epoch 114/350\n",
      " - 0s - loss: 13188.8557 - acc: 0.7400 - val_loss: 9711.6997 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00114: val_loss improved from 10031.91778 to 9711.69970, saving model to test.hdf5\n",
      "Epoch 115/350\n",
      " - 0s - loss: 12898.3935 - acc: 0.6720 - val_loss: 9466.8465 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00115: val_loss improved from 9711.69970 to 9466.84648, saving model to test.hdf5\n",
      "Epoch 116/350\n",
      " - 0s - loss: 12422.1022 - acc: 0.6880 - val_loss: 9149.2872 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00116: val_loss improved from 9466.84648 to 9149.28720, saving model to test.hdf5\n",
      "Epoch 117/350\n",
      " - 0s - loss: 12018.0206 - acc: 0.7200 - val_loss: 8903.9105 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00117: val_loss improved from 9149.28720 to 8903.91049, saving model to test.hdf5\n",
      "Epoch 118/350\n",
      " - 0s - loss: 11667.6215 - acc: 0.6280 - val_loss: 8685.4535 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00118: val_loss improved from 8903.91049 to 8685.45349, saving model to test.hdf5\n",
      "Epoch 119/350\n",
      " - 0s - loss: 11180.1551 - acc: 0.6840 - val_loss: 8415.9270 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00119: val_loss improved from 8685.45349 to 8415.92698, saving model to test.hdf5\n",
      "Epoch 120/350\n",
      " - 0s - loss: 11005.7627 - acc: 0.6760 - val_loss: 8095.1357 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00120: val_loss improved from 8415.92698 to 8095.13568, saving model to test.hdf5\n",
      "Epoch 121/350\n",
      " - 0s - loss: 10549.9740 - acc: 0.6960 - val_loss: 7984.3077 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00121: val_loss improved from 8095.13568 to 7984.30770, saving model to test.hdf5\n",
      "Epoch 122/350\n",
      " - 0s - loss: 10216.1878 - acc: 0.7080 - val_loss: 7690.2224 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00122: val_loss improved from 7984.30770 to 7690.22235, saving model to test.hdf5\n",
      "Epoch 123/350\n",
      " - 0s - loss: 9899.9819 - acc: 0.7040 - val_loss: 7531.1553 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00123: val_loss improved from 7690.22235 to 7531.15526, saving model to test.hdf5\n",
      "Epoch 124/350\n",
      " - 0s - loss: 9576.7432 - acc: 0.6800 - val_loss: 7264.5407 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00124: val_loss improved from 7531.15526 to 7264.54065, saving model to test.hdf5\n",
      "Epoch 125/350\n",
      " - 0s - loss: 9272.3631 - acc: 0.6960 - val_loss: 7069.1528 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00125: val_loss improved from 7264.54065 to 7069.15276, saving model to test.hdf5\n",
      "Epoch 126/350\n",
      " - 0s - loss: 8945.8249 - acc: 0.6920 - val_loss: 6828.8484 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00126: val_loss improved from 7069.15276 to 6828.84840, saving model to test.hdf5\n",
      "Epoch 127/350\n",
      " - 0s - loss: 8629.5923 - acc: 0.6960 - val_loss: 6567.0277 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00127: val_loss improved from 6828.84840 to 6567.02771, saving model to test.hdf5\n",
      "Epoch 128/350\n",
      " - 0s - loss: 8422.7348 - acc: 0.7520 - val_loss: 6368.6216 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00128: val_loss improved from 6567.02771 to 6368.62158, saving model to test.hdf5\n",
      "Epoch 129/350\n",
      " - 0s - loss: 8206.2712 - acc: 0.7160 - val_loss: 6244.3117 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00129: val_loss improved from 6368.62158 to 6244.31169, saving model to test.hdf5\n",
      "Epoch 130/350\n",
      " - 0s - loss: 7679.5936 - acc: 0.7000 - val_loss: 6086.9041 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00130: val_loss improved from 6244.31169 to 6086.90413, saving model to test.hdf5\n",
      "Epoch 131/350\n",
      " - 0s - loss: 7562.5121 - acc: 0.6600 - val_loss: 6011.8794 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00131: val_loss improved from 6086.90413 to 6011.87936, saving model to test.hdf5\n",
      "Epoch 132/350\n",
      " - 0s - loss: 7406.5275 - acc: 0.6960 - val_loss: 5703.3683 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00132: val_loss improved from 6011.87936 to 5703.36831, saving model to test.hdf5\n",
      "Epoch 133/350\n",
      " - 0s - loss: 7183.2683 - acc: 0.7000 - val_loss: 5604.7979 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00133: val_loss improved from 5703.36831 to 5604.79795, saving model to test.hdf5\n",
      "Epoch 134/350\n",
      " - 0s - loss: 6947.1822 - acc: 0.6680 - val_loss: 5442.7775 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00134: val_loss improved from 5604.79795 to 5442.77745, saving model to test.hdf5\n",
      "Epoch 135/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 6687.9741 - acc: 0.6960 - val_loss: 5217.5175 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00135: val_loss improved from 5442.77745 to 5217.51752, saving model to test.hdf5\n",
      "Epoch 136/350\n",
      " - 0s - loss: 6457.1736 - acc: 0.7040 - val_loss: 5135.7786 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00136: val_loss improved from 5217.51752 to 5135.77861, saving model to test.hdf5\n",
      "Epoch 137/350\n",
      " - 0s - loss: 6253.9489 - acc: 0.6720 - val_loss: 5042.8657 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00137: val_loss improved from 5135.77861 to 5042.86566, saving model to test.hdf5\n",
      "Epoch 138/350\n",
      " - 0s - loss: 6000.4505 - acc: 0.6920 - val_loss: 4821.9359 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00138: val_loss improved from 5042.86566 to 4821.93590, saving model to test.hdf5\n",
      "Epoch 139/350\n",
      " - 0s - loss: 5820.2854 - acc: 0.6560 - val_loss: 4637.5725 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00139: val_loss improved from 4821.93590 to 4637.57254, saving model to test.hdf5\n",
      "Epoch 140/350\n",
      " - 0s - loss: 5615.0164 - acc: 0.6760 - val_loss: 4519.5802 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00140: val_loss improved from 4637.57254 to 4519.58023, saving model to test.hdf5\n",
      "Epoch 141/350\n",
      " - 0s - loss: 5491.7916 - acc: 0.6800 - val_loss: 4354.3904 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00141: val_loss improved from 4519.58023 to 4354.39043, saving model to test.hdf5\n",
      "Epoch 142/350\n",
      " - 0s - loss: 5347.9189 - acc: 0.6840 - val_loss: 4217.2259 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00142: val_loss improved from 4354.39043 to 4217.22587, saving model to test.hdf5\n",
      "Epoch 143/350\n",
      " - 0s - loss: 5023.3640 - acc: 0.6760 - val_loss: 4106.4620 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00143: val_loss improved from 4217.22587 to 4106.46197, saving model to test.hdf5\n",
      "Epoch 144/350\n",
      " - 0s - loss: 4931.4873 - acc: 0.7120 - val_loss: 4005.8747 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00144: val_loss improved from 4106.46197 to 4005.87467, saving model to test.hdf5\n",
      "Epoch 145/350\n",
      " - 0s - loss: 4747.8516 - acc: 0.7200 - val_loss: 3966.8787 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00145: val_loss improved from 4005.87467 to 3966.87874, saving model to test.hdf5\n",
      "Epoch 146/350\n",
      " - 0s - loss: 4598.2403 - acc: 0.6840 - val_loss: 3770.6621 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00146: val_loss improved from 3966.87874 to 3770.66211, saving model to test.hdf5\n",
      "Epoch 147/350\n",
      " - 0s - loss: 4449.9354 - acc: 0.7040 - val_loss: 3660.9356 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00147: val_loss improved from 3770.66211 to 3660.93559, saving model to test.hdf5\n",
      "Epoch 148/350\n",
      " - 0s - loss: 4287.4456 - acc: 0.6800 - val_loss: 3554.7061 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00148: val_loss improved from 3660.93559 to 3554.70605, saving model to test.hdf5\n",
      "Epoch 149/350\n",
      " - 0s - loss: 4131.4167 - acc: 0.6520 - val_loss: 3421.1356 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00149: val_loss improved from 3554.70605 to 3421.13564, saving model to test.hdf5\n",
      "Epoch 150/350\n",
      " - 0s - loss: 4012.5288 - acc: 0.7200 - val_loss: 3319.7827 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00150: val_loss improved from 3421.13564 to 3319.78273, saving model to test.hdf5\n",
      "Epoch 151/350\n",
      " - 0s - loss: 3825.6091 - acc: 0.7000 - val_loss: 3248.6374 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\n",
      "Epoch 00151: val_loss improved from 3319.78273 to 3248.63739, saving model to test.hdf5\n",
      "Epoch 152/350\n",
      " - 0s - loss: 3765.4202 - acc: 0.7000 - val_loss: 3144.7342 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00152: val_loss improved from 3248.63739 to 3144.73415, saving model to test.hdf5\n",
      "Epoch 153/350\n",
      " - 0s - loss: 3610.3567 - acc: 0.7080 - val_loss: 3050.7667 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00153: val_loss improved from 3144.73415 to 3050.76668, saving model to test.hdf5\n",
      "Epoch 154/350\n",
      " - 0s - loss: 3531.3470 - acc: 0.6640 - val_loss: 2962.4506 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00154: val_loss improved from 3050.76668 to 2962.45062, saving model to test.hdf5\n",
      "Epoch 155/350\n",
      " - 0s - loss: 3439.4762 - acc: 0.7040 - val_loss: 2890.9341 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00155: val_loss improved from 2962.45062 to 2890.93414, saving model to test.hdf5\n",
      "Epoch 156/350\n",
      " - 0s - loss: 3342.2949 - acc: 0.6640 - val_loss: 2793.7764 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00156: val_loss improved from 2890.93414 to 2793.77638, saving model to test.hdf5\n",
      "Epoch 157/350\n",
      " - 0s - loss: 3199.7880 - acc: 0.7160 - val_loss: 2741.9041 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00157: val_loss improved from 2793.77638 to 2741.90410, saving model to test.hdf5\n",
      "Epoch 158/350\n",
      " - 0s - loss: 3116.9146 - acc: 0.6760 - val_loss: 2694.2725 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00158: val_loss improved from 2741.90410 to 2694.27251, saving model to test.hdf5\n",
      "Epoch 159/350\n",
      " - 0s - loss: 3067.9682 - acc: 0.6800 - val_loss: 2586.1669 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00159: val_loss improved from 2694.27251 to 2586.16691, saving model to test.hdf5\n",
      "Epoch 160/350\n",
      " - 0s - loss: 2922.5707 - acc: 0.7120 - val_loss: 2531.4698 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00160: val_loss improved from 2586.16691 to 2531.46984, saving model to test.hdf5\n",
      "Epoch 161/350\n",
      " - 0s - loss: 2799.6750 - acc: 0.7200 - val_loss: 2475.1213 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00161: val_loss improved from 2531.46984 to 2475.12129, saving model to test.hdf5\n",
      "Epoch 162/350\n",
      " - 0s - loss: 2743.4308 - acc: 0.6760 - val_loss: 2382.8819 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00162: val_loss improved from 2475.12129 to 2382.88195, saving model to test.hdf5\n",
      "Epoch 163/350\n",
      " - 0s - loss: 2661.8965 - acc: 0.6760 - val_loss: 2298.1186 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00163: val_loss improved from 2382.88195 to 2298.11857, saving model to test.hdf5\n",
      "Epoch 164/350\n",
      " - 0s - loss: 2558.9877 - acc: 0.6840 - val_loss: 2282.3686 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00164: val_loss improved from 2298.11857 to 2282.36857, saving model to test.hdf5\n",
      "Epoch 165/350\n",
      " - 0s - loss: 2529.0359 - acc: 0.7320 - val_loss: 2163.9160 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00165: val_loss improved from 2282.36857 to 2163.91597, saving model to test.hdf5\n",
      "Epoch 166/350\n",
      " - 0s - loss: 2404.8445 - acc: 0.7400 - val_loss: 2125.1163 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00166: val_loss improved from 2163.91597 to 2125.11627, saving model to test.hdf5\n",
      "Epoch 167/350\n",
      " - 0s - loss: 2342.5301 - acc: 0.6920 - val_loss: 2031.6019 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00167: val_loss improved from 2125.11627 to 2031.60194, saving model to test.hdf5\n",
      "Epoch 168/350\n",
      " - 0s - loss: 2265.0426 - acc: 0.7160 - val_loss: 2019.9956 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00168: val_loss improved from 2031.60194 to 2019.99565, saving model to test.hdf5\n",
      "Epoch 169/350\n",
      " - 0s - loss: 2176.9617 - acc: 0.6760 - val_loss: 1949.9951 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00169: val_loss improved from 2019.99565 to 1949.99508, saving model to test.hdf5\n",
      "Epoch 170/350\n",
      " - 0s - loss: 2128.0263 - acc: 0.6320 - val_loss: 1909.9160 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00170: val_loss improved from 1949.99508 to 1909.91602, saving model to test.hdf5\n",
      "Epoch 171/350\n",
      " - 0s - loss: 2056.2517 - acc: 0.6920 - val_loss: 1836.6100 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00171: val_loss improved from 1909.91602 to 1836.61002, saving model to test.hdf5\n",
      "Epoch 172/350\n",
      " - 0s - loss: 1972.5214 - acc: 0.7280 - val_loss: 1813.0813 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00172: val_loss improved from 1836.61002 to 1813.08130, saving model to test.hdf5\n",
      "Epoch 173/350\n",
      " - 0s - loss: 1952.1757 - acc: 0.7240 - val_loss: 1725.4726 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00173: val_loss improved from 1813.08130 to 1725.47259, saving model to test.hdf5\n",
      "Epoch 174/350\n",
      " - 0s - loss: 1893.9571 - acc: 0.6920 - val_loss: 1680.6391 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00174: val_loss improved from 1725.47259 to 1680.63906, saving model to test.hdf5\n",
      "Epoch 175/350\n",
      " - 0s - loss: 1780.8874 - acc: 0.7200 - val_loss: 1635.7093 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00175: val_loss improved from 1680.63906 to 1635.70934, saving model to test.hdf5\n",
      "Epoch 176/350\n",
      " - 0s - loss: 1731.3674 - acc: 0.6480 - val_loss: 1597.0368 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00176: val_loss improved from 1635.70934 to 1597.03676, saving model to test.hdf5\n",
      "Epoch 177/350\n",
      " - 0s - loss: 1703.7702 - acc: 0.6880 - val_loss: 1526.2940 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00177: val_loss improved from 1597.03676 to 1526.29396, saving model to test.hdf5\n",
      "Epoch 178/350\n",
      " - 0s - loss: 1643.7442 - acc: 0.6520 - val_loss: 1489.7934 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00178: val_loss improved from 1526.29396 to 1489.79342, saving model to test.hdf5\n",
      "Epoch 179/350\n",
      " - 0s - loss: 1596.1276 - acc: 0.7120 - val_loss: 1441.8211 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00179: val_loss improved from 1489.79342 to 1441.82107, saving model to test.hdf5\n",
      "Epoch 180/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1527.0762 - acc: 0.6520 - val_loss: 1419.6497 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00180: val_loss improved from 1441.82107 to 1419.64970, saving model to test.hdf5\n",
      "Epoch 181/350\n",
      " - 0s - loss: 1503.4654 - acc: 0.6880 - val_loss: 1360.1235 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00181: val_loss improved from 1419.64970 to 1360.12346, saving model to test.hdf5\n",
      "Epoch 182/350\n",
      " - 0s - loss: 1446.8620 - acc: 0.6600 - val_loss: 1330.3874 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00182: val_loss improved from 1360.12346 to 1330.38738, saving model to test.hdf5\n",
      "Epoch 183/350\n",
      " - 0s - loss: 1400.4780 - acc: 0.7280 - val_loss: 1287.7059 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00183: val_loss improved from 1330.38738 to 1287.70591, saving model to test.hdf5\n",
      "Epoch 184/350\n",
      " - 0s - loss: 1338.6818 - acc: 0.7080 - val_loss: 1245.6568 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00184: val_loss improved from 1287.70591 to 1245.65683, saving model to test.hdf5\n",
      "Epoch 185/350\n",
      " - 0s - loss: 1272.6247 - acc: 0.6840 - val_loss: 1228.9950 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00185: val_loss improved from 1245.65683 to 1228.99498, saving model to test.hdf5\n",
      "Epoch 186/350\n",
      " - 0s - loss: 1254.5428 - acc: 0.6720 - val_loss: 1174.6787 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00186: val_loss improved from 1228.99498 to 1174.67875, saving model to test.hdf5\n",
      "Epoch 187/350\n",
      " - 0s - loss: 1223.4038 - acc: 0.7120 - val_loss: 1138.6507 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00187: val_loss improved from 1174.67875 to 1138.65070, saving model to test.hdf5\n",
      "Epoch 188/350\n",
      " - 0s - loss: 1169.1262 - acc: 0.7400 - val_loss: 1095.8503 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00188: val_loss improved from 1138.65070 to 1095.85035, saving model to test.hdf5\n",
      "Epoch 189/350\n",
      " - 0s - loss: 1143.8924 - acc: 0.7120 - val_loss: 1066.9046 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00189: val_loss improved from 1095.85035 to 1066.90461, saving model to test.hdf5\n",
      "Epoch 190/350\n",
      " - 0s - loss: 1100.9514 - acc: 0.7080 - val_loss: 1040.4727 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00190: val_loss improved from 1066.90461 to 1040.47272, saving model to test.hdf5\n",
      "Epoch 191/350\n",
      " - 0s - loss: 1088.8638 - acc: 0.7320 - val_loss: 1018.6294 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00191: val_loss improved from 1040.47272 to 1018.62942, saving model to test.hdf5\n",
      "Epoch 192/350\n",
      " - 0s - loss: 1035.1806 - acc: 0.7120 - val_loss: 982.2834 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00192: val_loss improved from 1018.62942 to 982.28343, saving model to test.hdf5\n",
      "Epoch 193/350\n",
      " - 0s - loss: 991.0575 - acc: 0.6760 - val_loss: 958.1921 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00193: val_loss improved from 982.28343 to 958.19206, saving model to test.hdf5\n",
      "Epoch 194/350\n",
      " - 0s - loss: 947.3628 - acc: 0.7120 - val_loss: 933.2982 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00194: val_loss improved from 958.19206 to 933.29825, saving model to test.hdf5\n",
      "Epoch 195/350\n",
      " - 0s - loss: 918.7671 - acc: 0.7040 - val_loss: 914.6584 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00195: val_loss improved from 933.29825 to 914.65838, saving model to test.hdf5\n",
      "Epoch 196/350\n",
      " - 0s - loss: 872.2549 - acc: 0.7400 - val_loss: 858.2442 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00196: val_loss improved from 914.65838 to 858.24423, saving model to test.hdf5\n",
      "Epoch 197/350\n",
      " - 0s - loss: 871.9812 - acc: 0.7440 - val_loss: 837.8367 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00197: val_loss improved from 858.24423 to 837.83672, saving model to test.hdf5\n",
      "Epoch 198/350\n",
      " - 0s - loss: 834.1577 - acc: 0.6920 - val_loss: 810.3415 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00198: val_loss improved from 837.83672 to 810.34149, saving model to test.hdf5\n",
      "Epoch 199/350\n",
      " - 0s - loss: 808.1568 - acc: 0.7200 - val_loss: 783.6776 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00199: val_loss improved from 810.34149 to 783.67756, saving model to test.hdf5\n",
      "Epoch 200/350\n",
      " - 0s - loss: 784.4027 - acc: 0.7160 - val_loss: 760.0030 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00200: val_loss improved from 783.67756 to 760.00297, saving model to test.hdf5\n",
      "Epoch 201/350\n",
      " - 0s - loss: 757.5796 - acc: 0.6840 - val_loss: 733.6895 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "\n",
      "Epoch 00201: val_loss improved from 760.00297 to 733.68952, saving model to test.hdf5\n",
      "Epoch 202/350\n",
      " - 0s - loss: 730.4569 - acc: 0.7160 - val_loss: 717.1217 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00202: val_loss improved from 733.68952 to 717.12171, saving model to test.hdf5\n",
      "Epoch 203/350\n",
      " - 0s - loss: 700.9212 - acc: 0.7080 - val_loss: 697.5717 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00203: val_loss improved from 717.12171 to 697.57172, saving model to test.hdf5\n",
      "Epoch 204/350\n",
      " - 0s - loss: 678.0041 - acc: 0.7560 - val_loss: 673.6514 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00204: val_loss improved from 697.57172 to 673.65141, saving model to test.hdf5\n",
      "Epoch 205/350\n",
      " - 0s - loss: 658.7689 - acc: 0.7400 - val_loss: 661.1284 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00205: val_loss improved from 673.65141 to 661.12840, saving model to test.hdf5\n",
      "Epoch 206/350\n",
      " - 0s - loss: 636.1112 - acc: 0.7400 - val_loss: 650.1281 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00206: val_loss improved from 661.12840 to 650.12809, saving model to test.hdf5\n",
      "Epoch 207/350\n",
      " - 0s - loss: 621.8258 - acc: 0.6920 - val_loss: 632.3993 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00207: val_loss improved from 650.12809 to 632.39933, saving model to test.hdf5\n",
      "Epoch 208/350\n",
      " - 0s - loss: 610.0163 - acc: 0.6760 - val_loss: 612.4751 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00208: val_loss improved from 632.39933 to 612.47513, saving model to test.hdf5\n",
      "Epoch 209/350\n",
      " - 0s - loss: 586.7898 - acc: 0.7480 - val_loss: 586.4144 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00209: val_loss improved from 612.47513 to 586.41442, saving model to test.hdf5\n",
      "Epoch 210/350\n",
      " - 0s - loss: 559.3524 - acc: 0.6680 - val_loss: 584.9973 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00210: val_loss improved from 586.41442 to 584.99725, saving model to test.hdf5\n",
      "Epoch 211/350\n",
      " - 0s - loss: 551.1825 - acc: 0.7160 - val_loss: 549.7374 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00211: val_loss improved from 584.99725 to 549.73740, saving model to test.hdf5\n",
      "Epoch 212/350\n",
      " - 0s - loss: 519.0117 - acc: 0.7560 - val_loss: 550.6329 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 549.73740\n",
      "Epoch 213/350\n",
      " - 0s - loss: 523.0525 - acc: 0.7200 - val_loss: 517.5460 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00213: val_loss improved from 549.73740 to 517.54603, saving model to test.hdf5\n",
      "Epoch 214/350\n",
      " - 0s - loss: 501.8894 - acc: 0.7160 - val_loss: 506.5950 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00214: val_loss improved from 517.54603 to 506.59505, saving model to test.hdf5\n",
      "Epoch 215/350\n",
      " - 0s - loss: 480.3367 - acc: 0.7360 - val_loss: 494.7367 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00215: val_loss improved from 506.59505 to 494.73672, saving model to test.hdf5\n",
      "Epoch 216/350\n",
      " - 0s - loss: 463.5430 - acc: 0.7040 - val_loss: 492.2311 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00216: val_loss improved from 494.73672 to 492.23107, saving model to test.hdf5\n",
      "Epoch 217/350\n",
      " - 0s - loss: 454.4645 - acc: 0.7200 - val_loss: 459.7882 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00217: val_loss improved from 492.23107 to 459.78818, saving model to test.hdf5\n",
      "Epoch 218/350\n",
      " - 0s - loss: 438.3813 - acc: 0.7320 - val_loss: 452.2892 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00218: val_loss improved from 459.78818 to 452.28917, saving model to test.hdf5\n",
      "Epoch 219/350\n",
      " - 0s - loss: 416.7403 - acc: 0.7480 - val_loss: 440.9836 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00219: val_loss improved from 452.28917 to 440.98359, saving model to test.hdf5\n",
      "Epoch 220/350\n",
      " - 0s - loss: 409.3439 - acc: 0.7040 - val_loss: 427.0600 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00220: val_loss improved from 440.98359 to 427.05998, saving model to test.hdf5\n",
      "Epoch 221/350\n",
      " - 0s - loss: 391.2768 - acc: 0.7800 - val_loss: 412.6127 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00221: val_loss improved from 427.05998 to 412.61275, saving model to test.hdf5\n",
      "Epoch 222/350\n",
      " - 0s - loss: 394.2573 - acc: 0.7880 - val_loss: 398.4967 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00222: val_loss improved from 412.61275 to 398.49674, saving model to test.hdf5\n",
      "Epoch 223/350\n",
      " - 0s - loss: 372.7122 - acc: 0.6960 - val_loss: 388.3519 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00223: val_loss improved from 398.49674 to 388.35187, saving model to test.hdf5\n",
      "Epoch 224/350\n",
      " - 0s - loss: 360.7898 - acc: 0.7520 - val_loss: 371.3239 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00224: val_loss improved from 388.35187 to 371.32386, saving model to test.hdf5\n",
      "Epoch 225/350\n",
      " - 0s - loss: 349.6527 - acc: 0.7400 - val_loss: 369.5930 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00225: val_loss improved from 371.32386 to 369.59302, saving model to test.hdf5\n",
      "Epoch 226/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 342.2329 - acc: 0.7480 - val_loss: 351.4937 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00226: val_loss improved from 369.59302 to 351.49374, saving model to test.hdf5\n",
      "Epoch 227/350\n",
      " - 0s - loss: 322.4689 - acc: 0.7120 - val_loss: 343.1688 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00227: val_loss improved from 351.49374 to 343.16876, saving model to test.hdf5\n",
      "Epoch 228/350\n",
      " - 0s - loss: 313.5403 - acc: 0.7480 - val_loss: 326.0442 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00228: val_loss improved from 343.16876 to 326.04417, saving model to test.hdf5\n",
      "Epoch 229/350\n",
      " - 0s - loss: 305.2987 - acc: 0.7400 - val_loss: 317.0250 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00229: val_loss improved from 326.04417 to 317.02503, saving model to test.hdf5\n",
      "Epoch 230/350\n",
      " - 0s - loss: 296.4360 - acc: 0.7200 - val_loss: 308.5535 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00230: val_loss improved from 317.02503 to 308.55346, saving model to test.hdf5\n",
      "Epoch 231/350\n",
      " - 0s - loss: 281.1626 - acc: 0.7160 - val_loss: 302.8319 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00231: val_loss improved from 308.55346 to 302.83190, saving model to test.hdf5\n",
      "Epoch 232/350\n",
      " - 0s - loss: 275.4445 - acc: 0.7080 - val_loss: 289.0019 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00232: val_loss improved from 302.83190 to 289.00189, saving model to test.hdf5\n",
      "Epoch 233/350\n",
      " - 0s - loss: 267.2457 - acc: 0.7480 - val_loss: 279.8374 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00233: val_loss improved from 289.00189 to 279.83735, saving model to test.hdf5\n",
      "Epoch 234/350\n",
      " - 0s - loss: 250.1055 - acc: 0.7280 - val_loss: 271.5033 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00234: val_loss improved from 279.83735 to 271.50326, saving model to test.hdf5\n",
      "Epoch 235/350\n",
      " - 0s - loss: 246.2959 - acc: 0.7560 - val_loss: 264.2821 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00235: val_loss improved from 271.50326 to 264.28213, saving model to test.hdf5\n",
      "Epoch 236/350\n",
      " - 0s - loss: 238.2091 - acc: 0.7480 - val_loss: 263.4529 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00236: val_loss improved from 264.28213 to 263.45289, saving model to test.hdf5\n",
      "Epoch 237/350\n",
      " - 0s - loss: 231.0389 - acc: 0.7560 - val_loss: 253.7886 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00237: val_loss improved from 263.45289 to 253.78862, saving model to test.hdf5\n",
      "Epoch 238/350\n",
      " - 0s - loss: 224.4073 - acc: 0.7640 - val_loss: 242.1488 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00238: val_loss improved from 253.78862 to 242.14882, saving model to test.hdf5\n",
      "Epoch 239/350\n",
      " - 0s - loss: 212.9132 - acc: 0.7400 - val_loss: 232.4770 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00239: val_loss improved from 242.14882 to 232.47702, saving model to test.hdf5\n",
      "Epoch 240/350\n",
      " - 0s - loss: 208.1898 - acc: 0.7400 - val_loss: 225.3279 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00240: val_loss improved from 232.47702 to 225.32793, saving model to test.hdf5\n",
      "Epoch 241/350\n",
      " - 0s - loss: 201.0551 - acc: 0.7280 - val_loss: 217.6461 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00241: val_loss improved from 225.32793 to 217.64607, saving model to test.hdf5\n",
      "Epoch 242/350\n",
      " - 0s - loss: 197.7449 - acc: 0.7320 - val_loss: 210.7897 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00242: val_loss improved from 217.64607 to 210.78972, saving model to test.hdf5\n",
      "Epoch 243/350\n",
      " - 0s - loss: 187.2255 - acc: 0.7360 - val_loss: 207.1036 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00243: val_loss improved from 210.78972 to 207.10363, saving model to test.hdf5\n",
      "Epoch 244/350\n",
      " - 0s - loss: 178.3863 - acc: 0.7160 - val_loss: 196.5889 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00244: val_loss improved from 207.10363 to 196.58891, saving model to test.hdf5\n",
      "Epoch 245/350\n",
      " - 0s - loss: 177.4947 - acc: 0.7640 - val_loss: 193.5993 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00245: val_loss improved from 196.58891 to 193.59933, saving model to test.hdf5\n",
      "Epoch 246/350\n",
      " - 0s - loss: 168.3948 - acc: 0.7320 - val_loss: 188.0363 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00246: val_loss improved from 193.59933 to 188.03627, saving model to test.hdf5\n",
      "Epoch 247/350\n",
      " - 0s - loss: 162.9932 - acc: 0.7400 - val_loss: 176.4345 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00247: val_loss improved from 188.03627 to 176.43448, saving model to test.hdf5\n",
      "Epoch 248/350\n",
      " - 0s - loss: 155.5497 - acc: 0.7560 - val_loss: 170.5760 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00248: val_loss improved from 176.43448 to 170.57601, saving model to test.hdf5\n",
      "Epoch 249/350\n",
      " - 0s - loss: 153.1595 - acc: 0.7360 - val_loss: 166.5621 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00249: val_loss improved from 170.57601 to 166.56205, saving model to test.hdf5\n",
      "Epoch 250/350\n",
      " - 0s - loss: 146.1751 - acc: 0.7640 - val_loss: 164.5373 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00250: val_loss improved from 166.56205 to 164.53731, saving model to test.hdf5\n",
      "Epoch 251/350\n",
      " - 0s - loss: 140.7456 - acc: 0.7640 - val_loss: 158.4572 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "\n",
      "Epoch 00251: val_loss improved from 164.53731 to 158.45720, saving model to test.hdf5\n",
      "Epoch 252/350\n",
      " - 0s - loss: 132.9145 - acc: 0.7760 - val_loss: 152.1050 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00252: val_loss improved from 158.45720 to 152.10505, saving model to test.hdf5\n",
      "Epoch 253/350\n",
      " - 0s - loss: 132.5516 - acc: 0.7560 - val_loss: 145.7186 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00253: val_loss improved from 152.10505 to 145.71864, saving model to test.hdf5\n",
      "Epoch 254/350\n",
      " - 0s - loss: 126.5891 - acc: 0.7680 - val_loss: 142.3701 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00254: val_loss improved from 145.71864 to 142.37005, saving model to test.hdf5\n",
      "Epoch 255/350\n",
      " - 0s - loss: 123.8427 - acc: 0.7160 - val_loss: 137.8144 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00255: val_loss improved from 142.37005 to 137.81443, saving model to test.hdf5\n",
      "Epoch 256/350\n",
      " - 0s - loss: 117.8378 - acc: 0.7600 - val_loss: 134.2167 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00256: val_loss improved from 137.81443 to 134.21665, saving model to test.hdf5\n",
      "Epoch 257/350\n",
      " - 0s - loss: 113.3775 - acc: 0.7920 - val_loss: 128.6371 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00257: val_loss improved from 134.21665 to 128.63709, saving model to test.hdf5\n",
      "Epoch 258/350\n",
      " - 0s - loss: 112.0077 - acc: 0.8040 - val_loss: 126.4337 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00258: val_loss improved from 128.63709 to 126.43370, saving model to test.hdf5\n",
      "Epoch 259/350\n",
      " - 0s - loss: 108.2878 - acc: 0.7360 - val_loss: 122.4927 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00259: val_loss improved from 126.43370 to 122.49275, saving model to test.hdf5\n",
      "Epoch 260/350\n",
      " - 0s - loss: 101.6789 - acc: 0.7400 - val_loss: 120.7988 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00260: val_loss improved from 122.49275 to 120.79882, saving model to test.hdf5\n",
      "Epoch 261/350\n",
      " - 0s - loss: 100.9806 - acc: 0.7160 - val_loss: 117.7915 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00261: val_loss improved from 120.79882 to 117.79146, saving model to test.hdf5\n",
      "Epoch 262/350\n",
      " - 0s - loss: 98.9810 - acc: 0.7520 - val_loss: 111.2690 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00262: val_loss improved from 117.79146 to 111.26901, saving model to test.hdf5\n",
      "Epoch 263/350\n",
      " - 0s - loss: 95.6381 - acc: 0.7600 - val_loss: 108.4570 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00263: val_loss improved from 111.26901 to 108.45699, saving model to test.hdf5\n",
      "Epoch 264/350\n",
      " - 0s - loss: 91.4901 - acc: 0.7760 - val_loss: 102.7349 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00264: val_loss improved from 108.45699 to 102.73490, saving model to test.hdf5\n",
      "Epoch 265/350\n",
      " - 0s - loss: 88.6266 - acc: 0.7320 - val_loss: 100.9890 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00265: val_loss improved from 102.73490 to 100.98900, saving model to test.hdf5\n",
      "Epoch 266/350\n",
      " - 0s - loss: 84.7308 - acc: 0.7560 - val_loss: 96.4381 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00266: val_loss improved from 100.98900 to 96.43807, saving model to test.hdf5\n",
      "Epoch 267/350\n",
      " - 0s - loss: 82.4249 - acc: 0.7720 - val_loss: 95.1000 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00267: val_loss improved from 96.43807 to 95.09996, saving model to test.hdf5\n",
      "Epoch 268/350\n",
      " - 0s - loss: 79.2505 - acc: 0.7240 - val_loss: 95.0973 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00268: val_loss improved from 95.09996 to 95.09727, saving model to test.hdf5\n",
      "Epoch 269/350\n",
      " - 0s - loss: 76.6218 - acc: 0.7560 - val_loss: 88.9053 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00269: val_loss improved from 95.09727 to 88.90532, saving model to test.hdf5\n",
      "Epoch 270/350\n",
      " - 0s - loss: 70.8693 - acc: 0.7720 - val_loss: 87.1426 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00270: val_loss improved from 88.90532 to 87.14261, saving model to test.hdf5\n",
      "Epoch 271/350\n",
      " - 0s - loss: 71.9589 - acc: 0.7320 - val_loss: 85.3845 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00271: val_loss improved from 87.14261 to 85.38446, saving model to test.hdf5\n",
      "Epoch 272/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 70.5266 - acc: 0.7720 - val_loss: 80.0816 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00272: val_loss improved from 85.38446 to 80.08155, saving model to test.hdf5\n",
      "Epoch 273/350\n",
      " - 0s - loss: 65.9735 - acc: 0.7520 - val_loss: 77.4458 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00273: val_loss improved from 80.08155 to 77.44582, saving model to test.hdf5\n",
      "Epoch 274/350\n",
      " - 0s - loss: 64.8257 - acc: 0.7480 - val_loss: 77.8672 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 77.44582\n",
      "Epoch 275/350\n",
      " - 0s - loss: 61.6213 - acc: 0.7720 - val_loss: 73.4333 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00275: val_loss improved from 77.44582 to 73.43331, saving model to test.hdf5\n",
      "Epoch 276/350\n",
      " - 0s - loss: 61.2154 - acc: 0.7600 - val_loss: 72.7083 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00276: val_loss improved from 73.43331 to 72.70834, saving model to test.hdf5\n",
      "Epoch 277/350\n",
      " - 0s - loss: 58.3120 - acc: 0.7520 - val_loss: 68.2723 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00277: val_loss improved from 72.70834 to 68.27228, saving model to test.hdf5\n",
      "Epoch 278/350\n",
      " - 0s - loss: 57.0695 - acc: 0.7880 - val_loss: 65.8299 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00278: val_loss improved from 68.27228 to 65.82986, saving model to test.hdf5\n",
      "Epoch 279/350\n",
      " - 0s - loss: 55.5562 - acc: 0.7520 - val_loss: 63.0677 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00279: val_loss improved from 65.82986 to 63.06768, saving model to test.hdf5\n",
      "Epoch 280/350\n",
      " - 0s - loss: 55.3350 - acc: 0.7600 - val_loss: 60.9915 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00280: val_loss improved from 63.06768 to 60.99149, saving model to test.hdf5\n",
      "Epoch 281/350\n",
      " - 0s - loss: 52.8149 - acc: 0.7640 - val_loss: 59.4676 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00281: val_loss improved from 60.99149 to 59.46755, saving model to test.hdf5\n",
      "Epoch 282/350\n",
      " - 0s - loss: 48.2897 - acc: 0.7280 - val_loss: 57.5809 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00282: val_loss improved from 59.46755 to 57.58088, saving model to test.hdf5\n",
      "Epoch 283/350\n",
      " - 0s - loss: 47.3274 - acc: 0.7760 - val_loss: 54.9118 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00283: val_loss improved from 57.58088 to 54.91182, saving model to test.hdf5\n",
      "Epoch 284/350\n",
      " - 0s - loss: 54.9288 - acc: 0.8040 - val_loss: 54.0038 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00284: val_loss improved from 54.91182 to 54.00376, saving model to test.hdf5\n",
      "Epoch 285/350\n",
      " - 0s - loss: 43.2028 - acc: 0.7520 - val_loss: 52.1866 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00285: val_loss improved from 54.00376 to 52.18656, saving model to test.hdf5\n",
      "Epoch 286/350\n",
      " - 0s - loss: 41.2569 - acc: 0.7920 - val_loss: 48.9370 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00286: val_loss improved from 52.18656 to 48.93697, saving model to test.hdf5\n",
      "Epoch 287/350\n",
      " - 0s - loss: 40.8737 - acc: 0.7800 - val_loss: 47.5069 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00287: val_loss improved from 48.93697 to 47.50687, saving model to test.hdf5\n",
      "Epoch 288/350\n",
      " - 0s - loss: 39.1853 - acc: 0.7960 - val_loss: 47.0317 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00288: val_loss improved from 47.50687 to 47.03166, saving model to test.hdf5\n",
      "Epoch 289/350\n",
      " - 0s - loss: 38.4404 - acc: 0.7720 - val_loss: 46.8396 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00289: val_loss improved from 47.03166 to 46.83960, saving model to test.hdf5\n",
      "Epoch 290/350\n",
      " - 0s - loss: 47.9838 - acc: 0.7880 - val_loss: 44.7518 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00290: val_loss improved from 46.83960 to 44.75184, saving model to test.hdf5\n",
      "Epoch 291/350\n",
      " - 0s - loss: 36.4221 - acc: 0.7640 - val_loss: 41.6438 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00291: val_loss improved from 44.75184 to 41.64378, saving model to test.hdf5\n",
      "Epoch 292/350\n",
      " - 0s - loss: 34.0231 - acc: 0.7720 - val_loss: 43.1365 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 41.64378\n",
      "Epoch 293/350\n",
      " - 0s - loss: 32.4360 - acc: 0.7520 - val_loss: 38.1741 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00293: val_loss improved from 41.64378 to 38.17415, saving model to test.hdf5\n",
      "Epoch 294/350\n",
      " - 0s - loss: 30.3755 - acc: 0.7840 - val_loss: 36.7502 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00294: val_loss improved from 38.17415 to 36.75016, saving model to test.hdf5\n",
      "Epoch 295/350\n",
      " - 0s - loss: 31.0481 - acc: 0.7560 - val_loss: 36.9632 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 36.75016\n",
      "Epoch 296/350\n",
      " - 0s - loss: 28.4426 - acc: 0.7800 - val_loss: 34.2874 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00296: val_loss improved from 36.75016 to 34.28735, saving model to test.hdf5\n",
      "Epoch 297/350\n",
      " - 0s - loss: 27.6726 - acc: 0.7720 - val_loss: 33.3702 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00297: val_loss improved from 34.28735 to 33.37017, saving model to test.hdf5\n",
      "Epoch 298/350\n",
      " - 0s - loss: 27.4224 - acc: 0.7400 - val_loss: 32.6849 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00298: val_loss improved from 33.37017 to 32.68494, saving model to test.hdf5\n",
      "Epoch 299/350\n",
      " - 0s - loss: 26.1799 - acc: 0.7840 - val_loss: 32.9934 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 32.68494\n",
      "Epoch 300/350\n",
      " - 0s - loss: 25.4667 - acc: 0.7560 - val_loss: 30.1511 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00300: val_loss improved from 32.68494 to 30.15108, saving model to test.hdf5\n",
      "Epoch 301/350\n",
      " - 0s - loss: 23.9553 - acc: 0.7800 - val_loss: 28.5784 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "\n",
      "Epoch 00301: val_loss improved from 30.15108 to 28.57843, saving model to test.hdf5\n",
      "Epoch 302/350\n",
      " - 0s - loss: 23.4183 - acc: 0.7520 - val_loss: 27.4588 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00302: val_loss improved from 28.57843 to 27.45884, saving model to test.hdf5\n",
      "Epoch 303/350\n",
      " - 0s - loss: 21.7824 - acc: 0.7760 - val_loss: 26.6532 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00303: val_loss improved from 27.45884 to 26.65315, saving model to test.hdf5\n",
      "Epoch 304/350\n",
      " - 0s - loss: 21.6805 - acc: 0.7520 - val_loss: 25.8794 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00304: val_loss improved from 26.65315 to 25.87936, saving model to test.hdf5\n",
      "Epoch 305/350\n",
      " - 0s - loss: 20.4221 - acc: 0.7880 - val_loss: 25.5669 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00305: val_loss improved from 25.87936 to 25.56689, saving model to test.hdf5\n",
      "Epoch 306/350\n",
      " - 0s - loss: 19.5394 - acc: 0.7520 - val_loss: 24.0966 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00306: val_loss improved from 25.56689 to 24.09661, saving model to test.hdf5\n",
      "Epoch 307/350\n",
      " - 0s - loss: 19.6999 - acc: 0.7520 - val_loss: 23.9419 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00307: val_loss improved from 24.09661 to 23.94191, saving model to test.hdf5\n",
      "Epoch 308/350\n",
      " - 0s - loss: 18.7356 - acc: 0.7640 - val_loss: 22.4278 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00308: val_loss improved from 23.94191 to 22.42782, saving model to test.hdf5\n",
      "Epoch 309/350\n",
      " - 0s - loss: 17.9090 - acc: 0.7800 - val_loss: 21.6251 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00309: val_loss improved from 22.42782 to 21.62506, saving model to test.hdf5\n",
      "Epoch 310/350\n",
      " - 0s - loss: 17.2290 - acc: 0.8240 - val_loss: 21.0966 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00310: val_loss improved from 21.62506 to 21.09663, saving model to test.hdf5\n",
      "Epoch 311/350\n",
      " - 0s - loss: 16.9148 - acc: 0.7920 - val_loss: 20.3781 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00311: val_loss improved from 21.09663 to 20.37807, saving model to test.hdf5\n",
      "Epoch 312/350\n",
      " - 0s - loss: 16.0862 - acc: 0.7800 - val_loss: 19.2186 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00312: val_loss improved from 20.37807 to 19.21856, saving model to test.hdf5\n",
      "Epoch 313/350\n",
      " - 0s - loss: 15.6344 - acc: 0.7560 - val_loss: 18.5501 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00313: val_loss improved from 19.21856 to 18.55010, saving model to test.hdf5\n",
      "Epoch 314/350\n",
      " - 0s - loss: 15.2103 - acc: 0.7760 - val_loss: 18.3510 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00314: val_loss improved from 18.55010 to 18.35096, saving model to test.hdf5\n",
      "Epoch 315/350\n",
      " - 0s - loss: 14.6466 - acc: 0.7480 - val_loss: 17.5117 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00315: val_loss improved from 18.35096 to 17.51172, saving model to test.hdf5\n",
      "Epoch 316/350\n",
      " - 0s - loss: 13.9665 - acc: 0.7760 - val_loss: 17.2049 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00316: val_loss improved from 17.51172 to 17.20491, saving model to test.hdf5\n",
      "Epoch 317/350\n",
      " - 0s - loss: 15.4900 - acc: 0.7640 - val_loss: 16.0595 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00317: val_loss improved from 17.20491 to 16.05946, saving model to test.hdf5\n",
      "Epoch 318/350\n",
      " - 0s - loss: 14.5123 - acc: 0.7600 - val_loss: 15.8618 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00318: val_loss improved from 16.05946 to 15.86175, saving model to test.hdf5\n",
      "Epoch 319/350\n",
      " - 0s - loss: 14.0664 - acc: 0.7600 - val_loss: 16.1334 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 15.86175\n",
      "Epoch 320/350\n",
      " - 0s - loss: 13.8383 - acc: 0.7840 - val_loss: 14.2480 - val_acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00320: val_loss improved from 15.86175 to 14.24804, saving model to test.hdf5\n",
      "Epoch 321/350\n",
      " - 0s - loss: 11.9459 - acc: 0.7640 - val_loss: 13.9650 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00321: val_loss improved from 14.24804 to 13.96505, saving model to test.hdf5\n",
      "Epoch 322/350\n",
      " - 0s - loss: 13.4138 - acc: 0.7400 - val_loss: 13.4786 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00322: val_loss improved from 13.96505 to 13.47859, saving model to test.hdf5\n",
      "Epoch 323/350\n",
      " - 0s - loss: 11.6445 - acc: 0.7320 - val_loss: 14.5957 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 13.47859\n",
      "Epoch 324/350\n",
      " - 0s - loss: 13.3034 - acc: 0.7960 - val_loss: 15.0535 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 13.47859\n",
      "Epoch 325/350\n",
      " - 0s - loss: 29.5855 - acc: 0.7840 - val_loss: 12.8446 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00325: val_loss improved from 13.47859 to 12.84460, saving model to test.hdf5\n",
      "Epoch 326/350\n",
      " - 0s - loss: 12.3160 - acc: 0.7880 - val_loss: 14.0388 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 12.84460\n",
      "Epoch 327/350\n",
      " - 0s - loss: 70.3453 - acc: 0.8040 - val_loss: 13.2580 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 12.84460\n",
      "Epoch 328/350\n",
      " - 0s - loss: 11.5792 - acc: 0.7800 - val_loss: 11.3258 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00328: val_loss improved from 12.84460 to 11.32581, saving model to test.hdf5\n",
      "Epoch 329/350\n",
      " - 0s - loss: 9.7355 - acc: 0.7760 - val_loss: 11.1783 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00329: val_loss improved from 11.32581 to 11.17826, saving model to test.hdf5\n",
      "Epoch 330/350\n",
      " - 0s - loss: 9.5484 - acc: 0.8120 - val_loss: 9.9831 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00330: val_loss improved from 11.17826 to 9.98312, saving model to test.hdf5\n",
      "Epoch 331/350\n",
      " - 0s - loss: 8.6582 - acc: 0.7880 - val_loss: 9.4977 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00331: val_loss improved from 9.98312 to 9.49775, saving model to test.hdf5\n",
      "Epoch 332/350\n",
      " - 0s - loss: 8.6858 - acc: 0.7560 - val_loss: 9.8160 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 9.49775\n",
      "Epoch 333/350\n",
      " - 0s - loss: 8.6528 - acc: 0.7760 - val_loss: 8.8553 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00333: val_loss improved from 9.49775 to 8.85534, saving model to test.hdf5\n",
      "Epoch 334/350\n",
      " - 0s - loss: 8.3558 - acc: 0.7600 - val_loss: 8.6744 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00334: val_loss improved from 8.85534 to 8.67437, saving model to test.hdf5\n",
      "Epoch 335/350\n",
      " - 0s - loss: 7.5177 - acc: 0.7680 - val_loss: 8.5102 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00335: val_loss improved from 8.67437 to 8.51017, saving model to test.hdf5\n",
      "Epoch 336/350\n",
      " - 0s - loss: 8.3764 - acc: 0.7400 - val_loss: 8.0466 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00336: val_loss improved from 8.51017 to 8.04664, saving model to test.hdf5\n",
      "Epoch 337/350\n",
      " - 0s - loss: 12.7087 - acc: 0.7600 - val_loss: 8.2467 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 8.04664\n",
      "Epoch 338/350\n",
      " - 0s - loss: 9.7848 - acc: 0.7360 - val_loss: 8.1040 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 8.04664\n",
      "Epoch 339/350\n",
      " - 0s - loss: 6.9826 - acc: 0.7240 - val_loss: 7.1999 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00339: val_loss improved from 8.04664 to 7.19986, saving model to test.hdf5\n",
      "Epoch 340/350\n",
      " - 0s - loss: 6.5367 - acc: 0.7520 - val_loss: 7.5122 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 7.19986\n",
      "Epoch 341/350\n",
      " - 0s - loss: 6.0191 - acc: 0.8120 - val_loss: 6.4850 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00341: val_loss improved from 7.19986 to 6.48498, saving model to test.hdf5\n",
      "Epoch 342/350\n",
      " - 0s - loss: 7.0972 - acc: 0.7600 - val_loss: 6.5079 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 6.48498\n",
      "Epoch 343/350\n",
      " - 0s - loss: 6.7703 - acc: 0.7920 - val_loss: 6.0535 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00343: val_loss improved from 6.48498 to 6.05355, saving model to test.hdf5\n",
      "Epoch 344/350\n",
      " - 0s - loss: 9.4615 - acc: 0.7960 - val_loss: 6.4205 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 6.05355\n",
      "Epoch 345/350\n",
      " - 0s - loss: 6.7965 - acc: 0.7640 - val_loss: 6.0857 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 6.05355\n",
      "Epoch 346/350\n",
      " - 0s - loss: 11.4667 - acc: 0.7720 - val_loss: 5.8035 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00346: val_loss improved from 6.05355 to 5.80352, saving model to test.hdf5\n",
      "Epoch 347/350\n",
      " - 0s - loss: 10.4058 - acc: 0.7480 - val_loss: 5.3835 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00347: val_loss improved from 5.80352 to 5.38350, saving model to test.hdf5\n",
      "Epoch 348/350\n",
      " - 0s - loss: 5.7901 - acc: 0.7800 - val_loss: 5.3559 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00348: val_loss improved from 5.38350 to 5.35587, saving model to test.hdf5\n",
      "Epoch 349/350\n",
      " - 0s - loss: 5.3157 - acc: 0.8040 - val_loss: 5.8946 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 5.35587\n",
      "Epoch 350/350\n",
      " - 0s - loss: 36.6258 - acc: 0.7520 - val_loss: 7.1669 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 5.35587\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 350, \n",
    "          batch_size = 15, \n",
    "          verbose=2, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b22178a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b221750940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???? Есть один большой вопрос по метрикам ошибок в регрессиях - где-то есть mse, где-то rmse, нет унифицированного критерия. Также лично для меня значения mse/rmse не показательны - я не понимаю, это много или мало????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???? В регрессии получается, что метрика потерь и метрика качества одинаковая - это нормально????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  shuffle_in_unison (a, b):\n",
    "\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    " \n",
    "def create_Xt_Yt(X, y, percentage=0.9):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "     \n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    " \n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорректировали функцию X, Y - заменили Y пустым списком, добавили нормализацию (без нее также пробовал, она ухудшает прогноз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index out of bounds\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 26\n",
    "STEP = 1\n",
    "FORECAST = 5\n",
    "\n",
    "\n",
    "X, Y = [], []\n",
    "for i in range(0, len(data), STEP): \n",
    "    try:\n",
    "        x_i = data[i:i+WINDOW]\n",
    "        y_i = data[i+WINDOW+FORECAST]  \n",
    "\n",
    "        last_close = x_i[WINDOW-1]\n",
    "        next_close = y_i\n",
    "\n",
    "        y = []\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        break\n",
    "\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "\n",
    "X = [(np.array(x) - np.mean(x)) / np.std(x) for x in X]\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель простая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "по отношению к регрессии заменили метрикуи ошибку на mse, выходную функцию активации на сигмоид"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/350\n",
      " - 1s - loss: 307749.2544 - mean_squared_error: 307749.2544 - val_loss: 631761.7500 - val_mean_squared_error: 631761.7500\n",
      "Epoch 2/350\n",
      " - 0s - loss: 307676.9605 - mean_squared_error: 307676.9605 - val_loss: 631639.3845 - val_mean_squared_error: 631639.3845\n",
      "Epoch 3/350\n",
      " - 0s - loss: 307601.0023 - mean_squared_error: 307601.0023 - val_loss: 631514.1417 - val_mean_squared_error: 631514.1417\n",
      "Epoch 4/350\n",
      " - 0s - loss: 307523.0416 - mean_squared_error: 307523.0416 - val_loss: 631388.4046 - val_mean_squared_error: 631388.4046\n",
      "Epoch 5/350\n",
      " - 0s - loss: 307445.0877 - mean_squared_error: 307445.0877 - val_loss: 631263.9336 - val_mean_squared_error: 631263.9336\n",
      "Epoch 6/350\n",
      " - 0s - loss: 307367.6361 - mean_squared_error: 307367.6361 - val_loss: 631138.4570 - val_mean_squared_error: 631138.4570\n",
      "Epoch 7/350\n",
      " - 0s - loss: 307288.9961 - mean_squared_error: 307288.9961 - val_loss: 631012.2561 - val_mean_squared_error: 631012.2561\n",
      "Epoch 8/350\n",
      " - 0s - loss: 307210.4028 - mean_squared_error: 307210.4028 - val_loss: 630887.8560 - val_mean_squared_error: 630887.8560\n",
      "Epoch 9/350\n",
      " - 0s - loss: 307133.9770 - mean_squared_error: 307133.9770 - val_loss: 630761.1680 - val_mean_squared_error: 630761.1680\n",
      "Epoch 10/350\n",
      " - 0s - loss: 307055.7681 - mean_squared_error: 307055.7681 - val_loss: 630635.2489 - val_mean_squared_error: 630635.2489\n",
      "Epoch 11/350\n",
      " - 0s - loss: 306977.0306 - mean_squared_error: 306977.0306 - val_loss: 630510.8203 - val_mean_squared_error: 630510.8203\n",
      "Epoch 12/350\n",
      " - 0s - loss: 306899.9934 - mean_squared_error: 306899.9934 - val_loss: 630384.4062 - val_mean_squared_error: 630384.4062\n",
      "Epoch 13/350\n",
      " - 0s - loss: 306821.5703 - mean_squared_error: 306821.5703 - val_loss: 630258.0960 - val_mean_squared_error: 630258.0960\n",
      "Epoch 14/350\n",
      " - 0s - loss: 306744.1742 - mean_squared_error: 306744.1742 - val_loss: 630131.7288 - val_mean_squared_error: 630131.7288\n",
      "Epoch 15/350\n",
      " - 0s - loss: 306666.0098 - mean_squared_error: 306666.0098 - val_loss: 630008.0491 - val_mean_squared_error: 630008.0491\n",
      "Epoch 16/350\n",
      " - 0s - loss: 306589.2798 - mean_squared_error: 306589.2798 - val_loss: 629883.4475 - val_mean_squared_error: 629883.4475\n",
      "Epoch 17/350\n",
      " - 0s - loss: 306512.2250 - mean_squared_error: 306512.2250 - val_loss: 629758.1250 - val_mean_squared_error: 629758.1250\n",
      "Epoch 18/350\n",
      " - 0s - loss: 306434.3495 - mean_squared_error: 306434.3495 - val_loss: 629633.5748 - val_mean_squared_error: 629633.5748\n",
      "Epoch 19/350\n",
      " - 0s - loss: 306358.2511 - mean_squared_error: 306358.2511 - val_loss: 629508.5195 - val_mean_squared_error: 629508.5195\n",
      "Epoch 20/350\n",
      " - 0s - loss: 306280.5144 - mean_squared_error: 306280.5144 - val_loss: 629385.0033 - val_mean_squared_error: 629385.0033\n",
      "Epoch 21/350\n",
      " - 0s - loss: 306204.9680 - mean_squared_error: 306204.9680 - val_loss: 629259.0162 - val_mean_squared_error: 629259.0162\n",
      "Epoch 22/350\n",
      " - 0s - loss: 306127.4783 - mean_squared_error: 306127.4783 - val_loss: 629138.3677 - val_mean_squared_error: 629138.3677\n",
      "Epoch 23/350\n",
      " - 0s - loss: 306053.0267 - mean_squared_error: 306053.0267 - val_loss: 629013.9169 - val_mean_squared_error: 629013.9169\n",
      "Epoch 24/350\n",
      " - 0s - loss: 305976.8102 - mean_squared_error: 305976.8102 - val_loss: 628890.1133 - val_mean_squared_error: 628890.1133\n",
      "Epoch 25/350\n",
      " - 0s - loss: 305899.3209 - mean_squared_error: 305899.3209 - val_loss: 628767.9174 - val_mean_squared_error: 628767.9174\n",
      "Epoch 26/350\n",
      " - 0s - loss: 305823.3182 - mean_squared_error: 305823.3182 - val_loss: 628644.5112 - val_mean_squared_error: 628644.5112\n",
      "Epoch 27/350\n",
      " - 0s - loss: 305746.6250 - mean_squared_error: 305746.6250 - val_loss: 628524.1016 - val_mean_squared_error: 628524.1016\n",
      "Epoch 28/350\n",
      " - 0s - loss: 305673.3431 - mean_squared_error: 305673.3431 - val_loss: 628398.7751 - val_mean_squared_error: 628398.7751\n",
      "Epoch 29/350\n",
      " - 0s - loss: 305596.6894 - mean_squared_error: 305596.6894 - val_loss: 628278.3666 - val_mean_squared_error: 628278.3666\n",
      "Epoch 30/350\n",
      " - 0s - loss: 305521.5097 - mean_squared_error: 305521.5097 - val_loss: 628156.6233 - val_mean_squared_error: 628156.6233\n",
      "Epoch 31/350\n",
      " - 0s - loss: 305446.6869 - mean_squared_error: 305446.6869 - val_loss: 628033.8516 - val_mean_squared_error: 628033.8516\n",
      "Epoch 32/350\n",
      " - 0s - loss: 305370.7809 - mean_squared_error: 305370.7809 - val_loss: 627911.4732 - val_mean_squared_error: 627911.4732\n",
      "Epoch 33/350\n",
      " - 0s - loss: 305295.8705 - mean_squared_error: 305295.8705 - val_loss: 627787.2879 - val_mean_squared_error: 627787.2879\n",
      "Epoch 34/350\n",
      " - 0s - loss: 305220.7278 - mean_squared_error: 305220.7278 - val_loss: 627667.5725 - val_mean_squared_error: 627667.5725\n",
      "Epoch 35/350\n",
      " - 0s - loss: 305148.1098 - mean_squared_error: 305148.1098 - val_loss: 627547.1992 - val_mean_squared_error: 627547.1992\n",
      "Epoch 36/350\n",
      " - 0s - loss: 305073.7107 - mean_squared_error: 305073.7107 - val_loss: 627429.4431 - val_mean_squared_error: 627429.4431\n",
      "Epoch 37/350\n",
      " - 0s - loss: 305002.1859 - mean_squared_error: 305002.1859 - val_loss: 627309.2891 - val_mean_squared_error: 627309.2891\n",
      "Epoch 38/350\n",
      " - 0s - loss: 304928.9528 - mean_squared_error: 304928.9528 - val_loss: 627190.8203 - val_mean_squared_error: 627190.8203\n",
      "Epoch 39/350\n",
      " - 0s - loss: 304856.4545 - mean_squared_error: 304856.4545 - val_loss: 627072.5441 - val_mean_squared_error: 627072.5441\n",
      "Epoch 40/350\n",
      " - 0s - loss: 304783.6053 - mean_squared_error: 304783.6053 - val_loss: 626956.1641 - val_mean_squared_error: 626956.1641\n",
      "Epoch 41/350\n",
      " - 0s - loss: 304712.8483 - mean_squared_error: 304712.8483 - val_loss: 626837.9699 - val_mean_squared_error: 626837.9699\n",
      "Epoch 42/350\n",
      " - 0s - loss: 304640.7702 - mean_squared_error: 304640.7702 - val_loss: 626720.8761 - val_mean_squared_error: 626720.8761\n",
      "Epoch 43/350\n",
      " - 0s - loss: 304569.3231 - mean_squared_error: 304569.3231 - val_loss: 626604.7355 - val_mean_squared_error: 626604.7355\n",
      "Epoch 44/350\n",
      " - 0s - loss: 304497.9728 - mean_squared_error: 304497.9728 - val_loss: 626488.3722 - val_mean_squared_error: 626488.3722\n",
      "Epoch 45/350\n",
      " - 0s - loss: 304426.5318 - mean_squared_error: 304426.5318 - val_loss: 626371.8571 - val_mean_squared_error: 626371.8571\n",
      "Epoch 46/350\n",
      " - 0s - loss: 304355.6317 - mean_squared_error: 304355.6317 - val_loss: 626254.3940 - val_mean_squared_error: 626254.3940\n",
      "Epoch 47/350\n",
      " - 0s - loss: 304284.0527 - mean_squared_error: 304284.0527 - val_loss: 626138.5949 - val_mean_squared_error: 626138.5949\n",
      "Epoch 48/350\n",
      " - 0s - loss: 304213.4928 - mean_squared_error: 304213.4928 - val_loss: 626020.8270 - val_mean_squared_error: 626020.8270\n",
      "Epoch 49/350\n",
      " - 0s - loss: 304142.7495 - mean_squared_error: 304142.7495 - val_loss: 625902.8672 - val_mean_squared_error: 625902.8672\n",
      "Epoch 50/350\n",
      " - 0s - loss: 304070.8392 - mean_squared_error: 304070.8392 - val_loss: 625789.0262 - val_mean_squared_error: 625789.0262\n",
      "Epoch 51/350\n",
      " - 0s - loss: 304001.3278 - mean_squared_error: 304001.3278 - val_loss: 625672.2818 - val_mean_squared_error: 625672.2818\n",
      "Epoch 52/350\n",
      " - 0s - loss: 303931.9098 - mean_squared_error: 303931.9098 - val_loss: 625557.2651 - val_mean_squared_error: 625557.2651\n",
      "Epoch 53/350\n",
      " - 0s - loss: 303862.5623 - mean_squared_error: 303862.5623 - val_loss: 625444.0619 - val_mean_squared_error: 625444.0619\n",
      "Epoch 54/350\n",
      " - 0s - loss: 303793.7634 - mean_squared_error: 303793.7634 - val_loss: 625330.6964 - val_mean_squared_error: 625330.6964\n",
      "Epoch 55/350\n",
      " - 0s - loss: 303724.9533 - mean_squared_error: 303724.9533 - val_loss: 625218.0067 - val_mean_squared_error: 625218.0067\n",
      "Epoch 56/350\n",
      " - 0s - loss: 303656.5659 - mean_squared_error: 303656.5659 - val_loss: 625105.2595 - val_mean_squared_error: 625105.2595\n",
      "Epoch 57/350\n",
      " - 0s - loss: 303588.7366 - mean_squared_error: 303588.7366 - val_loss: 624991.1339 - val_mean_squared_error: 624991.1339\n",
      "Epoch 58/350\n",
      " - 0s - loss: 303520.3477 - mean_squared_error: 303520.3477 - val_loss: 624878.4169 - val_mean_squared_error: 624878.4169\n",
      "Epoch 59/350\n",
      " - 0s - loss: 303451.1011 - mean_squared_error: 303451.1011 - val_loss: 624767.6618 - val_mean_squared_error: 624767.6618\n",
      "Epoch 60/350\n",
      " - 0s - loss: 303383.0894 - mean_squared_error: 303383.0894 - val_loss: 624654.4849 - val_mean_squared_error: 624654.4849\n",
      "Epoch 61/350\n",
      " - 0s - loss: 303316.3412 - mean_squared_error: 303316.3412 - val_loss: 624538.7684 - val_mean_squared_error: 624538.7684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/350\n",
      " - 0s - loss: 303247.1872 - mean_squared_error: 303247.1872 - val_loss: 624429.3382 - val_mean_squared_error: 624429.3382\n",
      "Epoch 63/350\n",
      " - 0s - loss: 303181.4463 - mean_squared_error: 303181.4463 - val_loss: 624316.2902 - val_mean_squared_error: 624316.2902\n",
      "Epoch 64/350\n",
      " - 0s - loss: 303114.2006 - mean_squared_error: 303114.2006 - val_loss: 624204.4481 - val_mean_squared_error: 624204.4481\n",
      "Epoch 65/350\n",
      " - 0s - loss: 303047.3373 - mean_squared_error: 303047.3373 - val_loss: 624094.2941 - val_mean_squared_error: 624094.2941\n",
      "Epoch 66/350\n",
      " - 0s - loss: 302982.2578 - mean_squared_error: 302982.2578 - val_loss: 623980.7852 - val_mean_squared_error: 623980.7852\n",
      "Epoch 67/350\n",
      " - 0s - loss: 302915.0165 - mean_squared_error: 302915.0165 - val_loss: 623871.3265 - val_mean_squared_error: 623871.3265\n",
      "Epoch 68/350\n",
      " - 0s - loss: 302848.8473 - mean_squared_error: 302848.8473 - val_loss: 623763.1657 - val_mean_squared_error: 623763.1657\n",
      "Epoch 69/350\n",
      " - 0s - loss: 302783.6862 - mean_squared_error: 302783.6862 - val_loss: 623653.8856 - val_mean_squared_error: 623653.8856\n",
      "Epoch 70/350\n",
      " - 0s - loss: 302718.8403 - mean_squared_error: 302718.8403 - val_loss: 623543.7400 - val_mean_squared_error: 623543.7400\n",
      "Epoch 71/350\n",
      " - 0s - loss: 302653.5453 - mean_squared_error: 302653.5453 - val_loss: 623435.6864 - val_mean_squared_error: 623435.6864\n",
      "Epoch 72/350\n",
      " - 0s - loss: 302588.3650 - mean_squared_error: 302588.3650 - val_loss: 623326.8622 - val_mean_squared_error: 623326.8622\n",
      "Epoch 73/350\n",
      " - 0s - loss: 302522.3968 - mean_squared_error: 302522.3968 - val_loss: 623218.3917 - val_mean_squared_error: 623218.3917\n",
      "Epoch 74/350\n",
      " - 0s - loss: 302459.1044 - mean_squared_error: 302459.1044 - val_loss: 623107.7695 - val_mean_squared_error: 623107.7695\n",
      "Epoch 75/350\n",
      " - 0s - loss: 302394.0405 - mean_squared_error: 302394.0405 - val_loss: 623002.1551 - val_mean_squared_error: 623002.1551\n",
      "Epoch 76/350\n",
      " - 0s - loss: 302331.5588 - mean_squared_error: 302331.5588 - val_loss: 622895.3092 - val_mean_squared_error: 622895.3092\n",
      "Epoch 77/350\n",
      " - 0s - loss: 302267.5914 - mean_squared_error: 302267.5914 - val_loss: 622791.1038 - val_mean_squared_error: 622791.1038\n",
      "Epoch 78/350\n",
      " - 0s - loss: 302205.8872 - mean_squared_error: 302205.8872 - val_loss: 622683.5781 - val_mean_squared_error: 622683.5781\n",
      "Epoch 79/350\n",
      " - 0s - loss: 302143.0636 - mean_squared_error: 302143.0636 - val_loss: 622578.8231 - val_mean_squared_error: 622578.8231\n",
      "Epoch 80/350\n",
      " - 0s - loss: 302080.8859 - mean_squared_error: 302080.8859 - val_loss: 622474.2411 - val_mean_squared_error: 622474.2411\n",
      "Epoch 81/350\n",
      " - 0s - loss: 302018.0419 - mean_squared_error: 302018.0419 - val_loss: 622369.8002 - val_mean_squared_error: 622369.8002\n",
      "Epoch 82/350\n",
      " - 0s - loss: 301955.4980 - mean_squared_error: 301955.4980 - val_loss: 622264.6669 - val_mean_squared_error: 622264.6669\n",
      "Epoch 83/350\n",
      " - 0s - loss: 301894.4591 - mean_squared_error: 301894.4591 - val_loss: 622158.0871 - val_mean_squared_error: 622158.0871\n",
      "Epoch 84/350\n",
      " - 0s - loss: 301831.8900 - mean_squared_error: 301831.8900 - val_loss: 622055.4425 - val_mean_squared_error: 622055.4425\n",
      "Epoch 85/350\n",
      " - 0s - loss: 301770.8764 - mean_squared_error: 301770.8764 - val_loss: 621951.5932 - val_mean_squared_error: 621951.5932\n",
      "Epoch 86/350\n",
      " - 0s - loss: 301709.6000 - mean_squared_error: 301709.6000 - val_loss: 621846.7612 - val_mean_squared_error: 621846.7612\n",
      "Epoch 87/350\n",
      " - 0s - loss: 301647.8884 - mean_squared_error: 301647.8884 - val_loss: 621742.6696 - val_mean_squared_error: 621742.6696\n",
      "Epoch 88/350\n",
      " - 0s - loss: 301586.8666 - mean_squared_error: 301586.8666 - val_loss: 621637.0312 - val_mean_squared_error: 621637.0312\n",
      "Epoch 89/350\n",
      " - 0s - loss: 301525.4848 - mean_squared_error: 301525.4848 - val_loss: 621531.7612 - val_mean_squared_error: 621531.7612\n",
      "Epoch 90/350\n",
      " - 0s - loss: 301462.8470 - mean_squared_error: 301462.8470 - val_loss: 621432.2980 - val_mean_squared_error: 621432.2980\n",
      "Epoch 91/350\n",
      " - 0s - loss: 301404.3253 - mean_squared_error: 301404.3253 - val_loss: 621325.6897 - val_mean_squared_error: 621325.6897\n",
      "Epoch 92/350\n",
      " - 0s - loss: 301342.0281 - mean_squared_error: 301342.0281 - val_loss: 621223.8493 - val_mean_squared_error: 621223.8493\n",
      "Epoch 93/350\n",
      " - 0s - loss: 301282.0530 - mean_squared_error: 301282.0530 - val_loss: 621121.1283 - val_mean_squared_error: 621121.1283\n",
      "Epoch 94/350\n",
      " - 0s - loss: 301221.8103 - mean_squared_error: 301221.8103 - val_loss: 621017.0776 - val_mean_squared_error: 621017.0776\n",
      "Epoch 95/350\n",
      " - 0s - loss: 301160.9148 - mean_squared_error: 301160.9148 - val_loss: 620913.5748 - val_mean_squared_error: 620913.5748\n",
      "Epoch 96/350\n",
      " - 0s - loss: 301100.8662 - mean_squared_error: 301100.8662 - val_loss: 620811.4688 - val_mean_squared_error: 620811.4688\n",
      "Epoch 97/350\n",
      " - 0s - loss: 301041.5612 - mean_squared_error: 301041.5612 - val_loss: 620708.7718 - val_mean_squared_error: 620708.7718\n",
      "Epoch 98/350\n",
      " - 0s - loss: 300981.3292 - mean_squared_error: 300981.3292 - val_loss: 620608.2852 - val_mean_squared_error: 620608.2852\n",
      "Epoch 99/350\n",
      " - 0s - loss: 300922.8214 - mean_squared_error: 300922.8214 - val_loss: 620506.2137 - val_mean_squared_error: 620506.2137\n",
      "Epoch 100/350\n",
      " - 0s - loss: 300863.4305 - mean_squared_error: 300863.4305 - val_loss: 620404.3588 - val_mean_squared_error: 620404.3588\n",
      "Epoch 101/350\n",
      " - 0s - loss: 300803.8416 - mean_squared_error: 300803.8416 - val_loss: 620303.5926 - val_mean_squared_error: 620303.5926\n",
      "Epoch 102/350\n",
      " - 0s - loss: 300744.7363 - mean_squared_error: 300744.7363 - val_loss: 620202.9252 - val_mean_squared_error: 620202.9252\n",
      "Epoch 103/350\n",
      " - 0s - loss: 300685.4759 - mean_squared_error: 300685.4759 - val_loss: 620102.9436 - val_mean_squared_error: 620102.9436\n",
      "Epoch 104/350\n",
      " - 0s - loss: 300627.0923 - mean_squared_error: 300627.0923 - val_loss: 620000.1194 - val_mean_squared_error: 620000.1194\n",
      "Epoch 105/350\n",
      " - 0s - loss: 300567.8510 - mean_squared_error: 300567.8510 - val_loss: 619899.3906 - val_mean_squared_error: 619899.3906\n",
      "Epoch 106/350\n",
      " - 0s - loss: 300509.0923 - mean_squared_error: 300509.0923 - val_loss: 619799.2349 - val_mean_squared_error: 619799.2349\n",
      "Epoch 107/350\n",
      " - 0s - loss: 300450.8172 - mean_squared_error: 300450.8172 - val_loss: 619698.2160 - val_mean_squared_error: 619698.2160\n",
      "Epoch 108/350\n",
      " - 0s - loss: 300392.6883 - mean_squared_error: 300392.6883 - val_loss: 619595.6925 - val_mean_squared_error: 619595.6925\n",
      "Epoch 109/350\n",
      " - 0s - loss: 300333.2069 - mean_squared_error: 300333.2069 - val_loss: 619497.1317 - val_mean_squared_error: 619497.1317\n",
      "Epoch 110/350\n",
      " - 0s - loss: 300275.2947 - mean_squared_error: 300275.2947 - val_loss: 619396.7327 - val_mean_squared_error: 619396.7327\n",
      "Epoch 111/350\n",
      " - 0s - loss: 300217.7756 - mean_squared_error: 300217.7756 - val_loss: 619295.5335 - val_mean_squared_error: 619295.5335\n",
      "Epoch 112/350\n",
      " - 0s - loss: 300158.6981 - mean_squared_error: 300158.6981 - val_loss: 619195.7612 - val_mean_squared_error: 619195.7612\n",
      "Epoch 113/350\n",
      " - 0s - loss: 300100.4278 - mean_squared_error: 300100.4278 - val_loss: 619094.5943 - val_mean_squared_error: 619094.5943\n",
      "Epoch 114/350\n",
      " - 0s - loss: 300042.0922 - mean_squared_error: 300042.0922 - val_loss: 618994.0915 - val_mean_squared_error: 618994.0915\n",
      "Epoch 115/350\n",
      " - 0s - loss: 299983.9924 - mean_squared_error: 299983.9924 - val_loss: 618893.1579 - val_mean_squared_error: 618893.1579\n",
      "Epoch 116/350\n",
      " - 0s - loss: 299925.5130 - mean_squared_error: 299925.5130 - val_loss: 618792.8895 - val_mean_squared_error: 618792.8895\n",
      "Epoch 117/350\n",
      " - 0s - loss: 299868.1973 - mean_squared_error: 299868.1973 - val_loss: 618692.4860 - val_mean_squared_error: 618692.4860\n",
      "Epoch 118/350\n",
      " - 0s - loss: 299809.7216 - mean_squared_error: 299809.7216 - val_loss: 618594.2087 - val_mean_squared_error: 618594.2087\n",
      "Epoch 119/350\n",
      " - 0s - loss: 299752.9534 - mean_squared_error: 299752.9534 - val_loss: 618496.4682 - val_mean_squared_error: 618496.4682\n",
      "Epoch 120/350\n",
      " - 0s - loss: 299695.9506 - mean_squared_error: 299695.9506 - val_loss: 618396.8778 - val_mean_squared_error: 618396.8778\n",
      "Epoch 121/350\n",
      " - 0s - loss: 299638.6814 - mean_squared_error: 299638.6814 - val_loss: 618297.1853 - val_mean_squared_error: 618297.1853\n",
      "Epoch 122/350\n",
      " - 0s - loss: 299581.3144 - mean_squared_error: 299581.3144 - val_loss: 618196.8923 - val_mean_squared_error: 618196.8923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/350\n",
      " - 0s - loss: 299523.8334 - mean_squared_error: 299523.8334 - val_loss: 618096.0541 - val_mean_squared_error: 618096.0541\n",
      "Epoch 124/350\n",
      " - 0s - loss: 299465.2395 - mean_squared_error: 299465.2395 - val_loss: 617997.1970 - val_mean_squared_error: 617997.1970\n",
      "Epoch 125/350\n",
      " - 0s - loss: 299407.7789 - mean_squared_error: 299407.7789 - val_loss: 617896.3025 - val_mean_squared_error: 617896.3025\n",
      "Epoch 126/350\n",
      " - 0s - loss: 299350.2011 - mean_squared_error: 299350.2011 - val_loss: 617795.1802 - val_mean_squared_error: 617795.1802\n",
      "Epoch 127/350\n",
      " - 0s - loss: 299292.4280 - mean_squared_error: 299292.4280 - val_loss: 617695.3912 - val_mean_squared_error: 617695.3912\n",
      "Epoch 128/350\n",
      " - 0s - loss: 299235.0217 - mean_squared_error: 299235.0217 - val_loss: 617594.4191 - val_mean_squared_error: 617594.4191\n",
      "Epoch 129/350\n",
      " - 0s - loss: 299176.8862 - mean_squared_error: 299176.8862 - val_loss: 617494.6021 - val_mean_squared_error: 617494.6021\n",
      "Epoch 130/350\n",
      " - 0s - loss: 299119.3059 - mean_squared_error: 299119.3059 - val_loss: 617394.2857 - val_mean_squared_error: 617394.2857\n",
      "Epoch 131/350\n",
      " - 0s - loss: 299062.0661 - mean_squared_error: 299062.0661 - val_loss: 617292.4648 - val_mean_squared_error: 617292.4648\n",
      "Epoch 132/350\n",
      " - 0s - loss: 299003.2412 - mean_squared_error: 299003.2412 - val_loss: 617194.0709 - val_mean_squared_error: 617194.0709\n",
      "Epoch 133/350\n",
      " - 0s - loss: 298945.5037 - mean_squared_error: 298945.5037 - val_loss: 617092.6602 - val_mean_squared_error: 617092.6602\n",
      "Epoch 134/350\n",
      " - 0s - loss: 298886.6003 - mean_squared_error: 298886.6003 - val_loss: 616991.7729 - val_mean_squared_error: 616991.7729\n",
      "Epoch 135/350\n",
      " - 0s - loss: 298829.0498 - mean_squared_error: 298829.0498 - val_loss: 616889.7790 - val_mean_squared_error: 616889.7790\n",
      "Epoch 136/350\n",
      " - 0s - loss: 298770.0053 - mean_squared_error: 298770.0053 - val_loss: 616787.4743 - val_mean_squared_error: 616787.4743\n",
      "Epoch 137/350\n",
      " - 0s - loss: 298710.9238 - mean_squared_error: 298710.9238 - val_loss: 616685.6345 - val_mean_squared_error: 616685.6345\n",
      "Epoch 138/350\n",
      " - 0s - loss: 298652.8047 - mean_squared_error: 298652.8047 - val_loss: 616582.4760 - val_mean_squared_error: 616582.4760\n",
      "Epoch 139/350\n",
      " - 0s - loss: 298594.6784 - mean_squared_error: 298594.6784 - val_loss: 616479.0831 - val_mean_squared_error: 616479.0831\n",
      "Epoch 140/350\n",
      " - 0s - loss: 298535.6916 - mean_squared_error: 298535.6916 - val_loss: 616377.3750 - val_mean_squared_error: 616377.3750\n",
      "Epoch 141/350\n",
      " - 0s - loss: 298476.3433 - mean_squared_error: 298476.3433 - val_loss: 616278.0871 - val_mean_squared_error: 616278.0871\n",
      "Epoch 142/350\n",
      " - 0s - loss: 298418.4931 - mean_squared_error: 298418.4931 - val_loss: 616174.4704 - val_mean_squared_error: 616174.4704\n",
      "Epoch 143/350\n",
      " - 0s - loss: 298359.4050 - mean_squared_error: 298359.4050 - val_loss: 616069.6083 - val_mean_squared_error: 616069.6083\n",
      "Epoch 144/350\n",
      " - 0s - loss: 298298.7695 - mean_squared_error: 298298.7695 - val_loss: 615967.2539 - val_mean_squared_error: 615967.2539\n",
      "Epoch 145/350\n",
      " - 0s - loss: 298240.2055 - mean_squared_error: 298240.2055 - val_loss: 615862.4916 - val_mean_squared_error: 615862.4916\n",
      "Epoch 146/350\n",
      " - 0s - loss: 298180.3905 - mean_squared_error: 298180.3905 - val_loss: 615759.8393 - val_mean_squared_error: 615759.8393\n",
      "Epoch 147/350\n",
      " - 0s - loss: 298121.3344 - mean_squared_error: 298121.3344 - val_loss: 615653.8320 - val_mean_squared_error: 615653.8320\n",
      "Epoch 148/350\n",
      " - 0s - loss: 298060.4553 - mean_squared_error: 298060.4553 - val_loss: 615550.1501 - val_mean_squared_error: 615550.1501\n",
      "Epoch 149/350\n",
      " - 0s - loss: 298001.0463 - mean_squared_error: 298001.0463 - val_loss: 615444.3979 - val_mean_squared_error: 615444.3979\n",
      "Epoch 150/350\n",
      " - 0s - loss: 297939.6875 - mean_squared_error: 297939.6875 - val_loss: 615341.9018 - val_mean_squared_error: 615341.9018\n",
      "Epoch 151/350\n",
      " - 0s - loss: 297881.0069 - mean_squared_error: 297881.0069 - val_loss: 615234.1395 - val_mean_squared_error: 615234.1395\n",
      "Epoch 152/350\n",
      " - 0s - loss: 297818.3811 - mean_squared_error: 297818.3811 - val_loss: 615132.4498 - val_mean_squared_error: 615132.4498\n",
      "Epoch 153/350\n",
      " - 0s - loss: 297759.1989 - mean_squared_error: 297759.1989 - val_loss: 615024.8025 - val_mean_squared_error: 615024.8025\n",
      "Epoch 154/350\n",
      " - 0s - loss: 297698.2053 - mean_squared_error: 297698.2053 - val_loss: 614917.7137 - val_mean_squared_error: 614917.7137\n",
      "Epoch 155/350\n",
      " - 0s - loss: 297635.8634 - mean_squared_error: 297635.8634 - val_loss: 614812.9933 - val_mean_squared_error: 614812.9933\n",
      "Epoch 156/350\n",
      " - 0s - loss: 297575.0166 - mean_squared_error: 297575.0166 - val_loss: 614706.3945 - val_mean_squared_error: 614706.3945\n",
      "Epoch 157/350\n",
      " - 0s - loss: 297514.2756 - mean_squared_error: 297514.2756 - val_loss: 614599.7137 - val_mean_squared_error: 614599.7137\n",
      "Epoch 158/350\n",
      " - 0s - loss: 297452.5017 - mean_squared_error: 297452.5017 - val_loss: 614494.9492 - val_mean_squared_error: 614494.9492\n",
      "Epoch 159/350\n",
      " - 0s - loss: 297392.0388 - mean_squared_error: 297392.0388 - val_loss: 614387.1507 - val_mean_squared_error: 614387.1507\n",
      "Epoch 160/350\n",
      " - 0s - loss: 297330.2869 - mean_squared_error: 297330.2869 - val_loss: 614279.4660 - val_mean_squared_error: 614279.4660\n",
      "Epoch 161/350\n",
      " - 0s - loss: 297267.9496 - mean_squared_error: 297267.9496 - val_loss: 614174.0698 - val_mean_squared_error: 614174.0698\n",
      "Epoch 162/350\n",
      " - 0s - loss: 297207.0716 - mean_squared_error: 297207.0716 - val_loss: 614065.5352 - val_mean_squared_error: 614065.5352\n",
      "Epoch 163/350\n",
      " - 0s - loss: 297145.5584 - mean_squared_error: 297145.5584 - val_loss: 613957.5078 - val_mean_squared_error: 613957.5078\n",
      "Epoch 164/350\n",
      " - 0s - loss: 297083.3636 - mean_squared_error: 297083.3636 - val_loss: 613851.2785 - val_mean_squared_error: 613851.2785\n",
      "Epoch 165/350\n",
      " - 0s - loss: 297021.0162 - mean_squared_error: 297021.0162 - val_loss: 613743.8560 - val_mean_squared_error: 613743.8560\n",
      "Epoch 166/350\n",
      " - 0s - loss: 296959.3920 - mean_squared_error: 296959.3920 - val_loss: 613636.1417 - val_mean_squared_error: 613636.1417\n",
      "Epoch 167/350\n",
      " - 0s - loss: 296899.3452 - mean_squared_error: 296899.3452 - val_loss: 613527.2628 - val_mean_squared_error: 613527.2628\n",
      "Epoch 168/350\n",
      " - 0s - loss: 296835.7511 - mean_squared_error: 296835.7511 - val_loss: 613423.7673 - val_mean_squared_error: 613423.7673\n",
      "Epoch 169/350\n",
      " - 0s - loss: 296775.1345 - mean_squared_error: 296775.1345 - val_loss: 613315.5787 - val_mean_squared_error: 613315.5787\n",
      "Epoch 170/350\n",
      " - 0s - loss: 296713.8142 - mean_squared_error: 296713.8142 - val_loss: 613207.1663 - val_mean_squared_error: 613207.1663\n",
      "Epoch 171/350\n",
      " - 0s - loss: 296651.8422 - mean_squared_error: 296651.8422 - val_loss: 613099.8025 - val_mean_squared_error: 613099.8025\n",
      "Epoch 172/350\n",
      " - 0s - loss: 296589.9991 - mean_squared_error: 296589.9991 - val_loss: 612994.3465 - val_mean_squared_error: 612994.3465\n",
      "Epoch 173/350\n",
      " - 0s - loss: 296530.1627 - mean_squared_error: 296530.1627 - val_loss: 612886.5190 - val_mean_squared_error: 612886.5190\n",
      "Epoch 174/350\n",
      " - 0s - loss: 296468.4191 - mean_squared_error: 296468.4191 - val_loss: 612780.8504 - val_mean_squared_error: 612780.8504\n",
      "Epoch 175/350\n",
      " - 0s - loss: 296407.3572 - mean_squared_error: 296407.3572 - val_loss: 612673.7801 - val_mean_squared_error: 612673.7801\n",
      "Epoch 176/350\n",
      " - 0s - loss: 296345.2616 - mean_squared_error: 296345.2616 - val_loss: 612567.2271 - val_mean_squared_error: 612567.2271\n",
      "Epoch 177/350\n",
      " - 0s - loss: 296283.5861 - mean_squared_error: 296283.5861 - val_loss: 612460.2935 - val_mean_squared_error: 612460.2935\n",
      "Epoch 178/350\n",
      " - 0s - loss: 296222.0672 - mean_squared_error: 296222.0672 - val_loss: 612352.4107 - val_mean_squared_error: 612352.4107\n",
      "Epoch 179/350\n",
      " - 0s - loss: 296159.3928 - mean_squared_error: 296159.3928 - val_loss: 612245.6959 - val_mean_squared_error: 612245.6959\n",
      "Epoch 180/350\n",
      " - 0s - loss: 296097.7122 - mean_squared_error: 296097.7122 - val_loss: 612136.2238 - val_mean_squared_error: 612136.2238\n",
      "Epoch 181/350\n",
      " - 0s - loss: 296035.9447 - mean_squared_error: 296035.9447 - val_loss: 612026.1501 - val_mean_squared_error: 612026.1501\n",
      "Epoch 182/350\n",
      " - 0s - loss: 295973.1225 - mean_squared_error: 295973.1225 - val_loss: 611918.8984 - val_mean_squared_error: 611918.8984\n",
      "Epoch 183/350\n",
      " - 0s - loss: 295911.5084 - mean_squared_error: 295911.5084 - val_loss: 611811.6390 - val_mean_squared_error: 611811.6390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/350\n",
      " - 0s - loss: 295849.6523 - mean_squared_error: 295849.6523 - val_loss: 611704.3064 - val_mean_squared_error: 611704.3064\n",
      "Epoch 185/350\n",
      " - 0s - loss: 295788.6439 - mean_squared_error: 295788.6439 - val_loss: 611593.1440 - val_mean_squared_error: 611593.1440\n",
      "Epoch 186/350\n",
      " - 0s - loss: 295725.3796 - mean_squared_error: 295725.3796 - val_loss: 611485.7684 - val_mean_squared_error: 611485.7684\n",
      "Epoch 187/350\n",
      " - 0s - loss: 295662.3933 - mean_squared_error: 295662.3933 - val_loss: 611380.0592 - val_mean_squared_error: 611380.0592\n",
      "Epoch 188/350\n",
      " - 0s - loss: 295600.7731 - mean_squared_error: 295600.7731 - val_loss: 611273.2126 - val_mean_squared_error: 611273.2126\n",
      "Epoch 189/350\n",
      " - 0s - loss: 295540.4906 - mean_squared_error: 295540.4906 - val_loss: 611161.2472 - val_mean_squared_error: 611161.2472\n",
      "Epoch 190/350\n",
      " - 0s - loss: 295477.0141 - mean_squared_error: 295477.0141 - val_loss: 611053.3856 - val_mean_squared_error: 611053.3856\n",
      "Epoch 191/350\n",
      " - 0s - loss: 295414.3475 - mean_squared_error: 295414.3475 - val_loss: 610947.3170 - val_mean_squared_error: 610947.3170\n",
      "Epoch 192/350\n",
      " - 0s - loss: 295353.1133 - mean_squared_error: 295353.1133 - val_loss: 610837.3560 - val_mean_squared_error: 610837.3560\n",
      "Epoch 193/350\n",
      " - 0s - loss: 295289.4552 - mean_squared_error: 295289.4552 - val_loss: 610730.3956 - val_mean_squared_error: 610730.3956\n",
      "Epoch 194/350\n",
      " - 0s - loss: 295229.2645 - mean_squared_error: 295229.2645 - val_loss: 610616.3153 - val_mean_squared_error: 610616.3153\n",
      "Epoch 195/350\n",
      " - 0s - loss: 295164.2278 - mean_squared_error: 295164.2278 - val_loss: 610508.8756 - val_mean_squared_error: 610508.8756\n",
      "Epoch 196/350\n",
      " - 0s - loss: 295102.9295 - mean_squared_error: 295102.9295 - val_loss: 610398.5184 - val_mean_squared_error: 610398.5184\n",
      "Epoch 197/350\n",
      " - 0s - loss: 295039.3439 - mean_squared_error: 295039.3439 - val_loss: 610290.1791 - val_mean_squared_error: 610290.1791\n",
      "Epoch 198/350\n",
      " - 0s - loss: 294976.9778 - mean_squared_error: 294976.9778 - val_loss: 610180.4749 - val_mean_squared_error: 610180.4749\n",
      "Epoch 199/350\n",
      " - 0s - loss: 294913.5077 - mean_squared_error: 294913.5077 - val_loss: 610071.5703 - val_mean_squared_error: 610071.5703\n",
      "Epoch 200/350\n",
      " - 0s - loss: 294850.8963 - mean_squared_error: 294850.8963 - val_loss: 609962.3047 - val_mean_squared_error: 609962.3047\n",
      "Epoch 201/350\n",
      " - 0s - loss: 294787.9322 - mean_squared_error: 294787.9322 - val_loss: 609852.9939 - val_mean_squared_error: 609852.9939\n",
      "Epoch 202/350\n",
      " - 0s - loss: 294725.3550 - mean_squared_error: 294725.3550 - val_loss: 609743.6451 - val_mean_squared_error: 609743.6451\n",
      "Epoch 203/350\n",
      " - 0s - loss: 294662.9188 - mean_squared_error: 294662.9188 - val_loss: 609632.5792 - val_mean_squared_error: 609632.5792\n",
      "Epoch 204/350\n",
      " - 0s - loss: 294599.9650 - mean_squared_error: 294599.9650 - val_loss: 609524.0335 - val_mean_squared_error: 609524.0335\n",
      "Epoch 205/350\n",
      " - 0s - loss: 294536.9477 - mean_squared_error: 294536.9477 - val_loss: 609416.5820 - val_mean_squared_error: 609416.5820\n",
      "Epoch 206/350\n",
      " - 0s - loss: 294474.4809 - mean_squared_error: 294474.4809 - val_loss: 609306.8276 - val_mean_squared_error: 609306.8276\n",
      "Epoch 207/350\n",
      " - 0s - loss: 294411.9778 - mean_squared_error: 294411.9778 - val_loss: 609196.3817 - val_mean_squared_error: 609196.3817\n",
      "Epoch 208/350\n",
      " - 0s - loss: 294349.3904 - mean_squared_error: 294349.3904 - val_loss: 609084.5017 - val_mean_squared_error: 609084.5017\n",
      "Epoch 209/350\n",
      " - 0s - loss: 294285.4470 - mean_squared_error: 294285.4470 - val_loss: 608975.9989 - val_mean_squared_error: 608975.9989\n",
      "Epoch 210/350\n",
      " - 0s - loss: 294222.8934 - mean_squared_error: 294222.8934 - val_loss: 608866.8471 - val_mean_squared_error: 608866.8471\n",
      "Epoch 211/350\n",
      " - 0s - loss: 294160.6333 - mean_squared_error: 294160.6333 - val_loss: 608756.6735 - val_mean_squared_error: 608756.6735\n",
      "Epoch 212/350\n",
      " - 0s - loss: 294097.3298 - mean_squared_error: 294097.3298 - val_loss: 608647.2578 - val_mean_squared_error: 608647.2578\n",
      "Epoch 213/350\n",
      " - 0s - loss: 294034.4516 - mean_squared_error: 294034.4516 - val_loss: 608538.2450 - val_mean_squared_error: 608538.2450\n",
      "Epoch 214/350\n",
      " - 0s - loss: 293972.0431 - mean_squared_error: 293972.0431 - val_loss: 608427.8811 - val_mean_squared_error: 608427.8811\n",
      "Epoch 215/350\n",
      " - 0s - loss: 293908.4644 - mean_squared_error: 293908.4644 - val_loss: 608318.6853 - val_mean_squared_error: 608318.6853\n",
      "Epoch 216/350\n",
      " - 0s - loss: 293845.4402 - mean_squared_error: 293845.4402 - val_loss: 608208.0128 - val_mean_squared_error: 608208.0128\n",
      "Epoch 217/350\n",
      " - 0s - loss: 293781.9591 - mean_squared_error: 293781.9591 - val_loss: 608097.5240 - val_mean_squared_error: 608097.5240\n",
      "Epoch 218/350\n",
      " - 0s - loss: 293718.5322 - mean_squared_error: 293718.5322 - val_loss: 607986.4057 - val_mean_squared_error: 607986.4057\n",
      "Epoch 219/350\n",
      " - 0s - loss: 293654.2992 - mean_squared_error: 293654.2992 - val_loss: 607874.5731 - val_mean_squared_error: 607874.5731\n",
      "Epoch 220/350\n",
      " - 0s - loss: 293589.5459 - mean_squared_error: 293589.5459 - val_loss: 607766.5273 - val_mean_squared_error: 607766.5273\n",
      "Epoch 221/350\n",
      " - 0s - loss: 293527.8523 - mean_squared_error: 293527.8523 - val_loss: 607652.1886 - val_mean_squared_error: 607652.1886\n",
      "Epoch 222/350\n",
      " - 0s - loss: 293463.2853 - mean_squared_error: 293463.2853 - val_loss: 607540.8331 - val_mean_squared_error: 607540.8331\n",
      "Epoch 223/350\n",
      " - 0s - loss: 293399.5076 - mean_squared_error: 293399.5076 - val_loss: 607429.5469 - val_mean_squared_error: 607429.5469\n",
      "Epoch 224/350\n",
      " - 0s - loss: 293335.3020 - mean_squared_error: 293335.3020 - val_loss: 607317.8064 - val_mean_squared_error: 607317.8064\n",
      "Epoch 225/350\n",
      " - 0s - loss: 293270.4659 - mean_squared_error: 293270.4659 - val_loss: 607206.5195 - val_mean_squared_error: 607206.5195\n",
      "Epoch 226/350\n",
      " - 0s - loss: 293206.6542 - mean_squared_error: 293206.6542 - val_loss: 607093.1155 - val_mean_squared_error: 607093.1155\n",
      "Epoch 227/350\n",
      " - 0s - loss: 293141.0334 - mean_squared_error: 293141.0334 - val_loss: 606981.7600 - val_mean_squared_error: 606981.7600\n",
      "Epoch 228/350\n",
      " - 0s - loss: 293077.4361 - mean_squared_error: 293077.4361 - val_loss: 606865.9749 - val_mean_squared_error: 606865.9749\n",
      "Epoch 229/350\n",
      " - 0s - loss: 293011.5180 - mean_squared_error: 293011.5180 - val_loss: 606749.9096 - val_mean_squared_error: 606749.9096\n",
      "Epoch 230/350\n",
      " - 0s - loss: 292944.6119 - mean_squared_error: 292944.6119 - val_loss: 606638.9721 - val_mean_squared_error: 606638.9721\n",
      "Epoch 231/350\n",
      " - 0s - loss: 292879.4622 - mean_squared_error: 292879.4622 - val_loss: 606525.9872 - val_mean_squared_error: 606525.9872\n",
      "Epoch 232/350\n",
      " - 0s - loss: 292813.2394 - mean_squared_error: 292813.2394 - val_loss: 606412.6931 - val_mean_squared_error: 606412.6931\n",
      "Epoch 233/350\n",
      " - 0s - loss: 292748.5517 - mean_squared_error: 292748.5517 - val_loss: 606296.9537 - val_mean_squared_error: 606296.9537\n",
      "Epoch 234/350\n",
      " - 0s - loss: 292681.2709 - mean_squared_error: 292681.2709 - val_loss: 606181.3309 - val_mean_squared_error: 606181.3309\n",
      "Epoch 235/350\n",
      " - 0s - loss: 292613.6335 - mean_squared_error: 292613.6335 - val_loss: 606065.5167 - val_mean_squared_error: 606065.5167\n",
      "Epoch 236/350\n",
      " - 0s - loss: 292546.9870 - mean_squared_error: 292546.9870 - val_loss: 605947.6702 - val_mean_squared_error: 605947.6702\n",
      "Epoch 237/350\n",
      " - 0s - loss: 292479.0786 - mean_squared_error: 292479.0786 - val_loss: 605831.5580 - val_mean_squared_error: 605831.5580\n",
      "Epoch 238/350\n",
      " - 0s - loss: 292411.9483 - mean_squared_error: 292411.9483 - val_loss: 605713.0385 - val_mean_squared_error: 605713.0385\n",
      "Epoch 239/350\n",
      " - 0s - loss: 292344.0127 - mean_squared_error: 292344.0127 - val_loss: 605594.1819 - val_mean_squared_error: 605594.1819\n",
      "Epoch 240/350\n",
      " - 0s - loss: 292274.8467 - mean_squared_error: 292274.8467 - val_loss: 605477.0430 - val_mean_squared_error: 605477.0430\n",
      "Epoch 241/350\n",
      " - 0s - loss: 292205.9141 - mean_squared_error: 292205.9141 - val_loss: 605359.4844 - val_mean_squared_error: 605359.4844\n",
      "Epoch 242/350\n",
      " - 0s - loss: 292137.2006 - mean_squared_error: 292137.2006 - val_loss: 605237.9235 - val_mean_squared_error: 605237.9235\n",
      "Epoch 243/350\n",
      " - 0s - loss: 292067.2484 - mean_squared_error: 292067.2484 - val_loss: 605118.6802 - val_mean_squared_error: 605118.6802\n",
      "Epoch 244/350\n",
      " - 0s - loss: 291999.1175 - mean_squared_error: 291999.1175 - val_loss: 604996.2500 - val_mean_squared_error: 604996.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/350\n",
      " - 0s - loss: 291926.9359 - mean_squared_error: 291926.9359 - val_loss: 604878.8488 - val_mean_squared_error: 604878.8488\n",
      "Epoch 246/350\n",
      " - 0s - loss: 291858.3862 - mean_squared_error: 291858.3862 - val_loss: 604757.2494 - val_mean_squared_error: 604757.2494\n",
      "Epoch 247/350\n",
      " - 0s - loss: 291788.1350 - mean_squared_error: 291788.1350 - val_loss: 604635.7522 - val_mean_squared_error: 604635.7522\n",
      "Epoch 248/350\n",
      " - 0s - loss: 291717.6469 - mean_squared_error: 291717.6469 - val_loss: 604513.7433 - val_mean_squared_error: 604513.7433\n",
      "Epoch 249/350\n",
      " - 0s - loss: 291647.1280 - mean_squared_error: 291647.1280 - val_loss: 604391.3834 - val_mean_squared_error: 604391.3834\n",
      "Epoch 250/350\n",
      " - 0s - loss: 291575.8033 - mean_squared_error: 291575.8033 - val_loss: 604269.3750 - val_mean_squared_error: 604269.3750\n",
      "Epoch 251/350\n",
      " - 0s - loss: 291503.8750 - mean_squared_error: 291503.8750 - val_loss: 604146.8376 - val_mean_squared_error: 604146.8376\n",
      "Epoch 252/350\n",
      " - 0s - loss: 291432.0733 - mean_squared_error: 291432.0733 - val_loss: 604023.8398 - val_mean_squared_error: 604023.8398\n",
      "Epoch 253/350\n",
      " - 0s - loss: 291360.9003 - mean_squared_error: 291360.9003 - val_loss: 603899.5078 - val_mean_squared_error: 603899.5078\n",
      "Epoch 254/350\n",
      " - 0s - loss: 291288.2102 - mean_squared_error: 291288.2102 - val_loss: 603776.6635 - val_mean_squared_error: 603776.6635\n",
      "Epoch 255/350\n",
      " - 0s - loss: 291217.4561 - mean_squared_error: 291217.4561 - val_loss: 603649.6585 - val_mean_squared_error: 603649.6585\n",
      "Epoch 256/350\n",
      " - 0s - loss: 291143.4938 - mean_squared_error: 291143.4938 - val_loss: 603529.2037 - val_mean_squared_error: 603529.2037\n",
      "Epoch 257/350\n",
      " - 0s - loss: 291072.7895 - mean_squared_error: 291072.7895 - val_loss: 603401.2846 - val_mean_squared_error: 603401.2846\n",
      "Epoch 258/350\n",
      " - 0s - loss: 290998.6906 - mean_squared_error: 290998.6906 - val_loss: 603276.0781 - val_mean_squared_error: 603276.0781\n",
      "Epoch 259/350\n",
      " - 0s - loss: 290925.8120 - mean_squared_error: 290925.8120 - val_loss: 603150.1579 - val_mean_squared_error: 603150.1579\n",
      "Epoch 260/350\n",
      " - 0s - loss: 290852.1698 - mean_squared_error: 290852.1698 - val_loss: 603025.0525 - val_mean_squared_error: 603025.0525\n",
      "Epoch 261/350\n",
      " - 0s - loss: 290779.4566 - mean_squared_error: 290779.4566 - val_loss: 602895.8728 - val_mean_squared_error: 602895.8728\n",
      "Epoch 262/350\n",
      " - 0s - loss: 290703.6592 - mean_squared_error: 290703.6592 - val_loss: 602771.9794 - val_mean_squared_error: 602771.9794\n",
      "Epoch 263/350\n",
      " - 0s - loss: 290630.9398 - mean_squared_error: 290630.9398 - val_loss: 602645.5340 - val_mean_squared_error: 602645.5340\n",
      "Epoch 264/350\n",
      " - 0s - loss: 290556.3731 - mean_squared_error: 290556.3731 - val_loss: 602518.7751 - val_mean_squared_error: 602518.7751\n",
      "Epoch 265/350\n",
      " - 0s - loss: 290483.4672 - mean_squared_error: 290483.4672 - val_loss: 602387.0285 - val_mean_squared_error: 602387.0285\n",
      "Epoch 266/350\n",
      " - 0s - loss: 290407.3747 - mean_squared_error: 290407.3747 - val_loss: 602262.0586 - val_mean_squared_error: 602262.0586\n",
      "Epoch 267/350\n",
      " - 0s - loss: 290333.0352 - mean_squared_error: 290333.0352 - val_loss: 602134.7550 - val_mean_squared_error: 602134.7550\n",
      "Epoch 268/350\n",
      " - 0s - loss: 290258.4224 - mean_squared_error: 290258.4224 - val_loss: 602005.0162 - val_mean_squared_error: 602005.0162\n",
      "Epoch 269/350\n",
      " - 0s - loss: 290182.9120 - mean_squared_error: 290182.9120 - val_loss: 601877.0887 - val_mean_squared_error: 601877.0887\n",
      "Epoch 270/350\n",
      " - 0s - loss: 290108.3713 - mean_squared_error: 290108.3713 - val_loss: 601750.0156 - val_mean_squared_error: 601750.0156\n",
      "Epoch 271/350\n",
      " - 0s - loss: 290033.5416 - mean_squared_error: 290033.5416 - val_loss: 601621.2651 - val_mean_squared_error: 601621.2651\n",
      "Epoch 272/350\n",
      " - 0s - loss: 289959.0270 - mean_squared_error: 289959.0270 - val_loss: 601491.8114 - val_mean_squared_error: 601491.8114\n",
      "Epoch 273/350\n",
      " - 0s - loss: 289883.4219 - mean_squared_error: 289883.4219 - val_loss: 601362.8789 - val_mean_squared_error: 601362.8789\n",
      "Epoch 274/350\n",
      " - 0s - loss: 289808.2203 - mean_squared_error: 289808.2203 - val_loss: 601234.0441 - val_mean_squared_error: 601234.0441\n",
      "Epoch 275/350\n",
      " - 0s - loss: 289733.4213 - mean_squared_error: 289733.4213 - val_loss: 601103.6719 - val_mean_squared_error: 601103.6719\n",
      "Epoch 276/350\n",
      " - 0s - loss: 289658.6988 - mean_squared_error: 289658.6988 - val_loss: 600973.1456 - val_mean_squared_error: 600973.1456\n",
      "Epoch 277/350\n",
      " - 0s - loss: 289581.8063 - mean_squared_error: 289581.8063 - val_loss: 600844.5569 - val_mean_squared_error: 600844.5569\n",
      "Epoch 278/350\n",
      " - 0s - loss: 289506.1459 - mean_squared_error: 289506.1459 - val_loss: 600715.6323 - val_mean_squared_error: 600715.6323\n",
      "Epoch 279/350\n",
      " - 0s - loss: 289430.4559 - mean_squared_error: 289430.4559 - val_loss: 600586.1228 - val_mean_squared_error: 600586.1228\n",
      "Epoch 280/350\n",
      " - 0s - loss: 289353.9108 - mean_squared_error: 289353.9108 - val_loss: 600457.2997 - val_mean_squared_error: 600457.2997\n",
      "Epoch 281/350\n",
      " - 0s - loss: 289278.0700 - mean_squared_error: 289278.0700 - val_loss: 600326.8471 - val_mean_squared_error: 600326.8471\n",
      "Epoch 282/350\n",
      " - 0s - loss: 289201.8227 - mean_squared_error: 289201.8227 - val_loss: 600196.0965 - val_mean_squared_error: 600196.0965\n",
      "Epoch 283/350\n",
      " - 0s - loss: 289126.0555 - mean_squared_error: 289126.0555 - val_loss: 600063.5279 - val_mean_squared_error: 600063.5279\n",
      "Epoch 284/350\n",
      " - 0s - loss: 289048.9705 - mean_squared_error: 289048.9705 - val_loss: 599933.6618 - val_mean_squared_error: 599933.6618\n",
      "Epoch 285/350\n",
      " - 0s - loss: 288974.0406 - mean_squared_error: 288974.0406 - val_loss: 599803.3806 - val_mean_squared_error: 599803.3806\n",
      "Epoch 286/350\n",
      " - 0s - loss: 288897.7891 - mean_squared_error: 288897.7891 - val_loss: 599673.5017 - val_mean_squared_error: 599673.5017\n",
      "Epoch 287/350\n",
      " - 0s - loss: 288821.7175 - mean_squared_error: 288821.7175 - val_loss: 599542.9548 - val_mean_squared_error: 599542.9548\n",
      "Epoch 288/350\n",
      " - 0s - loss: 288745.4238 - mean_squared_error: 288745.4238 - val_loss: 599411.8449 - val_mean_squared_error: 599411.8449\n",
      "Epoch 289/350\n",
      " - 0s - loss: 288670.6847 - mean_squared_error: 288670.6847 - val_loss: 599279.4944 - val_mean_squared_error: 599279.4944\n",
      "Epoch 290/350\n",
      " - 0s - loss: 288592.7454 - mean_squared_error: 288592.7454 - val_loss: 599155.6250 - val_mean_squared_error: 599155.6250\n",
      "Epoch 291/350\n",
      " - 0s - loss: 288520.4097 - mean_squared_error: 288520.4097 - val_loss: 599023.6306 - val_mean_squared_error: 599023.6306\n",
      "Epoch 292/350\n",
      " - 0s - loss: 288444.6181 - mean_squared_error: 288444.6181 - val_loss: 598893.0011 - val_mean_squared_error: 598893.0011\n",
      "Epoch 293/350\n",
      " - 0s - loss: 288368.4655 - mean_squared_error: 288368.4655 - val_loss: 598766.8415 - val_mean_squared_error: 598766.8415\n",
      "Epoch 294/350\n",
      " - 0s - loss: 288295.9567 - mean_squared_error: 288295.9567 - val_loss: 598633.9849 - val_mean_squared_error: 598633.9849\n",
      "Epoch 295/350\n",
      " - 0s - loss: 288220.4664 - mean_squared_error: 288220.4664 - val_loss: 598504.1847 - val_mean_squared_error: 598504.1847\n",
      "Epoch 296/350\n",
      " - 0s - loss: 288143.8522 - mean_squared_error: 288143.8522 - val_loss: 598380.1574 - val_mean_squared_error: 598380.1574\n",
      "Epoch 297/350\n",
      " - 0s - loss: 288071.2103 - mean_squared_error: 288071.2103 - val_loss: 598249.1105 - val_mean_squared_error: 598249.1105\n",
      "Epoch 298/350\n",
      " - 0s - loss: 287995.9403 - mean_squared_error: 287995.9403 - val_loss: 598118.9001 - val_mean_squared_error: 598118.9001\n",
      "Epoch 299/350\n",
      " - 0s - loss: 287921.1067 - mean_squared_error: 287921.1067 - val_loss: 597991.4202 - val_mean_squared_error: 597991.4202\n",
      "Epoch 300/350\n",
      " - 0s - loss: 287846.5702 - mean_squared_error: 287846.5702 - val_loss: 597863.9788 - val_mean_squared_error: 597863.9788\n",
      "Epoch 301/350\n",
      " - 0s - loss: 287772.7597 - mean_squared_error: 287772.7597 - val_loss: 597735.5407 - val_mean_squared_error: 597735.5407\n",
      "Epoch 302/350\n",
      " - 0s - loss: 287697.0006 - mean_squared_error: 287697.0006 - val_loss: 597612.2461 - val_mean_squared_error: 597612.2461\n",
      "Epoch 303/350\n",
      " - 0s - loss: 287626.7941 - mean_squared_error: 287626.7941 - val_loss: 597477.5413 - val_mean_squared_error: 597477.5413\n",
      "Epoch 304/350\n",
      " - 0s - loss: 287550.3669 - mean_squared_error: 287550.3669 - val_loss: 597352.4671 - val_mean_squared_error: 597352.4671\n",
      "Epoch 305/350\n",
      " - 0s - loss: 287476.3214 - mean_squared_error: 287476.3214 - val_loss: 597224.3432 - val_mean_squared_error: 597224.3432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/350\n",
      " - 0s - loss: 287403.3425 - mean_squared_error: 287403.3425 - val_loss: 597092.5619 - val_mean_squared_error: 597092.5619\n",
      "Epoch 307/350\n",
      " - 0s - loss: 287327.3866 - mean_squared_error: 287327.3866 - val_loss: 596966.0698 - val_mean_squared_error: 596966.0698\n",
      "Epoch 308/350\n",
      " - 0s - loss: 287254.3544 - mean_squared_error: 287254.3544 - val_loss: 596835.1881 - val_mean_squared_error: 596835.1881\n",
      "Epoch 309/350\n",
      " - 0s - loss: 287179.6256 - mean_squared_error: 287179.6256 - val_loss: 596708.4498 - val_mean_squared_error: 596708.4498\n",
      "Epoch 310/350\n",
      " - 0s - loss: 287105.8900 - mean_squared_error: 287105.8900 - val_loss: 596580.0050 - val_mean_squared_error: 596580.0050\n",
      "Epoch 311/350\n",
      " - 0s - loss: 287032.4102 - mean_squared_error: 287032.4102 - val_loss: 596451.2662 - val_mean_squared_error: 596451.2662\n",
      "Epoch 312/350\n",
      " - 0s - loss: 286957.3858 - mean_squared_error: 286957.3858 - val_loss: 596323.2690 - val_mean_squared_error: 596323.2690\n",
      "Epoch 313/350\n",
      " - 0s - loss: 286883.2269 - mean_squared_error: 286883.2269 - val_loss: 596193.4035 - val_mean_squared_error: 596193.4035\n",
      "Epoch 314/350\n",
      " - 0s - loss: 286808.3014 - mean_squared_error: 286808.3014 - val_loss: 596066.2171 - val_mean_squared_error: 596066.2171\n",
      "Epoch 315/350\n",
      " - 0s - loss: 286733.8130 - mean_squared_error: 286733.8130 - val_loss: 595933.5045 - val_mean_squared_error: 595933.5045\n",
      "Epoch 316/350\n",
      " - 0s - loss: 286658.9834 - mean_squared_error: 286658.9834 - val_loss: 595803.1942 - val_mean_squared_error: 595803.1942\n",
      "Epoch 317/350\n",
      " - 0s - loss: 286583.4128 - mean_squared_error: 286583.4128 - val_loss: 595669.6596 - val_mean_squared_error: 595669.6596\n",
      "Epoch 318/350\n",
      " - 0s - loss: 286507.9758 - mean_squared_error: 286507.9758 - val_loss: 595536.0452 - val_mean_squared_error: 595536.0452\n",
      "Epoch 319/350\n",
      " - 0s - loss: 286433.3173 - mean_squared_error: 286433.3173 - val_loss: 595403.0022 - val_mean_squared_error: 595403.0022\n",
      "Epoch 320/350\n",
      " - 0s - loss: 286356.3770 - mean_squared_error: 286356.3770 - val_loss: 595274.4905 - val_mean_squared_error: 595274.4905\n",
      "Epoch 321/350\n",
      " - 0s - loss: 286281.5737 - mean_squared_error: 286281.5737 - val_loss: 595144.8153 - val_mean_squared_error: 595144.8153\n",
      "Epoch 322/350\n",
      " - 0s - loss: 286205.1615 - mean_squared_error: 286205.1615 - val_loss: 595016.5742 - val_mean_squared_error: 595016.5742\n",
      "Epoch 323/350\n",
      " - 0s - loss: 286131.7012 - mean_squared_error: 286131.7012 - val_loss: 594879.6339 - val_mean_squared_error: 594879.6339\n",
      "Epoch 324/350\n",
      " - 0s - loss: 286054.0539 - mean_squared_error: 286054.0539 - val_loss: 594748.7673 - val_mean_squared_error: 594748.7673\n",
      "Epoch 325/350\n",
      " - 0s - loss: 285977.4652 - mean_squared_error: 285977.4652 - val_loss: 594617.4894 - val_mean_squared_error: 594617.4894\n",
      "Epoch 326/350\n",
      " - 0s - loss: 285901.0766 - mean_squared_error: 285901.0766 - val_loss: 594481.6853 - val_mean_squared_error: 594481.6853\n",
      "Epoch 327/350\n",
      " - 0s - loss: 285822.5891 - mean_squared_error: 285822.5891 - val_loss: 594345.6936 - val_mean_squared_error: 594345.6936\n",
      "Epoch 328/350\n",
      " - 0s - loss: 285743.7042 - mean_squared_error: 285743.7042 - val_loss: 594209.6384 - val_mean_squared_error: 594209.6384\n",
      "Epoch 329/350\n",
      " - 0s - loss: 285666.6984 - mean_squared_error: 285666.6984 - val_loss: 594068.0257 - val_mean_squared_error: 594068.0257\n",
      "Epoch 330/350\n",
      " - 0s - loss: 285585.8066 - mean_squared_error: 285585.8066 - val_loss: 593932.8783 - val_mean_squared_error: 593932.8783\n",
      "Epoch 331/350\n",
      " - 0s - loss: 285507.1266 - mean_squared_error: 285507.1266 - val_loss: 593798.8722 - val_mean_squared_error: 593798.8722\n",
      "Epoch 332/350\n",
      " - 0s - loss: 285428.1155 - mean_squared_error: 285428.1155 - val_loss: 593663.3945 - val_mean_squared_error: 593663.3945\n",
      "Epoch 333/350\n",
      " - 0s - loss: 285349.0053 - mean_squared_error: 285349.0053 - val_loss: 593525.4347 - val_mean_squared_error: 593525.4347\n",
      "Epoch 334/350\n",
      " - 0s - loss: 285270.0787 - mean_squared_error: 285270.0787 - val_loss: 593383.9593 - val_mean_squared_error: 593383.9593\n",
      "Epoch 335/350\n",
      " - 0s - loss: 285187.8076 - mean_squared_error: 285187.8076 - val_loss: 593246.3493 - val_mean_squared_error: 593246.3493\n",
      "Epoch 336/350\n",
      " - 0s - loss: 285106.6802 - mean_squared_error: 285106.6802 - val_loss: 593106.7690 - val_mean_squared_error: 593106.7690\n",
      "Epoch 337/350\n",
      " - 0s - loss: 285025.2953 - mean_squared_error: 285025.2953 - val_loss: 592965.3114 - val_mean_squared_error: 592965.3114\n",
      "Epoch 338/350\n",
      " - 0s - loss: 284944.1161 - mean_squared_error: 284944.1161 - val_loss: 592821.3326 - val_mean_squared_error: 592821.3326\n",
      "Epoch 339/350\n",
      " - 0s - loss: 284859.9381 - mean_squared_error: 284859.9381 - val_loss: 592682.3806 - val_mean_squared_error: 592682.3806\n",
      "Epoch 340/350\n",
      " - 0s - loss: 284778.9713 - mean_squared_error: 284778.9713 - val_loss: 592537.5039 - val_mean_squared_error: 592537.5039\n",
      "Epoch 341/350\n",
      " - 0s - loss: 284695.0031 - mean_squared_error: 284695.0031 - val_loss: 592396.1908 - val_mean_squared_error: 592396.1908\n",
      "Epoch 342/350\n",
      " - 0s - loss: 284611.3441 - mean_squared_error: 284611.3441 - val_loss: 592251.7857 - val_mean_squared_error: 592251.7857\n",
      "Epoch 343/350\n",
      " - 0s - loss: 284527.1439 - mean_squared_error: 284527.1439 - val_loss: 592107.9481 - val_mean_squared_error: 592107.9481\n",
      "Epoch 344/350\n",
      " - 0s - loss: 284444.5196 - mean_squared_error: 284444.5196 - val_loss: 591960.5703 - val_mean_squared_error: 591960.5703\n",
      "Epoch 345/350\n",
      " - 0s - loss: 284358.5494 - mean_squared_error: 284358.5494 - val_loss: 591815.8778 - val_mean_squared_error: 591815.8778\n",
      "Epoch 346/350\n",
      " - 0s - loss: 284273.0542 - mean_squared_error: 284273.0542 - val_loss: 591670.8783 - val_mean_squared_error: 591670.8783\n",
      "Epoch 347/350\n",
      " - 0s - loss: 284186.7398 - mean_squared_error: 284186.7398 - val_loss: 591528.5748 - val_mean_squared_error: 591528.5748\n",
      "Epoch 348/350\n",
      " - 0s - loss: 284104.2936 - mean_squared_error: 284104.2936 - val_loss: 591377.8153 - val_mean_squared_error: 591377.8153\n",
      "Epoch 349/350\n",
      " - 0s - loss: 284015.9797 - mean_squared_error: 284015.9797 - val_loss: 591234.7411 - val_mean_squared_error: 591234.7411\n",
      "Epoch 350/350\n",
      " - 0s - loss: 283930.3155 - mean_squared_error: 283930.3155 - val_loss: 591084.8728 - val_mean_squared_error: 591084.8728\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 350, \n",
    "          batch_size = 15, \n",
    "          verbose=2, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b22face4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2261194e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее, добавили слой, два сигмоида"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 307151.7537 - mean_squared_error: 307151.7537 - val_loss: 630232.3075 - val_mean_squared_error: 630232.3075\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 306443.5911 - mean_squared_error: 306443.5911 - val_loss: 628963.7037 - val_mean_squared_error: 628963.7037\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 305675.5059 - mean_squared_error: 305675.5059 - val_loss: 627675.3929 - val_mean_squared_error: 627675.3929\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 304894.4519 - mean_squared_error: 304894.4519 - val_loss: 626388.7946 - val_mean_squared_error: 626388.7946\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 304114.4398 - mean_squared_error: 304114.4398 - val_loss: 625085.6390 - val_mean_squared_error: 625085.6390\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 303338.9939 - mean_squared_error: 303338.9939 - val_loss: 623806.2238 - val_mean_squared_error: 623806.2238\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 302576.5097 - mean_squared_error: 302576.5097 - val_loss: 622572.5932 - val_mean_squared_error: 622572.5932\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 301847.6458 - mean_squared_error: 301847.6458 - val_loss: 621365.1473 - val_mean_squared_error: 621365.1473\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 301135.8859 - mean_squared_error: 301135.8859 - val_loss: 620208.6685 - val_mean_squared_error: 620208.6685\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 300458.5008 - mean_squared_error: 300458.5008 - val_loss: 619094.4526 - val_mean_squared_error: 619094.4526\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 132us/step - loss: 299795.7595 - mean_squared_error: 299795.7595 - val_loss: 618059.5145 - val_mean_squared_error: 618059.5145\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 142us/step - loss: 299185.4406 - mean_squared_error: 299185.4406 - val_loss: 617061.5569 - val_mean_squared_error: 617061.5569\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 298600.0702 - mean_squared_error: 298600.0702 - val_loss: 616107.4916 - val_mean_squared_error: 616107.4916\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 134us/step - loss: 298045.1556 - mean_squared_error: 298045.1556 - val_loss: 615206.2879 - val_mean_squared_error: 615206.2879\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 297519.8327 - mean_squared_error: 297519.8327 - val_loss: 614368.5368 - val_mean_squared_error: 614368.5368\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 297038.2777 - mean_squared_error: 297038.2777 - val_loss: 613557.1099 - val_mean_squared_error: 613557.1099\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 142us/step - loss: 296566.8820 - mean_squared_error: 296566.8820 - val_loss: 612807.4180 - val_mean_squared_error: 612807.4180\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 296133.0429 - mean_squared_error: 296133.0429 - val_loss: 612083.7974 - val_mean_squared_error: 612083.7974\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 138us/step - loss: 295715.5558 - mean_squared_error: 295715.5558 - val_loss: 611385.6434 - val_mean_squared_error: 611385.6434\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 295310.4764 - mean_squared_error: 295310.4764 - val_loss: 610727.9280 - val_mean_squared_error: 610727.9280\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 294929.2058 - mean_squared_error: 294929.2058 - val_loss: 610081.2573 - val_mean_squared_error: 610081.2573\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 294552.8356 - mean_squared_error: 294552.8356 - val_loss: 609465.3800 - val_mean_squared_error: 609465.3800\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 126us/step - loss: 294192.3170 - mean_squared_error: 294192.3170 - val_loss: 608872.4766 - val_mean_squared_error: 608872.4766\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 123us/step - loss: 293847.5886 - mean_squared_error: 293847.5886 - val_loss: 608284.6596 - val_mean_squared_error: 608284.6596\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 293506.0383 - mean_squared_error: 293506.0383 - val_loss: 607711.9174 - val_mean_squared_error: 607711.9174\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 293174.6803 - mean_squared_error: 293174.6803 - val_loss: 607148.6523 - val_mean_squared_error: 607148.6523\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 292846.6781 - mean_squared_error: 292846.6781 - val_loss: 606601.4174 - val_mean_squared_error: 606601.4174\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 292525.0705 - mean_squared_error: 292525.0705 - val_loss: 606059.9280 - val_mean_squared_error: 606059.9280\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 292207.6581 - mean_squared_error: 292207.6581 - val_loss: 605521.2132 - val_mean_squared_error: 605521.2132\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 291894.0537 - mean_squared_error: 291894.0537 - val_loss: 604986.0603 - val_mean_squared_error: 604986.0603\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 291580.6598 - mean_squared_error: 291580.6598 - val_loss: 604459.2545 - val_mean_squared_error: 604459.2545\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 291274.1505 - mean_squared_error: 291274.1505 - val_loss: 603926.5753 - val_mean_squared_error: 603926.5753\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 290967.5061 - mean_squared_error: 290967.5061 - val_loss: 603406.6641 - val_mean_squared_error: 603406.6641\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 138us/step - loss: 290667.4948 - mean_squared_error: 290667.4948 - val_loss: 602895.3025 - val_mean_squared_error: 602895.3025\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 290369.2737 - mean_squared_error: 290369.2737 - val_loss: 602400.6049 - val_mean_squared_error: 602400.6049\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 290080.8394 - mean_squared_error: 290080.8394 - val_loss: 601901.4626 - val_mean_squared_error: 601901.4626\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 132us/step - loss: 289787.5883 - mean_squared_error: 289787.5883 - val_loss: 601407.7109 - val_mean_squared_error: 601407.7109\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 289497.0306 - mean_squared_error: 289497.0306 - val_loss: 600915.7109 - val_mean_squared_error: 600915.7109\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 289210.9753 - mean_squared_error: 289210.9753 - val_loss: 600423.1311 - val_mean_squared_error: 600423.1311\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 288926.3504 - mean_squared_error: 288926.3504 - val_loss: 599941.4967 - val_mean_squared_error: 599941.4967\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 288647.8503 - mean_squared_error: 288647.8503 - val_loss: 599460.7031 - val_mean_squared_error: 599460.7031\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 134us/step - loss: 288370.1708 - mean_squared_error: 288370.1708 - val_loss: 598986.1105 - val_mean_squared_error: 598986.1105\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 288096.0327 - mean_squared_error: 288096.0327 - val_loss: 598521.5580 - val_mean_squared_error: 598521.5580\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 287826.5300 - mean_squared_error: 287826.5300 - val_loss: 598055.0073 - val_mean_squared_error: 598055.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 287554.2644 - mean_squared_error: 287554.2644 - val_loss: 597594.1903 - val_mean_squared_error: 597594.1903\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 287284.5519 - mean_squared_error: 287284.5519 - val_loss: 597134.9950 - val_mean_squared_error: 597134.9950\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 287019.3122 - mean_squared_error: 287019.3122 - val_loss: 596670.0525 - val_mean_squared_error: 596670.0525\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 286748.6103 - mean_squared_error: 286748.6103 - val_loss: 596215.7718 - val_mean_squared_error: 596215.7718\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 132us/step - loss: 286483.0994 - mean_squared_error: 286483.0994 - val_loss: 595759.1004 - val_mean_squared_error: 595759.1004\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 286217.9258 - mean_squared_error: 286217.9258 - val_loss: 595314.1406 - val_mean_squared_error: 595314.1406\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 285960.9383 - mean_squared_error: 285960.9383 - val_loss: 594861.3544 - val_mean_squared_error: 594861.3544\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 285700.4689 - mean_squared_error: 285700.4689 - val_loss: 594417.6663 - val_mean_squared_error: 594417.6663\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 285442.3808 - mean_squared_error: 285442.3808 - val_loss: 593974.8622 - val_mean_squared_error: 593974.8622\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 285185.8066 - mean_squared_error: 285185.8066 - val_loss: 593530.7383 - val_mean_squared_error: 593530.7383\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 284929.2311 - mean_squared_error: 284929.2311 - val_loss: 593098.5748 - val_mean_squared_error: 593098.5748\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 284678.0329 - mean_squared_error: 284678.0329 - val_loss: 592657.9018 - val_mean_squared_error: 592657.9018\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 284422.5187 - mean_squared_error: 284422.5187 - val_loss: 592219.7260 - val_mean_squared_error: 592219.7260\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 284166.8373 - mean_squared_error: 284166.8373 - val_loss: 591777.8700 - val_mean_squared_error: 591777.8700\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 132us/step - loss: 283911.8781 - mean_squared_error: 283911.8781 - val_loss: 591328.0201 - val_mean_squared_error: 591328.0201\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 283653.1961 - mean_squared_error: 283653.1961 - val_loss: 590890.1975 - val_mean_squared_error: 590890.1975\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 283399.2677 - mean_squared_error: 283399.2677 - val_loss: 590455.4029 - val_mean_squared_error: 590455.4029\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 283146.0120 - mean_squared_error: 283146.0120 - val_loss: 590019.0792 - val_mean_squared_error: 590019.0792\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 282893.3088 - mean_squared_error: 282893.3088 - val_loss: 589577.8477 - val_mean_squared_error: 589577.8477\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 282642.5064 - mean_squared_error: 282642.5064 - val_loss: 589124.2439 - val_mean_squared_error: 589124.2439\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 282381.1925 - mean_squared_error: 282381.1925 - val_loss: 588681.2522 - val_mean_squared_error: 588681.2522\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 282120.8471 - mean_squared_error: 282120.8471 - val_loss: 588247.8622 - val_mean_squared_error: 588247.8622\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 281865.5055 - mean_squared_error: 281865.5055 - val_loss: 587804.1267 - val_mean_squared_error: 587804.1267\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 281608.8280 - mean_squared_error: 281608.8280 - val_loss: 587354.0340 - val_mean_squared_error: 587354.0340\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 281348.6864 - mean_squared_error: 281348.6864 - val_loss: 586903.7455 - val_mean_squared_error: 586903.7455\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 281088.6305 - mean_squared_error: 281088.6305 - val_loss: 586446.7260 - val_mean_squared_error: 586446.7260\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 280826.2730 - mean_squared_error: 280826.2730 - val_loss: 585998.8404 - val_mean_squared_error: 585998.8404\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 280567.3402 - mean_squared_error: 280567.3402 - val_loss: 585549.9771 - val_mean_squared_error: 585549.9771\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 280309.1972 - mean_squared_error: 280309.1972 - val_loss: 585100.1161 - val_mean_squared_error: 585100.1161\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 280049.2199 - mean_squared_error: 280049.2199 - val_loss: 584657.9364 - val_mean_squared_error: 584657.9364\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 138us/step - loss: 279794.5555 - mean_squared_error: 279794.5555 - val_loss: 584208.6423 - val_mean_squared_error: 584208.6423\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 279537.7439 - mean_squared_error: 279537.7439 - val_loss: 583763.7790 - val_mean_squared_error: 583763.7790\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 279280.8067 - mean_squared_error: 279280.8067 - val_loss: 583325.7042 - val_mean_squared_error: 583325.7042\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 279025.2200 - mean_squared_error: 279025.2200 - val_loss: 582893.0742 - val_mean_squared_error: 582893.0742\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 278775.1583 - mean_squared_error: 278775.1583 - val_loss: 582448.3549 - val_mean_squared_error: 582448.3549\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 278523.6498 - mean_squared_error: 278523.6498 - val_loss: 581997.5792 - val_mean_squared_error: 581997.5792\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 278265.7719 - mean_squared_error: 278265.7719 - val_loss: 581563.4330 - val_mean_squared_error: 581563.4330\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 278014.8420 - mean_squared_error: 278014.8420 - val_loss: 581127.8761 - val_mean_squared_error: 581127.8761\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 277765.0109 - mean_squared_error: 277765.0109 - val_loss: 580689.5346 - val_mean_squared_error: 580689.5346\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 277513.0708 - mean_squared_error: 277513.0708 - val_loss: 580257.0195 - val_mean_squared_error: 580257.0195\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 277270.2363 - mean_squared_error: 277270.2363 - val_loss: 579818.0407 - val_mean_squared_error: 579818.0407\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 277018.5769 - mean_squared_error: 277018.5769 - val_loss: 579390.6719 - val_mean_squared_error: 579390.6719\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 276772.9453 - mean_squared_error: 276772.9453 - val_loss: 578956.2081 - val_mean_squared_error: 578956.2081\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 276523.7026 - mean_squared_error: 276523.7026 - val_loss: 578522.6350 - val_mean_squared_error: 578522.6350\n",
      "Epoch 89/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 139us/step - loss: 276272.4647 - mean_squared_error: 276272.4647 - val_loss: 578097.1484 - val_mean_squared_error: 578097.1484\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 276025.4681 - mean_squared_error: 276025.4681 - val_loss: 577662.2640 - val_mean_squared_error: 577662.2640\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 275777.5828 - mean_squared_error: 275777.5828 - val_loss: 577234.8008 - val_mean_squared_error: 577234.8008\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 275535.3328 - mean_squared_error: 275535.3328 - val_loss: 576797.2679 - val_mean_squared_error: 576797.2679\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 275283.5845 - mean_squared_error: 275283.5845 - val_loss: 576366.7015 - val_mean_squared_error: 576366.7015\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 275037.0427 - mean_squared_error: 275037.0427 - val_loss: 575937.5391 - val_mean_squared_error: 575937.5391\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 274790.7012 - mean_squared_error: 274790.7012 - val_loss: 575503.4766 - val_mean_squared_error: 575503.4766\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 274542.7667 - mean_squared_error: 274542.7667 - val_loss: 575059.5698 - val_mean_squared_error: 575059.5698\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 274285.9708 - mean_squared_error: 274285.9708 - val_loss: 574624.0820 - val_mean_squared_error: 574624.0820\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 138us/step - loss: 274038.9450 - mean_squared_error: 274038.9450 - val_loss: 574180.1384 - val_mean_squared_error: 574180.1384\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 273785.7238 - mean_squared_error: 273785.7238 - val_loss: 573755.0502 - val_mean_squared_error: 573755.0502\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 273539.9541 - mean_squared_error: 273539.9541 - val_loss: 573327.8348 - val_mean_squared_error: 573327.8348\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 273295.8963 - mean_squared_error: 273295.8963 - val_loss: 572895.7662 - val_mean_squared_error: 572895.7662\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 273050.2284 - mean_squared_error: 273050.2284 - val_loss: 572473.9481 - val_mean_squared_error: 572473.9481\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 272808.9681 - mean_squared_error: 272808.9681 - val_loss: 572056.3242 - val_mean_squared_error: 572056.3242\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 272569.5325 - mean_squared_error: 272569.5325 - val_loss: 571634.3136 - val_mean_squared_error: 571634.3136\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 272330.7489 - mean_squared_error: 272330.7489 - val_loss: 571209.7405 - val_mean_squared_error: 571209.7405\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 272091.2586 - mean_squared_error: 272091.2586 - val_loss: 570790.6138 - val_mean_squared_error: 570790.6138\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 138us/step - loss: 271850.6362 - mean_squared_error: 271850.6362 - val_loss: 570382.4408 - val_mean_squared_error: 570382.4408\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 271616.8636 - mean_squared_error: 271616.8636 - val_loss: 569964.9676 - val_mean_squared_error: 569964.9676\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 271381.5991 - mean_squared_error: 271381.5991 - val_loss: 569546.9715 - val_mean_squared_error: 569546.9715\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 141us/step - loss: 271140.7964 - mean_squared_error: 271140.7964 - val_loss: 569143.4961 - val_mean_squared_error: 569143.4961\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 144us/step - loss: 270912.6996 - mean_squared_error: 270912.6996 - val_loss: 568716.3119 - val_mean_squared_error: 568716.3119\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 143us/step - loss: 270664.1389 - mean_squared_error: 270664.1389 - val_loss: 568307.4827 - val_mean_squared_error: 568307.4827\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 270432.4686 - mean_squared_error: 270432.4686 - val_loss: 567872.7874 - val_mean_squared_error: 567872.7874\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 270187.8548 - mean_squared_error: 270187.8548 - val_loss: 567464.5285 - val_mean_squared_error: 567464.5285\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 269954.7620 - mean_squared_error: 269954.7620 - val_loss: 567054.3164 - val_mean_squared_error: 567054.3164\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 269717.5426 - mean_squared_error: 269717.5426 - val_loss: 566650.2165 - val_mean_squared_error: 566650.2165\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 269484.9553 - mean_squared_error: 269484.9553 - val_loss: 566235.9927 - val_mean_squared_error: 566235.9927\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 269250.2766 - mean_squared_error: 269250.2766 - val_loss: 565828.3142 - val_mean_squared_error: 565828.3142\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 126us/step - loss: 269019.3585 - mean_squared_error: 269019.3585 - val_loss: 565418.1272 - val_mean_squared_error: 565418.1272\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 268782.8412 - mean_squared_error: 268782.8412 - val_loss: 565021.0770 - val_mean_squared_error: 565021.0770\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 268555.6281 - mean_squared_error: 268555.6281 - val_loss: 564613.4174 - val_mean_squared_error: 564613.4174\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 122us/step - loss: 268323.1780 - mean_squared_error: 268323.1780 - val_loss: 564212.8828 - val_mean_squared_error: 564212.8828\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 268093.9441 - mean_squared_error: 268093.9441 - val_loss: 563810.1016 - val_mean_squared_error: 563810.1016\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 267863.9883 - mean_squared_error: 267863.9883 - val_loss: 563406.7366 - val_mean_squared_error: 563406.7366\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 267634.6575 - mean_squared_error: 267634.6575 - val_loss: 563001.7026 - val_mean_squared_error: 563001.7026\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 267400.8808 - mean_squared_error: 267400.8808 - val_loss: 562604.8934 - val_mean_squared_error: 562604.8934\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 267173.2550 - mean_squared_error: 267173.2550 - val_loss: 562198.2238 - val_mean_squared_error: 562198.2238\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 266944.5530 - mean_squared_error: 266944.5530 - val_loss: 561785.3504 - val_mean_squared_error: 561785.3504\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 266704.6781 - mean_squared_error: 266704.6781 - val_loss: 561386.6752 - val_mean_squared_error: 561386.6752\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 266472.5544 - mean_squared_error: 266472.5544 - val_loss: 560978.0340 - val_mean_squared_error: 560978.0340\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 266234.2012 - mean_squared_error: 266234.2012 - val_loss: 560566.5893 - val_mean_squared_error: 560566.5893\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 265996.4500 - mean_squared_error: 265996.4500 - val_loss: 560141.7695 - val_mean_squared_error: 560141.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 265755.9931 - mean_squared_error: 265755.9931 - val_loss: 559726.2383 - val_mean_squared_error: 559726.2383\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 265521.0434 - mean_squared_error: 265521.0434 - val_loss: 559315.6975 - val_mean_squared_error: 559315.6975\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 134us/step - loss: 265284.8830 - mean_squared_error: 265284.8830 - val_loss: 558911.5301 - val_mean_squared_error: 558911.5301\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 265052.7425 - mean_squared_error: 265052.7425 - val_loss: 558506.1663 - val_mean_squared_error: 558506.1663\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 264820.4189 - mean_squared_error: 264820.4189 - val_loss: 558096.8761 - val_mean_squared_error: 558096.8761\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 264582.3652 - mean_squared_error: 264582.3652 - val_loss: 557697.3828 - val_mean_squared_error: 557697.3828\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 135us/step - loss: 264348.9200 - mean_squared_error: 264348.9200 - val_loss: 557274.6211 - val_mean_squared_error: 557274.6211\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 132us/step - loss: 264103.5196 - mean_squared_error: 264103.5196 - val_loss: 556854.2919 - val_mean_squared_error: 556854.2919\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 263862.7928 - mean_squared_error: 263862.7928 - val_loss: 556425.4275 - val_mean_squared_error: 556425.4275\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 263618.1752 - mean_squared_error: 263618.1752 - val_loss: 556007.9872 - val_mean_squared_error: 556007.9872\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 263380.6760 - mean_squared_error: 263380.6760 - val_loss: 555591.6914 - val_mean_squared_error: 555591.6914\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 263140.3703 - mean_squared_error: 263140.3703 - val_loss: 555187.9035 - val_mean_squared_error: 555187.9035\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 262906.2606 - mean_squared_error: 262906.2606 - val_loss: 554777.7584 - val_mean_squared_error: 554777.7584\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 262673.0600 - mean_squared_error: 262673.0600 - val_loss: 554367.1535 - val_mean_squared_error: 554367.1535\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 124us/step - loss: 262438.8395 - mean_squared_error: 262438.8395 - val_loss: 553964.8326 - val_mean_squared_error: 553964.8326\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 136us/step - loss: 262205.4353 - mean_squared_error: 262205.4353 - val_loss: 553566.6970 - val_mean_squared_error: 553566.6970\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 261973.0591 - mean_squared_error: 261973.0591 - val_loss: 553168.3013 - val_mean_squared_error: 553168.3013\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 261742.3114 - mean_squared_error: 261742.3114 - val_loss: 552763.5569 - val_mean_squared_error: 552763.5569\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 261512.5477 - mean_squared_error: 261512.5477 - val_loss: 552361.0195 - val_mean_squared_error: 552361.0195\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 123us/step - loss: 261279.0317 - mean_squared_error: 261279.0317 - val_loss: 551971.0519 - val_mean_squared_error: 551971.0519\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 261054.0225 - mean_squared_error: 261054.0225 - val_loss: 551567.9978 - val_mean_squared_error: 551567.9978\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 121us/step - loss: 260820.4542 - mean_squared_error: 260820.4542 - val_loss: 551179.0910 - val_mean_squared_error: 551179.0910\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 260594.0939 - mean_squared_error: 260594.0939 - val_loss: 550777.4135 - val_mean_squared_error: 550777.4135\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 260367.2502 - mean_squared_error: 260367.2502 - val_loss: 550372.8979 - val_mean_squared_error: 550372.8979\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 260135.8167 - mean_squared_error: 260135.8167 - val_loss: 549980.7215 - val_mean_squared_error: 549980.7215\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 259905.7423 - mean_squared_error: 259905.7423 - val_loss: 549590.2729 - val_mean_squared_error: 549590.2729\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 259680.6247 - mean_squared_error: 259680.6247 - val_loss: 549189.5240 - val_mean_squared_error: 549189.5240\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 133us/step - loss: 259451.9433 - mean_squared_error: 259451.9433 - val_loss: 548794.6071 - val_mean_squared_error: 548794.6071\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 259225.2383 - mean_squared_error: 259225.2383 - val_loss: 548410.8186 - val_mean_squared_error: 548410.8186\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 259001.9901 - mean_squared_error: 259001.9901 - val_loss: 548016.2444 - val_mean_squared_error: 548016.2444\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 258774.6783 - mean_squared_error: 258774.6783 - val_loss: 547619.8956 - val_mean_squared_error: 547619.8956\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 258547.0669 - mean_squared_error: 258547.0669 - val_loss: 547225.5737 - val_mean_squared_error: 547225.5737\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 258319.4138 - mean_squared_error: 258319.4138 - val_loss: 546836.2919 - val_mean_squared_error: 546836.2919\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 258095.6344 - mean_squared_error: 258095.6344 - val_loss: 546452.3270 - val_mean_squared_error: 546452.3270\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 257874.4306 - mean_squared_error: 257874.4306 - val_loss: 546062.6836 - val_mean_squared_error: 546062.6836\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 257647.6098 - mean_squared_error: 257647.6098 - val_loss: 545674.5396 - val_mean_squared_error: 545674.5396\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 136us/step - loss: 257425.0452 - mean_squared_error: 257425.0452 - val_loss: 545277.3672 - val_mean_squared_error: 545277.3672\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 257195.8943 - mean_squared_error: 257195.8943 - val_loss: 544897.5234 - val_mean_squared_error: 544897.5234\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 256975.8561 - mean_squared_error: 256975.8561 - val_loss: 544499.2985 - val_mean_squared_error: 544499.2985\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 256750.2697 - mean_squared_error: 256750.2697 - val_loss: 544100.7584 - val_mean_squared_error: 544100.7584\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 256518.1016 - mean_squared_error: 256518.1016 - val_loss: 543707.0943 - val_mean_squared_error: 543707.0943\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 256292.8737 - mean_squared_error: 256292.8737 - val_loss: 543302.1267 - val_mean_squared_error: 543302.1267\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 256062.5998 - mean_squared_error: 256062.5998 - val_loss: 542907.2573 - val_mean_squared_error: 542907.2573\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 126us/step - loss: 255837.1580 - mean_squared_error: 255837.1580 - val_loss: 542513.9358 - val_mean_squared_error: 542513.9358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 255608.3920 - mean_squared_error: 255608.3920 - val_loss: 542127.5195 - val_mean_squared_error: 542127.5195\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 255386.3869 - mean_squared_error: 255386.3869 - val_loss: 541730.6350 - val_mean_squared_error: 541730.6350\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 255164.1604 - mean_squared_error: 255164.1604 - val_loss: 541333.0826 - val_mean_squared_error: 541333.0826\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 126us/step - loss: 254936.3553 - mean_squared_error: 254936.3553 - val_loss: 540946.4012 - val_mean_squared_error: 540946.4012\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 254713.2749 - mean_squared_error: 254713.2749 - val_loss: 540561.3627 - val_mean_squared_error: 540561.3627\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 254489.3009 - mean_squared_error: 254489.3009 - val_loss: 540181.2679 - val_mean_squared_error: 540181.2679\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 254270.0105 - mean_squared_error: 254270.0105 - val_loss: 539781.4431 - val_mean_squared_error: 539781.4431\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 128us/step - loss: 254044.2150 - mean_squared_error: 254044.2150 - val_loss: 539395.3482 - val_mean_squared_error: 539395.3482\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 253821.2086 - mean_squared_error: 253821.2086 - val_loss: 539015.4554 - val_mean_squared_error: 539015.4554\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 253604.5030 - mean_squared_error: 253604.5030 - val_loss: 538621.8689 - val_mean_squared_error: 538621.8689\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 253382.3073 - mean_squared_error: 253382.3073 - val_loss: 538231.8052 - val_mean_squared_error: 538231.8052\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 253156.9100 - mean_squared_error: 253156.9100 - val_loss: 537851.5089 - val_mean_squared_error: 537851.5089\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 252936.7930 - mean_squared_error: 252936.7930 - val_loss: 537468.2310 - val_mean_squared_error: 537468.2310\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 130us/step - loss: 252721.7008 - mean_squared_error: 252721.7008 - val_loss: 537072.1602 - val_mean_squared_error: 537072.1602\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 252500.7550 - mean_squared_error: 252500.7550 - val_loss: 536690.9593 - val_mean_squared_error: 536690.9593\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 131us/step - loss: 252280.5334 - mean_squared_error: 252280.5334 - val_loss: 536312.0619 - val_mean_squared_error: 536312.0619\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 123us/step - loss: 252066.4049 - mean_squared_error: 252066.4049 - val_loss: 535923.1233 - val_mean_squared_error: 535923.1233\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 251843.2331 - mean_squared_error: 251843.2331 - val_loss: 535548.0184 - val_mean_squared_error: 535548.0184\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 123us/step - loss: 251628.0490 - mean_squared_error: 251628.0490 - val_loss: 535168.8326 - val_mean_squared_error: 535168.8326\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 125us/step - loss: 251407.8375 - mean_squared_error: 251407.8375 - val_loss: 534793.6295 - val_mean_squared_error: 534793.6295\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 127us/step - loss: 251193.1534 - mean_squared_error: 251193.1534 - val_loss: 534403.5552 - val_mean_squared_error: 534403.5552\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 129us/step - loss: 250974.3867 - mean_squared_error: 250974.3867 - val_loss: 534015.0402 - val_mean_squared_error: 534015.0402\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 137us/step - loss: 250750.3247 - mean_squared_error: 250750.3247 - val_loss: 533645.1462 - val_mean_squared_error: 533645.1462\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 250539.2333 - mean_squared_error: 250539.2333 - val_loss: 533252.3203 - val_mean_squared_error: 533252.3203\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 250314.1041 - mean_squared_error: 250314.1041 - val_loss: 532886.8292 - val_mean_squared_error: 532886.8292\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 140us/step - loss: 250103.0767 - mean_squared_error: 250103.0767 - val_loss: 532494.2874 - val_mean_squared_error: 532494.2874\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 139us/step - loss: 249885.2377 - mean_squared_error: 249885.2377 - val_loss: 532115.9057 - val_mean_squared_error: 532115.9057\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 249668.1642 - mean_squared_error: 249668.1642 - val_loss: 531745.1948 - val_mean_squared_error: 531745.1948\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 249458.2433 - mean_squared_error: 249458.2433 - val_loss: 531361.9570 - val_mean_squared_error: 531361.9570\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 249243.0117 - mean_squared_error: 249243.0117 - val_loss: 530985.7578 - val_mean_squared_error: 530985.7578\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 249027.9955 - mean_squared_error: 249027.9955 - val_loss: 530607.7416 - val_mean_squared_error: 530607.7416\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 248809.0905 - mean_squared_error: 248809.0905 - val_loss: 530243.2511 - val_mean_squared_error: 530243.2511\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 248599.2000 - mean_squared_error: 248599.2000 - val_loss: 529863.2048 - val_mean_squared_error: 529863.2048\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 248387.5233 - mean_squared_error: 248387.5233 - val_loss: 529480.4397 - val_mean_squared_error: 529480.4397\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 248169.2693 - mean_squared_error: 248169.2693 - val_loss: 529113.1825 - val_mean_squared_error: 529113.1825\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 247957.0980 - mean_squared_error: 247957.0980 - val_loss: 528735.7182 - val_mean_squared_error: 528735.7182\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 247740.8934 - mean_squared_error: 247740.8934 - val_loss: 528361.8800 - val_mean_squared_error: 528361.8800\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 247528.3700 - mean_squared_error: 247528.3700 - val_loss: 527985.0050 - val_mean_squared_error: 527985.0050\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 247314.0046 - mean_squared_error: 247314.0046 - val_loss: 527603.6473 - val_mean_squared_error: 527603.6473\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 247097.8680 - mean_squared_error: 247097.8680 - val_loss: 527232.6819 - val_mean_squared_error: 527232.6819\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 246889.8109 - mean_squared_error: 246889.8109 - val_loss: 526849.2154 - val_mean_squared_error: 526849.2154\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 246675.0490 - mean_squared_error: 246675.0490 - val_loss: 526476.2137 - val_mean_squared_error: 526476.2137\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 246463.0392 - mean_squared_error: 246463.0392 - val_loss: 526092.5251 - val_mean_squared_error: 526092.5251\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 246244.4552 - mean_squared_error: 246244.4552 - val_loss: 525729.8164 - val_mean_squared_error: 525729.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 246034.6659 - mean_squared_error: 246034.6659 - val_loss: 525362.3521 - val_mean_squared_error: 525362.3521\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 245828.2171 - mean_squared_error: 245828.2171 - val_loss: 524979.1735 - val_mean_squared_error: 524979.1735\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 245611.1141 - mean_squared_error: 245611.1141 - val_loss: 524616.5480 - val_mean_squared_error: 524616.5480\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 245401.8656 - mean_squared_error: 245401.8656 - val_loss: 524237.0134 - val_mean_squared_error: 524237.0134\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 245189.9134 - mean_squared_error: 245189.9134 - val_loss: 523863.0787 - val_mean_squared_error: 523863.0787\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 244980.0176 - mean_squared_error: 244980.0176 - val_loss: 523491.2104 - val_mean_squared_error: 523491.2104\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 244771.7538 - mean_squared_error: 244771.7538 - val_loss: 523114.4498 - val_mean_squared_error: 523114.4498\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 244557.5327 - mean_squared_error: 244557.5327 - val_loss: 522748.6083 - val_mean_squared_error: 522748.6083\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 244349.3932 - mean_squared_error: 244349.3932 - val_loss: 522378.5268 - val_mean_squared_error: 522378.5268\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 244137.6352 - mean_squared_error: 244137.6352 - val_loss: 522011.6730 - val_mean_squared_error: 522011.6730\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 243930.1414 - mean_squared_error: 243930.1414 - val_loss: 521632.3331 - val_mean_squared_error: 521632.3331\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 243717.7228 - mean_squared_error: 243717.7228 - val_loss: 521260.8555 - val_mean_squared_error: 521260.8555\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 243503.5923 - mean_squared_error: 243503.5923 - val_loss: 520895.9900 - val_mean_squared_error: 520895.9900\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 243299.6258 - mean_squared_error: 243299.6258 - val_loss: 520513.6574 - val_mean_squared_error: 520513.6574\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 243084.2805 - mean_squared_error: 243084.2805 - val_loss: 520155.0402 - val_mean_squared_error: 520155.0402\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 242881.6798 - mean_squared_error: 242881.6798 - val_loss: 519775.2188 - val_mean_squared_error: 519775.2188\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 242668.1353 - mean_squared_error: 242668.1353 - val_loss: 519408.6998 - val_mean_squared_error: 519408.6998\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 242458.9680 - mean_squared_error: 242458.9680 - val_loss: 519043.7467 - val_mean_squared_error: 519043.7467\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 242252.2580 - mean_squared_error: 242252.2580 - val_loss: 518671.9604 - val_mean_squared_error: 518671.9604\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 242047.6817 - mean_squared_error: 242047.6817 - val_loss: 518293.5067 - val_mean_squared_error: 518293.5067\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 241836.1702 - mean_squared_error: 241836.1702 - val_loss: 517927.8917 - val_mean_squared_error: 517927.8917\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 241627.6386 - mean_squared_error: 241627.6386 - val_loss: 517568.5926 - val_mean_squared_error: 517568.5926\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 241420.4197 - mean_squared_error: 241420.4197 - val_loss: 517205.0508 - val_mean_squared_error: 517205.0508\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 241212.5767 - mean_squared_error: 241212.5767 - val_loss: 516836.3225 - val_mean_squared_error: 516836.3225\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 180us/step - loss: 241005.9333 - mean_squared_error: 241005.9333 - val_loss: 516470.6752 - val_mean_squared_error: 516470.6752\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 240796.5938 - mean_squared_error: 240796.5938 - val_loss: 516108.1964 - val_mean_squared_error: 516108.1964\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 240590.1468 - mean_squared_error: 240590.1468 - val_loss: 515727.2757 - val_mean_squared_error: 515727.2757\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 240381.0500 - mean_squared_error: 240381.0500 - val_loss: 515353.7790 - val_mean_squared_error: 515353.7790\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 240171.9523 - mean_squared_error: 240171.9523 - val_loss: 514990.7617 - val_mean_squared_error: 514990.7617\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 170us/step - loss: 239966.2780 - mean_squared_error: 239966.2780 - val_loss: 514628.4721 - val_mean_squared_error: 514628.4721\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 239764.7280 - mean_squared_error: 239764.7280 - val_loss: 514256.1808 - val_mean_squared_error: 514256.1808\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 239555.7673 - mean_squared_error: 239555.7673 - val_loss: 513897.8421 - val_mean_squared_error: 513897.8421\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 239352.2209 - mean_squared_error: 239352.2209 - val_loss: 513537.3767 - val_mean_squared_error: 513537.3767\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 239146.8046 - mean_squared_error: 239146.8046 - val_loss: 513178.0871 - val_mean_squared_error: 513178.0871\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 162us/step - loss: 238944.5777 - mean_squared_error: 238944.5777 - val_loss: 512809.2545 - val_mean_squared_error: 512809.2545\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 238735.8973 - mean_squared_error: 238735.8973 - val_loss: 512448.3069 - val_mean_squared_error: 512448.3069\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 238535.9471 - mean_squared_error: 238535.9471 - val_loss: 512074.8890 - val_mean_squared_error: 512074.8890\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 238325.2881 - mean_squared_error: 238325.2881 - val_loss: 511713.1557 - val_mean_squared_error: 511713.1557\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 238119.7073 - mean_squared_error: 238119.7073 - val_loss: 511357.8398 - val_mean_squared_error: 511357.8398\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 237922.0816 - mean_squared_error: 237922.0816 - val_loss: 510982.1451 - val_mean_squared_error: 510982.1451\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 237712.1353 - mean_squared_error: 237712.1353 - val_loss: 510627.8343 - val_mean_squared_error: 510627.8343\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 237509.0076 - mean_squared_error: 237509.0076 - val_loss: 510271.3923 - val_mean_squared_error: 510271.3923\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 237310.0118 - mean_squared_error: 237310.0118 - val_loss: 509898.9648 - val_mean_squared_error: 509898.9648\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 237102.3048 - mean_squared_error: 237102.3048 - val_loss: 509534.9308 - val_mean_squared_error: 509534.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 236900.1150 - mean_squared_error: 236900.1150 - val_loss: 509171.2098 - val_mean_squared_error: 509171.2098\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 236693.2283 - mean_squared_error: 236693.2283 - val_loss: 508818.9838 - val_mean_squared_error: 508818.9838\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 236491.6560 - mean_squared_error: 236491.6560 - val_loss: 508464.8203 - val_mean_squared_error: 508464.8203\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 236290.6376 - mean_squared_error: 236290.6376 - val_loss: 508102.5798 - val_mean_squared_error: 508102.5798\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 236092.2841 - mean_squared_error: 236092.2841 - val_loss: 507736.4369 - val_mean_squared_error: 507736.4369\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 235887.9543 - mean_squared_error: 235887.9543 - val_loss: 507381.1010 - val_mean_squared_error: 507381.1010\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 235687.7061 - mean_squared_error: 235687.7061 - val_loss: 507020.4894 - val_mean_squared_error: 507020.4894\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 235483.7936 - mean_squared_error: 235483.7936 - val_loss: 506667.5463 - val_mean_squared_error: 506667.5463\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 235281.5319 - mean_squared_error: 235281.5319 - val_loss: 506310.8253 - val_mean_squared_error: 506310.8253\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 235083.9037 - mean_squared_error: 235083.9037 - val_loss: 505941.7662 - val_mean_squared_error: 505941.7662\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 162us/step - loss: 234880.5312 - mean_squared_error: 234880.5312 - val_loss: 505582.0642 - val_mean_squared_error: 505582.0642\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 234677.5177 - mean_squared_error: 234677.5177 - val_loss: 505223.8253 - val_mean_squared_error: 505223.8253\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 234476.5858 - mean_squared_error: 234476.5858 - val_loss: 504861.2785 - val_mean_squared_error: 504861.2785\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 234272.7087 - mean_squared_error: 234272.7087 - val_loss: 504502.5603 - val_mean_squared_error: 504502.5603\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 234072.8942 - mean_squared_error: 234072.8942 - val_loss: 504135.8516 - val_mean_squared_error: 504135.8516\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 233865.2653 - mean_squared_error: 233865.2653 - val_loss: 503788.6261 - val_mean_squared_error: 503788.6261\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 233668.4331 - mean_squared_error: 233668.4331 - val_loss: 503423.0246 - val_mean_squared_error: 503423.0246\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 233467.2466 - mean_squared_error: 233467.2466 - val_loss: 503062.2896 - val_mean_squared_error: 503062.2896\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 233264.3298 - mean_squared_error: 233264.3298 - val_loss: 502711.2467 - val_mean_squared_error: 502711.2467\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 233063.7077 - mean_squared_error: 233063.7077 - val_loss: 502362.2243 - val_mean_squared_error: 502362.2243\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 232868.3857 - mean_squared_error: 232868.3857 - val_loss: 501996.4157 - val_mean_squared_error: 501996.4157\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 232670.1689 - mean_squared_error: 232670.1689 - val_loss: 501638.4023 - val_mean_squared_error: 501638.4023\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 232468.9887 - mean_squared_error: 232468.9887 - val_loss: 501286.4414 - val_mean_squared_error: 501286.4414\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 232269.4379 - mean_squared_error: 232269.4379 - val_loss: 500931.7768 - val_mean_squared_error: 500931.7768\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 232069.4961 - mean_squared_error: 232069.4961 - val_loss: 500572.7768 - val_mean_squared_error: 500572.7768\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 231864.8935 - mean_squared_error: 231864.8935 - val_loss: 500224.0485 - val_mean_squared_error: 500224.0485\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 231669.5109 - mean_squared_error: 231669.5109 - val_loss: 499861.1378 - val_mean_squared_error: 499861.1378\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 231472.0764 - mean_squared_error: 231472.0764 - val_loss: 499499.4860 - val_mean_squared_error: 499499.4860\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 231274.6241 - mean_squared_error: 231274.6241 - val_loss: 499142.3588 - val_mean_squared_error: 499142.3588\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 231070.7523 - mean_squared_error: 231070.7523 - val_loss: 498807.1038 - val_mean_squared_error: 498807.1038\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 230877.3001 - mean_squared_error: 230877.3001 - val_loss: 498448.7455 - val_mean_squared_error: 498448.7455\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 230677.0958 - mean_squared_error: 230677.0958 - val_loss: 498093.1127 - val_mean_squared_error: 498093.1127\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 230477.1954 - mean_squared_error: 230477.1954 - val_loss: 497734.7963 - val_mean_squared_error: 497734.7963\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 230276.4561 - mean_squared_error: 230276.4561 - val_loss: 497386.8359 - val_mean_squared_error: 497386.8359\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 230084.6942 - mean_squared_error: 230084.6942 - val_loss: 497017.1875 - val_mean_squared_error: 497017.1875\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 229879.3636 - mean_squared_error: 229879.3636 - val_loss: 496662.9330 - val_mean_squared_error: 496662.9330\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 229678.5711 - mean_squared_error: 229678.5711 - val_loss: 496308.0932 - val_mean_squared_error: 496308.0932\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 229478.7189 - mean_squared_error: 229478.7189 - val_loss: 495953.4431 - val_mean_squared_error: 495953.4431\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 229280.3073 - mean_squared_error: 229280.3073 - val_loss: 495585.8638 - val_mean_squared_error: 495585.8638\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 229078.6833 - mean_squared_error: 229078.6833 - val_loss: 495229.2810 - val_mean_squared_error: 495229.2810\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 162us/step - loss: 228879.4188 - mean_squared_error: 228879.4188 - val_loss: 494879.5619 - val_mean_squared_error: 494879.5619\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 228681.7097 - mean_squared_error: 228681.7097 - val_loss: 494537.1549 - val_mean_squared_error: 494537.1549\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 228488.3325 - mean_squared_error: 228488.3325 - val_loss: 494185.2017 - val_mean_squared_error: 494185.2017\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 228290.6565 - mean_squared_error: 228290.6565 - val_loss: 493825.1242 - val_mean_squared_error: 493825.1242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 228090.9057 - mean_squared_error: 228090.9057 - val_loss: 493476.1334 - val_mean_squared_error: 493476.1334\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 227897.6454 - mean_squared_error: 227897.6454 - val_loss: 493118.0653 - val_mean_squared_error: 493118.0653\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 227698.5773 - mean_squared_error: 227698.5773 - val_loss: 492765.4986 - val_mean_squared_error: 492765.4986\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 227504.3152 - mean_squared_error: 227504.3152 - val_loss: 492402.5237 - val_mean_squared_error: 492402.5237\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 227300.9014 - mean_squared_error: 227300.9014 - val_loss: 492061.9434 - val_mean_squared_error: 492061.9434\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 227111.9506 - mean_squared_error: 227111.9506 - val_loss: 491705.7866 - val_mean_squared_error: 491705.7866\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 226912.2206 - mean_squared_error: 226912.2206 - val_loss: 491363.3591 - val_mean_squared_error: 491363.3591\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 226718.3788 - mean_squared_error: 226718.3788 - val_loss: 491010.0215 - val_mean_squared_error: 491010.0215\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 226520.0820 - mean_squared_error: 226520.0820 - val_loss: 490668.0430 - val_mean_squared_error: 490668.0430\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 226323.8506 - mean_squared_error: 226323.8506 - val_loss: 490328.9389 - val_mean_squared_error: 490328.9389\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 226131.3203 - mean_squared_error: 226131.3203 - val_loss: 489972.7628 - val_mean_squared_error: 489972.7628\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 225935.6766 - mean_squared_error: 225935.6766 - val_loss: 489613.3647 - val_mean_squared_error: 489613.3647\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 225739.2200 - mean_squared_error: 225739.2200 - val_loss: 489259.6222 - val_mean_squared_error: 489259.6222\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 225540.4813 - mean_squared_error: 225540.4813 - val_loss: 488919.7849 - val_mean_squared_error: 488919.7849\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 225348.1571 - mean_squared_error: 225348.1571 - val_loss: 488569.4537 - val_mean_squared_error: 488569.4537\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 225153.7915 - mean_squared_error: 225153.7915 - val_loss: 488218.9925 - val_mean_squared_error: 488218.9925\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 224958.5999 - mean_squared_error: 224958.5999 - val_loss: 487876.3828 - val_mean_squared_error: 487876.3828\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 224763.4027 - mean_squared_error: 224763.4027 - val_loss: 487539.6412 - val_mean_squared_error: 487539.6412\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 224571.4009 - mean_squared_error: 224571.4009 - val_loss: 487189.8309 - val_mean_squared_error: 487189.8309\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 224376.9086 - mean_squared_error: 224376.9086 - val_loss: 486829.6030 - val_mean_squared_error: 486829.6030\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 224181.5360 - mean_squared_error: 224181.5360 - val_loss: 486474.7748 - val_mean_squared_error: 486474.7748\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 223984.5220 - mean_squared_error: 223984.5220 - val_loss: 486128.7182 - val_mean_squared_error: 486128.7182\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 223788.2592 - mean_squared_error: 223788.2592 - val_loss: 485780.3225 - val_mean_squared_error: 485780.3225\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 223594.1742 - mean_squared_error: 223594.1742 - val_loss: 485432.2081 - val_mean_squared_error: 485432.2081\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 223399.2819 - mean_squared_error: 223399.2819 - val_loss: 485086.9099 - val_mean_squared_error: 485086.9099\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 223208.9172 - mean_squared_error: 223208.9172 - val_loss: 484736.1900 - val_mean_squared_error: 484736.1900\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 223011.6237 - mean_squared_error: 223011.6237 - val_loss: 484398.7497 - val_mean_squared_error: 484398.7497\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 222817.7569 - mean_squared_error: 222817.7569 - val_loss: 484057.6376 - val_mean_squared_error: 484057.6376\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 222623.3280 - mean_squared_error: 222623.3280 - val_loss: 483715.7215 - val_mean_squared_error: 483715.7215\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 222432.9032 - mean_squared_error: 222432.9032 - val_loss: 483364.1537 - val_mean_squared_error: 483364.1537\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 222239.4047 - mean_squared_error: 222239.4047 - val_loss: 483013.1685 - val_mean_squared_error: 483013.1685\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 222045.3955 - mean_squared_error: 222045.3955 - val_loss: 482672.5424 - val_mean_squared_error: 482672.5424\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 221853.6388 - mean_squared_error: 221853.6388 - val_loss: 482331.9584 - val_mean_squared_error: 482331.9584\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 221662.0810 - mean_squared_error: 221662.0810 - val_loss: 481983.6236 - val_mean_squared_error: 481983.6236\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 221467.3283 - mean_squared_error: 221467.3283 - val_loss: 481637.1864 - val_mean_squared_error: 481637.1864\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 221276.5651 - mean_squared_error: 221276.5651 - val_loss: 481285.9618 - val_mean_squared_error: 481285.9618\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 221086.7113 - mean_squared_error: 221086.7113 - val_loss: 480928.8471 - val_mean_squared_error: 480928.8471\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 220889.2921 - mean_squared_error: 220889.2921 - val_loss: 480593.0198 - val_mean_squared_error: 480593.0198\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 220698.2208 - mean_squared_error: 220698.2208 - val_loss: 480251.4174 - val_mean_squared_error: 480251.4174\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 220506.3223 - mean_squared_error: 220506.3223 - val_loss: 479916.2932 - val_mean_squared_error: 479916.2932\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 220322.6612 - mean_squared_error: 220322.6612 - val_loss: 479560.2015 - val_mean_squared_error: 479560.2015\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 220126.7953 - mean_squared_error: 220126.7953 - val_loss: 479219.5594 - val_mean_squared_error: 479219.5594\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 219933.0352 - mean_squared_error: 219933.0352 - val_loss: 478884.2578 - val_mean_squared_error: 478884.2578\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 219744.4889 - mean_squared_error: 219744.4889 - val_loss: 478546.1892 - val_mean_squared_error: 478546.1892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 219556.6220 - mean_squared_error: 219556.6220 - val_loss: 478192.2737 - val_mean_squared_error: 478192.2737\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 219362.9334 - mean_squared_error: 219362.9334 - val_loss: 477849.0435 - val_mean_squared_error: 477849.0435\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 219172.5196 - mean_squared_error: 219172.5196 - val_loss: 477505.2492 - val_mean_squared_error: 477505.2492\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 218981.5701 - mean_squared_error: 218981.5701 - val_loss: 477165.9333 - val_mean_squared_error: 477165.9333\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 218790.0825 - mean_squared_error: 218790.0825 - val_loss: 476823.9975 - val_mean_squared_error: 476823.9975\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 218607.2686 - mean_squared_error: 218607.2686 - val_loss: 476462.0988 - val_mean_squared_error: 476462.0988\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 218409.9385 - mean_squared_error: 218409.9385 - val_loss: 476125.5402 - val_mean_squared_error: 476125.5402\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 218219.8871 - mean_squared_error: 218219.8871 - val_loss: 475791.5472 - val_mean_squared_error: 475791.5472\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 218032.0134 - mean_squared_error: 218032.0134 - val_loss: 475445.4805 - val_mean_squared_error: 475445.4805\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 217838.7748 - mean_squared_error: 217838.7748 - val_loss: 475112.1359 - val_mean_squared_error: 475112.1359\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 217651.0505 - mean_squared_error: 217651.0505 - val_loss: 474770.9311 - val_mean_squared_error: 474770.9311\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 217460.2061 - mean_squared_error: 217460.2061 - val_loss: 474428.7475 - val_mean_squared_error: 474428.7475\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 217274.0756 - mean_squared_error: 217274.0756 - val_loss: 474073.4953 - val_mean_squared_error: 474073.4953\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 217080.1402 - mean_squared_error: 217080.1402 - val_loss: 473730.0117 - val_mean_squared_error: 473730.0117\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 216887.9248 - mean_squared_error: 216887.9248 - val_loss: 473392.7129 - val_mean_squared_error: 473392.7129\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 216698.0280 - mean_squared_error: 216698.0280 - val_loss: 473043.7952 - val_mean_squared_error: 473043.7952\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 216506.6180 - mean_squared_error: 216506.6180 - val_loss: 472708.8094 - val_mean_squared_error: 472708.8094\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 216319.2344 - mean_squared_error: 216319.2344 - val_loss: 472366.9032 - val_mean_squared_error: 472366.9032\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 216132.3305 - mean_squared_error: 216132.3305 - val_loss: 472019.9693 - val_mean_squared_error: 472019.9693\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 215942.3847 - mean_squared_error: 215942.3847 - val_loss: 471676.1939 - val_mean_squared_error: 471676.1939\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 215750.0775 - mean_squared_error: 215750.0775 - val_loss: 471341.2762 - val_mean_squared_error: 471341.2762\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 215561.9860 - mean_squared_error: 215561.9860 - val_loss: 470992.8750 - val_mean_squared_error: 470992.8750\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 215375.2539 - mean_squared_error: 215375.2539 - val_loss: 470641.0541 - val_mean_squared_error: 470641.0541\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 215181.2770 - mean_squared_error: 215181.2770 - val_loss: 470312.6016 - val_mean_squared_error: 470312.6016\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 215002.3709 - mean_squared_error: 215002.3709 - val_loss: 469971.3368 - val_mean_squared_error: 469971.3368\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 214815.2365 - mean_squared_error: 214815.2365 - val_loss: 469630.6484 - val_mean_squared_error: 469630.6484\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 214622.1020 - mean_squared_error: 214622.1020 - val_loss: 469306.9788 - val_mean_squared_error: 469306.9788\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 214442.6486 - mean_squared_error: 214442.6486 - val_loss: 468960.5617 - val_mean_squared_error: 468960.5617\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 214251.5830 - mean_squared_error: 214251.5830 - val_loss: 468632.8198 - val_mean_squared_error: 468632.8198\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 214068.1267 - mean_squared_error: 214068.1267 - val_loss: 468290.0762 - val_mean_squared_error: 468290.0762\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 213882.6260 - mean_squared_error: 213882.6260 - val_loss: 467950.2327 - val_mean_squared_error: 467950.2327\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 213698.9140 - mean_squared_error: 213698.9140 - val_loss: 467603.0117 - val_mean_squared_error: 467603.0117\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 213504.6823 - mean_squared_error: 213504.6823 - val_loss: 467277.9682 - val_mean_squared_error: 467277.9682\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 213321.3104 - mean_squared_error: 213321.3104 - val_loss: 466943.2687 - val_mean_squared_error: 466943.2687\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 213141.9495 - mean_squared_error: 213141.9495 - val_loss: 466594.1138 - val_mean_squared_error: 466594.1138\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 212951.8651 - mean_squared_error: 212951.8651 - val_loss: 466262.0675 - val_mean_squared_error: 466262.0675\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 212767.7572 - mean_squared_error: 212767.7572 - val_loss: 465927.9132 - val_mean_squared_error: 465927.9132\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 212581.8702 - mean_squared_error: 212581.8702 - val_loss: 465598.1699 - val_mean_squared_error: 465598.1699\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 212400.5938 - mean_squared_error: 212400.5938 - val_loss: 465257.4378 - val_mean_squared_error: 465257.4378\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 212215.8905 - mean_squared_error: 212215.8905 - val_loss: 464924.8828 - val_mean_squared_error: 464924.8828\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 212030.5520 - mean_squared_error: 212030.5520 - val_loss: 464592.0248 - val_mean_squared_error: 464592.0248\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 211848.3489 - mean_squared_error: 211848.3489 - val_loss: 464258.3027 - val_mean_squared_error: 464258.3027\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 211667.5577 - mean_squared_error: 211667.5577 - val_loss: 463919.6657 - val_mean_squared_error: 463919.6657\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 211483.8509 - mean_squared_error: 211483.8509 - val_loss: 463585.0968 - val_mean_squared_error: 463585.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 211299.9223 - mean_squared_error: 211299.9223 - val_loss: 463251.0368 - val_mean_squared_error: 463251.0368\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 211112.4764 - mean_squared_error: 211112.4764 - val_loss: 462925.9249 - val_mean_squared_error: 462925.9249\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 210932.7062 - mean_squared_error: 210932.7062 - val_loss: 462592.5441 - val_mean_squared_error: 462592.5441\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 210752.4592 - mean_squared_error: 210752.4592 - val_loss: 462250.1992 - val_mean_squared_error: 462250.1992\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 210564.7127 - mean_squared_error: 210564.7127 - val_loss: 461926.5686 - val_mean_squared_error: 461926.5686\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 210385.1241 - mean_squared_error: 210385.1241 - val_loss: 461584.1613 - val_mean_squared_error: 461584.1613\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 210202.8320 - mean_squared_error: 210202.8320 - val_loss: 461248.4701 - val_mean_squared_error: 461248.4701\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 210016.0653 - mean_squared_error: 210016.0653 - val_loss: 460924.9900 - val_mean_squared_error: 460924.9900\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 209837.2872 - mean_squared_error: 209837.2872 - val_loss: 460592.9830 - val_mean_squared_error: 460592.9830\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 209655.1678 - mean_squared_error: 209655.1678 - val_loss: 460262.2921 - val_mean_squared_error: 460262.2921\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 209476.3778 - mean_squared_error: 209476.3778 - val_loss: 459926.5089 - val_mean_squared_error: 459926.5089\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 209294.1637 - mean_squared_error: 209294.1637 - val_loss: 459595.8421 - val_mean_squared_error: 459595.8421\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 209112.0416 - mean_squared_error: 209112.0416 - val_loss: 459265.7425 - val_mean_squared_error: 459265.7425\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 208928.1280 - mean_squared_error: 208928.1280 - val_loss: 458942.9802 - val_mean_squared_error: 458942.9802\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 208750.6319 - mean_squared_error: 208750.6319 - val_loss: 458605.9690 - val_mean_squared_error: 458605.9690\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 208570.5663 - mean_squared_error: 208570.5663 - val_loss: 458270.6345 - val_mean_squared_error: 458270.6345\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 208384.2728 - mean_squared_error: 208384.2728 - val_loss: 457952.9528 - val_mean_squared_error: 457952.9528\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 208208.4204 - mean_squared_error: 208208.4204 - val_loss: 457618.2480 - val_mean_squared_error: 457618.2480\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 208025.6475 - mean_squared_error: 208025.6475 - val_loss: 457299.0455 - val_mean_squared_error: 457299.0455\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 207852.0513 - mean_squared_error: 207852.0513 - val_loss: 456949.0873 - val_mean_squared_error: 456949.0873\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 207662.0312 - mean_squared_error: 207662.0312 - val_loss: 456627.1030 - val_mean_squared_error: 456627.1030\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 207482.5047 - mean_squared_error: 207482.5047 - val_loss: 456293.7324 - val_mean_squared_error: 456293.7324\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 207302.0556 - mean_squared_error: 207302.0556 - val_loss: 455964.7282 - val_mean_squared_error: 455964.7282\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 207121.2172 - mean_squared_error: 207121.2172 - val_loss: 455631.4643 - val_mean_squared_error: 455631.4643\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 206939.9860 - mean_squared_error: 206939.9860 - val_loss: 455301.6992 - val_mean_squared_error: 455301.6992\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 206761.1798 - mean_squared_error: 206761.1798 - val_loss: 454973.9400 - val_mean_squared_error: 454973.9400\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 206580.7478 - mean_squared_error: 206580.7478 - val_loss: 454651.0678 - val_mean_squared_error: 454651.0678\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 206405.7942 - mean_squared_error: 206405.7942 - val_loss: 454314.6724 - val_mean_squared_error: 454314.6724\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 206226.2178 - mean_squared_error: 206226.2178 - val_loss: 453977.0675 - val_mean_squared_error: 453977.0675\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 170us/step - loss: 206042.9487 - mean_squared_error: 206042.9487 - val_loss: 453656.5681 - val_mean_squared_error: 453656.5681\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 205866.4982 - mean_squared_error: 205866.4982 - val_loss: 453330.1454 - val_mean_squared_error: 453330.1454\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 205685.7586 - mean_squared_error: 205685.7586 - val_loss: 453008.9065 - val_mean_squared_error: 453008.9065\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 150us/step - loss: 205513.1496 - mean_squared_error: 205513.1496 - val_loss: 452668.6571 - val_mean_squared_error: 452668.6571\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 205330.4878 - mean_squared_error: 205330.4878 - val_loss: 452343.1370 - val_mean_squared_error: 452343.1370\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 205149.5835 - mean_squared_error: 205149.5835 - val_loss: 452023.3443 - val_mean_squared_error: 452023.3443\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 204971.5113 - mean_squared_error: 204971.5113 - val_loss: 451694.8401 - val_mean_squared_error: 451694.8401\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 204795.8624 - mean_squared_error: 204795.8624 - val_loss: 451357.8711 - val_mean_squared_error: 451357.8711\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 160us/step - loss: 204615.2467 - mean_squared_error: 204615.2467 - val_loss: 451030.4007 - val_mean_squared_error: 451030.4007\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 204434.0165 - mean_squared_error: 204434.0165 - val_loss: 450707.5340 - val_mean_squared_error: 450707.5340\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 204260.4980 - mean_squared_error: 204260.4980 - val_loss: 450370.7037 - val_mean_squared_error: 450370.7037\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 204078.3953 - mean_squared_error: 204078.3953 - val_loss: 450053.7620 - val_mean_squared_error: 450053.7620\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 203905.9547 - mean_squared_error: 203905.9547 - val_loss: 449717.7288 - val_mean_squared_error: 449717.7288\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 203723.3734 - mean_squared_error: 203723.3734 - val_loss: 449390.5187 - val_mean_squared_error: 449390.5187\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 203543.5989 - mean_squared_error: 203543.5989 - val_loss: 449069.9534 - val_mean_squared_error: 449069.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 203366.6245 - mean_squared_error: 203366.6245 - val_loss: 448744.2860 - val_mean_squared_error: 448744.2860\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 203190.5667 - mean_squared_error: 203190.5667 - val_loss: 448413.9414 - val_mean_squared_error: 448413.9414\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 203012.9291 - mean_squared_error: 203012.9291 - val_loss: 448076.4325 - val_mean_squared_error: 448076.4325\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 202834.2752 - mean_squared_error: 202834.2752 - val_loss: 447747.8728 - val_mean_squared_error: 447747.8728\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 202654.4405 - mean_squared_error: 202654.4405 - val_loss: 447423.6465 - val_mean_squared_error: 447423.6465\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 202479.7298 - mean_squared_error: 202479.7298 - val_loss: 447102.6057 - val_mean_squared_error: 447102.6057\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 202304.0231 - mean_squared_error: 202304.0231 - val_loss: 446772.4330 - val_mean_squared_error: 446772.4330\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 202126.6683 - mean_squared_error: 202126.6683 - val_loss: 446449.8072 - val_mean_squared_error: 446449.8072\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 201950.2837 - mean_squared_error: 201950.2837 - val_loss: 446118.0022 - val_mean_squared_error: 446118.0022\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 201768.9758 - mean_squared_error: 201768.9758 - val_loss: 445797.2324 - val_mean_squared_error: 445797.2324\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 201595.2851 - mean_squared_error: 201595.2851 - val_loss: 445463.3940 - val_mean_squared_error: 445463.3940\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 201416.4500 - mean_squared_error: 201416.4500 - val_loss: 445144.5103 - val_mean_squared_error: 445144.5103\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 201244.5292 - mean_squared_error: 201244.5292 - val_loss: 444817.2492 - val_mean_squared_error: 444817.2492\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 201067.4223 - mean_squared_error: 201067.4223 - val_loss: 444498.6328 - val_mean_squared_error: 444498.6328\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 200896.6784 - mean_squared_error: 200896.6784 - val_loss: 444172.0951 - val_mean_squared_error: 444172.0951\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 200721.6850 - mean_squared_error: 200721.6850 - val_loss: 443849.6574 - val_mean_squared_error: 443849.6574\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 200543.5398 - mean_squared_error: 200543.5398 - val_loss: 443528.2893 - val_mean_squared_error: 443528.2893\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 152us/step - loss: 200370.9794 - mean_squared_error: 200370.9794 - val_loss: 443205.1992 - val_mean_squared_error: 443205.1992\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 200199.5798 - mean_squared_error: 200199.5798 - val_loss: 442877.8128 - val_mean_squared_error: 442877.8128\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 200025.5909 - mean_squared_error: 200025.5909 - val_loss: 442553.5686 - val_mean_squared_error: 442553.5686\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 199850.3183 - mean_squared_error: 199850.3183 - val_loss: 442235.8970 - val_mean_squared_error: 442235.8970\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 199679.8605 - mean_squared_error: 199679.8605 - val_loss: 441913.7341 - val_mean_squared_error: 441913.7341\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 199502.8423 - mean_squared_error: 199502.8423 - val_loss: 441603.6306 - val_mean_squared_error: 441603.6306\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 156us/step - loss: 199336.9069 - mean_squared_error: 199336.9069 - val_loss: 441272.3619 - val_mean_squared_error: 441272.3619\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 146us/step - loss: 199158.8591 - mean_squared_error: 199158.8591 - val_loss: 440953.4305 - val_mean_squared_error: 440953.4305\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 149us/step - loss: 198984.2973 - mean_squared_error: 198984.2973 - val_loss: 440643.1398 - val_mean_squared_error: 440643.1398\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 151us/step - loss: 198818.4313 - mean_squared_error: 198818.4313 - val_loss: 440305.2645 - val_mean_squared_error: 440305.2645\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 147us/step - loss: 198640.5844 - mean_squared_error: 198640.5844 - val_loss: 439988.5580 - val_mean_squared_error: 439988.5580\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 145us/step - loss: 198467.6606 - mean_squared_error: 198467.6606 - val_loss: 439678.7427 - val_mean_squared_error: 439678.7427\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 198298.7727 - mean_squared_error: 198298.7727 - val_loss: 439360.0645 - val_mean_squared_error: 439360.0645\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 198127.8297 - mean_squared_error: 198127.8297 - val_loss: 439037.4065 - val_mean_squared_error: 439037.4065\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 153us/step - loss: 197956.6975 - mean_squared_error: 197956.6975 - val_loss: 438721.9283 - val_mean_squared_error: 438721.9283\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 197789.5910 - mean_squared_error: 197789.5910 - val_loss: 438395.4674 - val_mean_squared_error: 438395.4674\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 197609.6970 - mean_squared_error: 197609.6970 - val_loss: 438088.9696 - val_mean_squared_error: 438088.9696\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 197444.7945 - mean_squared_error: 197444.7945 - val_loss: 437761.0209 - val_mean_squared_error: 437761.0209\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 197272.9519 - mean_squared_error: 197272.9519 - val_loss: 437433.9448 - val_mean_squared_error: 437433.9448\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 197097.7682 - mean_squared_error: 197097.7682 - val_loss: 437120.5181 - val_mean_squared_error: 437120.5181\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 196929.2760 - mean_squared_error: 196929.2760 - val_loss: 436801.9065 - val_mean_squared_error: 436801.9065\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 164us/step - loss: 196761.9725 - mean_squared_error: 196761.9725 - val_loss: 436485.8457 - val_mean_squared_error: 436485.8457\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 196587.9502 - mean_squared_error: 196587.9502 - val_loss: 436169.6903 - val_mean_squared_error: 436169.6903\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 196416.9190 - mean_squared_error: 196416.9190 - val_loss: 435852.3156 - val_mean_squared_error: 435852.3156\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 196246.8524 - mean_squared_error: 196246.8524 - val_loss: 435533.3323 - val_mean_squared_error: 435533.3323\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 196078.9503 - mean_squared_error: 196078.9503 - val_loss: 435203.4830 - val_mean_squared_error: 435203.4830\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 195906.7252 - mean_squared_error: 195906.7252 - val_loss: 434885.1970 - val_mean_squared_error: 434885.1970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 195736.8661 - mean_squared_error: 195736.8661 - val_loss: 434576.7221 - val_mean_squared_error: 434576.7221\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 195567.2555 - mean_squared_error: 195567.2555 - val_loss: 434262.5700 - val_mean_squared_error: 434262.5700\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 195399.2620 - mean_squared_error: 195399.2620 - val_loss: 433941.1434 - val_mean_squared_error: 433941.1434\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 195227.8895 - mean_squared_error: 195227.8895 - val_loss: 433631.4534 - val_mean_squared_error: 433631.4534\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 195056.6850 - mean_squared_error: 195056.6850 - val_loss: 433326.9369 - val_mean_squared_error: 433326.9369\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 194894.4356 - mean_squared_error: 194894.4356 - val_loss: 432989.8689 - val_mean_squared_error: 432989.8689\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 194720.3608 - mean_squared_error: 194720.3608 - val_loss: 432676.7140 - val_mean_squared_error: 432676.7140\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 194552.3441 - mean_squared_error: 194552.3441 - val_loss: 432360.2079 - val_mean_squared_error: 432360.2079\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 194381.6015 - mean_squared_error: 194381.6015 - val_loss: 432048.9634 - val_mean_squared_error: 432048.9634\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 194215.2059 - mean_squared_error: 194215.2059 - val_loss: 431727.3937 - val_mean_squared_error: 431727.3937\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 194046.9671 - mean_squared_error: 194046.9671 - val_loss: 431400.1339 - val_mean_squared_error: 431400.1339\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 193874.5706 - mean_squared_error: 193874.5706 - val_loss: 431088.0243 - val_mean_squared_error: 431088.0243\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 193706.5672 - mean_squared_error: 193706.5672 - val_loss: 430768.7972 - val_mean_squared_error: 430768.7972\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 193539.9519 - mean_squared_error: 193539.9519 - val_loss: 430453.3577 - val_mean_squared_error: 430453.3577\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 193369.7171 - mean_squared_error: 193369.7171 - val_loss: 430140.2146 - val_mean_squared_error: 430140.2146\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 193204.0510 - mean_squared_error: 193204.0510 - val_loss: 429823.7215 - val_mean_squared_error: 429823.7215\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 193037.2136 - mean_squared_error: 193037.2136 - val_loss: 429515.4358 - val_mean_squared_error: 429515.4358\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 192869.8242 - mean_squared_error: 192869.8242 - val_loss: 429210.3404 - val_mean_squared_error: 429210.3404\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 192709.0641 - mean_squared_error: 192709.0641 - val_loss: 428892.0539 - val_mean_squared_error: 428892.0539\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 192539.4406 - mean_squared_error: 192539.4406 - val_loss: 428583.3485 - val_mean_squared_error: 428583.3485\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 189us/step - loss: 192373.4228 - mean_squared_error: 192373.4228 - val_loss: 428270.3761 - val_mean_squared_error: 428270.3761\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 192202.6115 - mean_squared_error: 192202.6115 - val_loss: 427959.3518 - val_mean_squared_error: 427959.3518\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 192039.4273 - mean_squared_error: 192039.4273 - val_loss: 427637.7623 - val_mean_squared_error: 427637.7623\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 191875.4418 - mean_squared_error: 191875.4418 - val_loss: 427315.2430 - val_mean_squared_error: 427315.2430\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 191702.5232 - mean_squared_error: 191702.5232 - val_loss: 427014.0374 - val_mean_squared_error: 427014.0374\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 191538.9856 - mean_squared_error: 191538.9856 - val_loss: 426700.1501 - val_mean_squared_error: 426700.1501\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 172us/step - loss: 191374.7185 - mean_squared_error: 191374.7185 - val_loss: 426384.8064 - val_mean_squared_error: 426384.8064\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 191207.0265 - mean_squared_error: 191207.0265 - val_loss: 426078.1370 - val_mean_squared_error: 426078.1370\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 191041.5933 - mean_squared_error: 191041.5933 - val_loss: 425758.9900 - val_mean_squared_error: 425758.9900\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 190874.0521 - mean_squared_error: 190874.0521 - val_loss: 425451.8560 - val_mean_squared_error: 425451.8560\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 190709.4858 - mean_squared_error: 190709.4858 - val_loss: 425132.2771 - val_mean_squared_error: 425132.2771\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 176us/step - loss: 190545.0015 - mean_squared_error: 190545.0015 - val_loss: 424816.1069 - val_mean_squared_error: 424816.1069\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 190382.5229 - mean_squared_error: 190382.5229 - val_loss: 424505.1002 - val_mean_squared_error: 424505.1002\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 190213.4457 - mean_squared_error: 190213.4457 - val_loss: 424205.7059 - val_mean_squared_error: 424205.7059\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 190051.7418 - mean_squared_error: 190051.7418 - val_loss: 423900.1219 - val_mean_squared_error: 423900.1219\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 189892.4695 - mean_squared_error: 189892.4695 - val_loss: 423587.1987 - val_mean_squared_error: 423587.1987\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 184us/step - loss: 189726.2309 - mean_squared_error: 189726.2309 - val_loss: 423273.3008 - val_mean_squared_error: 423273.3008\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 189556.8744 - mean_squared_error: 189556.8744 - val_loss: 422968.8449 - val_mean_squared_error: 422968.8449\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 189395.2542 - mean_squared_error: 189395.2542 - val_loss: 422658.4266 - val_mean_squared_error: 422658.4266\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 189231.3889 - mean_squared_error: 189231.3889 - val_loss: 422343.7740 - val_mean_squared_error: 422343.7740\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 189065.0110 - mean_squared_error: 189065.0110 - val_loss: 422030.9406 - val_mean_squared_error: 422030.9406\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 188897.5630 - mean_squared_error: 188897.5630 - val_loss: 421724.0583 - val_mean_squared_error: 421724.0583\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 182us/step - loss: 188733.7180 - mean_squared_error: 188733.7180 - val_loss: 421408.0126 - val_mean_squared_error: 421408.0126\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 188569.0508 - mean_squared_error: 188569.0508 - val_loss: 421089.4308 - val_mean_squared_error: 421089.4308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 188400.4309 - mean_squared_error: 188400.4309 - val_loss: 420789.5441 - val_mean_squared_error: 420789.5441\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 188242.7708 - mean_squared_error: 188242.7708 - val_loss: 420480.5991 - val_mean_squared_error: 420480.5991\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 188081.1198 - mean_squared_error: 188081.1198 - val_loss: 420160.0605 - val_mean_squared_error: 420160.0605\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 187908.2120 - mean_squared_error: 187908.2120 - val_loss: 419861.0519 - val_mean_squared_error: 419861.0519\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 187753.0336 - mean_squared_error: 187753.0336 - val_loss: 419536.6886 - val_mean_squared_error: 419536.6886\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 187589.5858 - mean_squared_error: 187589.5858 - val_loss: 419226.4266 - val_mean_squared_error: 419226.4266\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 187424.0284 - mean_squared_error: 187424.0284 - val_loss: 418929.5430 - val_mean_squared_error: 418929.5430\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 187264.5362 - mean_squared_error: 187264.5362 - val_loss: 418622.8917 - val_mean_squared_error: 418622.8917\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 187103.2532 - mean_squared_error: 187103.2532 - val_loss: 418322.2670 - val_mean_squared_error: 418322.2670\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 186945.7055 - mean_squared_error: 186945.7055 - val_loss: 418012.1057 - val_mean_squared_error: 418012.1057\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 158us/step - loss: 186778.5548 - mean_squared_error: 186778.5548 - val_loss: 417712.2296 - val_mean_squared_error: 417712.2296\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 186619.5322 - mean_squared_error: 186619.5322 - val_loss: 417402.6735 - val_mean_squared_error: 417402.6735\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 155us/step - loss: 186454.9710 - mean_squared_error: 186454.9710 - val_loss: 417106.4411 - val_mean_squared_error: 417106.4411\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 154us/step - loss: 186295.9731 - mean_squared_error: 186295.9731 - val_loss: 416789.4933 - val_mean_squared_error: 416789.4933\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 186140.7874 - mean_squared_error: 186140.7874 - val_loss: 416467.7369 - val_mean_squared_error: 416467.7369\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 185968.1667 - mean_squared_error: 185968.1667 - val_loss: 416181.2260 - val_mean_squared_error: 416181.2260\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 185812.2271 - mean_squared_error: 185812.2271 - val_loss: 415870.1155 - val_mean_squared_error: 415870.1155\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 185648.3120 - mean_squared_error: 185648.3120 - val_loss: 415568.4724 - val_mean_squared_error: 415568.4724\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 185491.5232 - mean_squared_error: 185491.5232 - val_loss: 415256.1175 - val_mean_squared_error: 415256.1175\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 185329.6855 - mean_squared_error: 185329.6855 - val_loss: 414954.0413 - val_mean_squared_error: 414954.0413\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 185169.1529 - mean_squared_error: 185169.1529 - val_loss: 414649.7991 - val_mean_squared_error: 414649.7991\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 185005.9219 - mean_squared_error: 185005.9219 - val_loss: 414349.2257 - val_mean_squared_error: 414349.2257\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b23db6d400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b235320710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее+, добавили слой, два сигмоида, уменьшаем кол-во эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 306546.2088 - mean_squared_error: 306546.2088 - val_loss: 629215.0474 - val_mean_squared_error: 629215.0474\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 145us/step - loss: 305873.2714 - mean_squared_error: 305873.2714 - val_loss: 628033.6323 - val_mean_squared_error: 628033.6323\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 146us/step - loss: 305151.0470 - mean_squared_error: 305151.0470 - val_loss: 626791.1049 - val_mean_squared_error: 626791.1049\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 304393.1219 - mean_squared_error: 304393.1219 - val_loss: 625547.6177 - val_mean_squared_error: 625547.6177\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 147us/step - loss: 303642.5106 - mean_squared_error: 303642.5106 - val_loss: 624293.1613 - val_mean_squared_error: 624293.1613\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 302884.6453 - mean_squared_error: 302884.6453 - val_loss: 623056.6602 - val_mean_squared_error: 623056.6602\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 302157.8651 - mean_squared_error: 302157.8651 - val_loss: 621821.4157 - val_mean_squared_error: 621821.4157\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 301429.6522 - mean_squared_error: 301429.6522 - val_loss: 620651.8650 - val_mean_squared_error: 620651.8650\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 300725.9170 - mean_squared_error: 300725.9170 - val_loss: 619528.9180 - val_mean_squared_error: 619528.9180\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 300069.3812 - mean_squared_error: 300069.3812 - val_loss: 618434.0195 - val_mean_squared_error: 618434.0195\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 299432.1027 - mean_squared_error: 299432.1027 - val_loss: 617391.4816 - val_mean_squared_error: 617391.4816\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 361us/step - loss: 298812.3270 - mean_squared_error: 298812.3270 - val_loss: 616417.2154 - val_mean_squared_error: 616417.2154\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 266us/step - loss: 298245.0622 - mean_squared_error: 298245.0622 - val_loss: 615466.8041 - val_mean_squared_error: 615466.8041\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 244us/step - loss: 297694.6408 - mean_squared_error: 297694.6408 - val_loss: 614579.1992 - val_mean_squared_error: 614579.1992\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 232us/step - loss: 297174.2828 - mean_squared_error: 297174.2828 - val_loss: 613750.1507 - val_mean_squared_error: 613750.1507\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 248us/step - loss: 296692.6270 - mean_squared_error: 296692.6270 - val_loss: 612955.6914 - val_mean_squared_error: 612955.6914\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 224us/step - loss: 296230.6622 - mean_squared_error: 296230.6622 - val_loss: 612200.5061 - val_mean_squared_error: 612200.5061\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 221us/step - loss: 295789.8806 - mean_squared_error: 295789.8806 - val_loss: 611472.7779 - val_mean_squared_error: 611472.7779\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 198us/step - loss: 295363.5264 - mean_squared_error: 295363.5264 - val_loss: 610777.0698 - val_mean_squared_error: 610777.0698\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 202us/step - loss: 294960.2213 - mean_squared_error: 294960.2213 - val_loss: 610095.9213 - val_mean_squared_error: 610095.9213\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 224us/step - loss: 294563.7463 - mean_squared_error: 294563.7463 - val_loss: 609441.3019 - val_mean_squared_error: 609441.3019\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 214us/step - loss: 294183.7651 - mean_squared_error: 294183.7651 - val_loss: 608809.9810 - val_mean_squared_error: 608809.9810\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 293815.8917 - mean_squared_error: 293815.8917 - val_loss: 608200.3566 - val_mean_squared_error: 608200.3566\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 200us/step - loss: 293456.9317 - mean_squared_error: 293456.9317 - val_loss: 607601.7182 - val_mean_squared_error: 607601.7182\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 206us/step - loss: 293105.0159 - mean_squared_error: 293105.0159 - val_loss: 607006.5837 - val_mean_squared_error: 607006.5837\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 204us/step - loss: 292760.4730 - mean_squared_error: 292760.4730 - val_loss: 606417.0056 - val_mean_squared_error: 606417.0056\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 211us/step - loss: 292419.8280 - mean_squared_error: 292419.8280 - val_loss: 605845.7031 - val_mean_squared_error: 605845.7031\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 217us/step - loss: 292084.6997 - mean_squared_error: 292084.6997 - val_loss: 605285.3789 - val_mean_squared_error: 605285.3789\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 212us/step - loss: 291758.3461 - mean_squared_error: 291758.3461 - val_loss: 604723.4844 - val_mean_squared_error: 604723.4844\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 278us/step - loss: 291433.6024 - mean_squared_error: 291433.6024 - val_loss: 604170.3912 - val_mean_squared_error: 604170.3912\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 206us/step - loss: 291108.3952 - mean_squared_error: 291108.3952 - val_loss: 603625.5346 - val_mean_squared_error: 603625.5346\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 214us/step - loss: 290790.1675 - mean_squared_error: 290790.1675 - val_loss: 603081.2104 - val_mean_squared_error: 603081.2104\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 198us/step - loss: 290475.4342 - mean_squared_error: 290475.4342 - val_loss: 602546.4163 - val_mean_squared_error: 602546.4163\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 196us/step - loss: 290161.1014 - mean_squared_error: 290161.1014 - val_loss: 602021.2193 - val_mean_squared_error: 602021.2193\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 289851.9546 - mean_squared_error: 289851.9546 - val_loss: 601490.8761 - val_mean_squared_error: 601490.8761\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 289543.7750 - mean_squared_error: 289543.7750 - val_loss: 600966.5435 - val_mean_squared_error: 600966.5435\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 289240.4845 - mean_squared_error: 289240.4845 - val_loss: 600451.8683 - val_mean_squared_error: 600451.8683\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 288942.9331 - mean_squared_error: 288942.9331 - val_loss: 599944.1730 - val_mean_squared_error: 599944.1730\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 288651.2882 - mean_squared_error: 288651.2882 - val_loss: 599436.5374 - val_mean_squared_error: 599436.5374\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 288356.0095 - mean_squared_error: 288356.0095 - val_loss: 598944.9609 - val_mean_squared_error: 598944.9609\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 288068.9091 - mean_squared_error: 288068.9091 - val_loss: 598450.7260 - val_mean_squared_error: 598450.7260\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 287779.7495 - mean_squared_error: 287779.7495 - val_loss: 597963.2667 - val_mean_squared_error: 597963.2667\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 287494.1506 - mean_squared_error: 287494.1506 - val_loss: 597468.7372 - val_mean_squared_error: 597468.7372\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 287204.8981 - mean_squared_error: 287204.8981 - val_loss: 596980.0513 - val_mean_squared_error: 596980.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 286925.5009 - mean_squared_error: 286925.5009 - val_loss: 596478.6942 - val_mean_squared_error: 596478.6942\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 286633.8992 - mean_squared_error: 286633.8992 - val_loss: 596003.1244 - val_mean_squared_error: 596003.1244\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 286356.1247 - mean_squared_error: 286356.1247 - val_loss: 595514.8253 - val_mean_squared_error: 595514.8253\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 286070.0372 - mean_squared_error: 286070.0372 - val_loss: 595032.9464 - val_mean_squared_error: 595032.9464\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 285789.2752 - mean_squared_error: 285789.2752 - val_loss: 594537.1579 - val_mean_squared_error: 594537.1579\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 285501.0812 - mean_squared_error: 285501.0812 - val_loss: 594045.1964 - val_mean_squared_error: 594045.1964\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 285214.3978 - mean_squared_error: 285214.3978 - val_loss: 593549.6311 - val_mean_squared_error: 593549.6311\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 284926.9688 - mean_squared_error: 284926.9688 - val_loss: 593056.2818 - val_mean_squared_error: 593056.2818\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 284642.6838 - mean_squared_error: 284642.6838 - val_loss: 592566.5073 - val_mean_squared_error: 592566.5073\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 284358.9581 - mean_squared_error: 284358.9581 - val_loss: 592086.6903 - val_mean_squared_error: 592086.6903\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 284078.2109 - mean_squared_error: 284078.2109 - val_loss: 591609.7065 - val_mean_squared_error: 591609.7065\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 283802.6277 - mean_squared_error: 283802.6277 - val_loss: 591126.0675 - val_mean_squared_error: 591126.0675\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 283528.4675 - mean_squared_error: 283528.4675 - val_loss: 590639.6445 - val_mean_squared_error: 590639.6445\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 283246.5150 - mean_squared_error: 283246.5150 - val_loss: 590167.2857 - val_mean_squared_error: 590167.2857\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 282971.1130 - mean_squared_error: 282971.1130 - val_loss: 589702.4342 - val_mean_squared_error: 589702.4342\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 282704.8977 - mean_squared_error: 282704.8977 - val_loss: 589226.2751 - val_mean_squared_error: 589226.2751\n",
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 282428.0553 - mean_squared_error: 282428.0553 - val_loss: 588758.1780 - val_mean_squared_error: 588758.1780\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 282154.0284 - mean_squared_error: 282154.0284 - val_loss: 588280.7511 - val_mean_squared_error: 588280.7511\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 281877.2888 - mean_squared_error: 281877.2888 - val_loss: 587803.5485 - val_mean_squared_error: 587803.5485\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 281602.8477 - mean_squared_error: 281602.8477 - val_loss: 587331.4777 - val_mean_squared_error: 587331.4777\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 281328.1027 - mean_squared_error: 281328.1027 - val_loss: 586863.5100 - val_mean_squared_error: 586863.5100\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 281060.5557 - mean_squared_error: 281060.5557 - val_loss: 586386.8850 - val_mean_squared_error: 586386.8850\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 280784.5234 - mean_squared_error: 280784.5234 - val_loss: 585928.9581 - val_mean_squared_error: 585928.9581\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 280518.4397 - mean_squared_error: 280518.4397 - val_loss: 585460.7461 - val_mean_squared_error: 585460.7461\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 280249.4848 - mean_squared_error: 280249.4848 - val_loss: 584998.1752 - val_mean_squared_error: 584998.1752\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 279984.2930 - mean_squared_error: 279984.2930 - val_loss: 584533.1819 - val_mean_squared_error: 584533.1819\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 279715.9451 - mean_squared_error: 279715.9451 - val_loss: 584075.1948 - val_mean_squared_error: 584075.1948\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 279451.6780 - mean_squared_error: 279451.6780 - val_loss: 583606.3906 - val_mean_squared_error: 583606.3906\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 279185.8295 - mean_squared_error: 279185.8295 - val_loss: 583133.9319 - val_mean_squared_error: 583133.9319\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 278909.9959 - mean_squared_error: 278909.9959 - val_loss: 582685.0737 - val_mean_squared_error: 582685.0737\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 278646.9485 - mean_squared_error: 278646.9485 - val_loss: 582219.1412 - val_mean_squared_error: 582219.1412\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 278383.0287 - mean_squared_error: 278383.0287 - val_loss: 581752.3683 - val_mean_squared_error: 581752.3683\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 278116.5616 - mean_squared_error: 278116.5616 - val_loss: 581295.3449 - val_mean_squared_error: 581295.3449\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 277854.7459 - mean_squared_error: 277854.7459 - val_loss: 580831.1194 - val_mean_squared_error: 580831.1194\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 277588.9005 - mean_squared_error: 277588.9005 - val_loss: 580377.6066 - val_mean_squared_error: 580377.6066\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 277328.6661 - mean_squared_error: 277328.6661 - val_loss: 579921.1027 - val_mean_squared_error: 579921.1027\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 277067.4192 - mean_squared_error: 277067.4192 - val_loss: 579472.1507 - val_mean_squared_error: 579472.1507\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 276809.5839 - mean_squared_error: 276809.5839 - val_loss: 579019.3203 - val_mean_squared_error: 579019.3203\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 276551.1188 - mean_squared_error: 276551.1188 - val_loss: 578573.1066 - val_mean_squared_error: 578573.1066\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 276292.5419 - mean_squared_error: 276292.5419 - val_loss: 578132.5541 - val_mean_squared_error: 578132.5541\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 276038.8179 - mean_squared_error: 276038.8179 - val_loss: 577677.9090 - val_mean_squared_error: 577677.9090\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 275778.7222 - mean_squared_error: 275778.7222 - val_loss: 577229.2494 - val_mean_squared_error: 577229.2494\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 275521.5031 - mean_squared_error: 275521.5031 - val_loss: 576783.4810 - val_mean_squared_error: 576783.4810\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 275265.3070 - mean_squared_error: 275265.3070 - val_loss: 576337.5558 - val_mean_squared_error: 576337.5558\n",
      "Epoch 89/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 161us/step - loss: 275015.0486 - mean_squared_error: 275015.0486 - val_loss: 575889.0882 - val_mean_squared_error: 575889.0882\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 274758.5947 - mean_squared_error: 274758.5947 - val_loss: 575460.8398 - val_mean_squared_error: 575460.8398\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 274511.5361 - mean_squared_error: 274511.5361 - val_loss: 575022.8203 - val_mean_squared_error: 575022.8203\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 274260.8093 - mean_squared_error: 274260.8093 - val_loss: 574585.1507 - val_mean_squared_error: 574585.1507\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 274010.3019 - mean_squared_error: 274010.3019 - val_loss: 574154.5910 - val_mean_squared_error: 574154.5910\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 273763.8557 - mean_squared_error: 273763.8557 - val_loss: 573715.6362 - val_mean_squared_error: 573715.6362\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 273517.4156 - mean_squared_error: 273517.4156 - val_loss: 573275.7517 - val_mean_squared_error: 573275.7517\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 273265.4756 - mean_squared_error: 273265.4756 - val_loss: 572848.7506 - val_mean_squared_error: 572848.7506\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 273019.1952 - mean_squared_error: 273019.1952 - val_loss: 572415.3259 - val_mean_squared_error: 572415.3259\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 272771.1611 - mean_squared_error: 272771.1611 - val_loss: 571973.8683 - val_mean_squared_error: 571973.8683\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 272518.5333 - mean_squared_error: 272518.5333 - val_loss: 571538.1942 - val_mean_squared_error: 571538.1942\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 272264.6059 - mean_squared_error: 272264.6059 - val_loss: 571113.4520 - val_mean_squared_error: 571113.4520\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 272020.8039 - mean_squared_error: 272020.8039 - val_loss: 570669.8482 - val_mean_squared_error: 570669.8482\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 271771.5187 - mean_squared_error: 271771.5187 - val_loss: 570230.7154 - val_mean_squared_error: 570230.7154\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 271523.0022 - mean_squared_error: 271523.0022 - val_loss: 569798.4381 - val_mean_squared_error: 569798.4381\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 271272.3872 - mean_squared_error: 271272.3872 - val_loss: 569371.7383 - val_mean_squared_error: 569371.7383\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 271030.9437 - mean_squared_error: 271030.9437 - val_loss: 568938.9643 - val_mean_squared_error: 568938.9643\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 270785.3392 - mean_squared_error: 270785.3392 - val_loss: 568511.6032 - val_mean_squared_error: 568511.6032\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 270540.0102 - mean_squared_error: 270540.0102 - val_loss: 568073.7545 - val_mean_squared_error: 568073.7545\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 270288.5622 - mean_squared_error: 270288.5622 - val_loss: 567639.5173 - val_mean_squared_error: 567639.5173\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 270040.9300 - mean_squared_error: 270040.9300 - val_loss: 567205.1998 - val_mean_squared_error: 567205.1998\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 269793.0244 - mean_squared_error: 269793.0244 - val_loss: 566775.5552 - val_mean_squared_error: 566775.5552\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 269549.1633 - mean_squared_error: 269549.1633 - val_loss: 566354.8499 - val_mean_squared_error: 566354.8499\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 269307.6792 - mean_squared_error: 269307.6792 - val_loss: 565928.6323 - val_mean_squared_error: 565928.6323\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 269063.3275 - mean_squared_error: 269063.3275 - val_loss: 565516.2913 - val_mean_squared_error: 565516.2913\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 268830.8922 - mean_squared_error: 268830.8922 - val_loss: 565086.0619 - val_mean_squared_error: 565086.0619\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 268588.5241 - mean_squared_error: 268588.5241 - val_loss: 564668.2612 - val_mean_squared_error: 564668.2612\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 268347.8701 - mean_squared_error: 268347.8701 - val_loss: 564254.0592 - val_mean_squared_error: 564254.0592\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 268108.8577 - mean_squared_error: 268108.8577 - val_loss: 563836.8080 - val_mean_squared_error: 563836.8080\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 267871.3287 - mean_squared_error: 267871.3287 - val_loss: 563418.3080 - val_mean_squared_error: 563418.3080\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 267632.4060 - mean_squared_error: 267632.4060 - val_loss: 563000.5809 - val_mean_squared_error: 563000.5809\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 267393.1217 - mean_squared_error: 267393.1217 - val_loss: 562589.4531 - val_mean_squared_error: 562589.4531\n",
      "Epoch 121/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 267160.0337 - mean_squared_error: 267160.0337 - val_loss: 562171.0357 - val_mean_squared_error: 562171.0357\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 266919.3223 - mean_squared_error: 266919.3223 - val_loss: 561765.3432 - val_mean_squared_error: 561765.3432\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 266686.9133 - mean_squared_error: 266686.9133 - val_loss: 561352.2199 - val_mean_squared_error: 561352.2199\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 266452.3295 - mean_squared_error: 266452.3295 - val_loss: 560943.9710 - val_mean_squared_error: 560943.9710\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 266218.5925 - mean_squared_error: 266218.5925 - val_loss: 560537.0246 - val_mean_squared_error: 560537.0246\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 265983.0078 - mean_squared_error: 265983.0078 - val_loss: 560131.9062 - val_mean_squared_error: 560131.9062\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 265753.3614 - mean_squared_error: 265753.3614 - val_loss: 559711.0128 - val_mean_squared_error: 559711.0128\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 265511.8028 - mean_squared_error: 265511.8028 - val_loss: 559307.9944 - val_mean_squared_error: 559307.9944\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 265279.2731 - mean_squared_error: 265279.2731 - val_loss: 558896.8359 - val_mean_squared_error: 558896.8359\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 265042.6195 - mean_squared_error: 265042.6195 - val_loss: 558494.2383 - val_mean_squared_error: 558494.2383\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 264813.9262 - mean_squared_error: 264813.9262 - val_loss: 558073.9381 - val_mean_squared_error: 558073.9381\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 264577.9822 - mean_squared_error: 264577.9822 - val_loss: 557666.8655 - val_mean_squared_error: 557666.8655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 264339.6245 - mean_squared_error: 264339.6245 - val_loss: 557272.0435 - val_mean_squared_error: 557272.0435\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 264109.9127 - mean_squared_error: 264109.9127 - val_loss: 556868.0195 - val_mean_squared_error: 556868.0195\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 263879.2498 - mean_squared_error: 263879.2498 - val_loss: 556466.3320 - val_mean_squared_error: 556466.3320\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 263647.0969 - mean_squared_error: 263647.0969 - val_loss: 556069.0837 - val_mean_squared_error: 556069.0837\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 263419.4848 - mean_squared_error: 263419.4848 - val_loss: 555661.2221 - val_mean_squared_error: 555661.2221\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 263185.7263 - mean_squared_error: 263185.7263 - val_loss: 555261.8962 - val_mean_squared_error: 555261.8962\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 262953.3222 - mean_squared_error: 262953.3222 - val_loss: 554864.3890 - val_mean_squared_error: 554864.3890\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 262724.9770 - mean_squared_error: 262724.9770 - val_loss: 554463.1529 - val_mean_squared_error: 554463.1529\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 262495.7475 - mean_squared_error: 262495.7475 - val_loss: 554062.5006 - val_mean_squared_error: 554062.5006\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 262262.9103 - mean_squared_error: 262262.9103 - val_loss: 553665.5525 - val_mean_squared_error: 553665.5525\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 262033.8119 - mean_squared_error: 262033.8119 - val_loss: 553267.2467 - val_mean_squared_error: 553267.2467\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 261800.4924 - mean_squared_error: 261800.4924 - val_loss: 552871.0391 - val_mean_squared_error: 552871.0391\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 261572.8403 - mean_squared_error: 261572.8403 - val_loss: 552462.7885 - val_mean_squared_error: 552462.7885\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 261339.0514 - mean_squared_error: 261339.0514 - val_loss: 552068.5151 - val_mean_squared_error: 552068.5151\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 261111.2336 - mean_squared_error: 261111.2336 - val_loss: 551664.4386 - val_mean_squared_error: 551664.4386\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 260880.2847 - mean_squared_error: 260880.2847 - val_loss: 551268.9319 - val_mean_squared_error: 551268.9319\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 260653.1958 - mean_squared_error: 260653.1958 - val_loss: 550872.5385 - val_mean_squared_error: 550872.5385\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 260425.6775 - mean_squared_error: 260425.6775 - val_loss: 550472.3220 - val_mean_squared_error: 550472.3220\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 260191.6154 - mean_squared_error: 260191.6154 - val_loss: 550071.8811 - val_mean_squared_error: 550071.8811\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 259956.4312 - mean_squared_error: 259956.4312 - val_loss: 549659.3454 - val_mean_squared_error: 549659.3454\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 259719.7862 - mean_squared_error: 259719.7862 - val_loss: 549237.6038 - val_mean_squared_error: 549237.6038\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 259475.9159 - mean_squared_error: 259475.9159 - val_loss: 548835.2790 - val_mean_squared_error: 548835.2790\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 259245.0972 - mean_squared_error: 259245.0972 - val_loss: 548420.2533 - val_mean_squared_error: 548420.2533\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 259008.2341 - mean_squared_error: 259008.2341 - val_loss: 548014.5798 - val_mean_squared_error: 548014.5798\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 258773.9810 - mean_squared_error: 258773.9810 - val_loss: 547614.7980 - val_mean_squared_error: 547614.7980\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 258542.0175 - mean_squared_error: 258542.0175 - val_loss: 547198.8287 - val_mean_squared_error: 547198.8287\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 258300.1203 - mean_squared_error: 258300.1203 - val_loss: 546783.0128 - val_mean_squared_error: 546783.0128\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 258060.8438 - mean_squared_error: 258060.8438 - val_loss: 546361.8984 - val_mean_squared_error: 546361.8984\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 257826.7339 - mean_squared_error: 257826.7339 - val_loss: 545943.4163 - val_mean_squared_error: 545943.4163\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 257585.1375 - mean_squared_error: 257585.1375 - val_loss: 545555.7801 - val_mean_squared_error: 545555.7801\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 257361.7867 - mean_squared_error: 257361.7867 - val_loss: 545143.9816 - val_mean_squared_error: 545143.9816\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 257125.9498 - mean_squared_error: 257125.9498 - val_loss: 544743.0725 - val_mean_squared_error: 544743.0725\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 256892.6472 - mean_squared_error: 256892.6472 - val_loss: 544346.3968 - val_mean_squared_error: 544346.3968\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 256665.7527 - mean_squared_error: 256665.7527 - val_loss: 543937.3761 - val_mean_squared_error: 543937.3761\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 256436.0791 - mean_squared_error: 256436.0791 - val_loss: 543529.7874 - val_mean_squared_error: 543529.7874\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 256199.1260 - mean_squared_error: 256199.1260 - val_loss: 543143.5999 - val_mean_squared_error: 543143.5999\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 255973.4414 - mean_squared_error: 255973.4414 - val_loss: 542739.1032 - val_mean_squared_error: 542739.1032\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 255744.8372 - mean_squared_error: 255744.8372 - val_loss: 542336.5854 - val_mean_squared_error: 542336.5854\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 255511.2823 - mean_squared_error: 255511.2823 - val_loss: 541952.4475 - val_mean_squared_error: 541952.4475\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 255290.9309 - mean_squared_error: 255290.9309 - val_loss: 541542.8878 - val_mean_squared_error: 541542.8878\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 255057.5987 - mean_squared_error: 255057.5987 - val_loss: 541152.0670 - val_mean_squared_error: 541152.0670\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 254830.9473 - mean_squared_error: 254830.9473 - val_loss: 540758.2472 - val_mean_squared_error: 540758.2472\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 254607.0102 - mean_squared_error: 254607.0102 - val_loss: 540353.7712 - val_mean_squared_error: 540353.7712\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 254378.5169 - mean_squared_error: 254378.5169 - val_loss: 539964.8711 - val_mean_squared_error: 539964.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 254158.4088 - mean_squared_error: 254158.4088 - val_loss: 539566.4849 - val_mean_squared_error: 539566.4849\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 145us/step - loss: 253928.6183 - mean_squared_error: 253928.6183 - val_loss: 539181.3198 - val_mean_squared_error: 539181.3198\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 253706.9069 - mean_squared_error: 253706.9069 - val_loss: 538787.2171 - val_mean_squared_error: 538787.2171\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 253481.9347 - mean_squared_error: 253481.9347 - val_loss: 538392.9827 - val_mean_squared_error: 538392.9827\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 253258.7058 - mean_squared_error: 253258.7058 - val_loss: 537996.6931 - val_mean_squared_error: 537996.6931\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 253033.3737 - mean_squared_error: 253033.3737 - val_loss: 537607.9252 - val_mean_squared_error: 537607.9252\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 252808.4577 - mean_squared_error: 252808.4577 - val_loss: 537219.4883 - val_mean_squared_error: 537219.4883\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 252583.7031 - mean_squared_error: 252583.7031 - val_loss: 536830.0826 - val_mean_squared_error: 536830.0826\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 252364.7352 - mean_squared_error: 252364.7352 - val_loss: 536426.8890 - val_mean_squared_error: 536426.8890\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 252134.0242 - mean_squared_error: 252134.0242 - val_loss: 536042.3092 - val_mean_squared_error: 536042.3092\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 251912.7803 - mean_squared_error: 251912.7803 - val_loss: 535650.7081 - val_mean_squared_error: 535650.7081\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 251688.9097 - mean_squared_error: 251688.9097 - val_loss: 535259.1814 - val_mean_squared_error: 535259.1814\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 251465.0480 - mean_squared_error: 251465.0480 - val_loss: 534868.3750 - val_mean_squared_error: 534868.3750\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 251242.6003 - mean_squared_error: 251242.6003 - val_loss: 534471.8616 - val_mean_squared_error: 534471.8616\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 251017.3323 - mean_squared_error: 251017.3323 - val_loss: 534084.6730 - val_mean_squared_error: 534084.6730\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 250794.3841 - mean_squared_error: 250794.3841 - val_loss: 533697.1417 - val_mean_squared_error: 533697.1417\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 250572.8788 - mean_squared_error: 250572.8788 - val_loss: 533300.9280 - val_mean_squared_error: 533300.9280\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 250350.5934 - mean_squared_error: 250350.5934 - val_loss: 532912.4023 - val_mean_squared_error: 532912.4023\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 250127.3261 - mean_squared_error: 250127.3261 - val_loss: 532532.4621 - val_mean_squared_error: 532532.4621\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 249911.1975 - mean_squared_error: 249911.1975 - val_loss: 532136.1920 - val_mean_squared_error: 532136.1920\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 249685.2786 - mean_squared_error: 249685.2786 - val_loss: 531760.0982 - val_mean_squared_error: 531760.0982\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 249467.1842 - mean_squared_error: 249467.1842 - val_loss: 531368.4799 - val_mean_squared_error: 531368.4799\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 249242.2233 - mean_squared_error: 249242.2233 - val_loss: 530977.0720 - val_mean_squared_error: 530977.0720\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 249023.8263 - mean_squared_error: 249023.8263 - val_loss: 530576.6473 - val_mean_squared_error: 530576.6473\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 248794.3549 - mean_squared_error: 248794.3549 - val_loss: 530193.3694 - val_mean_squared_error: 530193.3694\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 248576.5837 - mean_squared_error: 248576.5837 - val_loss: 529803.0541 - val_mean_squared_error: 529803.0541\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 248354.8321 - mean_squared_error: 248354.8321 - val_loss: 529418.3142 - val_mean_squared_error: 529418.3142\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 248139.0314 - mean_squared_error: 248139.0314 - val_loss: 529021.6775 - val_mean_squared_error: 529021.6775\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 247916.2086 - mean_squared_error: 247916.2086 - val_loss: 528631.7310 - val_mean_squared_error: 528631.7310\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 247694.2388 - mean_squared_error: 247694.2388 - val_loss: 528252.5279 - val_mean_squared_error: 528252.5279\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 247476.5736 - mean_squared_error: 247476.5736 - val_loss: 527867.5011 - val_mean_squared_error: 527867.5011\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 247259.3584 - mean_squared_error: 247259.3584 - val_loss: 527480.7338 - val_mean_squared_error: 527480.7338\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 247040.7113 - mean_squared_error: 247040.7113 - val_loss: 527100.8711 - val_mean_squared_error: 527100.8711\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 246824.4278 - mean_squared_error: 246824.4278 - val_loss: 526717.1680 - val_mean_squared_error: 526717.1680\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 246604.5516 - mean_squared_error: 246604.5516 - val_loss: 526338.0195 - val_mean_squared_error: 526338.0195\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 246391.1830 - mean_squared_error: 246391.1830 - val_loss: 525952.8421 - val_mean_squared_error: 525952.8421\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 246171.0682 - mean_squared_error: 246171.0682 - val_loss: 525568.7779 - val_mean_squared_error: 525568.7779\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 245952.8375 - mean_squared_error: 245952.8375 - val_loss: 525186.8984 - val_mean_squared_error: 525186.8984\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 245737.3313 - mean_squared_error: 245737.3313 - val_loss: 524801.9872 - val_mean_squared_error: 524801.9872\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 245518.2655 - mean_squared_error: 245518.2655 - val_loss: 524419.3454 - val_mean_squared_error: 524419.3454\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 245307.2690 - mean_squared_error: 245307.2690 - val_loss: 524026.0385 - val_mean_squared_error: 524026.0385\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 245084.3356 - mean_squared_error: 245084.3356 - val_loss: 523660.7427 - val_mean_squared_error: 523660.7427\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 244874.1030 - mean_squared_error: 244874.1030 - val_loss: 523276.2416 - val_mean_squared_error: 523276.2416\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 244656.8867 - mean_squared_error: 244656.8867 - val_loss: 522895.3689 - val_mean_squared_error: 522895.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 244440.7915 - mean_squared_error: 244440.7915 - val_loss: 522521.1194 - val_mean_squared_error: 522521.1194\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 244227.8174 - mean_squared_error: 244227.8174 - val_loss: 522131.8304 - val_mean_squared_error: 522131.8304\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 204us/step - loss: 244010.6064 - mean_squared_error: 244010.6064 - val_loss: 521753.0670 - val_mean_squared_error: 521753.0670\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 243799.1284 - mean_squared_error: 243799.1284 - val_loss: 521370.6306 - val_mean_squared_error: 521370.6306\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 243581.0791 - mean_squared_error: 243581.0791 - val_loss: 521001.2160 - val_mean_squared_error: 521001.2160\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 243370.5708 - mean_squared_error: 243370.5708 - val_loss: 520625.4448 - val_mean_squared_error: 520625.4448\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 243158.7516 - mean_squared_error: 243158.7516 - val_loss: 520237.4358 - val_mean_squared_error: 520237.4358\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 242939.8980 - mean_squared_error: 242939.8980 - val_loss: 519858.3973 - val_mean_squared_error: 519858.3973\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 242729.0872 - mean_squared_error: 242729.0872 - val_loss: 519470.6228 - val_mean_squared_error: 519470.6228\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 192us/step - loss: 242508.6214 - mean_squared_error: 242508.6214 - val_loss: 519107.9051 - val_mean_squared_error: 519107.9051\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 242298.0722 - mean_squared_error: 242298.0722 - val_loss: 518727.9431 - val_mean_squared_error: 518727.9431\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 242083.6256 - mean_squared_error: 242083.6256 - val_loss: 518350.8477 - val_mean_squared_error: 518350.8477\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 241875.3374 - mean_squared_error: 241875.3374 - val_loss: 517958.6445 - val_mean_squared_error: 517958.6445\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 0s 190us/step - loss: 241654.9813 - mean_squared_error: 241654.9813 - val_loss: 517589.5765 - val_mean_squared_error: 517589.5765\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 241444.6159 - mean_squared_error: 241444.6159 - val_loss: 517216.9526 - val_mean_squared_error: 517216.9526\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 241232.5308 - mean_squared_error: 241232.5308 - val_loss: 516840.7963 - val_mean_squared_error: 516840.7963\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 241020.0755 - mean_squared_error: 241020.0755 - val_loss: 516464.4665 - val_mean_squared_error: 516464.4665\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 240810.5009 - mean_squared_error: 240810.5009 - val_loss: 516086.9799 - val_mean_squared_error: 516086.9799\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 240599.1128 - mean_squared_error: 240599.1128 - val_loss: 515712.2199 - val_mean_squared_error: 515712.2199\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 240387.9806 - mean_squared_error: 240387.9806 - val_loss: 515337.9459 - val_mean_squared_error: 515337.9459\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 240176.3452 - mean_squared_error: 240176.3452 - val_loss: 514965.4414 - val_mean_squared_error: 514965.4414\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 239966.2047 - mean_squared_error: 239966.2047 - val_loss: 514592.2048 - val_mean_squared_error: 514592.2048\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 239759.1889 - mean_squared_error: 239759.1889 - val_loss: 514216.5095 - val_mean_squared_error: 514216.5095\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 239543.8941 - mean_squared_error: 239543.8941 - val_loss: 513854.8488 - val_mean_squared_error: 513854.8488\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 196us/step - loss: 239340.9718 - mean_squared_error: 239340.9718 - val_loss: 513471.6289 - val_mean_squared_error: 513471.6289\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 239125.4640 - mean_squared_error: 239125.4640 - val_loss: 513112.2193 - val_mean_squared_error: 513112.2193\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 238919.6752 - mean_squared_error: 238919.6752 - val_loss: 512740.5441 - val_mean_squared_error: 512740.5441\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 238710.6830 - mean_squared_error: 238710.6830 - val_loss: 512364.4682 - val_mean_squared_error: 512364.4682\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 238502.4136 - mean_squared_error: 238502.4136 - val_loss: 511988.6802 - val_mean_squared_error: 511988.6802\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 238288.7458 - mean_squared_error: 238288.7458 - val_loss: 511626.8744 - val_mean_squared_error: 511626.8744\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYVdWd7//3t+aCKqqogbFAUEEQB9QSSYz5xSQiaiLanahtVDrJDUk6uUnfTtJKutOaofua+0sn0XSahEQjJjHENrFDogZn07ntBIqKDIKCUozFUMxVUMX3/rHW4ZwqDkUBtetA8Xk9z37OOWuvvc/aHvDD2nvttc3dERERSVJerhsgIiK9n8JGREQSp7AREZHEKWxERCRxChsREUmcwkZERBKnsBHJMTO7x8y+1cW6K83sg0e7H5GeprAREZHEKWxERCRxChuRLoinr75iZq+a2U4zu8vMBprZI2a23cweN7P+GfWvNLPXzazJzJ42s7EZ684xs5fidr8GSjp814fMbEHc9r/N7KwjbPOnzGy5mW02szlmNiSWm5l9z8w2mNnWeExnxHWXm9mi2LbVZvblI/oPJtKBwkak6/4SuAQYDXwYeAT4KlBD+Lv0BQAzGw38CvhboBZ4GPi9mRWZWRHwn8DPgSrgP+J+idueC9wNfBqoBn4MzDGz4sNpqJm9H/jfwDXAYOBtYHZcPQl4bzyOSuBaYFNcdxfwaXcvB84Anjyc7xU5GIWNSNf9wN3Xu/tq4L+A5939ZXdvAR4Ezon1rgUecvfH3H0v8B2gFHg3MBEoBL7v7nvd/QHgxYzv+BTwY3d/3t3b3H0W0BK3OxwfA+5295di+6YD7zKzEcBeoBwYA5i7L3b3tXG7vcDpZtbP3be4+0uH+b0iWSlsRLpufcb73Vk+l8X3Qwg9CQDcfR+wChga16329jPgvp3x/iTgS/EUWpOZNQHD4naHo2MbdhB6L0Pd/Ung34AfAuvNbKaZ9YtV/xK4HHjbzJ4xs3cd5veKZKWwEel+awihAYRrJITAWA2sBYbGspThGe9XAf/s7pUZSx93/9VRtqEv4bTcagB3v9PdzwPGEU6nfSWWv+juU4ABhNN99x/m94pkpbAR6X73A1eY2QfMrBD4EuFU2H8DzwKtwBfMrMDM/gKYkLHtT4DPmNkF8UJ+XzO7wszKD7MN9wEfN7Px8XrPvxBO+600s/Pj/guBnUAz0BavKX3MzCri6b9tQNtR/HcQ2U9hI9LN3H0pcAPwA2AjYTDBh919j7vvAf4C+GtgC+H6zm8ztp1HuG7zb3H98lj3cNvwBPA14DeE3tQpwHVxdT9CqG0hnGrbRLiuBHAjsNLMtgGficchctRMD08TEZGkqWcjIiKJU9iIiEjiFDYiIpI4hY2IiCSuINcNOFbU1NT4iBEjct0MEZHjyvz58ze6e+2h6ilsohEjRjBv3rxcN0NE5LhiZm8fupZOo4mISA9Q2IiISOIUNiIikjhdsxEROUJ79+6loaGB5ubmXDclcSUlJdTV1VFYWHhE2ytsRESOUENDA+Xl5YwYMYL2E3n3Lu7Opk2baGhoYOTIkUe0D51GExE5Qs3NzVRXV/fqoAEwM6qrq4+qB6ewERE5Cr09aFKO9jgVNkfrzSfhuRmwt/efsxUROVIKm6O15GH44y1w5znw4k+htSXXLRKRE0hTUxP//u//ftjbXX755TQ1NSXQouwUNkfriu/A1N9D5XB46Evwg/Ng/j3QtjfXLRORE8DBwqatrfOHrD788MNUVlYm1awDKGy6w8j3wif+CDc+CGUD4fdfhB+cG0KndU+uWycivdgtt9zCm2++yfjx4zn//PO5+OKLuf766znzzDMBuOqqqzjvvPMYN24cM2fO3L/diBEj2LhxIytXrmTs2LF86lOfYty4cUyaNIndu3d3ezv1pM6ovr7eu2VuNHdY9hg8czusng/96uCi/wXn3AgFxUe/fxE5ZixevJixY8cC8PXfv86iNdu6df+nD+nHrR8e12mdlStX8qEPfYiFCxfy9NNPc8UVV7Bw4cL9Q5Q3b95MVVUVu3fv5vzzz+eZZ56hurp6/3yQO3bs4NRTT2XevHmMHz+ea665hiuvvJIbbjjwieCZx5tiZvPdvf5Qx6KeTXczg9GT4H88ATf8BvoNCafX7hgPz/4QmrfmuoUi0otNmDCh3b0wd955J2effTYTJ05k1apVLFu27IBtRo4cyfjx4wE477zzWLlyZbe3Szd1JsUMTv0gnPIBeOtpeOb/wNyvwpP/DOOvhwnToHZ0rlspIt3kUD2QntK3b9/9759++mkef/xxnn32Wfr06cP73ve+rPfKFBenz7rk5+cnchpNYZM0Mzjl4rCseRmenwkvzYIXfwLD3w1nXwfjroKSily3VESOQ+Xl5Wzfvj3ruq1bt9K/f3/69OnDkiVLeO6553q4dWkKm5405By4egZc8g14+efwyq/g91+AR/4eRk+GMR+CUZdAac+NEBGR41t1dTUXXnghZ5xxBqWlpQwcOHD/usmTJ/OjH/2Is846i9NOO42JEyfmrJ0aIBB12wCBw+EeejuvzIbXfws7GyGvAE66EMZcEQKo/0k92yYR6bJsF8x7s6MZIKCeTS6ZwdBzwzL5dlg9D5Y8BEsfDr2dR/4eqk6Gk98XlhEXQZ+q3LZZROQIKGyOFXl5MGxCWC75OmxcDssfh7eeglfvh3l3AwaDzoST3g3D3xVeywbkuuUiIoeksDlW1ZwalomfCbMRrJ4Pbz4Fb/9fmD8Lnv9RqFd1Sgyed4XXqpNDj0lE5BiSaNiYWSXwU+AMwIFPAEuBXwMjgJXANe6+xcKUoncAlwO7gL9295fifqYC/xh3+y13nxXLzwPuAUqBh4EvurubWVW270jyWBOVXwjDJ4YFwqwEa1+Bd54Ny9KHYMEvwrqygaFe3QSoOx8GnwWFpblru4gIyfds7gD+6O4fMbMioA/wVeAJd7/dzG4BbgFuBi4DRsXlAmAGcEEMjluBekJgzTezOTE8ZgDTgOcIYTMZeCTuM9t39A4FRTDs/LBc+AXYtw82vpEOn7efhUW/C3XzCmDgGVBXD0Prw2vVKeG0nYhID0ksbMysH/Be4K8B3H0PsMfMpgDvi9VmAU8TgmAKcK+H4XHPmVmlmQ2OdR9z981xv48Bk83saaCfuz8by+8FriKEzcG+o3fKy4MBY8JS//FQtn19GHDQMC+8vvLrMCs1hHt6hp6XDp8h50JZbe7aLyK9XpI9m5OBRuBnZnY2MB/4IjDQ3dcCuPtaM0td4R4KrMrYviGWdVbekKWcTr6jHTObRugZMXz48CM8zGNU+cAwfHrMFeHzvrbQ+0mFT8M8+K/vgO8L6/vVwZDxMHh8uB9oyHjoW5O79otIlzQ1NXHffffxN3/zN4e97fe//32mTZtGnz59EmhZe0mGTQFwLvA/3f15M7uDcDrrYLJd1fYjKO8yd58JzIRwn83hbHvcycuHAWPDcu6NoaxlB6xdEO71WbMgvF/yh/Q2qQAaMh4GK4BEjkWpRwwcadjccMMNx33YNAAN7v58/PwAIWzWm9ng2OMYDGzIqD8sY/s6YE0sf1+H8qdjeV2W+nTyHZKpuAxGvCcsKc1bYe2r7UMoM4AqhsHgs9O9n8HnQN/qnm+7iADtHzFwySWXMGDAAO6//35aWlq4+uqr+frXv87OnTu55ppraGhooK2tja997WusX7+eNWvWcPHFF1NTU8NTTz2VaDsTCxt3X2dmq8zsNHdfCnwAWBSXqcDt8TVeyWYO8Hkzm00YILA1hsVc4F/MrH+sNwmY7u6bzWy7mU0EngduAn6Qsa9s3yGHUlIBIy8KS0rz1jD6LdX7WfNyhwAaDkPOzjgFd45uPpUTzyO3wLrXunefg86Ey27vtMrtt9/OwoULWbBgAY8++igPPPAAL7zwAu7OlVdeyZ/+9CcaGxsZMmQIDz30EBDmTKuoqOC73/0uTz31FDU1yZ+xSHo02v8EfhlHor0FfJzwWIP7zeyTwDvAR2PdhwnDnpcThj5/HCCGyjeBF2O9b6QGCwCfJT30+ZG4QAiZbN8hR6KkIjwgbuR702W7m2Ddq+nez5qXYfHv0+srhmecghuvABLpAY8++iiPPvoo55xzDgA7duxg2bJlXHTRRXz5y1/m5ptv5kMf+hAXXXTRIfbU/RING3dfQBiy3NEHstR14HMH2c/dwN1ZyucR7uHpWL4p23dINyqtzB5Aa18JwbN2QQihxXPS6yuHh1Nwg84O9/8MPhvKB/V820WScIgeSE9wd6ZPn86nP/3pA9bNnz+fhx9+mOnTpzNp0iT+6Z/+qUfbphkEpPuUVsLJ/19YUnZvSZ+CW/Ny6A1l9oD6DgjBMyiGz+CzoP9IzYIg0kWZjxi49NJL+drXvsbHPvYxysrKWL16NYWFhbS2tlJVVcUNN9xAWVkZ99xzT7tte8NpNDnRlfZPTySa0rwN1i8MIbT21RBAbz0N+1rD+uJ+4Vz14LNjCJ0FNadBvv64inSU+YiByy67jOuvv553vetdAJSVlfGLX/yC5cuX85WvfIW8vDwKCwuZMWMGANOmTeOyyy5j8ODBiQ8Q0CMGopw8YkDS9jZD4+L2AbRuIbTGJwYWlMCA09v3ggaO01Q8klN6xIAeMSDHm8KS9Ei2lH1tsHFZCJ61r4TX1/8T5t8T1ls+1IyGQWeEKXkGnQEDzww3tIrIMUVhI8euvPz0NDxnXRPK3KHpnRhAsQf09rPw2n+kt+tb2z58Bp0RQim/MDfHISIKGznOmIWnl/Y/CcZ+OF2+azOsfz1cC1q3ENa/Bs/PhLaWsD6/CGpPS4fPwDPCdSENx5aj5O7YCTCg5WgvuShspHfoU3Xgzahte2HT8nT4rFsIbz4Br9yXrlM+5MDTcFUnazCCdElJSQmbNm2iurq6VweOu7Np0yZKSkqOeB/6GyW9V35hej64zPt6dzSmwyfVE3rzyfRouPxiqB0dBiQMOD0MRBgwFvoN1ZBsaaeuro6GhgYaGxtz3ZTElZSUUFdXd+iKB6HRaJFGo53gWlugcWk4FbfhddiwGNYvgu1r0nWKK0LoDDw9I4hOD8O7RU5QGo0mcjgKiuOsBme1L9+9JQZPDKANi+C130BLxoQW5YPTwZMKodrTNCxbJIPCRqQzpf3hpHeHJcUdtq2J4fN66AFtWNR+QILlhWs/A8bCgHHpIKo6OYyyEznBKGxEDpcZVAwNy6gPpsvbWmHLioxeUAyixX9g/6OWCkrCMOyB49qfiisfrOtB0qspbES6S34B1IwKy7ir0uV7dsHGpRmn4xaF6Xle+VW6Tkllxqm42BsaMDbMNyfSCyhsRJJW1OfA2REg3BuUug60YVHoBb16P7RsS9fpNzT2gMamR8XVnBZmXBA5jihsRHKlTxWMuDAsKe6wbXX6OlAqhFY8A217Qh3Lg6pTYi9oXDqI+o/Q9SA5ZilsRI4lZlBRF5bRk9Llba2w+c10+GxYFJ4KuWgO+68H5ReH60G1p4Upfmrj0n+kblKVnEv0T6CZrQS2A21Aq7vXm9ltwKeA1F1QX3X3h2P96cAnY/0vuPvcWD4ZuAPIB37q7rfH8pHAbKAKeAm40d33mFkxcC9wHrAJuNbdVyZ5rCKJyi8IIVJ7Goy7Ol2+Z2e4P2jDImhcEt6vegEWPpCxbRFUj8oIoNOgdixUjdR8cdJjeuKfOxe7+8YOZd9z9+9kFpjZ6cB1wDhgCPC4mY2Oq38IXAI0AC+a2Rx3XwR8O+5rtpn9iBBUM+LrFnc/1cyui/WuTej4RHKnqC8MPTcsmVp2wMY3YgDFEGqYBwt/k66TVwjVp7bvBdWOCcOzC4p69jik1zuW+tZTgNnu3gKsMLPlwIS4brm7vwVgZrOBKWa2GHg/cH2sMwu4jRA2U+J7gAeAfzMzc02XICeK4rLsIbRnZwyhpSGENiwJT1F9/T/ZfzouryCEUO1p7UOo+lSFkByxpMPGgUfNzIEfu/vMWP55M7sJmAd8yd23AEOB5zK2bYhlAKs6lF8AVANN7t6apf7Q1Dbu3mpmW2P9dj0sM5sGTAMYPnz4UR6qyHGgqG/2kXF7d6dDaMPi8LpuYXiEt+8LdSwfqk9Jn4ZLhVHNqDADg0gnkg6bC919jZkNAB4zsyWEnsc3CUH0TeBfgU8A2e5ocyDvIOUHq88h1qULQvjNhDA3WueHItKLFZaGp58OPrt9+d7dYebs/SG0JLwueSgjhOJsCZm9oAFjwnUiDdGWKNGwcfc18XWDmT0ITHD3P6XWm9lPgD/Ejw3AsIzN64DULIjZyjcClWZWEHs3mfVT+2owswKgAtjcnccmckIoLA3P/Rl0Zvvy1pYQQqleUOra0NJHwNtCHcsLw7Eze0GpECrq0+OHIrmVWNiYWV8gz923x/eTgG+Y2WB3XxurXQ0sjO/nAPeZ2XcJAwRGAS8Qeimj4siz1YRBBNe7u5vZU8BHCCPSpgK/y9jXVODZuP5JXa8R6UYFxeHenoHj2pe37ok9oTgooTGG0bK56Uc4YDGE4si4ATGMakaH03zSKyXZsxkIPBgfKFQA3OfufzSzn5vZeMJprZXApwHc/XUzux9YBLQCn3MP/0Qys88DcwlDn+9299fjd9wMzDazbwEvA3fF8ruAn8dBBpsJASUiSSsoCjebDjy9fXnrHtj8VsbouBhGyx+HfXtjJYPK4VlC6LQw4EGOa3qeTaTn2YjkQNte2LyifQhtWAKblqVnTACoGH7gzaq1p0Fxee7aLoCeZyMix4P8wvBU1NrRwJXp8rZW2LIynoaLvaANS2DFn9KPcQDoV3fgzaq1o6GkoqePRA5BYSMix578Aqg5NSxjP5wu39cWQyijF9S4BFb+GVqb0/XKh6RnXEhN4VNzGvSt0aMcckRhIyLHj7x4r0/1KTDminT5vjZoerv9EO3GpfDSz2HvznS90v4hdGpHx9cYRhXDIC/bXRbSXRQ2InL8y8sP9/pUnQynXZYu37cvzKK9cSk0vpF+XfIQ7Lo3Xa+wT3rWhMww0tQ93UZhIyK9V14eVA4Ly6kfbL9u56YYPkvTsye88xy89h8Z2xeEWbPbnY4bHRaNkDssChsROTH1rYa+74aT3t2+vGVHGA3XGCcyTQVR5g2rEAYn7D8dl3Farm9Nzx7HcUJhIyKSqbgs+/xxqXuF2p2SWwpvPwutu9P1SqvSjwdP9YJqRkPlSSf0c4VO3CMXETkcBUVhmPWAMe3L9+2DravSPaBNy2DjMnhjLrz8i3S9vMIwsKFdCI0K0/eU9OvZY8kBhY2IyNHIy4P+J4Vl1CXt1+3aHKbv2bgshNHGZWG49pKH25+SKx8cBihkhlDNaOg3tNeMklPYiIgkpU8V9JkAwya0L2/dE+4X2vhGOoQ2vgGvPQAtW9P1UqPkOoZQ9SlhktTjiMJGRKSnFRRlzJyQwR12Nh4YQg0vxKesZjxFpXJ4RgBlnJrrW3tM3riqsBEROVaYQdmAsIx4T/t1e3bB5jdjAC1LB9Lb/xf27krXK6k4sCdUMzrMtJ1f2KOHk0lhIyJyPCjqk/3ZQvtvXH2jfQgtfwIW/DJdL3XPUMcQqhkFpZWJN19hIyJyPGt34+oH2q9r3pYeHZd5am7ZoxmPdgCu+xWMuTzRZipsRER6q5J+MPS8sGRqaw1zyaXCp+PjwBOgsBEROdHkF6QnNM2cSy5BiQ7gNrOVZvaamS0ws3mxrMrMHjOzZfG1fyw3M7vTzJab2atmdm7GfqbG+svMbGpG+Xlx/8vjttbZd4iISG70xN1CF7v7+Iwnud0CPOHuo4An4meAy4BRcZkGzIAQHMCtwAXABODWjPCYEeumtpt8iO8QEZEcyMWtqVOAWfH9LOCqjPJ7PXgOqDSzwcClwGPuvtndtwCPAZPjun7u/qyHZ1vf22Ff2b5DRERyIOmwceBRM5tvZtNi2UB3XwsQXwfE8qHAqoxtG2JZZ+UNWco7+w4REcmBpAcIXOjua8xsAPCYmS3ppG62W179CMq7LAbgNIDhw4cfzqYiInIYEu3ZuPua+LoBeJBwzWV9PAVGfN0QqzcAwzI2rwPWHKK8Lks5nXxHx/bNdPd6d6+vra090sMUEZFDSCxszKyvmZWn3gOTgIXAHCA1omwq8Lv4fg5wUxyVNhHYGk+BzQUmmVn/ODBgEjA3rttuZhPjKLSbOuwr23eIiEgOJHkabSDwYByNXADc5+5/NLMXgfvN7JPAO8BHY/2HgcuB5cAu4OMA7r7ZzL4JvBjrfcPdN8f3nwXuAUqBR+ICcPtBvkNERHLAwkAuqa+v93nz5uW6GSIixxUzm59xa8tB9Y6n8oiIyDFNYSMiIolT2IiISOIUNiIikjiFjYiIJE5hIyIiiVPYiIhI4hQ2IiKSOIWNiIgkTmEjIiKJU9iIiEjiFDYiIpI4hY2IiCROYSMiIolT2IiISOIUNiIikjiFjYiIJC7xsDGzfDN72cz+ED/fY2YrzGxBXMbHcjOzO81suZm9ambnZuxjqpkti8vUjPLzzOy1uM2dFp9BbWZVZvZYrP+YmfVP+jhFROTgeqJn80VgcYeyr7j7+LgsiGWXAaPiMg2YASE4gFuBC4AJwK0Z4TEj1k1tNzmW3wI84e6jgCfiZxERyZFEw8bM6oArgJ92ofoU4F4PngMqzWwwcCnwmLtvdvctwGPA5Liun7s/6+4O3AtclbGvWfH9rIxyERHJgaR7Nt8H/h7Y16H8n+Opsu+ZWXEsGwqsyqjTEMs6K2/IUg4w0N3XAsTXAdkaZ2bTzGyemc1rbGw87IMTEZGuSSxszOxDwAZ3n99h1XRgDHA+UAXcnNoky278CMq7zN1nunu9u9fX1tYezqYiInIYuhQ2ZvZFM+sXL+LfZWYvmdmkQ2x2IXClma0EZgPvN7NfuPvaeKqsBfgZ4ToMhJ7JsIzt64A1hyivy1IOsD6eZiO+bujKcYqISDK62rP5hLtvAyYBtcDHgds728Ddp7t7nbuPAK4DnnT3GzJCwAjXUhbGTeYAN8VAmwhsjafA5gKTzKx/HBgwCZgb1203s4lxXzcBv8vYV2rU2tSMchERyYGCLtZLnbK6HPiZu7+SGmZ8BH5pZrVxnwuAz8Tyh+P+lwO7CIGGu282s28CL8Z633D3zfH9Z4F7gFLgkbhACML7zeyTwDvAR4+wrSIi0g0sDOQ6RCWznxEuvo8Ezgbygafd/bxkm9dz6uvrfd68ebluhojIccXM5rt7/aHqdbVn80lgPPCWu++K9758/GgaKCIiJ46uXrN5F7DU3ZvM7AbgH4GtyTVLRER6k66GzQxgl5mdTbhv5m3CTZQiIiKH1NWwaY136U8B7nD3O4Dy5JolIiK9SVev2Ww3s+nAjcBFZpYPFCbXLBER6U262rO5Fmgh3G+zjjAy7f9PrFUiItKrdClsYsD8EqiI09A0u7uu2YiISJd0dbqaa4AXCDdHXgM8b2YfSbJhIiLSe3T1ms0/AOe7+waAOAPA48ADSTVMRER6j65es8lLBU206TC2FRGRE1xXezZ/NLO5wK/i52sJc5mJiIgcUpfCxt2/YmZ/SXhsgAEz3f3BRFsmIiK9Rld7Nrj7b4DfJNgWERHppToNGzPbTvanXxrg7t4vkVaJiEiv0mnYuLumpBERkaOmEWUiIpK4xMPGzPLN7GUz+0P8PNLMnjezZWb2azMriuXF8fPyuH5Exj6mx/KlZnZpRvnkWLbczG7JKM/6HSIikhs90bP5IrA44/O3ge+5+yhgC+HBbMTXLe5+KvC9WA8zOx24DhgHTAb+PQZYPvBD4DLgdOCvYt3OvkNERHIg0bAxszrgCuCn8bMB7yc988As4Kr4fkr8TFz/gVh/CjDb3VvcfQWwHJgQl+Xu/pa77wFmA1MO8R0iIpIDSfdsvk942Nq++LkaaHL31vi5gTCDNPF1FUBcvzXW31/eYZuDlXf2He2Y2TQzm2dm8xobG4/0GEVE5BASC5s4O/QGd5+fWZylqh9iXXeVH1joPtPd6929vra2NlsVERHpBl2+qfMIXAhcaWaXAyVAP0JPp9LMCmLPow5YE+s3AMOABjMrACqAzRnlKZnbZCvf2Ml3iIhIDiTWs3H36e5e5+4jCBf4n3T3jwFPAanHE0wFfhffz4mfieufjI+ingNcF0erjQRGER538CIwKo48K4rfMSduc7DvEBGRHMjFfTY3A39nZssJ11fuiuV3AdWx/O+AWwDc/XXgfmAR8Efgc+7eFnstnwfmEka73R/rdvYdIiKSAxY6AlJfX+/z5s3LdTNERI4rZjbf3esPVU8zCIiISOIUNiIikjiFjYiIJE5hIyIiiVPYiIhI4hQ2IiKSOIWNiIgkTmEjIiKJU9iIiEjiFDYiIpI4hY2IiCROYSMiIolT2IiISOIUNiIikjiFjYiIJE5hIyIiiUssbMysxMxeMLNXzOx1M/t6LL/HzFaY2YK4jI/lZmZ3mtlyM3vVzM7N2NdUM1sWl6kZ5eeZ2WtxmzvNzGJ5lZk9Fus/Zmb9kzpOERE5tCR7Ni3A+939bGA8MNnMJsZ1X3H38XFZEMsuA0bFZRowA0JwALcCFwATgFszwmNGrJvabnIsvwV4wt1HAU/EzyIikiOJhY0HO+LHwrh09gzqKcC9cbvngEozGwxcCjzm7pvdfQvwGCG4BgP93P1ZD8+2vhe4KmNfs+L7WRnlIiKSA4leszGzfDNbAGwgBMbzcdU/x1Nl3zOz4lg2FFiVsXlDLOusvCFLOcBAd18LEF8HHKR908xsnpnNa2xsPOLjFBGRziUaNu7e5u7jgTpggpmdAUwHxgDnA1XAzbG6ZdvFEZQfTvtmunu9u9fX1tYezqYiInIYemQ0mrs3AU8Dk919bTxV1gL8jHAdBkLPZFjGZnXAmkOU12UpB1gfT7MRXzd06wGJiMhhSXI0Wq2ZVcb3pcAHgSUZIWCEaykL4yZzgJviqLSJwNZ4CmwuMMnM+seBAZOAuXHddjObGPd1E/C7jH2lRq1NzSgXEZEcKEhw34OBWWaWTwi1+939D2b2pJnVEk6DLQA+E+s/DFwOLAd2AR8HcPfNZvZN4MWYx24kAAAShUlEQVRY7xvuvjm+/yxwD1AKPBIXgNuB+83sk8A7wEcTO0oRETkkCwO5pL6+3ufNm5frZoiIHFfMbL671x+qnmYQEBGRxClsREQkcQobERFJnMJGREQSp7AREZHEKWxERCRxChsREUmcwkZERBKnsBERkcQpbEREJHEKGxERSZzCRkREEqewERGRxClsREQkcQobERFJnMLmKL2yqomnlm6geW9brpsiInLMSvJJnSeEWf+9kt++vJo+Rfm859QaPjh2IBePGUBteXGumyYicsxILGzMrAT4E1Acv+cBd7/VzEYCs4Eq4CXgRnffY2bFwL3AecAm4Fp3Xxn3NR34JNAGfMHd58byycAdQD7wU3e/PZZn/Y4kjvNf/uJMPjx+CE8sXs8Tizfw6KL1mMHZdZW8f8wA3j9mAOOG9MPMkvh6EZHjQmKPhbbwf9e+7r7DzAqBPwNfBP4O+K27zzazHwGvuPsMM/sb4Cx3/4yZXQdc7e7XmtnpwK+ACcAQ4HFgdPyaN4BLgAbgReCv3H2Rmd2f7Ts6a293PBba3Vm0dhtPLN7Ak0s28EpDE+4wqF8JF4+p5f1jBnLhqdX0KVKHUkR6h64+FjqxsOnQmD6EsPks8BAwyN1bzexdwG3ufqmZzY3vnzWzAmAdUAvcAuDu/zvuay5wW9z1be5+aSyfHstuBxqzfUdnbeyOsOmocXsLTy8NwfNfyzayo6WVwnzjrLpKJoys4oKRVdSPqKKsWOEjIsenroZNov+XM7N8YD5wKvBD4E2gyd1bY5UGYGh8PxRYBRBDYitQHcufy9ht5jarOpRfELc52Hd0bN80YBrA8OHDj+wgO1FbXsxH64fx0fph7GndxwsrNvPn5Rt5fsUmfvKnt5jx9Jvk5xljBpVz5tAKxg2t4MyhFYwZVE5JYX63t0dEJFcSDRt3bwPGm1kl8CAwNlu1+JrtooZ3Up5tJF1n9bO1byYwE0LPJlud7lJUkMd7RtXwnlE1AOza08pLbzfx/IpNLFjVxB9fX8fsF0N25ucZJ9f0ZdTAMk4dUM6oAWWcOqCMkTV9FUIiclzqkfM37t5kZk8DE4FKMyuIPY86YE2s1gAMAxriabQKYHNGeUrmNtnKN3byHceMPkUF7cLH3VndtJuFq7excPVWlq7fzuK12/njwnXsizGYZzCsqg8nVfflpKo+nFQd3o+o7sOwqj4KIhE5ZiU5Gq0W2BuDphT4IPBt4CngI4TRYlOB38VN5sTPz8b1T7q7m9kc4D4z+y5hgMAo4AVCD2ZUHHm2GrgOuD5uc7DvOGaZGXX9+1DXvw+Tzxi0v7x5bxsrNu5k2YYdLFu/nRUbd/L2pl28/M4Wtje3ZmwfBiKcVN2Hk6r6clJNH4ZXhf0NrSylpqxII+JEJGeS7NkMBmbF6zZ5wP3u/gczWwTMNrNvAS8Dd8X6dwE/N7PlhB7NdQDu/nocXbYIaAU+F0/PYWafB+YShj7f7e6vx33dfJDvOO6UFOYzdnA/xg7u167c3WnatZeVm3byzuZdrNy4i7c3hyB6Ysl6Nu7Y02E/eQytLGVo/z7U9S+lrn8pQytLqevfh2H9S6kpKyYvT2EkIsnokdFox4MkRqPl0o6WVlZt3sXqLbtp2LKL1U27adgSltVNu9m8s30YFeXnMTQjhIZUljK4oqTdq07TiUhHx8RoNMmdsuKCrD2ilJ0traxu2r0/jBoywmjx4gN7RgD9+xQyuKKUIZUlDK4oZXBlCUMq0mE0sF8JRQWaAUlEDqSwOUH1LS5g9MByRg8sz7q+eW8b67c1s6apmbVbd7N2azNrmsJrw5bdvLhyC1t37223jRnUlBUzpKJDGMVwGlJZwoDyEvJ1uk7khKOwkaxKCvPDqLfqvgets7OllbVbYxg1NbMm43V54w7+a1kjO/e0n6A0P88YWF7M4A6n6TJ7TBrMINL7KGzkiPUtLuDUeA9QNu7OtuZW1m7dzZqm3eleUgyk11Zv5dFF69nTuq/ddkX5eQyqKGkfRpWl+3tMQypLqCgtVCCJHEcUNpIYM6OitJCK0kLGDMp+7cjd2bRzT0bPKJ6y29rM2qbdvLBiM+u2NdO2r/1Alj5F+QyqSF8zSoXRwH6ppZiqvuohiRwrFDaSU2ZGTVkxNWXFnFlXkbVO2z6ncXvL/tN0oacUX7c288YbjTTuaKHjwMqi/Dxqy4sZVBHCJxVEgzICaVBFiSZGFekB+lsmx7z8PGNQRQmDKkrgIFPY7WndR+OOFtZtbWbDtmbWbWtm/bYW1m9rZt3WZpas284zSw+8hgRQXlzAwKyBlP5cW15MYb5G2okcKYWN9ApFBfGm1crSTuvtaGnNGkjr4+fn39rM+m3NtHY4bZcaaTewXzGD+pUwIEsgDepXQmUfXUsSyUZhIyeUskMMagDYt8/ZvGsP67Y2xyBqYd22dECtbmrmpXeaDrgxFkLoDexXzMDyEgZWlDCgvJgB5fG1XzG18XN/hZKcYBQ2Ih3k5aWvI50xNPt1JICW1jY2bGthw/Zm1m1N95BSvaRFa7bx9LbmrKfuCvON2rJiavulAimEUG3qfb/wuaasiAKdvpNeQGEjcoSKC/IZVhVm3O7MzpZWGre3sGF7CKYQUOF94/YWVm3exfy3t2TtKZlBdd8iajODaH8gZfSc+hVrOiE5pilsRBLWt7iAvsUFjKg5+A2yEAY5bNwRg2hbMxu2t+wPqcbt4fMb67azcUfLAdeUIAx0qO1XfMCpu3Y9pvIS+pUW6BSe9DiFjcgxoqggjyFxEtTOpK4p7e8ttQum0HN6paGJDdta2L33wFN4xQV5+8OnNrWUlaTflxdTU1ZETZl6S9J9FDYix5nMa0pjBx+8nruzo6U1BlL6tF1mMK3YuJMXVmxmy669WffRr6QgI4TCNaQQTplBFW6g1bUl6YzCRqSXMjPKSwopLynklNqDj76DcApv084WNm7fQ+OOEEr7lx2hfOHqrTRub2FHS+sB26euLdV0CKGO72vKijU8/ASlsBERigrywkzdFaWEJ7If3K49rTGU0mGUGU4bd7TwVuNOGne0HDDvHYSRePtDKSOEasvbh1NNeTF9i/IVTL1Eko+FHgbcCwwC9gEz3f0OM7sN+BTQGKt+1d0fjttMBz4JtAFfcPe5sXwycAfhiZw/dffbY/lIwqOfq4CXgBvdfY+ZFcfvPg/YBFzr7iuTOlaRE0mfogKGVxcwvLrzUXipiVgzQ6hjOK3d2sxrq7eycUcLWcY8UFqY3yGAig64vpS6xlRcoOtLx7IkezatwJfc/SUzKwfmm9ljcd333P07mZXN7HTCo6DHAUOAx81sdFz9Q+ASoAF40czmuPsi4NtxX7PN7EeEoJoRX7e4+6lmdl2sd22CxyoiHWROxNrZTbQQ5r/bEgc9tAumjHB6s3EHz69oObrrS+XFVPct1jOVciCxsHH3tcDa+H67mS0GhnayyRRgtru3ACvMbDkwIa5b7u5vAZjZbGBK3N/7getjnVnAbYSwmRLfAzwA/JuZmesZ2CLHpPwuDnqA9PWljqfuMoPptYYmNu7Yc1TXl2rLi/Uoi27UI9dszGwEcA7wPHAh8HkzuwmYR+j9bCEE0XMZmzWQDqdVHcovAKqBJndvzVJ/aGobd281s62x/sYO7ZoGTAMYPvwgMzyKyDGl/fWlzqWvL2UMetixp12v6a3GnTRub2FP25FfX6otL6ZvsS6Bdybx/zpmVgb8Bvhbd99mZjOAbwIeX/8V+ASQ7Z8PDmQbT+md1OcQ69IF7jOBmQD19fXq9Yj0Mkd6fSnzulKq17R2azOvrt7Kpi5eX8oaTCfw9aVEw8bMCglB80t3/y2Au6/PWP8T4A/xYwMwLGPzOmBNfJ+tfCNQaWYFsXeTWT+1rwYzKyAMr9ncjYcmIr3I0VxfygynjRnXl55bsYmmLl5fSg1+qOlbTHW8oba6l91Ym+RoNAPuAha7+3czygfH6zkAVwML4/s5wH1m9l3CAIFRwAuEXsqoOPJsNWEQwfXu7mb2FPARwoi0qcDvMvY1FXg2rn9S12tEpDsczvWlltY2Nu3Y037AQ+repYzrSxu2t7Ary4StEGYqrykrorqsOFxrKi+mJr5W9y3ev66mrOiYvsaUZM/mQuBG4DUzWxDLvgr8lZmNJ5zWWgl8GsDdXzez+4FFhJFsn3P3NgAz+zwwlzD0+W53fz3u72Zgtpl9C3iZEG7E15/HQQabCQElItKjigvyuzQFEYTrS6lg2v+6M/SgNu3cw6YdLazctDNM2rprzwFPpoVwjamqb6pnlJ52qLpv+95STZz1oaig52Z9MP2DP6ivr/d58+bluhkiIofU2raPLbv27g+m1Oi8TTv3sDH1Gtcd7OZagIrSQqrLiviXq89k4snVR9QWM5vv7vWHqqfhEyIix5mC/Lz913wOJTVHXqq3tDGG08bt8XVHCxWlhcm3OfFvEBGRnMmcI+9Qj7lIkqZpFRGRxClsREQkcQobERFJnMJGREQSp7AREZHEKWxERCRxChsREUmcwkZERBKn6WoiM2sE3j7CzWvo8KycE4CO+cRxIh63jrnrTnL32kNVUth0AzOb15W5gXoTHfOJ40Q8bh1z99NpNBERSZzCRkREEqew6R4zc92AHNAxnzhOxOPWMXczXbMREZHEqWcjIiKJU9iIiEjiFDZHycwmm9lSM1tuZrfkuj1JMbOVZvaamS0ws3mxrMrMHjOzZfG1f67beTTM7G4z22BmCzPKsh6jBXfG3/1VMzs3dy0/cgc55tvMbHX8rReY2eUZ66bHY15qZpfmptVHx8yGmdlTZrbYzF43sy/G8l77W3dyzD33W7u7liNcgHzgTeBkoAh4BTg91+1K6FhXAjUdyv4PcEt8fwvw7Vy38yiP8b3AucDCQx0jcDnwCGDAROD5XLe/G4/5NuDLWeqeHv+MFwMj45/9/FwfwxEc82Dg3Pi+HHgjHluv/a07OeYe+63Vszk6E4Dl7v6Wu+8BZgNTctymnjQFmBXfzwKuymFbjpq7/wnY3KH4YMc4BbjXg+eASjMb3DMt7T4HOeaDmQLMdvcWd18BLCf8HTiuuPtad38pvt8OLAaG0ot/606O+WC6/bdW2BydocCqjM8NdP4DHs8ceNTM5pvZtFg20N3XQvjDDAzIWeuSc7Bj7O2//efjKaO7M06P9rpjNrMRwDnA85wgv3WHY4Ye+q0VNkfHspT11rHkF7r7ucBlwOfM7L25blCO9ebffgZwCjAeWAv8ayzvVcdsZmXAb4C/dfdtnVXNUnZcHneWY+6x31phc3QagGEZn+uANTlqS6LcfU183QA8SOhSr0+dToivG3LXwsQc7Bh77W/v7uvdvc3d9wE/IX36pNccs5kVEv6n+0t3/20s7tW/dbZj7snfWmFzdF4ERpnZSDMrAq4D5uS4Td3OzPqaWXnqPTAJWEg41qmx2lTgd7lpYaIOdoxzgJviSKWJwNbUKZjjXYfrEVcTfmsIx3ydmRWb2UhgFPBCT7fvaJmZAXcBi939uxmreu1vfbBj7tHfOtejJI73hTBS5Q3CaI1/yHV7EjrGkwkjU14BXk8dJ1ANPAEsi69VuW7rUR7nrwinEvYS/mX3yYMdI+E0ww/j7/4aUJ/r9nfjMf88HtOr8X86gzPq/0M85qXAZblu/xEe83sIp4ReBRbE5fLe/Ft3csw99ltruhoREUmcTqOJiEjiFDYiIpI4hY2IiCROYSMiIolT2IiISOIUNiK9gJm9z8z+kOt2iByMwkZERBKnsBHpQWZ2g5m9EJ8d8mMzyzezHWb2r2b2kpk9YWa1se54M3suTpL4YMbzVU41s8fN7JW4zSlx92Vm9oCZLTGzX8a7xkWOCQobkR5iZmOBawmTmo4H2oCPAX2BlzxMdPoMcGvc5F7gZnc/i3CXd6r8l8AP3f1s4N2EGQAgzOT7t4RnkZwMXJj4QYl0UUGuGyByAvkAcB7wYux0lBIme9wH/DrW+QXwWzOrACrd/ZlYPgv4jzhH3VB3fxDA3ZsB4v5ecPeG+HkBMAL4c/KHJXJoChuRnmPALHef3q7Q7Gsd6nU2h1Rnp8ZaMt63ob/fcgzRaTSRnvME8BEzGwD7n3l/EuHv4UdineuBP7v7VmCLmV0Uy28EnvHwDJIGM7sq7qPYzPr06FGIHAH9y0ekh7j7IjP7R8ITT/MIMy1/DtgJjDOz+cBWwnUdCNPc/yiGyVvAx2P5jcCPzewbcR8f7cHDEDkimvVZJMfMbIe7l+W6HSJJ0mk0ERFJnHo2IiKSOPVsREQkcQobERFJnMJGREQSp7AREZHEKWxERCRx/w+3Z3vcGiTz9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b23378a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b23378a860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее-2, попробовали tanh вместо sigmoid, плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 306621.4306 - mean_squared_error: 306621.4306 - val_loss: 629236.2165 - val_mean_squared_error: 629236.2165\n",
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 305648.6278 - mean_squared_error: 305648.6278 - val_loss: 627452.0681 - val_mean_squared_error: 627452.0681\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 143us/step - loss: 304504.0811 - mean_squared_error: 304504.0811 - val_loss: 625467.5128 - val_mean_squared_error: 625467.5128\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 145us/step - loss: 303266.3067 - mean_squared_error: 303266.3067 - val_loss: 623263.9353 - val_mean_squared_error: 623263.9353\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 301849.2208 - mean_squared_error: 301849.2208 - val_loss: 620898.0184 - val_mean_squared_error: 620898.0184\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 300364.4348 - mean_squared_error: 300364.4348 - val_loss: 618400.2388 - val_mean_squared_error: 618400.2388\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 298863.9763 - mean_squared_error: 298863.9763 - val_loss: 615921.3789 - val_mean_squared_error: 615921.3789\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 147us/step - loss: 297402.9952 - mean_squared_error: 297402.9952 - val_loss: 613534.5943 - val_mean_squared_error: 613534.5943\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 296023.7248 - mean_squared_error: 296023.7248 - val_loss: 611329.1948 - val_mean_squared_error: 611329.1948\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 294790.9591 - mean_squared_error: 294790.9591 - val_loss: 609318.4559 - val_mean_squared_error: 609318.4559\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 293677.7014 - mean_squared_error: 293677.7014 - val_loss: 607494.6602 - val_mean_squared_error: 607494.6602\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 292688.4826 - mean_squared_error: 292688.4826 - val_loss: 605793.7472 - val_mean_squared_error: 605793.7472\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 291801.9370 - mean_squared_error: 291801.9370 - val_loss: 604230.2054 - val_mean_squared_error: 604230.2054\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 290978.2528 - mean_squared_error: 290978.2528 - val_loss: 602789.6579 - val_mean_squared_error: 602789.6579\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 290231.0847 - mean_squared_error: 290231.0847 - val_loss: 601397.1390 - val_mean_squared_error: 601397.1390\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 289528.7811 - mean_squared_error: 289528.7811 - val_loss: 600043.7935 - val_mean_squared_error: 600043.7935\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 288852.4683 - mean_squared_error: 288852.4683 - val_loss: 598774.4598 - val_mean_squared_error: 598774.4598\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 288209.8267 - mean_squared_error: 288209.8267 - val_loss: 597485.8231 - val_mean_squared_error: 597485.8231\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 287579.8236 - mean_squared_error: 287579.8236 - val_loss: 596239.2980 - val_mean_squared_error: 596239.2980\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 286982.0602 - mean_squared_error: 286982.0602 - val_loss: 595027.0915 - val_mean_squared_error: 595027.0915\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 286389.0191 - mean_squared_error: 286389.0191 - val_loss: 593830.8968 - val_mean_squared_error: 593830.8968\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 285818.0667 - mean_squared_error: 285818.0667 - val_loss: 592669.3767 - val_mean_squared_error: 592669.3767\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 285266.4384 - mean_squared_error: 285266.4384 - val_loss: 591537.6189 - val_mean_squared_error: 591537.6189\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 284719.9759 - mean_squared_error: 284719.9759 - val_loss: 590439.0112 - val_mean_squared_error: 590439.0112\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 284186.5550 - mean_squared_error: 284186.5550 - val_loss: 589359.0597 - val_mean_squared_error: 589359.0597\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 283671.6142 - mean_squared_error: 283671.6142 - val_loss: 588286.8443 - val_mean_squared_error: 588286.8443\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 283151.0219 - mean_squared_error: 283151.0219 - val_loss: 587270.3086 - val_mean_squared_error: 587270.3086\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 282659.3820 - mean_squared_error: 282659.3820 - val_loss: 586255.2338 - val_mean_squared_error: 586255.2338\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 282159.6095 - mean_squared_error: 282159.6095 - val_loss: 585260.7974 - val_mean_squared_error: 585260.7974\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 281682.5950 - mean_squared_error: 281682.5950 - val_loss: 584301.6055 - val_mean_squared_error: 584301.6055\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 281201.5363 - mean_squared_error: 281201.5363 - val_loss: 583386.1914 - val_mean_squared_error: 583386.1914\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 280753.2922 - mean_squared_error: 280753.2922 - val_loss: 582473.0078 - val_mean_squared_error: 582473.0078\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 280291.0132 - mean_squared_error: 280291.0132 - val_loss: 581599.3499 - val_mean_squared_error: 581599.3499\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 279852.2633 - mean_squared_error: 279852.2633 - val_loss: 580750.3209 - val_mean_squared_error: 580750.3209\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 279410.3105 - mean_squared_error: 279410.3105 - val_loss: 579922.0938 - val_mean_squared_error: 579922.0938\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 278975.7544 - mean_squared_error: 278975.7544 - val_loss: 579066.4682 - val_mean_squared_error: 579066.4682\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 278542.7441 - mean_squared_error: 278542.7441 - val_loss: 578240.5804 - val_mean_squared_error: 578240.5804\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 278114.0666 - mean_squared_error: 278114.0666 - val_loss: 577445.5965 - val_mean_squared_error: 577445.5965\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 277694.4238 - mean_squared_error: 277694.4238 - val_loss: 576643.5820 - val_mean_squared_error: 576643.5820\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 277280.7039 - mean_squared_error: 277280.7039 - val_loss: 575859.3968 - val_mean_squared_error: 575859.3968\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 276877.5216 - mean_squared_error: 276877.5216 - val_loss: 575099.9738 - val_mean_squared_error: 575099.9738\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 276460.0411 - mean_squared_error: 276460.0411 - val_loss: 574333.0117 - val_mean_squared_error: 574333.0117\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 276052.1945 - mean_squared_error: 276052.1945 - val_loss: 573575.8259 - val_mean_squared_error: 573575.8259\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 275648.8120 - mean_squared_error: 275648.8120 - val_loss: 572829.6440 - val_mean_squared_error: 572829.6440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 275245.8219 - mean_squared_error: 275245.8219 - val_loss: 572097.2896 - val_mean_squared_error: 572097.2896\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 274842.2641 - mean_squared_error: 274842.2641 - val_loss: 571364.6842 - val_mean_squared_error: 571364.6842\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 274452.5628 - mean_squared_error: 274452.5628 - val_loss: 570620.6334 - val_mean_squared_error: 570620.6334\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 274055.7541 - mean_squared_error: 274055.7541 - val_loss: 569921.0815 - val_mean_squared_error: 569921.0815\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 273673.9058 - mean_squared_error: 273673.9058 - val_loss: 569186.0167 - val_mean_squared_error: 569186.0167\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 273276.8859 - mean_squared_error: 273276.8859 - val_loss: 568493.0982 - val_mean_squared_error: 568493.0982\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 272895.8619 - mean_squared_error: 272895.8619 - val_loss: 567790.6261 - val_mean_squared_error: 567790.6261\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 272502.3584 - mean_squared_error: 272502.3584 - val_loss: 567111.3583 - val_mean_squared_error: 567111.3583\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 272121.4388 - mean_squared_error: 272121.4388 - val_loss: 566405.9531 - val_mean_squared_error: 566405.9531\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 271735.0861 - mean_squared_error: 271735.0861 - val_loss: 565711.3097 - val_mean_squared_error: 565711.3097\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 271349.3631 - mean_squared_error: 271349.3631 - val_loss: 565024.5167 - val_mean_squared_error: 565024.5167\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 270970.1274 - mean_squared_error: 270970.1274 - val_loss: 564340.0631 - val_mean_squared_error: 564340.0631\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 270588.1369 - mean_squared_error: 270588.1369 - val_loss: 563660.0926 - val_mean_squared_error: 563660.0926\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 270207.5787 - mean_squared_error: 270207.5787 - val_loss: 562984.6992 - val_mean_squared_error: 562984.6992\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 269836.8731 - mean_squared_error: 269836.8731 - val_loss: 562301.9230 - val_mean_squared_error: 562301.9230\n",
      "Epoch 60/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 269451.6291 - mean_squared_error: 269451.6291 - val_loss: 561628.4782 - val_mean_squared_error: 561628.4782\n",
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 269078.3181 - mean_squared_error: 269078.3181 - val_loss: 560960.1200 - val_mean_squared_error: 560960.1200\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 268695.2292 - mean_squared_error: 268695.2292 - val_loss: 560289.2439 - val_mean_squared_error: 560289.2439\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 268320.9889 - mean_squared_error: 268320.9889 - val_loss: 559612.1864 - val_mean_squared_error: 559612.1864\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 267942.3673 - mean_squared_error: 267942.3673 - val_loss: 558961.5151 - val_mean_squared_error: 558961.5151\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 267568.8541 - mean_squared_error: 267568.8541 - val_loss: 558316.9900 - val_mean_squared_error: 558316.9900\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 267199.5559 - mean_squared_error: 267199.5559 - val_loss: 557665.4877 - val_mean_squared_error: 557665.4877\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 266818.5378 - mean_squared_error: 266818.5378 - val_loss: 557023.7232 - val_mean_squared_error: 557023.7232\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 266452.8431 - mean_squared_error: 266452.8431 - val_loss: 556363.1032 - val_mean_squared_error: 556363.1032\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 266076.5614 - mean_squared_error: 266076.5614 - val_loss: 555717.1518 - val_mean_squared_error: 555717.1518\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 265709.5714 - mean_squared_error: 265709.5714 - val_loss: 555066.8119 - val_mean_squared_error: 555066.8119\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 265338.5797 - mean_squared_error: 265338.5797 - val_loss: 554411.1373 - val_mean_squared_error: 554411.1373\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 264956.5017 - mean_squared_error: 264956.5017 - val_loss: 553773.4609 - val_mean_squared_error: 553773.4609\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 264580.9902 - mean_squared_error: 264580.9902 - val_loss: 553142.5765 - val_mean_squared_error: 553142.5765\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 264208.4047 - mean_squared_error: 264208.4047 - val_loss: 552506.1083 - val_mean_squared_error: 552506.1083\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 263839.3619 - mean_squared_error: 263839.3619 - val_loss: 551861.3767 - val_mean_squared_error: 551861.3767\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 263461.1606 - mean_squared_error: 263461.1606 - val_loss: 551234.6334 - val_mean_squared_error: 551234.6334\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 263097.2374 - mean_squared_error: 263097.2374 - val_loss: 550598.5781 - val_mean_squared_error: 550598.5781\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 262723.7911 - mean_squared_error: 262723.7911 - val_loss: 549964.1914 - val_mean_squared_error: 549964.1914\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 262355.0606 - mean_squared_error: 262355.0606 - val_loss: 549351.4727 - val_mean_squared_error: 549351.4727\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 261994.6552 - mean_squared_error: 261994.6552 - val_loss: 548715.5848 - val_mean_squared_error: 548715.5848\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 261620.6423 - mean_squared_error: 261620.6423 - val_loss: 548109.2824 - val_mean_squared_error: 548109.2824\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 261261.0450 - mean_squared_error: 261261.0450 - val_loss: 547498.0675 - val_mean_squared_error: 547498.0675\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 260889.7059 - mean_squared_error: 260889.7059 - val_loss: 546893.6295 - val_mean_squared_error: 546893.6295\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 260525.4191 - mean_squared_error: 260525.4191 - val_loss: 546281.1373 - val_mean_squared_error: 546281.1373\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 260159.9370 - mean_squared_error: 260159.9370 - val_loss: 545685.3410 - val_mean_squared_error: 545685.3410\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 259798.0453 - mean_squared_error: 259798.0453 - val_loss: 545082.2584 - val_mean_squared_error: 545082.2584\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 259438.8414 - mean_squared_error: 259438.8414 - val_loss: 544458.3477 - val_mean_squared_error: 544458.3477\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 259064.6409 - mean_squared_error: 259064.6409 - val_loss: 543872.3968 - val_mean_squared_error: 543872.3968\n",
      "Epoch 89/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 167us/step - loss: 258706.5709 - mean_squared_error: 258706.5709 - val_loss: 543264.3783 - val_mean_squared_error: 543264.3783\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 194us/step - loss: 258343.8108 - mean_squared_error: 258343.8108 - val_loss: 542658.8661 - val_mean_squared_error: 542658.8661\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 257980.8283 - mean_squared_error: 257980.8283 - val_loss: 542048.4660 - val_mean_squared_error: 542048.4660\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 257612.0986 - mean_squared_error: 257612.0986 - val_loss: 541476.0530 - val_mean_squared_error: 541476.0530\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 257264.8177 - mean_squared_error: 257264.8177 - val_loss: 540851.1451 - val_mean_squared_error: 540851.1451\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 256898.4370 - mean_squared_error: 256898.4370 - val_loss: 540238.1038 - val_mean_squared_error: 540238.1038\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 297us/step - loss: 256532.9380 - mean_squared_error: 256532.9380 - val_loss: 539659.0725 - val_mean_squared_error: 539659.0725\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 256174.4242 - mean_squared_error: 256174.4242 - val_loss: 539076.6602 - val_mean_squared_error: 539076.6602\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 255827.9970 - mean_squared_error: 255827.9970 - val_loss: 538459.8789 - val_mean_squared_error: 538459.8789\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 255455.4400 - mean_squared_error: 255455.4400 - val_loss: 537901.2355 - val_mean_squared_error: 537901.2355\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 255105.5705 - mean_squared_error: 255105.5705 - val_loss: 537319.4475 - val_mean_squared_error: 537319.4475\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 254754.7559 - mean_squared_error: 254754.7559 - val_loss: 536721.0776 - val_mean_squared_error: 536721.0776\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 254398.6134 - mean_squared_error: 254398.6134 - val_loss: 536139.6708 - val_mean_squared_error: 536139.6708\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 254041.6580 - mean_squared_error: 254041.6580 - val_loss: 535563.3220 - val_mean_squared_error: 535563.3220\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 253692.2478 - mean_squared_error: 253692.2478 - val_loss: 534953.7662 - val_mean_squared_error: 534953.7662\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 253327.5620 - mean_squared_error: 253327.5620 - val_loss: 534383.8951 - val_mean_squared_error: 534383.8951\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 252980.6958 - mean_squared_error: 252980.6958 - val_loss: 533798.5396 - val_mean_squared_error: 533798.5396\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 252621.4652 - mean_squared_error: 252621.4652 - val_loss: 533232.6730 - val_mean_squared_error: 533232.6730\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 252272.7005 - mean_squared_error: 252272.7005 - val_loss: 532646.3170 - val_mean_squared_error: 532646.3170\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 251918.5053 - mean_squared_error: 251918.5053 - val_loss: 532062.3945 - val_mean_squared_error: 532062.3945\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 251567.4311 - mean_squared_error: 251567.4311 - val_loss: 531478.6574 - val_mean_squared_error: 531478.6574\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 251209.9614 - mean_squared_error: 251209.9614 - val_loss: 530900.0965 - val_mean_squared_error: 530900.0965\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 250857.1942 - mean_squared_error: 250857.1942 - val_loss: 530328.7037 - val_mean_squared_error: 530328.7037\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 250501.2023 - mean_squared_error: 250501.2023 - val_loss: 529763.8610 - val_mean_squared_error: 529763.8610\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 250150.6231 - mean_squared_error: 250150.6231 - val_loss: 529182.5792 - val_mean_squared_error: 529182.5792\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 249787.3784 - mean_squared_error: 249787.3784 - val_loss: 528615.6384 - val_mean_squared_error: 528615.6384\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 249432.9358 - mean_squared_error: 249432.9358 - val_loss: 528025.5536 - val_mean_squared_error: 528025.5536\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 249069.2977 - mean_squared_error: 249069.2977 - val_loss: 527457.6055 - val_mean_squared_error: 527457.6055\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 248709.3148 - mean_squared_error: 248709.3148 - val_loss: 526868.5022 - val_mean_squared_error: 526868.5022\n",
      "Epoch 118/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 248344.3958 - mean_squared_error: 248344.3958 - val_loss: 526297.8527 - val_mean_squared_error: 526297.8527\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 247980.4342 - mean_squared_error: 247980.4342 - val_loss: 525729.0792 - val_mean_squared_error: 525729.0792\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 247621.9303 - mean_squared_error: 247621.9303 - val_loss: 525124.8956 - val_mean_squared_error: 525124.8956\n",
      "Epoch 121/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 247248.4412 - mean_squared_error: 247248.4412 - val_loss: 524566.0675 - val_mean_squared_error: 524566.0675\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 246880.9127 - mean_squared_error: 246880.9127 - val_loss: 524005.9732 - val_mean_squared_error: 524005.9732\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 246509.1447 - mean_squared_error: 246509.1447 - val_loss: 523454.2215 - val_mean_squared_error: 523454.2215\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 246145.7748 - mean_squared_error: 246145.7748 - val_loss: 522875.7517 - val_mean_squared_error: 522875.7517\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 245766.9303 - mean_squared_error: 245766.9303 - val_loss: 522306.2009 - val_mean_squared_error: 522306.2009\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 245398.7052 - mean_squared_error: 245398.7052 - val_loss: 521742.7405 - val_mean_squared_error: 521742.7405\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 245017.1558 - mean_squared_error: 245017.1558 - val_loss: 521164.2673 - val_mean_squared_error: 521164.2673\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 244637.2959 - mean_squared_error: 244637.2959 - val_loss: 520613.0318 - val_mean_squared_error: 520613.0318\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 244264.4600 - mean_squared_error: 244264.4600 - val_loss: 520021.0636 - val_mean_squared_error: 520021.0636\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 243877.5038 - mean_squared_error: 243877.5038 - val_loss: 519458.3929 - val_mean_squared_error: 519458.3929\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 243490.1778 - mean_squared_error: 243490.1778 - val_loss: 518901.0184 - val_mean_squared_error: 518901.0184\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 243107.7237 - mean_squared_error: 243107.7237 - val_loss: 518322.3164 - val_mean_squared_error: 518322.3164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 242715.6634 - mean_squared_error: 242715.6634 - val_loss: 517762.9258 - val_mean_squared_error: 517762.9258\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 242330.9198 - mean_squared_error: 242330.9198 - val_loss: 517222.5301 - val_mean_squared_error: 517222.5301\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 241945.0151 - mean_squared_error: 241945.0151 - val_loss: 516642.1920 - val_mean_squared_error: 516642.1920\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 241553.8994 - mean_squared_error: 241553.8994 - val_loss: 516091.1378 - val_mean_squared_error: 516091.1378\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 241170.0541 - mean_squared_error: 241170.0541 - val_loss: 515529.3610 - val_mean_squared_error: 515529.3610\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 240785.4204 - mean_squared_error: 240785.4204 - val_loss: 514965.6412 - val_mean_squared_error: 514965.6412\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 240397.6408 - mean_squared_error: 240397.6408 - val_loss: 514400.6155 - val_mean_squared_error: 514400.6155\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 240001.2941 - mean_squared_error: 240001.2941 - val_loss: 513859.2333 - val_mean_squared_error: 513859.2333\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 239625.4373 - mean_squared_error: 239625.4373 - val_loss: 513266.1501 - val_mean_squared_error: 513266.1501\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 239241.0888 - mean_squared_error: 239241.0888 - val_loss: 512688.8387 - val_mean_squared_error: 512688.8387\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 238868.8112 - mean_squared_error: 238868.8112 - val_loss: 512126.4107 - val_mean_squared_error: 512126.4107\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 238497.6994 - mean_squared_error: 238497.6994 - val_loss: 511550.8677 - val_mean_squared_error: 511550.8677\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 238135.9003 - mean_squared_error: 238135.9003 - val_loss: 510967.9113 - val_mean_squared_error: 510967.9113\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 237763.6866 - mean_squared_error: 237763.6866 - val_loss: 510389.0882 - val_mean_squared_error: 510389.0882\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 237403.1167 - mean_squared_error: 237403.1167 - val_loss: 509823.0262 - val_mean_squared_error: 509823.0262\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 237049.6277 - mean_squared_error: 237049.6277 - val_loss: 509238.7238 - val_mean_squared_error: 509238.7238\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 236690.9183 - mean_squared_error: 236690.9183 - val_loss: 508665.8839 - val_mean_squared_error: 508665.8839\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 236337.4981 - mean_squared_error: 236337.4981 - val_loss: 508080.1317 - val_mean_squared_error: 508080.1317\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 235992.8988 - mean_squared_error: 235992.8988 - val_loss: 507488.3158 - val_mean_squared_error: 507488.3158\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 235639.5044 - mean_squared_error: 235639.5044 - val_loss: 506927.4263 - val_mean_squared_error: 506927.4263\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 235296.2114 - mean_squared_error: 235296.2114 - val_loss: 506339.0318 - val_mean_squared_error: 506339.0318\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 234951.2305 - mean_squared_error: 234951.2305 - val_loss: 505778.4275 - val_mean_squared_error: 505778.4275\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 234605.6450 - mean_squared_error: 234605.6450 - val_loss: 505208.6618 - val_mean_squared_error: 505208.6618\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 234273.7445 - mean_squared_error: 234273.7445 - val_loss: 504622.5614 - val_mean_squared_error: 504622.5614\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 233931.1338 - mean_squared_error: 233931.1338 - val_loss: 504057.5407 - val_mean_squared_error: 504057.5407\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 233596.4845 - mean_squared_error: 233596.4845 - val_loss: 503473.8002 - val_mean_squared_error: 503473.8002\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 233252.7730 - mean_squared_error: 233252.7730 - val_loss: 502919.9180 - val_mean_squared_error: 502919.9180\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 232924.2301 - mean_squared_error: 232924.2301 - val_loss: 502345.4849 - val_mean_squared_error: 502345.4849\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 232592.1353 - mean_squared_error: 232592.1353 - val_loss: 501777.6239 - val_mean_squared_error: 501777.6239\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 232262.9783 - mean_squared_error: 232262.9783 - val_loss: 501208.5279 - val_mean_squared_error: 501208.5279\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 231929.2141 - mean_squared_error: 231929.2141 - val_loss: 500642.0536 - val_mean_squared_error: 500642.0536\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 231603.2673 - mean_squared_error: 231603.2673 - val_loss: 500064.7868 - val_mean_squared_error: 500064.7868\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 231271.1345 - mean_squared_error: 231271.1345 - val_loss: 499493.0619 - val_mean_squared_error: 499493.0619\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 230945.0305 - mean_squared_error: 230945.0305 - val_loss: 498920.0128 - val_mean_squared_error: 498920.0128\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 230619.5761 - mean_squared_error: 230619.5761 - val_loss: 498357.2679 - val_mean_squared_error: 498357.2679\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 230293.3384 - mean_squared_error: 230293.3384 - val_loss: 497810.2204 - val_mean_squared_error: 497810.2204\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 229987.1050 - mean_squared_error: 229987.1050 - val_loss: 497220.2104 - val_mean_squared_error: 497220.2104\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 229657.7886 - mean_squared_error: 229657.7886 - val_loss: 496673.3382 - val_mean_squared_error: 496673.3382\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 229334.3597 - mean_squared_error: 229334.3597 - val_loss: 496112.0033 - val_mean_squared_error: 496112.0033\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 229020.2186 - mean_squared_error: 229020.2186 - val_loss: 495546.8610 - val_mean_squared_error: 495546.8610\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 228701.1239 - mean_squared_error: 228701.1239 - val_loss: 494961.5352 - val_mean_squared_error: 494961.5352\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 228372.7158 - mean_squared_error: 228372.7158 - val_loss: 494416.3493 - val_mean_squared_error: 494416.3493\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 228064.5800 - mean_squared_error: 228064.5800 - val_loss: 493856.1122 - val_mean_squared_error: 493856.1122\n",
      "Epoch 176/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 227739.2167 - mean_squared_error: 227739.2167 - val_loss: 493283.3206 - val_mean_squared_error: 493283.3206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 227424.2897 - mean_squared_error: 227424.2897 - val_loss: 492734.9333 - val_mean_squared_error: 492734.9333\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 227107.5055 - mean_squared_error: 227107.5055 - val_loss: 492179.3245 - val_mean_squared_error: 492179.3245\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 226796.7764 - mean_squared_error: 226796.7764 - val_loss: 491608.7977 - val_mean_squared_error: 491608.7977\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 226489.8594 - mean_squared_error: 226489.8594 - val_loss: 491052.9166 - val_mean_squared_error: 491052.9166\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 226165.3212 - mean_squared_error: 226165.3212 - val_loss: 490497.9858 - val_mean_squared_error: 490497.9858\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 225849.4380 - mean_squared_error: 225849.4380 - val_loss: 489948.4180 - val_mean_squared_error: 489948.4180\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 225538.6506 - mean_squared_error: 225538.6506 - val_loss: 489391.5279 - val_mean_squared_error: 489391.5279\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 225232.0336 - mean_squared_error: 225232.0336 - val_loss: 488838.5340 - val_mean_squared_error: 488838.5340\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 224919.4547 - mean_squared_error: 224919.4547 - val_loss: 488297.0762 - val_mean_squared_error: 488297.0762\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 224614.5087 - mean_squared_error: 224614.5087 - val_loss: 487735.6889 - val_mean_squared_error: 487735.6889\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 224301.9244 - mean_squared_error: 224301.9244 - val_loss: 487170.0340 - val_mean_squared_error: 487170.0340\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 223983.4410 - mean_squared_error: 223983.4410 - val_loss: 486634.5366 - val_mean_squared_error: 486634.5366\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 223680.1458 - mean_squared_error: 223680.1458 - val_loss: 486088.5893 - val_mean_squared_error: 486088.5893\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 170us/step - loss: 223368.6570 - mean_squared_error: 223368.6570 - val_loss: 485542.8393 - val_mean_squared_error: 485542.8393\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 223067.7107 - mean_squared_error: 223067.7107 - val_loss: 484978.4464 - val_mean_squared_error: 484978.4464\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 222760.7174 - mean_squared_error: 222760.7174 - val_loss: 484424.8901 - val_mean_squared_error: 484424.8901\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 222452.4344 - mean_squared_error: 222452.4344 - val_loss: 483873.1515 - val_mean_squared_error: 483873.1515\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 222148.3647 - mean_squared_error: 222148.3647 - val_loss: 483330.2930 - val_mean_squared_error: 483330.2930\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 170us/step - loss: 221841.8519 - mean_squared_error: 221841.8519 - val_loss: 482810.1864 - val_mean_squared_error: 482810.1864\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 221546.4323 - mean_squared_error: 221546.4323 - val_loss: 482257.4076 - val_mean_squared_error: 482257.4076\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 221243.1453 - mean_squared_error: 221243.1453 - val_loss: 481717.2444 - val_mean_squared_error: 481717.2444\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 220942.9284 - mean_squared_error: 220942.9284 - val_loss: 481172.8694 - val_mean_squared_error: 481172.8694\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 220633.0521 - mean_squared_error: 220633.0521 - val_loss: 480661.2335 - val_mean_squared_error: 480661.2335\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 220347.9099 - mean_squared_error: 220347.9099 - val_loss: 480096.6738 - val_mean_squared_error: 480096.6738\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 220043.9009 - mean_squared_error: 220043.9009 - val_loss: 479547.8624 - val_mean_squared_error: 479547.8624\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 219744.4178 - mean_squared_error: 219744.4178 - val_loss: 479013.5896 - val_mean_squared_error: 479013.5896\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 219445.1080 - mean_squared_error: 219445.1080 - val_loss: 478481.7679 - val_mean_squared_error: 478481.7679\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 219154.7151 - mean_squared_error: 219154.7151 - val_loss: 477931.4344 - val_mean_squared_error: 477931.4344\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 218853.8188 - mean_squared_error: 218853.8188 - val_loss: 477401.1434 - val_mean_squared_error: 477401.1434\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 218549.6674 - mean_squared_error: 218549.6674 - val_loss: 476886.0095 - val_mean_squared_error: 476886.0095\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 218262.6366 - mean_squared_error: 218262.6366 - val_loss: 476346.2907 - val_mean_squared_error: 476346.2907\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 217967.5966 - mean_squared_error: 217967.5966 - val_loss: 475805.5388 - val_mean_squared_error: 475805.5388\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 217666.2864 - mean_squared_error: 217666.2864 - val_loss: 475268.3934 - val_mean_squared_error: 475268.3934\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 217371.7600 - mean_squared_error: 217371.7600 - val_loss: 474736.0391 - val_mean_squared_error: 474736.0391\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 217075.6142 - mean_squared_error: 217075.6142 - val_loss: 474208.8786 - val_mean_squared_error: 474208.8786\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 216787.3062 - mean_squared_error: 216787.3062 - val_loss: 473670.1359 - val_mean_squared_error: 473670.1359\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 216488.5133 - mean_squared_error: 216488.5133 - val_loss: 473130.4406 - val_mean_squared_error: 473130.4406\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 216185.0562 - mean_squared_error: 216185.0562 - val_loss: 472606.0271 - val_mean_squared_error: 472606.0271\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 215895.9773 - mean_squared_error: 215895.9773 - val_loss: 472074.3186 - val_mean_squared_error: 472074.3186\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 215600.6480 - mean_squared_error: 215600.6480 - val_loss: 471546.1839 - val_mean_squared_error: 471546.1839\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 215309.4207 - mean_squared_error: 215309.4207 - val_loss: 471006.3465 - val_mean_squared_error: 471006.3465\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 215017.3866 - mean_squared_error: 215017.3866 - val_loss: 470488.4068 - val_mean_squared_error: 470488.4068\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 214728.9325 - mean_squared_error: 214728.9325 - val_loss: 469960.9699 - val_mean_squared_error: 469960.9699\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 214434.8039 - mean_squared_error: 214434.8039 - val_loss: 469421.4810 - val_mean_squared_error: 469421.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 214137.7540 - mean_squared_error: 214137.7540 - val_loss: 468904.3270 - val_mean_squared_error: 468904.3270\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 213852.7244 - mean_squared_error: 213852.7244 - val_loss: 468364.7260 - val_mean_squared_error: 468364.7260\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 213557.0205 - mean_squared_error: 213557.0205 - val_loss: 467844.7754 - val_mean_squared_error: 467844.7754\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 213267.8523 - mean_squared_error: 213267.8523 - val_loss: 467316.0645 - val_mean_squared_error: 467316.0645\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 212981.8283 - mean_squared_error: 212981.8283 - val_loss: 466798.6903 - val_mean_squared_error: 466798.6903\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 212700.2389 - mean_squared_error: 212700.2389 - val_loss: 466261.6200 - val_mean_squared_error: 466261.6200\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 212406.2172 - mean_squared_error: 212406.2172 - val_loss: 465758.2257 - val_mean_squared_error: 465758.2257\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 212127.5724 - mean_squared_error: 212127.5724 - val_loss: 465234.0257 - val_mean_squared_error: 465234.0257\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 211844.0556 - mean_squared_error: 211844.0556 - val_loss: 464715.2592 - val_mean_squared_error: 464715.2592\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 211552.6667 - mean_squared_error: 211552.6667 - val_loss: 464206.2849 - val_mean_squared_error: 464206.2849\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 211279.0320 - mean_squared_error: 211279.0320 - val_loss: 463667.0686 - val_mean_squared_error: 463667.0686\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 210981.7672 - mean_squared_error: 210981.7672 - val_loss: 463161.3030 - val_mean_squared_error: 463161.3030\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 210703.4298 - mean_squared_error: 210703.4298 - val_loss: 462649.9540 - val_mean_squared_error: 462649.9540\n",
      "Epoch 234/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 210420.3317 - mean_squared_error: 210420.3317 - val_loss: 462119.9208 - val_mean_squared_error: 462119.9208\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 210132.2423 - mean_squared_error: 210132.2423 - val_loss: 461604.8278 - val_mean_squared_error: 461604.8278\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 209840.7216 - mean_squared_error: 209840.7216 - val_loss: 461089.7148 - val_mean_squared_error: 461089.7148\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 209560.1734 - mean_squared_error: 209560.1734 - val_loss: 460583.1844 - val_mean_squared_error: 460583.1844\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 209282.3358 - mean_squared_error: 209282.3358 - val_loss: 460072.7712 - val_mean_squared_error: 460072.7712\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 209003.8116 - mean_squared_error: 209003.8116 - val_loss: 459551.9824 - val_mean_squared_error: 459551.9824\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 208722.5380 - mean_squared_error: 208722.5380 - val_loss: 459046.9632 - val_mean_squared_error: 459046.9632\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 208444.5931 - mean_squared_error: 208444.5931 - val_loss: 458521.0806 - val_mean_squared_error: 458521.0806\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 208151.0854 - mean_squared_error: 208151.0854 - val_loss: 458021.0580 - val_mean_squared_error: 458021.0580\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 207877.9184 - mean_squared_error: 207877.9184 - val_loss: 457502.1652 - val_mean_squared_error: 457502.1652\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 207595.2277 - mean_squared_error: 207595.2277 - val_loss: 456985.5642 - val_mean_squared_error: 456985.5642\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 207312.5246 - mean_squared_error: 207312.5246 - val_loss: 456484.6440 - val_mean_squared_error: 456484.6440\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 207037.1398 - mean_squared_error: 207037.1398 - val_loss: 455972.0218 - val_mean_squared_error: 455972.0218\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 206759.9367 - mean_squared_error: 206759.9367 - val_loss: 455456.6719 - val_mean_squared_error: 455456.6719\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 206485.1625 - mean_squared_error: 206485.1625 - val_loss: 454958.1440 - val_mean_squared_error: 454958.1440\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 152us/step - loss: 206208.0037 - mean_squared_error: 206208.0037 - val_loss: 454441.4713 - val_mean_squared_error: 454441.4713\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 149us/step - loss: 205923.1616 - mean_squared_error: 205923.1616 - val_loss: 453929.8828 - val_mean_squared_error: 453929.8828\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b241051d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b241051cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее-3,  добавили reduce lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(360))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/250\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 305546.6778 - mean_squared_error: 305546.6778 - val_loss: 627535.6970 - val_mean_squared_error: 627535.6970\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 627535.69699, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_mse` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 304843.6303 - mean_squared_error: 304843.6303 - val_loss: 626293.5876 - val_mean_squared_error: 626293.5876\n",
      "\n",
      "Epoch 00002: val_loss improved from 627535.69699 to 626293.58761, saving model to test.hdf5\n",
      "Epoch 3/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 304071.3973 - mean_squared_error: 304071.3973 - val_loss: 625004.4950 - val_mean_squared_error: 625004.4950\n",
      "\n",
      "Epoch 00003: val_loss improved from 626293.58761 to 625004.49498, saving model to test.hdf5\n",
      "Epoch 4/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 303308.2286 - mean_squared_error: 303308.2286 - val_loss: 623702.4414 - val_mean_squared_error: 623702.4414\n",
      "\n",
      "Epoch 00004: val_loss improved from 625004.49498 to 623702.44141, saving model to test.hdf5\n",
      "Epoch 5/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 302530.1139 - mean_squared_error: 302530.1139 - val_loss: 622441.8733 - val_mean_squared_error: 622441.8733\n",
      "\n",
      "Epoch 00005: val_loss improved from 623702.44141 to 622441.87333, saving model to test.hdf5\n",
      "Epoch 6/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 301783.5953 - mean_squared_error: 301783.5953 - val_loss: 621186.9487 - val_mean_squared_error: 621186.9487\n",
      "\n",
      "Epoch 00006: val_loss improved from 622441.87333 to 621186.94866, saving model to test.hdf5\n",
      "Epoch 7/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 301026.0329 - mean_squared_error: 301026.0329 - val_loss: 619970.1657 - val_mean_squared_error: 619970.1657\n",
      "\n",
      "Epoch 00007: val_loss improved from 621186.94866 to 619970.16574, saving model to test.hdf5\n",
      "Epoch 8/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 300301.0636 - mean_squared_error: 300301.0636 - val_loss: 618761.0050 - val_mean_squared_error: 618761.0050\n",
      "\n",
      "Epoch 00008: val_loss improved from 619970.16574 to 618761.00502, saving model to test.hdf5\n",
      "Epoch 9/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 299587.2780 - mean_squared_error: 299587.2780 - val_loss: 617607.1724 - val_mean_squared_error: 617607.1724\n",
      "\n",
      "Epoch 00009: val_loss improved from 618761.00502 to 617607.17243, saving model to test.hdf5\n",
      "Epoch 10/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 298907.3294 - mean_squared_error: 298907.3294 - val_loss: 616493.6239 - val_mean_squared_error: 616493.6239\n",
      "\n",
      "Epoch 00010: val_loss improved from 617607.17243 to 616493.62388, saving model to test.hdf5\n",
      "Epoch 11/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 298253.6819 - mean_squared_error: 298253.6819 - val_loss: 615436.7935 - val_mean_squared_error: 615436.7935\n",
      "\n",
      "Epoch 00011: val_loss improved from 616493.62388 to 615436.79353, saving model to test.hdf5\n",
      "Epoch 12/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 297633.7991 - mean_squared_error: 297633.7991 - val_loss: 614432.0346 - val_mean_squared_error: 614432.0346\n",
      "\n",
      "Epoch 00012: val_loss improved from 615436.79353 to 614432.03460, saving model to test.hdf5\n",
      "Epoch 13/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 297048.0445 - mean_squared_error: 297048.0445 - val_loss: 613475.1501 - val_mean_squared_error: 613475.1501\n",
      "\n",
      "Epoch 00013: val_loss improved from 614432.03460 to 613475.15011, saving model to test.hdf5\n",
      "Epoch 14/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 296495.1309 - mean_squared_error: 296495.1309 - val_loss: 612554.9079 - val_mean_squared_error: 612554.9079\n",
      "\n",
      "Epoch 00014: val_loss improved from 613475.15011 to 612554.90792, saving model to test.hdf5\n",
      "Epoch 15/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 295955.9664 - mean_squared_error: 295955.9664 - val_loss: 611705.9381 - val_mean_squared_error: 611705.9381\n",
      "\n",
      "Epoch 00015: val_loss improved from 612554.90792 to 611705.93806, saving model to test.hdf5\n",
      "Epoch 16/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 295459.1955 - mean_squared_error: 295459.1955 - val_loss: 610875.9531 - val_mean_squared_error: 610875.9531\n",
      "\n",
      "Epoch 00016: val_loss improved from 611705.93806 to 610875.95312, saving model to test.hdf5\n",
      "Epoch 17/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 294973.2266 - mean_squared_error: 294973.2266 - val_loss: 610084.4900 - val_mean_squared_error: 610084.4900\n",
      "\n",
      "Epoch 00017: val_loss improved from 610875.95312 to 610084.48996, saving model to test.hdf5\n",
      "Epoch 18/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 294511.7556 - mean_squared_error: 294511.7556 - val_loss: 609320.5653 - val_mean_squared_error: 609320.5653\n",
      "\n",
      "Epoch 00018: val_loss improved from 610084.48996 to 609320.56529, saving model to test.hdf5\n",
      "Epoch 19/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 294071.4564 - mean_squared_error: 294071.4564 - val_loss: 608583.4576 - val_mean_squared_error: 608583.4576\n",
      "\n",
      "Epoch 00019: val_loss improved from 609320.56529 to 608583.45759, saving model to test.hdf5\n",
      "Epoch 20/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 293641.9844 - mean_squared_error: 293641.9844 - val_loss: 607881.3292 - val_mean_squared_error: 607881.3292\n",
      "\n",
      "Epoch 00020: val_loss improved from 608583.45759 to 607881.32924, saving model to test.hdf5\n",
      "Epoch 21/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 293234.3262 - mean_squared_error: 293234.3262 - val_loss: 607196.2790 - val_mean_squared_error: 607196.2790\n",
      "\n",
      "Epoch 00021: val_loss improved from 607881.32924 to 607196.27902, saving model to test.hdf5\n",
      "Epoch 22/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 292834.8569 - mean_squared_error: 292834.8569 - val_loss: 606538.6551 - val_mean_squared_error: 606538.6551\n",
      "\n",
      "Epoch 00022: val_loss improved from 607196.27902 to 606538.65513, saving model to test.hdf5\n",
      "Epoch 23/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 292457.1565 - mean_squared_error: 292457.1565 - val_loss: 605883.7176 - val_mean_squared_error: 605883.7176\n",
      "\n",
      "Epoch 00023: val_loss improved from 606538.65513 to 605883.71763, saving model to test.hdf5\n",
      "Epoch 24/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 292079.6069 - mean_squared_error: 292079.6069 - val_loss: 605255.5631 - val_mean_squared_error: 605255.5631\n",
      "\n",
      "Epoch 00024: val_loss improved from 605883.71763 to 605255.56306, saving model to test.hdf5\n",
      "Epoch 25/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 291710.9764 - mean_squared_error: 291710.9764 - val_loss: 604640.8376 - val_mean_squared_error: 604640.8376\n",
      "\n",
      "Epoch 00025: val_loss improved from 605255.56306 to 604640.83761, saving model to test.hdf5\n",
      "Epoch 26/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 291352.9761 - mean_squared_error: 291352.9761 - val_loss: 604024.9537 - val_mean_squared_error: 604024.9537\n",
      "\n",
      "Epoch 00026: val_loss improved from 604640.83761 to 604024.95368, saving model to test.hdf5\n",
      "Epoch 27/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 290996.0779 - mean_squared_error: 290996.0779 - val_loss: 603433.2059 - val_mean_squared_error: 603433.2059\n",
      "\n",
      "Epoch 00027: val_loss improved from 604024.95368 to 603433.20592, saving model to test.hdf5\n",
      "Epoch 28/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 290652.6037 - mean_squared_error: 290652.6037 - val_loss: 602855.3013 - val_mean_squared_error: 602855.3013\n",
      "\n",
      "Epoch 00028: val_loss improved from 603433.20592 to 602855.30134, saving model to test.hdf5\n",
      "Epoch 29/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 290314.6459 - mean_squared_error: 290314.6459 - val_loss: 602275.1434 - val_mean_squared_error: 602275.1434\n",
      "\n",
      "Epoch 00029: val_loss improved from 602855.30134 to 602275.14342, saving model to test.hdf5\n",
      "Epoch 30/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 289977.1009 - mean_squared_error: 289977.1009 - val_loss: 601708.6350 - val_mean_squared_error: 601708.6350\n",
      "\n",
      "Epoch 00030: val_loss improved from 602275.14342 to 601708.63504, saving model to test.hdf5\n",
      "Epoch 31/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 289654.2205 - mean_squared_error: 289654.2205 - val_loss: 601138.6267 - val_mean_squared_error: 601138.6267\n",
      "\n",
      "Epoch 00031: val_loss improved from 601708.63504 to 601138.62667, saving model to test.hdf5\n",
      "Epoch 32/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 289325.0509 - mean_squared_error: 289325.0509 - val_loss: 600592.5128 - val_mean_squared_error: 600592.5128\n",
      "\n",
      "Epoch 00032: val_loss improved from 601138.62667 to 600592.51283, saving model to test.hdf5\n",
      "Epoch 33/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 289007.3756 - mean_squared_error: 289007.3756 - val_loss: 600045.8510 - val_mean_squared_error: 600045.8510\n",
      "\n",
      "Epoch 00033: val_loss improved from 600592.51283 to 600045.85100, saving model to test.hdf5\n",
      "Epoch 34/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 288686.6789 - mean_squared_error: 288686.6789 - val_loss: 599509.0988 - val_mean_squared_error: 599509.0988\n",
      "\n",
      "Epoch 00034: val_loss improved from 600045.85100 to 599509.09877, saving model to test.hdf5\n",
      "Epoch 35/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 288375.4738 - mean_squared_error: 288375.4738 - val_loss: 598965.5346 - val_mean_squared_error: 598965.5346\n",
      "\n",
      "Epoch 00035: val_loss improved from 599509.09877 to 598965.53460, saving model to test.hdf5\n",
      "Epoch 36/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 288059.6378 - mean_squared_error: 288059.6378 - val_loss: 598430.3583 - val_mean_squared_error: 598430.3583\n",
      "\n",
      "Epoch 00036: val_loss improved from 598965.53460 to 598430.35826, saving model to test.hdf5\n",
      "Epoch 37/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 287746.9245 - mean_squared_error: 287746.9245 - val_loss: 597898.0184 - val_mean_squared_error: 597898.0184\n",
      "\n",
      "Epoch 00037: val_loss improved from 598430.35826 to 597898.01842, saving model to test.hdf5\n",
      "Epoch 38/250\n",
      "250/250 [==============================] - 0s 174us/step - loss: 287436.5453 - mean_squared_error: 287436.5453 - val_loss: 597365.0815 - val_mean_squared_error: 597365.0815\n",
      "\n",
      "Epoch 00038: val_loss improved from 597898.01842 to 597365.08147, saving model to test.hdf5\n",
      "Epoch 39/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 287129.6455 - mean_squared_error: 287129.6455 - val_loss: 596834.2640 - val_mean_squared_error: 596834.2640\n",
      "\n",
      "Epoch 00039: val_loss improved from 597365.08147 to 596834.26395, saving model to test.hdf5\n",
      "Epoch 40/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 286818.4103 - mean_squared_error: 286818.4103 - val_loss: 596320.9408 - val_mean_squared_error: 596320.9408\n",
      "\n",
      "Epoch 00040: val_loss improved from 596834.26395 to 596320.94085, saving model to test.hdf5\n",
      "Epoch 41/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 286519.2184 - mean_squared_error: 286519.2184 - val_loss: 595786.6283 - val_mean_squared_error: 595786.6283\n",
      "\n",
      "Epoch 00041: val_loss improved from 596320.94085 to 595786.62835, saving model to test.hdf5\n",
      "Epoch 42/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 286209.1537 - mean_squared_error: 286209.1537 - val_loss: 595264.8237 - val_mean_squared_error: 595264.8237\n",
      "\n",
      "Epoch 00042: val_loss improved from 595786.62835 to 595264.82366, saving model to test.hdf5\n",
      "Epoch 43/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 285906.4098 - mean_squared_error: 285906.4098 - val_loss: 594737.0586 - val_mean_squared_error: 594737.0586\n",
      "\n",
      "Epoch 00043: val_loss improved from 595264.82366 to 594737.05859, saving model to test.hdf5\n",
      "Epoch 44/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 285601.9275 - mean_squared_error: 285601.9275 - val_loss: 594216.6557 - val_mean_squared_error: 594216.6557\n",
      "\n",
      "Epoch 00044: val_loss improved from 594737.05859 to 594216.65569, saving model to test.hdf5\n",
      "Epoch 45/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 285299.4404 - mean_squared_error: 285299.4404 - val_loss: 593708.2221 - val_mean_squared_error: 593708.2221\n",
      "\n",
      "Epoch 00045: val_loss improved from 594216.65569 to 593708.22210, saving model to test.hdf5\n",
      "Epoch 46/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 285004.2577 - mean_squared_error: 285004.2577 - val_loss: 593195.2422 - val_mean_squared_error: 593195.2422\n",
      "\n",
      "Epoch 00046: val_loss improved from 593708.22210 to 593195.24219, saving model to test.hdf5\n",
      "Epoch 47/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 284710.0530 - mean_squared_error: 284710.0530 - val_loss: 592687.0452 - val_mean_squared_error: 592687.0452\n",
      "\n",
      "Epoch 00047: val_loss improved from 593195.24219 to 592687.04520, saving model to test.hdf5\n",
      "Epoch 48/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 284416.8061 - mean_squared_error: 284416.8061 - val_loss: 592184.2662 - val_mean_squared_error: 592184.2662\n",
      "\n",
      "Epoch 00048: val_loss improved from 592687.04520 to 592184.26618, saving model to test.hdf5\n",
      "Epoch 49/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 284127.6289 - mean_squared_error: 284127.6289 - val_loss: 591683.6825 - val_mean_squared_error: 591683.6825\n",
      "\n",
      "Epoch 00049: val_loss improved from 592184.26618 to 591683.68248, saving model to test.hdf5\n",
      "Epoch 50/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 283839.8903 - mean_squared_error: 283839.8903 - val_loss: 591189.6830 - val_mean_squared_error: 591189.6830\n",
      "\n",
      "Epoch 00050: val_loss improved from 591683.68248 to 591189.68304, saving model to test.hdf5\n",
      "Epoch 51/250\n",
      "250/250 [==============================] - 0s 168us/step - loss: 283551.4709 - mean_squared_error: 283551.4709 - val_loss: 590705.3583 - val_mean_squared_error: 590705.3583\n",
      "\n",
      "Epoch 00051: val_loss improved from 591189.68304 to 590705.35826, saving model to test.hdf5\n",
      "Epoch 52/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 283270.2797 - mean_squared_error: 283270.2797 - val_loss: 590209.5084 - val_mean_squared_error: 590209.5084\n",
      "\n",
      "Epoch 00052: val_loss improved from 590705.35826 to 590209.50837, saving model to test.hdf5\n",
      "Epoch 53/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 282989.0761 - mean_squared_error: 282989.0761 - val_loss: 589720.8410 - val_mean_squared_error: 589720.8410\n",
      "\n",
      "Epoch 00053: val_loss improved from 590209.50837 to 589720.84096, saving model to test.hdf5\n",
      "Epoch 54/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 282705.1272 - mean_squared_error: 282705.1272 - val_loss: 589243.9169 - val_mean_squared_error: 589243.9169\n",
      "\n",
      "Epoch 00054: val_loss improved from 589720.84096 to 589243.91685, saving model to test.hdf5\n",
      "Epoch 55/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 282429.8317 - mean_squared_error: 282429.8317 - val_loss: 588769.7059 - val_mean_squared_error: 588769.7059\n",
      "\n",
      "Epoch 00055: val_loss improved from 589243.91685 to 588769.70592, saving model to test.hdf5\n",
      "Epoch 56/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 282158.7730 - mean_squared_error: 282158.7730 - val_loss: 588289.8677 - val_mean_squared_error: 588289.8677\n",
      "\n",
      "Epoch 00056: val_loss improved from 588769.70592 to 588289.86775, saving model to test.hdf5\n",
      "Epoch 57/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 281879.1294 - mean_squared_error: 281879.1294 - val_loss: 587826.4939 - val_mean_squared_error: 587826.4939\n",
      "\n",
      "Epoch 00057: val_loss improved from 588289.86775 to 587826.49386, saving model to test.hdf5\n",
      "Epoch 58/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 281610.6030 - mean_squared_error: 281610.6030 - val_loss: 587349.2533 - val_mean_squared_error: 587349.2533\n",
      "\n",
      "Epoch 00058: val_loss improved from 587826.49386 to 587349.25335, saving model to test.hdf5\n",
      "Epoch 59/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 281339.4311 - mean_squared_error: 281339.4311 - val_loss: 586874.8895 - val_mean_squared_error: 586874.8895\n",
      "\n",
      "Epoch 00059: val_loss improved from 587349.25335 to 586874.88951, saving model to test.hdf5\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 157us/step - loss: 281062.8023 - mean_squared_error: 281062.8023 - val_loss: 586412.6942 - val_mean_squared_error: 586412.6942\n",
      "\n",
      "Epoch 00060: val_loss improved from 586874.88951 to 586412.69420, saving model to test.hdf5\n",
      "Epoch 61/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 280794.4551 - mean_squared_error: 280794.4551 - val_loss: 585939.4972 - val_mean_squared_error: 585939.4972\n",
      "\n",
      "Epoch 00061: val_loss improved from 586412.69420 to 585939.49721, saving model to test.hdf5\n",
      "Epoch 62/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 280521.2056 - mean_squared_error: 280521.2056 - val_loss: 585474.7126 - val_mean_squared_error: 585474.7126\n",
      "\n",
      "Epoch 00062: val_loss improved from 585939.49721 to 585474.71261, saving model to test.hdf5\n",
      "Epoch 63/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 280254.0186 - mean_squared_error: 280254.0186 - val_loss: 584996.4576 - val_mean_squared_error: 584996.4576\n",
      "\n",
      "Epoch 00063: val_loss improved from 585474.71261 to 584996.45759, saving model to test.hdf5\n",
      "Epoch 64/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 279977.2456 - mean_squared_error: 279977.2456 - val_loss: 584525.1356 - val_mean_squared_error: 584525.1356\n",
      "\n",
      "Epoch 00064: val_loss improved from 584996.45759 to 584525.13560, saving model to test.hdf5\n",
      "Epoch 65/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 279708.9714 - mean_squared_error: 279708.9714 - val_loss: 584042.6892 - val_mean_squared_error: 584042.6892\n",
      "\n",
      "Epoch 00065: val_loss improved from 584525.13560 to 584042.68917, saving model to test.hdf5\n",
      "Epoch 66/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 279428.1784 - mean_squared_error: 279428.1784 - val_loss: 583576.9475 - val_mean_squared_error: 583576.9475\n",
      "\n",
      "Epoch 00066: val_loss improved from 584042.68917 to 583576.94754, saving model to test.hdf5\n",
      "Epoch 67/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 279159.9844 - mean_squared_error: 279159.9844 - val_loss: 583090.8594 - val_mean_squared_error: 583090.8594\n",
      "\n",
      "Epoch 00067: val_loss improved from 583576.94754 to 583090.85938, saving model to test.hdf5\n",
      "Epoch 68/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 278880.2317 - mean_squared_error: 278880.2317 - val_loss: 582615.4671 - val_mean_squared_error: 582615.4671\n",
      "\n",
      "Epoch 00068: val_loss improved from 583090.85938 to 582615.46708, saving model to test.hdf5\n",
      "Epoch 69/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 278607.4776 - mean_squared_error: 278607.4776 - val_loss: 582131.8404 - val_mean_squared_error: 582131.8404\n",
      "\n",
      "Epoch 00069: val_loss improved from 582615.46708 to 582131.84040, saving model to test.hdf5\n",
      "Epoch 70/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 278324.3030 - mean_squared_error: 278324.3030 - val_loss: 581655.6110 - val_mean_squared_error: 581655.6110\n",
      "\n",
      "Epoch 00070: val_loss improved from 582131.84040 to 581655.61105, saving model to test.hdf5\n",
      "Epoch 71/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 278048.5084 - mean_squared_error: 278048.5084 - val_loss: 581165.7059 - val_mean_squared_error: 581165.7059\n",
      "\n",
      "Epoch 00071: val_loss improved from 581655.61105 to 581165.70592, saving model to test.hdf5\n",
      "Epoch 72/250\n",
      "250/250 [==============================] - 0s 182us/step - loss: 277774.6194 - mean_squared_error: 277774.6194 - val_loss: 580675.9079 - val_mean_squared_error: 580675.9079\n",
      "\n",
      "Epoch 00072: val_loss improved from 581165.70592 to 580675.90792, saving model to test.hdf5\n",
      "Epoch 73/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 277494.4423 - mean_squared_error: 277494.4423 - val_loss: 580201.3348 - val_mean_squared_error: 580201.3348\n",
      "\n",
      "Epoch 00073: val_loss improved from 580675.90792 to 580201.33482, saving model to test.hdf5\n",
      "Epoch 74/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 277217.9256 - mean_squared_error: 277217.9256 - val_loss: 579730.2517 - val_mean_squared_error: 579730.2517\n",
      "\n",
      "Epoch 00074: val_loss improved from 580201.33482 to 579730.25167, saving model to test.hdf5\n",
      "Epoch 75/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 276945.7853 - mean_squared_error: 276945.7853 - val_loss: 579245.8516 - val_mean_squared_error: 579245.8516\n",
      "\n",
      "Epoch 00075: val_loss improved from 579730.25167 to 579245.85156, saving model to test.hdf5\n",
      "Epoch 76/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 276669.9109 - mean_squared_error: 276669.9109 - val_loss: 578763.4330 - val_mean_squared_error: 578763.4330\n",
      "\n",
      "Epoch 00076: val_loss improved from 579245.85156 to 578763.43304, saving model to test.hdf5\n",
      "Epoch 77/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 276392.3986 - mean_squared_error: 276392.3986 - val_loss: 578280.1696 - val_mean_squared_error: 578280.1696\n",
      "\n",
      "Epoch 00077: val_loss improved from 578763.43304 to 578280.16964, saving model to test.hdf5\n",
      "Epoch 78/250\n",
      "250/250 [==============================] - 0s 270us/step - loss: 276116.7713 - mean_squared_error: 276116.7713 - val_loss: 577787.7656 - val_mean_squared_error: 577787.7656\n",
      "\n",
      "Epoch 00078: val_loss improved from 578280.16964 to 577787.76562, saving model to test.hdf5\n",
      "Epoch 79/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 275832.6375 - mean_squared_error: 275832.6375 - val_loss: 577306.7969 - val_mean_squared_error: 577306.7969\n",
      "\n",
      "Epoch 00079: val_loss improved from 577787.76562 to 577306.79688, saving model to test.hdf5\n",
      "Epoch 80/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 275552.8241 - mean_squared_error: 275552.8241 - val_loss: 576817.7048 - val_mean_squared_error: 576817.7048\n",
      "\n",
      "Epoch 00080: val_loss improved from 577306.79688 to 576817.70480, saving model to test.hdf5\n",
      "Epoch 81/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 275272.5517 - mean_squared_error: 275272.5517 - val_loss: 576323.9671 - val_mean_squared_error: 576323.9671\n",
      "\n",
      "Epoch 00081: val_loss improved from 576817.70480 to 576323.96708, saving model to test.hdf5\n",
      "Epoch 82/250\n",
      "250/250 [==============================] - 0s 176us/step - loss: 274986.5655 - mean_squared_error: 274986.5655 - val_loss: 575839.7785 - val_mean_squared_error: 575839.7785\n",
      "\n",
      "Epoch 00082: val_loss improved from 576323.96708 to 575839.77846, saving model to test.hdf5\n",
      "Epoch 83/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 274710.2922 - mean_squared_error: 274710.2922 - val_loss: 575331.9185 - val_mean_squared_error: 575331.9185\n",
      "\n",
      "Epoch 00083: val_loss improved from 575839.77846 to 575331.91853, saving model to test.hdf5\n",
      "Epoch 84/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 274424.7895 - mean_squared_error: 274424.7895 - val_loss: 574834.4470 - val_mean_squared_error: 574834.4470\n",
      "\n",
      "Epoch 00084: val_loss improved from 575331.91853 to 574834.44699, saving model to test.hdf5\n",
      "Epoch 85/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 274141.1163 - mean_squared_error: 274141.1163 - val_loss: 574344.6429 - val_mean_squared_error: 574344.6429\n",
      "\n",
      "Epoch 00085: val_loss improved from 574834.44699 to 574344.64286, saving model to test.hdf5\n",
      "Epoch 86/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 273858.2105 - mean_squared_error: 273858.2105 - val_loss: 573853.1289 - val_mean_squared_error: 573853.1289\n",
      "\n",
      "Epoch 00086: val_loss improved from 574344.64286 to 573853.12891, saving model to test.hdf5\n",
      "Epoch 87/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 273580.0950 - mean_squared_error: 273580.0950 - val_loss: 573354.8181 - val_mean_squared_error: 573354.8181\n",
      "\n",
      "Epoch 00087: val_loss improved from 573853.12891 to 573354.81808, saving model to test.hdf5\n",
      "Epoch 88/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 273295.3152 - mean_squared_error: 273295.3152 - val_loss: 572862.9699 - val_mean_squared_error: 572862.9699\n",
      "\n",
      "Epoch 00088: val_loss improved from 573354.81808 to 572862.96987, saving model to test.hdf5\n",
      "Epoch 89/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 273008.4770 - mean_squared_error: 273008.4770 - val_loss: 572375.2662 - val_mean_squared_error: 572375.2662\n",
      "\n",
      "Epoch 00089: val_loss improved from 572862.96987 to 572375.26618, saving model to test.hdf5\n",
      "Epoch 90/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 272728.9949 - mean_squared_error: 272728.9949 - val_loss: 571875.3309 - val_mean_squared_error: 571875.3309\n",
      "\n",
      "Epoch 00090: val_loss improved from 572375.26618 to 571875.33092, saving model to test.hdf5\n",
      "Epoch 91/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 272444.7714 - mean_squared_error: 272444.7714 - val_loss: 571391.1127 - val_mean_squared_error: 571391.1127\n",
      "\n",
      "Epoch 00091: val_loss improved from 571875.33092 to 571391.11272, saving model to test.hdf5\n",
      "Epoch 92/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 272172.1720 - mean_squared_error: 272172.1720 - val_loss: 570894.4224 - val_mean_squared_error: 570894.4224\n",
      "\n",
      "Epoch 00092: val_loss improved from 571391.11272 to 570894.42243, saving model to test.hdf5\n",
      "Epoch 93/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 271890.2303 - mean_squared_error: 271890.2303 - val_loss: 570422.1244 - val_mean_squared_error: 570422.1244\n",
      "\n",
      "Epoch 00093: val_loss improved from 570894.42243 to 570422.12444, saving model to test.hdf5\n",
      "Epoch 94/250\n",
      "250/250 [==============================] - 0s 190us/step - loss: 271620.3617 - mean_squared_error: 271620.3617 - val_loss: 569946.0709 - val_mean_squared_error: 569946.0709\n",
      "\n",
      "Epoch 00094: val_loss improved from 570422.12444 to 569946.07087, saving model to test.hdf5\n",
      "Epoch 95/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 271351.6183 - mean_squared_error: 271351.6183 - val_loss: 569468.1786 - val_mean_squared_error: 569468.1786\n",
      "\n",
      "Epoch 00095: val_loss improved from 569946.07087 to 569468.17857, saving model to test.hdf5\n",
      "Epoch 96/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 271080.2184 - mean_squared_error: 271080.2184 - val_loss: 568997.2556 - val_mean_squared_error: 568997.2556\n",
      "\n",
      "Epoch 00096: val_loss improved from 569468.17857 to 568997.25558, saving model to test.hdf5\n",
      "Epoch 97/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 270810.8402 - mean_squared_error: 270810.8402 - val_loss: 568531.4994 - val_mean_squared_error: 568531.4994\n",
      "\n",
      "Epoch 00097: val_loss improved from 568997.25558 to 568531.49944, saving model to test.hdf5\n",
      "Epoch 98/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 270544.0609 - mean_squared_error: 270544.0609 - val_loss: 568054.7026 - val_mean_squared_error: 568054.7026\n",
      "\n",
      "Epoch 00098: val_loss improved from 568531.49944 to 568054.70257, saving model to test.hdf5\n",
      "Epoch 99/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 270273.1066 - mean_squared_error: 270273.1066 - val_loss: 567576.2796 - val_mean_squared_error: 567576.2796\n",
      "\n",
      "Epoch 00099: val_loss improved from 568054.70257 to 567576.27958, saving model to test.hdf5\n",
      "Epoch 100/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 270002.4739 - mean_squared_error: 270002.4739 - val_loss: 567104.9448 - val_mean_squared_error: 567104.9448\n",
      "\n",
      "Epoch 00100: val_loss improved from 567576.27958 to 567104.94475, saving model to test.hdf5\n",
      "Epoch 101/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 269734.1273 - mean_squared_error: 269734.1273 - val_loss: 566631.4163 - val_mean_squared_error: 566631.4163\n",
      "\n",
      "Epoch 00101: val_loss improved from 567104.94475 to 566631.41629, saving model to test.hdf5\n",
      "Epoch 102/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 269461.9950 - mean_squared_error: 269461.9950 - val_loss: 566171.5028 - val_mean_squared_error: 566171.5028\n",
      "\n",
      "Epoch 00102: val_loss improved from 566631.41629 to 566171.50279, saving model to test.hdf5\n",
      "Epoch 103/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 269201.0662 - mean_squared_error: 269201.0662 - val_loss: 565700.4799 - val_mean_squared_error: 565700.4799\n",
      "\n",
      "Epoch 00103: val_loss improved from 566171.50279 to 565700.47991, saving model to test.hdf5\n",
      "Epoch 104/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 268934.3681 - mean_squared_error: 268934.3681 - val_loss: 565252.9459 - val_mean_squared_error: 565252.9459\n",
      "\n",
      "Epoch 00104: val_loss improved from 565700.47991 to 565252.94587, saving model to test.hdf5\n",
      "Epoch 105/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 268678.7725 - mean_squared_error: 268678.7725 - val_loss: 564799.1267 - val_mean_squared_error: 564799.1267\n",
      "\n",
      "Epoch 00105: val_loss improved from 565252.94587 to 564799.12667, saving model to test.hdf5\n",
      "Epoch 106/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 268420.2791 - mean_squared_error: 268420.2791 - val_loss: 564347.1819 - val_mean_squared_error: 564347.1819\n",
      "\n",
      "Epoch 00106: val_loss improved from 564799.12667 to 564347.18192, saving model to test.hdf5\n",
      "Epoch 107/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 268164.1713 - mean_squared_error: 268164.1713 - val_loss: 563891.4414 - val_mean_squared_error: 563891.4414\n",
      "\n",
      "Epoch 00107: val_loss improved from 564347.18192 to 563891.44141, saving model to test.hdf5\n",
      "Epoch 108/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 267905.2162 - mean_squared_error: 267905.2162 - val_loss: 563439.9403 - val_mean_squared_error: 563439.9403\n",
      "\n",
      "Epoch 00108: val_loss improved from 563891.44141 to 563439.94029, saving model to test.hdf5\n",
      "Epoch 109/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 267648.5742 - mean_squared_error: 267648.5742 - val_loss: 562990.8097 - val_mean_squared_error: 562990.8097\n",
      "\n",
      "Epoch 00109: val_loss improved from 563439.94029 to 562990.80971, saving model to test.hdf5\n",
      "Epoch 110/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 267393.9380 - mean_squared_error: 267393.9380 - val_loss: 562534.4526 - val_mean_squared_error: 562534.4526\n",
      "\n",
      "Epoch 00110: val_loss improved from 562990.80971 to 562534.45257, saving model to test.hdf5\n",
      "Epoch 111/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 267133.3206 - mean_squared_error: 267133.3206 - val_loss: 562093.2015 - val_mean_squared_error: 562093.2015\n",
      "\n",
      "Epoch 00111: val_loss improved from 562534.45257 to 562093.20145, saving model to test.hdf5\n",
      "Epoch 112/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 266883.5596 - mean_squared_error: 266883.5596 - val_loss: 561638.9129 - val_mean_squared_error: 561638.9129\n",
      "\n",
      "Epoch 00112: val_loss improved from 562093.20145 to 561638.91295, saving model to test.hdf5\n",
      "Epoch 113/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 266621.5777 - mean_squared_error: 266621.5777 - val_loss: 561204.2679 - val_mean_squared_error: 561204.2679\n",
      "\n",
      "Epoch 00113: val_loss improved from 561638.91295 to 561204.26786, saving model to test.hdf5\n",
      "Epoch 114/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 266373.2167 - mean_squared_error: 266373.2167 - val_loss: 560756.2093 - val_mean_squared_error: 560756.2093\n",
      "\n",
      "Epoch 00114: val_loss improved from 561204.26786 to 560756.20926, saving model to test.hdf5\n",
      "Epoch 115/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 266119.1420 - mean_squared_error: 266119.1420 - val_loss: 560315.6055 - val_mean_squared_error: 560315.6055\n",
      "\n",
      "Epoch 00115: val_loss improved from 560756.20926 to 560315.60547, saving model to test.hdf5\n",
      "Epoch 116/250\n",
      "250/250 [==============================] - 0s 158us/step - loss: 265864.0205 - mean_squared_error: 265864.0205 - val_loss: 559871.1920 - val_mean_squared_error: 559871.1920\n",
      "\n",
      "Epoch 00116: val_loss improved from 560315.60547 to 559871.19196, saving model to test.hdf5\n",
      "Epoch 117/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 265606.5991 - mean_squared_error: 265606.5991 - val_loss: 559415.2550 - val_mean_squared_error: 559415.2550\n",
      "\n",
      "Epoch 00117: val_loss improved from 559871.19196 to 559415.25502, saving model to test.hdf5\n",
      "Epoch 118/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 163us/step - loss: 265348.1313 - mean_squared_error: 265348.1313 - val_loss: 558961.7606 - val_mean_squared_error: 558961.7606\n",
      "\n",
      "Epoch 00118: val_loss improved from 559415.25502 to 558961.76060, saving model to test.hdf5\n",
      "Epoch 119/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 265089.3589 - mean_squared_error: 265089.3589 - val_loss: 558511.9269 - val_mean_squared_error: 558511.9269\n",
      "\n",
      "Epoch 00119: val_loss improved from 558961.76060 to 558511.92690, saving model to test.hdf5\n",
      "Epoch 120/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 264832.3937 - mean_squared_error: 264832.3937 - val_loss: 558062.1596 - val_mean_squared_error: 558062.1596\n",
      "\n",
      "Epoch 00120: val_loss improved from 558511.92690 to 558062.15960, saving model to test.hdf5\n",
      "Epoch 121/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 264574.8442 - mean_squared_error: 264574.8442 - val_loss: 557611.2667 - val_mean_squared_error: 557611.2667\n",
      "\n",
      "Epoch 00121: val_loss improved from 558062.15960 to 557611.26674, saving model to test.hdf5\n",
      "Epoch 122/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 264313.7179 - mean_squared_error: 264313.7179 - val_loss: 557160.2684 - val_mean_squared_error: 557160.2684\n",
      "\n",
      "Epoch 00122: val_loss improved from 557611.26674 to 557160.26842, saving model to test.hdf5\n",
      "Epoch 123/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 264055.7400 - mean_squared_error: 264055.7400 - val_loss: 556703.8929 - val_mean_squared_error: 556703.8929\n",
      "\n",
      "Epoch 00123: val_loss improved from 557160.26842 to 556703.89286, saving model to test.hdf5\n",
      "Epoch 124/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 263798.2552 - mean_squared_error: 263798.2552 - val_loss: 556249.3265 - val_mean_squared_error: 556249.3265\n",
      "\n",
      "Epoch 00124: val_loss improved from 556703.89286 to 556249.32645, saving model to test.hdf5\n",
      "Epoch 125/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 263534.8387 - mean_squared_error: 263534.8387 - val_loss: 555812.1300 - val_mean_squared_error: 555812.1300\n",
      "\n",
      "Epoch 00125: val_loss improved from 556249.32645 to 555812.13002, saving model to test.hdf5\n",
      "Epoch 126/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 263278.1065 - mean_squared_error: 263278.1065 - val_loss: 555357.2969 - val_mean_squared_error: 555357.2969\n",
      "\n",
      "Epoch 00126: val_loss improved from 555812.13002 to 555357.29688, saving model to test.hdf5\n",
      "Epoch 127/250\n",
      "250/250 [==============================] - 0s 155us/step - loss: 263020.5098 - mean_squared_error: 263020.5098 - val_loss: 554881.4470 - val_mean_squared_error: 554881.4470\n",
      "\n",
      "Epoch 00127: val_loss improved from 555357.29688 to 554881.44699, saving model to test.hdf5\n",
      "Epoch 128/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 262752.5719 - mean_squared_error: 262752.5719 - val_loss: 554428.4431 - val_mean_squared_error: 554428.4431\n",
      "\n",
      "Epoch 00128: val_loss improved from 554881.44699 to 554428.44308, saving model to test.hdf5\n",
      "Epoch 129/250\n",
      "250/250 [==============================] - 0s 153us/step - loss: 262494.2636 - mean_squared_error: 262494.2636 - val_loss: 553979.9163 - val_mean_squared_error: 553979.9163\n",
      "\n",
      "Epoch 00129: val_loss improved from 554428.44308 to 553979.91629, saving model to test.hdf5\n",
      "Epoch 130/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 262238.2549 - mean_squared_error: 262238.2549 - val_loss: 553538.0335 - val_mean_squared_error: 553538.0335\n",
      "\n",
      "Epoch 00130: val_loss improved from 553979.91629 to 553538.03348, saving model to test.hdf5\n",
      "Epoch 131/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 261980.5598 - mean_squared_error: 261980.5598 - val_loss: 553108.0407 - val_mean_squared_error: 553108.0407\n",
      "\n",
      "Epoch 00131: val_loss improved from 553538.03348 to 553108.04074, saving model to test.hdf5\n",
      "Epoch 132/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 261729.1389 - mean_squared_error: 261729.1389 - val_loss: 552668.8761 - val_mean_squared_error: 552668.8761\n",
      "\n",
      "Epoch 00132: val_loss improved from 553108.04074 to 552668.87612, saving model to test.hdf5\n",
      "Epoch 133/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 261476.7642 - mean_squared_error: 261476.7642 - val_loss: 552228.6311 - val_mean_squared_error: 552228.6311\n",
      "\n",
      "Epoch 00133: val_loss improved from 552668.87612 to 552228.63114, saving model to test.hdf5\n",
      "Epoch 134/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 261227.7405 - mean_squared_error: 261227.7405 - val_loss: 551780.9403 - val_mean_squared_error: 551780.9403\n",
      "\n",
      "Epoch 00134: val_loss improved from 552228.63114 to 551780.94029, saving model to test.hdf5\n",
      "Epoch 135/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 260971.6864 - mean_squared_error: 260971.6864 - val_loss: 551339.1864 - val_mean_squared_error: 551339.1864\n",
      "\n",
      "Epoch 00135: val_loss improved from 551780.94029 to 551339.18638, saving model to test.hdf5\n",
      "Epoch 136/250\n",
      "250/250 [==============================] - 0s 151us/step - loss: 260718.6148 - mean_squared_error: 260718.6148 - val_loss: 550901.5675 - val_mean_squared_error: 550901.5675\n",
      "\n",
      "Epoch 00136: val_loss improved from 551339.18638 to 550901.56752, saving model to test.hdf5\n",
      "Epoch 137/250\n",
      "250/250 [==============================] - 0s 154us/step - loss: 260467.0944 - mean_squared_error: 260467.0944 - val_loss: 550464.6964 - val_mean_squared_error: 550464.6964\n",
      "\n",
      "Epoch 00137: val_loss improved from 550901.56752 to 550464.69643, saving model to test.hdf5\n",
      "Epoch 138/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 260214.9375 - mean_squared_error: 260214.9375 - val_loss: 550030.3811 - val_mean_squared_error: 550030.3811\n",
      "\n",
      "Epoch 00138: val_loss improved from 550464.69643 to 550030.38114, saving model to test.hdf5\n",
      "Epoch 139/250\n",
      "250/250 [==============================] - 0s 187us/step - loss: 259964.7284 - mean_squared_error: 259964.7284 - val_loss: 549595.4141 - val_mean_squared_error: 549595.4141\n",
      "\n",
      "Epoch 00139: val_loss improved from 550030.38114 to 549595.41406, saving model to test.hdf5\n",
      "Epoch 140/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 259717.4823 - mean_squared_error: 259717.4823 - val_loss: 549159.3968 - val_mean_squared_error: 549159.3968\n",
      "\n",
      "Epoch 00140: val_loss improved from 549595.41406 to 549159.39676, saving model to test.hdf5\n",
      "Epoch 141/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 259466.1928 - mean_squared_error: 259466.1928 - val_loss: 548726.3516 - val_mean_squared_error: 548726.3516\n",
      "\n",
      "Epoch 00141: val_loss improved from 549159.39676 to 548726.35156, saving model to test.hdf5\n",
      "Epoch 142/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 259214.4995 - mean_squared_error: 259214.4995 - val_loss: 548302.0363 - val_mean_squared_error: 548302.0363\n",
      "\n",
      "Epoch 00142: val_loss improved from 548726.35156 to 548302.03627, saving model to test.hdf5\n",
      "Epoch 143/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 258969.1487 - mean_squared_error: 258969.1487 - val_loss: 547864.7160 - val_mean_squared_error: 547864.7160\n",
      "\n",
      "Epoch 00143: val_loss improved from 548302.03627 to 547864.71596, saving model to test.hdf5\n",
      "Epoch 144/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 258716.2052 - mean_squared_error: 258716.2052 - val_loss: 547433.6339 - val_mean_squared_error: 547433.6339\n",
      "\n",
      "Epoch 00144: val_loss improved from 547864.71596 to 547433.63393, saving model to test.hdf5\n",
      "Epoch 145/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 258469.6181 - mean_squared_error: 258469.6181 - val_loss: 546993.9894 - val_mean_squared_error: 546993.9894\n",
      "\n",
      "Epoch 00145: val_loss improved from 547433.63393 to 546993.98940, saving model to test.hdf5\n",
      "Epoch 146/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 258221.9825 - mean_squared_error: 258221.9825 - val_loss: 546555.3281 - val_mean_squared_error: 546555.3281\n",
      "\n",
      "Epoch 00146: val_loss improved from 546993.98940 to 546555.32812, saving model to test.hdf5\n",
      "Epoch 147/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 257971.6972 - mean_squared_error: 257971.6972 - val_loss: 546133.3086 - val_mean_squared_error: 546133.3086\n",
      "\n",
      "Epoch 00147: val_loss improved from 546555.32812 to 546133.30859, saving model to test.hdf5\n",
      "Epoch 148/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 257726.3528 - mean_squared_error: 257726.3528 - val_loss: 545709.6440 - val_mean_squared_error: 545709.6440\n",
      "\n",
      "Epoch 00148: val_loss improved from 546133.30859 to 545709.64397, saving model to test.hdf5\n",
      "Epoch 149/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 257481.3272 - mean_squared_error: 257481.3272 - val_loss: 545279.3097 - val_mean_squared_error: 545279.3097\n",
      "\n",
      "Epoch 00149: val_loss improved from 545709.64397 to 545279.30971, saving model to test.hdf5\n",
      "Epoch 150/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 257232.2016 - mean_squared_error: 257232.2016 - val_loss: 544859.0067 - val_mean_squared_error: 544859.0067\n",
      "\n",
      "Epoch 00150: val_loss improved from 545279.30971 to 544859.00670, saving model to test.hdf5\n",
      "Epoch 151/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 256988.8480 - mean_squared_error: 256988.8480 - val_loss: 544426.5965 - val_mean_squared_error: 544426.5965\n",
      "\n",
      "Epoch 00151: val_loss improved from 544859.00670 to 544426.59654, saving model to test.hdf5\n",
      "Epoch 152/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 256743.4595 - mean_squared_error: 256743.4595 - val_loss: 543990.3912 - val_mean_squared_error: 543990.3912\n",
      "\n",
      "Epoch 00152: val_loss improved from 544426.59654 to 543990.39118, saving model to test.hdf5\n",
      "Epoch 153/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 256493.8499 - mean_squared_error: 256493.8499 - val_loss: 543568.5898 - val_mean_squared_error: 543568.5898\n",
      "\n",
      "Epoch 00153: val_loss improved from 543990.39118 to 543568.58984, saving model to test.hdf5\n",
      "Epoch 154/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 256249.6562 - mean_squared_error: 256249.6562 - val_loss: 543136.8778 - val_mean_squared_error: 543136.8778\n",
      "\n",
      "Epoch 00154: val_loss improved from 543568.58984 to 543136.87779, saving model to test.hdf5\n",
      "Epoch 155/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 256003.0234 - mean_squared_error: 256003.0234 - val_loss: 542702.8125 - val_mean_squared_error: 542702.8125\n",
      "\n",
      "Epoch 00155: val_loss improved from 543136.87779 to 542702.81250, saving model to test.hdf5\n",
      "Epoch 156/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 255758.2595 - mean_squared_error: 255758.2595 - val_loss: 542277.9007 - val_mean_squared_error: 542277.9007\n",
      "\n",
      "Epoch 00156: val_loss improved from 542702.81250 to 542277.90067, saving model to test.hdf5\n",
      "Epoch 157/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 255513.9047 - mean_squared_error: 255513.9047 - val_loss: 541868.4392 - val_mean_squared_error: 541868.4392\n",
      "\n",
      "Epoch 00157: val_loss improved from 542277.90067 to 541868.43917, saving model to test.hdf5\n",
      "Epoch 158/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 255273.9570 - mean_squared_error: 255273.9570 - val_loss: 541448.5759 - val_mean_squared_error: 541448.5759\n",
      "\n",
      "Epoch 00158: val_loss improved from 541868.43917 to 541448.57589, saving model to test.hdf5\n",
      "Epoch 159/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 255030.0508 - mean_squared_error: 255030.0508 - val_loss: 541020.8638 - val_mean_squared_error: 541020.8638\n",
      "\n",
      "Epoch 00159: val_loss improved from 541448.57589 to 541020.86384, saving model to test.hdf5\n",
      "Epoch 160/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 254783.3797 - mean_squared_error: 254783.3797 - val_loss: 540599.3906 - val_mean_squared_error: 540599.3906\n",
      "\n",
      "Epoch 00160: val_loss improved from 541020.86384 to 540599.39062, saving model to test.hdf5\n",
      "Epoch 161/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 254541.9255 - mean_squared_error: 254541.9255 - val_loss: 540172.4381 - val_mean_squared_error: 540172.4381\n",
      "\n",
      "Epoch 00161: val_loss improved from 540599.39062 to 540172.43806, saving model to test.hdf5\n",
      "Epoch 162/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 254303.3944 - mean_squared_error: 254303.3944 - val_loss: 539735.9883 - val_mean_squared_error: 539735.9883\n",
      "\n",
      "Epoch 00162: val_loss improved from 540172.43806 to 539735.98828, saving model to test.hdf5\n",
      "Epoch 163/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 254054.8707 - mean_squared_error: 254054.8707 - val_loss: 539319.2573 - val_mean_squared_error: 539319.2573\n",
      "\n",
      "Epoch 00163: val_loss improved from 539735.98828 to 539319.25725, saving model to test.hdf5\n",
      "Epoch 164/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 253817.1400 - mean_squared_error: 253817.1400 - val_loss: 538892.3114 - val_mean_squared_error: 538892.3114\n",
      "\n",
      "Epoch 00164: val_loss improved from 539319.25725 to 538892.31138, saving model to test.hdf5\n",
      "Epoch 165/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 253576.5088 - mean_squared_error: 253576.5088 - val_loss: 538464.1814 - val_mean_squared_error: 538464.1814\n",
      "\n",
      "Epoch 00165: val_loss improved from 538892.31138 to 538464.18136, saving model to test.hdf5\n",
      "Epoch 166/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 253332.9866 - mean_squared_error: 253332.9866 - val_loss: 538050.3008 - val_mean_squared_error: 538050.3008\n",
      "\n",
      "Epoch 00166: val_loss improved from 538464.18136 to 538050.30078, saving model to test.hdf5\n",
      "Epoch 167/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 253093.5799 - mean_squared_error: 253093.5799 - val_loss: 537629.1819 - val_mean_squared_error: 537629.1819\n",
      "\n",
      "Epoch 00167: val_loss improved from 538050.30078 to 537629.18192, saving model to test.hdf5\n",
      "Epoch 168/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 252855.8048 - mean_squared_error: 252855.8048 - val_loss: 537209.6032 - val_mean_squared_error: 537209.6032\n",
      "\n",
      "Epoch 00168: val_loss improved from 537629.18192 to 537209.60324, saving model to test.hdf5\n",
      "Epoch 169/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 252615.2849 - mean_squared_error: 252615.2849 - val_loss: 536795.6613 - val_mean_squared_error: 536795.6613\n",
      "\n",
      "Epoch 00169: val_loss improved from 537209.60324 to 536795.66127, saving model to test.hdf5\n",
      "Epoch 170/250\n",
      "250/250 [==============================] - 0s 164us/step - loss: 252377.6922 - mean_squared_error: 252377.6922 - val_loss: 536371.5631 - val_mean_squared_error: 536371.5631\n",
      "\n",
      "Epoch 00170: val_loss improved from 536795.66127 to 536371.56306, saving model to test.hdf5\n",
      "Epoch 171/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 252135.6195 - mean_squared_error: 252135.6195 - val_loss: 535961.3800 - val_mean_squared_error: 535961.3800\n",
      "\n",
      "Epoch 00171: val_loss improved from 536371.56306 to 535961.38002, saving model to test.hdf5\n",
      "Epoch 172/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 251898.2236 - mean_squared_error: 251898.2236 - val_loss: 535539.5419 - val_mean_squared_error: 535539.5419\n",
      "\n",
      "Epoch 00172: val_loss improved from 535961.38002 to 535539.54185, saving model to test.hdf5\n",
      "Epoch 173/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 251655.3458 - mean_squared_error: 251655.3458 - val_loss: 535122.4978 - val_mean_squared_error: 535122.4978\n",
      "\n",
      "Epoch 00173: val_loss improved from 535539.54185 to 535122.49777, saving model to test.hdf5\n",
      "Epoch 174/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 251416.8375 - mean_squared_error: 251416.8375 - val_loss: 534716.0943 - val_mean_squared_error: 534716.0943\n",
      "\n",
      "Epoch 00174: val_loss improved from 535122.49777 to 534716.09431, saving model to test.hdf5\n",
      "Epoch 175/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 251183.0180 - mean_squared_error: 251183.0180 - val_loss: 534296.2394 - val_mean_squared_error: 534296.2394\n",
      "\n",
      "Epoch 00175: val_loss improved from 534716.09431 to 534296.23940, saving model to test.hdf5\n",
      "Epoch 176/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 169us/step - loss: 250948.7034 - mean_squared_error: 250948.7034 - val_loss: 533872.0318 - val_mean_squared_error: 533872.0318\n",
      "\n",
      "Epoch 00176: val_loss improved from 534296.23940 to 533872.03181, saving model to test.hdf5\n",
      "Epoch 177/250\n",
      "250/250 [==============================] - 0s 166us/step - loss: 250706.6903 - mean_squared_error: 250706.6903 - val_loss: 533464.0011 - val_mean_squared_error: 533464.0011\n",
      "\n",
      "Epoch 00177: val_loss improved from 533872.03181 to 533464.00112, saving model to test.hdf5\n",
      "Epoch 178/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 250473.4518 - mean_squared_error: 250473.4518 - val_loss: 533042.9157 - val_mean_squared_error: 533042.9157\n",
      "\n",
      "Epoch 00178: val_loss improved from 533464.00112 to 533042.91574, saving model to test.hdf5\n",
      "Epoch 179/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 250232.5464 - mean_squared_error: 250232.5464 - val_loss: 532634.0971 - val_mean_squared_error: 532634.0971\n",
      "\n",
      "Epoch 00179: val_loss improved from 533042.91574 to 532634.09710, saving model to test.hdf5\n",
      "Epoch 180/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 249999.0544 - mean_squared_error: 249999.0544 - val_loss: 532224.6032 - val_mean_squared_error: 532224.6032\n",
      "\n",
      "Epoch 00180: val_loss improved from 532634.09710 to 532224.60324, saving model to test.hdf5\n",
      "Epoch 181/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 249763.3463 - mean_squared_error: 249763.3463 - val_loss: 531812.1055 - val_mean_squared_error: 531812.1055\n",
      "\n",
      "Epoch 00181: val_loss improved from 532224.60324 to 531812.10547, saving model to test.hdf5\n",
      "Epoch 182/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 249529.9212 - mean_squared_error: 249529.9212 - val_loss: 531389.9838 - val_mean_squared_error: 531389.9838\n",
      "\n",
      "Epoch 00182: val_loss improved from 531812.10547 to 531389.98382, saving model to test.hdf5\n",
      "Epoch 183/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 249289.4639 - mean_squared_error: 249289.4639 - val_loss: 530982.2734 - val_mean_squared_error: 530982.2734\n",
      "\n",
      "Epoch 00183: val_loss improved from 531389.98382 to 530982.27344, saving model to test.hdf5\n",
      "Epoch 184/250\n",
      "250/250 [==============================] - 0s 190us/step - loss: 249059.1067 - mean_squared_error: 249059.1067 - val_loss: 530565.0251 - val_mean_squared_error: 530565.0251\n",
      "\n",
      "Epoch 00184: val_loss improved from 530982.27344 to 530565.02511, saving model to test.hdf5\n",
      "Epoch 185/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 248822.4086 - mean_squared_error: 248822.4086 - val_loss: 530156.1373 - val_mean_squared_error: 530156.1373\n",
      "\n",
      "Epoch 00185: val_loss improved from 530565.02511 to 530156.13728, saving model to test.hdf5\n",
      "Epoch 186/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 248592.7935 - mean_squared_error: 248592.7935 - val_loss: 529737.1596 - val_mean_squared_error: 529737.1596\n",
      "\n",
      "Epoch 00186: val_loss improved from 530156.13728 to 529737.15960, saving model to test.hdf5\n",
      "Epoch 187/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 248354.2641 - mean_squared_error: 248354.2641 - val_loss: 529329.3047 - val_mean_squared_error: 529329.3047\n",
      "\n",
      "Epoch 00187: val_loss improved from 529737.15960 to 529329.30469, saving model to test.hdf5\n",
      "Epoch 188/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 248121.9256 - mean_squared_error: 248121.9256 - val_loss: 528919.0452 - val_mean_squared_error: 528919.0452\n",
      "\n",
      "Epoch 00188: val_loss improved from 529329.30469 to 528919.04520, saving model to test.hdf5\n",
      "Epoch 189/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 247885.8518 - mean_squared_error: 247885.8518 - val_loss: 528518.1925 - val_mean_squared_error: 528518.1925\n",
      "\n",
      "Epoch 00189: val_loss improved from 528919.04520 to 528518.19252, saving model to test.hdf5\n",
      "Epoch 190/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 247654.0163 - mean_squared_error: 247654.0163 - val_loss: 528102.7383 - val_mean_squared_error: 528102.7383\n",
      "\n",
      "Epoch 00190: val_loss improved from 528518.19252 to 528102.73828, saving model to test.hdf5\n",
      "Epoch 191/250\n",
      "250/250 [==============================] - 0s 156us/step - loss: 247419.0058 - mean_squared_error: 247419.0058 - val_loss: 527693.3398 - val_mean_squared_error: 527693.3398\n",
      "\n",
      "Epoch 00191: val_loss improved from 528102.73828 to 527693.33984, saving model to test.hdf5\n",
      "Epoch 192/250\n",
      "250/250 [==============================] - 0s 170us/step - loss: 247188.1620 - mean_squared_error: 247188.1620 - val_loss: 527273.8359 - val_mean_squared_error: 527273.8359\n",
      "\n",
      "Epoch 00192: val_loss improved from 527693.33984 to 527273.83594, saving model to test.hdf5\n",
      "Epoch 193/250\n",
      "250/250 [==============================] - 0s 157us/step - loss: 246952.7273 - mean_squared_error: 246952.7273 - val_loss: 526863.4420 - val_mean_squared_error: 526863.4420\n",
      "\n",
      "Epoch 00193: val_loss improved from 527273.83594 to 526863.44196, saving model to test.hdf5\n",
      "Epoch 194/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 246721.8127 - mean_squared_error: 246721.8127 - val_loss: 526450.0569 - val_mean_squared_error: 526450.0569\n",
      "\n",
      "Epoch 00194: val_loss improved from 526863.44196 to 526450.05692, saving model to test.hdf5\n",
      "Epoch 195/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 246486.5738 - mean_squared_error: 246486.5738 - val_loss: 526039.8722 - val_mean_squared_error: 526039.8722\n",
      "\n",
      "Epoch 00195: val_loss improved from 526450.05692 to 526039.87221, saving model to test.hdf5\n",
      "Epoch 196/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 246253.0961 - mean_squared_error: 246253.0961 - val_loss: 525634.6044 - val_mean_squared_error: 525634.6044\n",
      "\n",
      "Epoch 00196: val_loss improved from 526039.87221 to 525634.60435, saving model to test.hdf5\n",
      "Epoch 197/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 246024.0248 - mean_squared_error: 246024.0248 - val_loss: 525223.7997 - val_mean_squared_error: 525223.7997\n",
      "\n",
      "Epoch 00197: val_loss improved from 525634.60435 to 525223.79967, saving model to test.hdf5\n",
      "Epoch 198/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 245790.8669 - mean_squared_error: 245790.8669 - val_loss: 524817.1133 - val_mean_squared_error: 524817.1133\n",
      "\n",
      "Epoch 00198: val_loss improved from 525223.79967 to 524817.11328, saving model to test.hdf5\n",
      "Epoch 199/250\n",
      "250/250 [==============================] - 0s 202us/step - loss: 245560.6513 - mean_squared_error: 245560.6513 - val_loss: 524410.4648 - val_mean_squared_error: 524410.4648\n",
      "\n",
      "Epoch 00199: val_loss improved from 524817.11328 to 524410.46484, saving model to test.hdf5\n",
      "Epoch 200/250\n",
      "250/250 [==============================] - 0s 177us/step - loss: 245327.7014 - mean_squared_error: 245327.7014 - val_loss: 524000.3761 - val_mean_squared_error: 524000.3761\n",
      "\n",
      "Epoch 00200: val_loss improved from 524410.46484 to 524000.37612, saving model to test.hdf5\n",
      "Epoch 201/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 245097.3167 - mean_squared_error: 245097.3167 - val_loss: 523592.8158 - val_mean_squared_error: 523592.8158\n",
      "\n",
      "Epoch 00201: val_loss improved from 524000.37612 to 523592.81585, saving model to test.hdf5\n",
      "Epoch 202/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 244869.3180 - mean_squared_error: 244869.3180 - val_loss: 523181.8337 - val_mean_squared_error: 523181.8337\n",
      "\n",
      "Epoch 00202: val_loss improved from 523592.81585 to 523181.83371, saving model to test.hdf5\n",
      "Epoch 203/250\n",
      "250/250 [==============================] - 0s 190us/step - loss: 244638.5686 - mean_squared_error: 244638.5686 - val_loss: 522776.7081 - val_mean_squared_error: 522776.7081\n",
      "\n",
      "Epoch 00203: val_loss improved from 523181.83371 to 522776.70815, saving model to test.hdf5\n",
      "Epoch 204/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 244407.2134 - mean_squared_error: 244407.2134 - val_loss: 522381.4381 - val_mean_squared_error: 522381.4381\n",
      "\n",
      "Epoch 00204: val_loss improved from 522776.70815 to 522381.43806, saving model to test.hdf5\n",
      "Epoch 205/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 244176.6379 - mean_squared_error: 244176.6379 - val_loss: 521977.4459 - val_mean_squared_error: 521977.4459\n",
      "\n",
      "Epoch 00205: val_loss improved from 522381.43806 to 521977.44587, saving model to test.hdf5\n",
      "Epoch 206/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 243945.9780 - mean_squared_error: 243945.9780 - val_loss: 521561.7974 - val_mean_squared_error: 521561.7974\n",
      "\n",
      "Epoch 00206: val_loss improved from 521977.44587 to 521561.79743, saving model to test.hdf5\n",
      "Epoch 207/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 243714.2952 - mean_squared_error: 243714.2952 - val_loss: 521148.2930 - val_mean_squared_error: 521148.2930\n",
      "\n",
      "Epoch 00207: val_loss improved from 521561.79743 to 521148.29297, saving model to test.hdf5\n",
      "Epoch 208/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 243483.2049 - mean_squared_error: 243483.2049 - val_loss: 520745.4626 - val_mean_squared_error: 520745.4626\n",
      "\n",
      "Epoch 00208: val_loss improved from 521148.29297 to 520745.46261, saving model to test.hdf5\n",
      "Epoch 209/250\n",
      "250/250 [==============================] - 0s 185us/step - loss: 243257.7814 - mean_squared_error: 243257.7814 - val_loss: 520339.3036 - val_mean_squared_error: 520339.3036\n",
      "\n",
      "Epoch 00209: val_loss improved from 520745.46261 to 520339.30357, saving model to test.hdf5\n",
      "Epoch 210/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 243029.9616 - mean_squared_error: 243029.9616 - val_loss: 519934.9526 - val_mean_squared_error: 519934.9526\n",
      "\n",
      "Epoch 00210: val_loss improved from 520339.30357 to 519934.95257, saving model to test.hdf5\n",
      "Epoch 211/250\n",
      "250/250 [==============================] - 0s 179us/step - loss: 242802.2600 - mean_squared_error: 242802.2600 - val_loss: 519533.7840 - val_mean_squared_error: 519533.7840\n",
      "\n",
      "Epoch 00211: val_loss improved from 519934.95257 to 519533.78404, saving model to test.hdf5\n",
      "Epoch 212/250\n",
      "250/250 [==============================] - 0s 197us/step - loss: 242573.0577 - mean_squared_error: 242573.0577 - val_loss: 519135.3142 - val_mean_squared_error: 519135.3142\n",
      "\n",
      "Epoch 00212: val_loss improved from 519533.78404 to 519135.31417, saving model to test.hdf5\n",
      "Epoch 213/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 242348.9020 - mean_squared_error: 242348.9020 - val_loss: 518727.6010 - val_mean_squared_error: 518727.6010\n",
      "\n",
      "Epoch 00213: val_loss improved from 519135.31417 to 518727.60100, saving model to test.hdf5\n",
      "Epoch 214/250\n",
      "250/250 [==============================] - 0s 200us/step - loss: 242120.7881 - mean_squared_error: 242120.7881 - val_loss: 518328.1116 - val_mean_squared_error: 518328.1116\n",
      "\n",
      "Epoch 00214: val_loss improved from 518727.60100 to 518328.11161, saving model to test.hdf5\n",
      "Epoch 215/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 241895.5853 - mean_squared_error: 241895.5853 - val_loss: 517926.9498 - val_mean_squared_error: 517926.9498\n",
      "\n",
      "Epoch 00215: val_loss improved from 518328.11161 to 517926.94978, saving model to test.hdf5\n",
      "Epoch 216/250\n",
      "250/250 [==============================] - 0s 198us/step - loss: 241669.2909 - mean_squared_error: 241669.2909 - val_loss: 517526.2539 - val_mean_squared_error: 517526.2539\n",
      "\n",
      "Epoch 00216: val_loss improved from 517926.94978 to 517526.25391, saving model to test.hdf5\n",
      "Epoch 217/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 241442.8084 - mean_squared_error: 241442.8084 - val_loss: 517125.6529 - val_mean_squared_error: 517125.6529\n",
      "\n",
      "Epoch 00217: val_loss improved from 517526.25391 to 517125.65290, saving model to test.hdf5\n",
      "Epoch 218/250\n",
      "250/250 [==============================] - 0s 184us/step - loss: 241215.9592 - mean_squared_error: 241215.9592 - val_loss: 516724.0095 - val_mean_squared_error: 516724.0095\n",
      "\n",
      "Epoch 00218: val_loss improved from 517125.65290 to 516724.00949, saving model to test.hdf5\n",
      "Epoch 219/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 240987.4554 - mean_squared_error: 240987.4554 - val_loss: 516327.8041 - val_mean_squared_error: 516327.8041\n",
      "\n",
      "Epoch 00219: val_loss improved from 516724.00949 to 516327.80413, saving model to test.hdf5\n",
      "Epoch 220/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 240764.5102 - mean_squared_error: 240764.5102 - val_loss: 515923.6948 - val_mean_squared_error: 515923.6948\n",
      "\n",
      "Epoch 00220: val_loss improved from 516327.80413 to 515923.69475, saving model to test.hdf5\n",
      "Epoch 221/250\n",
      "250/250 [==============================] - 0s 200us/step - loss: 240537.9746 - mean_squared_error: 240537.9746 - val_loss: 515525.1786 - val_mean_squared_error: 515525.1786\n",
      "\n",
      "Epoch 00221: val_loss improved from 515923.69475 to 515525.17857, saving model to test.hdf5\n",
      "Epoch 222/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 240312.0297 - mean_squared_error: 240312.0297 - val_loss: 515131.5452 - val_mean_squared_error: 515131.5452\n",
      "\n",
      "Epoch 00222: val_loss improved from 515525.17857 to 515131.54520, saving model to test.hdf5\n",
      "Epoch 223/250\n",
      "250/250 [==============================] - 0s 173us/step - loss: 240092.7061 - mean_squared_error: 240092.7061 - val_loss: 514724.6775 - val_mean_squared_error: 514724.6775\n",
      "\n",
      "Epoch 00223: val_loss improved from 515131.54520 to 514724.67746, saving model to test.hdf5\n",
      "Epoch 224/250\n",
      "250/250 [==============================] - 0s 183us/step - loss: 239865.1855 - mean_squared_error: 239865.1855 - val_loss: 514321.5033 - val_mean_squared_error: 514321.5033\n",
      "\n",
      "Epoch 00224: val_loss improved from 514724.67746 to 514321.50335, saving model to test.hdf5\n",
      "Epoch 225/250\n",
      "250/250 [==============================] - 0s 188us/step - loss: 239636.2162 - mean_squared_error: 239636.2162 - val_loss: 513936.2573 - val_mean_squared_error: 513936.2573\n",
      "\n",
      "Epoch 00225: val_loss improved from 514321.50335 to 513936.25725, saving model to test.hdf5\n",
      "Epoch 226/250\n",
      "250/250 [==============================] - 0s 186us/step - loss: 239416.1462 - mean_squared_error: 239416.1462 - val_loss: 513529.2500 - val_mean_squared_error: 513529.2500\n",
      "\n",
      "Epoch 00226: val_loss improved from 513936.25725 to 513529.25000, saving model to test.hdf5\n",
      "Epoch 227/250\n",
      "250/250 [==============================] - 0s 204us/step - loss: 239188.8930 - mean_squared_error: 239188.8930 - val_loss: 513130.4833 - val_mean_squared_error: 513130.4833\n",
      "\n",
      "Epoch 00227: val_loss improved from 513529.25000 to 513130.48326, saving model to test.hdf5\n",
      "Epoch 228/250\n",
      "250/250 [==============================] - 0s 189us/step - loss: 238969.2971 - mean_squared_error: 238969.2971 - val_loss: 512722.5385 - val_mean_squared_error: 512722.5385\n",
      "\n",
      "Epoch 00228: val_loss improved from 513130.48326 to 512722.53850, saving model to test.hdf5\n",
      "Epoch 229/250\n",
      "250/250 [==============================] - 0s 192us/step - loss: 238737.3621 - mean_squared_error: 238737.3621 - val_loss: 512337.2868 - val_mean_squared_error: 512337.2868\n",
      "\n",
      "Epoch 00229: val_loss improved from 512722.53850 to 512337.28683, saving model to test.hdf5\n",
      "Epoch 230/250\n",
      "250/250 [==============================] - 0s 181us/step - loss: 238515.9314 - mean_squared_error: 238515.9314 - val_loss: 511933.5831 - val_mean_squared_error: 511933.5831\n",
      "\n",
      "Epoch 00230: val_loss improved from 512337.28683 to 511933.58315, saving model to test.hdf5\n",
      "Epoch 231/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 238291.4991 - mean_squared_error: 238291.4991 - val_loss: 511532.3438 - val_mean_squared_error: 511532.3438\n",
      "\n",
      "Epoch 00231: val_loss improved from 511933.58315 to 511532.34375, saving model to test.hdf5\n",
      "Epoch 232/250\n",
      "250/250 [==============================] - 0s 165us/step - loss: 238071.0788 - mean_squared_error: 238071.0788 - val_loss: 511129.0112 - val_mean_squared_error: 511129.0112\n",
      "\n",
      "Epoch 00232: val_loss improved from 511532.34375 to 511129.01116, saving model to test.hdf5\n",
      "Epoch 233/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 237845.3114 - mean_squared_error: 237845.3114 - val_loss: 510731.0497 - val_mean_squared_error: 510731.0497\n",
      "\n",
      "Epoch 00233: val_loss improved from 511129.01116 to 510731.04967, saving model to test.hdf5\n",
      "Epoch 234/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 166us/step - loss: 237620.5325 - mean_squared_error: 237620.5325 - val_loss: 510336.7891 - val_mean_squared_error: 510336.7891\n",
      "\n",
      "Epoch 00234: val_loss improved from 510731.04967 to 510336.78906, saving model to test.hdf5\n",
      "Epoch 235/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 237399.9067 - mean_squared_error: 237399.9067 - val_loss: 509935.8432 - val_mean_squared_error: 509935.8432\n",
      "\n",
      "Epoch 00235: val_loss improved from 510336.78906 to 509935.84319, saving model to test.hdf5\n",
      "Epoch 236/250\n",
      "250/250 [==============================] - 0s 174us/step - loss: 237173.8636 - mean_squared_error: 237173.8636 - val_loss: 509548.1373 - val_mean_squared_error: 509548.1373\n",
      "\n",
      "Epoch 00236: val_loss improved from 509935.84319 to 509548.13728, saving model to test.hdf5\n",
      "Epoch 237/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 236956.0691 - mean_squared_error: 236956.0691 - val_loss: 509148.7193 - val_mean_squared_error: 509148.7193\n",
      "\n",
      "Epoch 00237: val_loss improved from 509548.13728 to 509148.71931, saving model to test.hdf5\n",
      "Epoch 238/250\n",
      "250/250 [==============================] - 0s 175us/step - loss: 236731.7267 - mean_squared_error: 236731.7267 - val_loss: 508763.8895 - val_mean_squared_error: 508763.8895\n",
      "\n",
      "Epoch 00238: val_loss improved from 509148.71931 to 508763.88951, saving model to test.hdf5\n",
      "Epoch 239/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 236515.3098 - mean_squared_error: 236515.3098 - val_loss: 508364.3767 - val_mean_squared_error: 508364.3767\n",
      "\n",
      "Epoch 00239: val_loss improved from 508763.88951 to 508364.37667, saving model to test.hdf5\n",
      "Epoch 240/250\n",
      "250/250 [==============================] - 0s 180us/step - loss: 236291.8036 - mean_squared_error: 236291.8036 - val_loss: 507977.5809 - val_mean_squared_error: 507977.5809\n",
      "\n",
      "Epoch 00240: val_loss improved from 508364.37667 to 507977.58092, saving model to test.hdf5\n",
      "Epoch 241/250\n",
      "250/250 [==============================] - 0s 159us/step - loss: 236071.9006 - mean_squared_error: 236071.9006 - val_loss: 507587.5848 - val_mean_squared_error: 507587.5848\n",
      "\n",
      "Epoch 00241: val_loss improved from 507977.58092 to 507587.58482, saving model to test.hdf5\n",
      "Epoch 242/250\n",
      "250/250 [==============================] - 0s 169us/step - loss: 235853.8768 - mean_squared_error: 235853.8768 - val_loss: 507185.1099 - val_mean_squared_error: 507185.1099\n",
      "\n",
      "Epoch 00242: val_loss improved from 507587.58482 to 507185.10993, saving model to test.hdf5\n",
      "Epoch 243/250\n",
      "250/250 [==============================] - 0s 167us/step - loss: 235630.2523 - mean_squared_error: 235630.2523 - val_loss: 506792.0424 - val_mean_squared_error: 506792.0424\n",
      "\n",
      "Epoch 00243: val_loss improved from 507185.10993 to 506792.04241, saving model to test.hdf5\n",
      "Epoch 244/250\n",
      "250/250 [==============================] - 0s 161us/step - loss: 235411.5592 - mean_squared_error: 235411.5592 - val_loss: 506396.3756 - val_mean_squared_error: 506396.3756\n",
      "\n",
      "Epoch 00244: val_loss improved from 506792.04241 to 506396.37556, saving model to test.hdf5\n",
      "Epoch 245/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 235186.2776 - mean_squared_error: 235186.2776 - val_loss: 506011.1574 - val_mean_squared_error: 506011.1574\n",
      "\n",
      "Epoch 00245: val_loss improved from 506396.37556 to 506011.15737, saving model to test.hdf5\n",
      "Epoch 246/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 234967.7128 - mean_squared_error: 234967.7128 - val_loss: 505616.4007 - val_mean_squared_error: 505616.4007\n",
      "\n",
      "Epoch 00246: val_loss improved from 506011.15737 to 505616.40067, saving model to test.hdf5\n",
      "Epoch 247/250\n",
      "250/250 [==============================] - 0s 163us/step - loss: 234747.2992 - mean_squared_error: 234747.2992 - val_loss: 505219.5151 - val_mean_squared_error: 505219.5151\n",
      "\n",
      "Epoch 00247: val_loss improved from 505616.40067 to 505219.51507, saving model to test.hdf5\n",
      "Epoch 248/250\n",
      "250/250 [==============================] - 0s 160us/step - loss: 234527.1841 - mean_squared_error: 234527.1841 - val_loss: 504820.5915 - val_mean_squared_error: 504820.5915\n",
      "\n",
      "Epoch 00248: val_loss improved from 505219.51507 to 504820.59152, saving model to test.hdf5\n",
      "Epoch 249/250\n",
      "250/250 [==============================] - 0s 162us/step - loss: 234308.3193 - mean_squared_error: 234308.3193 - val_loss: 504423.3493 - val_mean_squared_error: 504423.3493\n",
      "\n",
      "Epoch 00249: val_loss improved from 504820.59152 to 504423.34933, saving model to test.hdf5\n",
      "Epoch 250/250\n",
      "250/250 [==============================] - 0s 171us/step - loss: 234084.0897 - mean_squared_error: 234084.0897 - val_loss: 504037.4035 - val_mean_squared_error: 504037.4035\n",
      "\n",
      "Epoch 00250: val_loss improved from 504423.34933 to 504037.40346, saving model to test.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 250, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xt8VdWd///XJ/eEXICQhHATVFQuKgre6teO2qqonaLTVq210k6n9DptH7181Znp1F5mxvl+Z9rqtKWl1YptldpafzKKxXv9dqoiKCpXQUWJXBJu4ZpAks/vj7UOOQlJCJCdQ8L7+Xjsxzln7bX32dsDvllrr722uTsiIiJJysr0AYiISP+nsBERkcQpbEREJHEKGxERSZzCRkREEqewERGRxClsRDLMzO42s+91s+4aM3v/ke5HpLcpbEREJHEKGxERSZzCRqQbYvfVN8zsVTPbZWZ3mlmVmT1qZjvM7AkzG5RW/4NmttTMtpnZM2Y2Lm3dGWb2Utzut0BBu+/6gJktjtv+xcxOO8xj/rSZrTazLWY218yGxXIzsx+YWa2Z1cdzmhjXXWFmy+KxvWtmXz+s/2Ai7ShsRLrvQ8AlwEnAXwOPAv8ADCH8XfoSgJmdBNwHfAWoAOYB/21meWaWB/x/wK+AwcDv4n6J254J3AV8BigHfgbMNbP8QzlQM7sY+DfgGqAaeBuYE1dfCrw3nsdA4Fpgc1x3J/AZdy8BJgJPHcr3inRGYSPSff/l7hvd/V3g/wEvuPvL7t4IPAicEetdCzzi7o+7+z7gP4BC4D3AuUAu8EN33+fuvwdeTPuOTwM/c/cX3L3Z3WcDjXG7Q/Ex4C53fyke3y3AeWY2GtgHlACnAObuy919fdxuHzDezErdfau7v3SI3yvSIYWNSPdtTHu/p4PPxfH9MEJLAgB3bwHWAsPjune97Qy4b6e9Pw74WuxC22Zm24CRcbtD0f4YdhJaL8Pd/SngR8CPgY1mNsvMSmPVDwFXAG+b2Z/M7LxD/F6RDilsRHreOkJoAOEaCSEw3gXWA8NjWcqotPdrgX9x94FpS5G733eExzCA0C33LoC73+Huk4EJhO60b8TyF919GlBJ6O67/xC/V6RDChuRnnc/cKWZvc/McoGvEbrC/gI8BzQBXzKzHDP7G+DstG1/DnzWzM6JF/IHmNmVZlZyiMdwL/BJM5sUr/f8K6Hbb42ZnRX3nwvsAhqA5nhN6WNmVha7/7YDzUfw30FkP4WNSA9z95XADcB/AZsIgwn+2t33uvte4G+ATwBbCdd3/pC27ULCdZsfxfWrY91DPYYngW8CDxBaUycA18XVpYRQ20roattMuK4E8HFgjZltBz4bz0PkiJkeniYiIklTy0ZERBKnsBERkcQpbEREJHEKGxERSVxOpg/gaDFkyBAfPXp0pg9DRKRPWbRo0SZ3rzhYPYVNNHr0aBYuXJjpwxAR6VPM7O2D11I3moiI9AKFjYiIJE5hIyIiidM1GxGRw7Rv3z5qampoaGjI9KEkrqCggBEjRpCbm3tY2ytsREQOU01NDSUlJYwePZq2E3n3L+7O5s2bqampYcyYMYe1D3WjiYgcpoaGBsrLy/t10ACYGeXl5UfUglPYiIgcgf4eNClHep4KmyP1xlPw/EzYtyfTRyIictRS2BypFfPgjzfD7ZPghVmwr/9fKBSRo8e2bdv4yU9+csjbXXHFFWzbti2BI+qYwuZIXfkfMP1hKD8BHv0G3HEGLPg5NDVm+shE5BjQWdg0N3f9kNV58+YxcODApA7rAAqbnjDmAvjEI3DjQzBwFMz7OtxxJrx4JzTtzfTRiUg/dvPNN/PGG28wadIkzjrrLC666CKuv/56Tj31VACuuuoqJk+ezIQJE5g1a9b+7UaPHs2mTZtYs2YN48aN49Of/jQTJkzg0ksvZc+enr8soKHPPcUMjr8QxvwVvPk0PP1v8MhX4c8/gAu+BpM+Bjl5mT5KEUnIt/97KcvWbe/RfY4fVsq3/npCl3Vuu+02lixZwuLFi3nmmWe48sorWbJkyf4hynfddReDBw9mz549nHXWWXzoQx+ivLy8zT5WrVrFfffdx89//nOuueYaHnjgAW64oWefCK6WTU8zgxMuhk89Bjc8AMVV8PBX4EeT4aV7oHlfpo9QRPqxs88+u829MHfccQenn3465557LmvXrmXVqlUHbDNmzBgmTZoEwOTJk1mzZk2PH5daNkkxgxPfDye8D1Y/AU//K8z9e/jT/4Epn4QzboTig87KLSJ9xMFaIL1lwIAB+98/88wzPPHEEzz33HMUFRVx4YUXdnivTH5+/v732dnZiXSjqWWTNDMYewl8+im4/n4YPAae/A58fxw88Hfw1rPQ0pLpoxSRPqqkpIQdO3Z0uK6+vp5BgwZRVFTEihUreP7553v56FqpZdNbzOCky8JStxIW3gWL74XXfgclw+DUD8Gp18DQU0NdEZFuKC8v5/zzz2fixIkUFhZSVVW1f93UqVP56U9/ymmnncbJJ5/Mueeem7HjNHfP2JcfTaZMmeK9/vC0vbvh9Ufh1d/B6sehpQkGHgenXAknXwGjzoNs/XtA5Gi1fPlyxo0bl+nD6DUdna+ZLXL3KQfbVv8ny6S8Ipj4obDs3gLL54abRF+8E57/CRQMDC2hEy4Oo9xKqzN9xCIih0Vhc7QoGgyTPxGWxp1hGpyV82DVY/Dqb0OdilPC8OrjL4LR50N+SeaOV0TkECQaNmY2EPgFMBFw4G+BlcBvgdHAGuAad99qYZa324ErgN3AJ9z9pbif6cA/xd1+z91nx/LJwN1AITAP+LK7u5kN7ug7kjzXHpVfDOM/GJaWFti4BN58Jty/s2g2vPBTsGyoPh2Oe09YRp0XAktE5CiUdMvmduCP7v5hM8sDioB/AJ5099vM7GbgZuAm4HJgbFzOAWYC58Tg+BYwhRBYi8xsbgyPmcAM4HlC2EwFHo377Og7+p6sLKg+LSznfynMvVazAN78E7zzXJga57kfhboVp8TgeQ+MOgfKRmqwgYgcFRILGzMrBd4LfALA3fcCe81sGnBhrDYbeIYQBNOAezyMWHjezAaaWXWs+7i7b4n7fRyYambPAKXu/lwsvwe4ihA2nX1H35dbAGPeGxYI4bPuZXj7f0L4vPq7MNINwg2lI86CEVNg+BQYdkZoNYmI9LIkWzbHA3XAL83sdGAR8GWgyt3XA7j7ejOrjPWHA2vTtq+JZV2V13RQThff0YaZzSC0jBg1atRhnmaG5RbAceeFBaC5KXS71bzYuqx4OKyzLKicEMJnxFlhKT8xtJ5ERBKUZNjkAGcCf+/uL5jZ7YTurM501N/jh1Hebe4+C5gFYejzoWx71MrOgWGTwnL2p0PZrs3w7qLW8FnyACz6ZVhXUAbDJ7eGz/DJuvYj0ods27aNe++9l89//vOHvO0Pf/hDZsyYQVFRUQJH1laSYVMD1Lj7C/Hz7wlhs9HMqmOLoxqoTas/Mm37EcC6WH5hu/JnYvmIDurTxXccmwaUw0mXhgXCoIPNq9JaPwvh2f8LHmcyKD+xNXiGnQFVE0MLSkSOOqlHDBxu2Nxwww19O2zcfYOZrTWzk919JfA+YFlcpgO3xdeH4iZzgS+a2RzCAIH6GBbzgX81s0Gx3qXALe6+xcx2mNm5wAvAjcB/pe2ro+8QCN1mFSeH5Yw4s2vjjnDtp2ZhWFY/Aa/cF+vnQOU4qJ4UwmfYGVA1AXLyO/8OEekV6Y8YuOSSS6isrOT++++nsbGRq6++mm9/+9vs2rWLa665hpqaGpqbm/nmN7/Jxo0bWbduHRdddBFDhgzh6aefTvQ4kx6N9vfAb+JItDeBTxLmY7vfzD4FvAN8JNadRxj2vJow9PmTADFUvgu8GOt9JzVYAPgcrUOfH40LhJDp6DukM/klbQceuMP2d0MApZYVj8DLvwrrs3JD4KTCZ9gZIZCyczN3DiKZ9OjNsOG1nt3n0FPh8tu6rJL+iIHHHnuM3//+9yxYsAB354Mf/CDPPvssdXV1DBs2jEceeQQIc6aVlZXx/e9/n6effpohQ4b07HF3INGwcffFhCHL7b2vg7oOfKGT/dwF3NVB+ULCPTztyzd39B1yCMygbERYxv11KHOHbe+0DaClf2i9/pOdD0Mnhvt/qk8PLaHKcWoBifSSxx57jMcee4wzzjgDgJ07d7Jq1SouuOACvv71r3PTTTfxgQ98gAsuuKDXj00zCEj3mcGg48Iy4apQ5g5b30oLoMXw2gOtw6+zcmMXXFoAVU0IU/WI9CcHaYH0Bnfnlltu4TOf+cwB6xYtWsS8efO45ZZbuPTSS/nnf/7nXj02hY0cGTMYfHxYJn4olLnD1jWw/pXWZeW81i44y4IhJ6cF0Omhu6CgNGOnIdJXpT9i4LLLLuOb3/wmH/vYxyguLubdd98lNzeXpqYmBg8ezA033EBxcTF33313m237fDeaHKPMwnN7Bo9p2wLavi4tgBbDW3+CV+e0bjf4hLYBVH26hmGLHET6IwYuv/xyrr/+es47L9x3V1xczK9//WtWr17NN77xDbKyssjNzWXmzJkAzJgxg8svv5zq6urEBwjoEQNRRh4xILBjI2x4NYRPKoi2vdO6vmxUnK4n3jtUfToUd3iPrkiv0yMG9IgB6StKqqDkkvA005TdW2IApXXDpWZBACipDuGT3gIqHaZ54ESOYgobOfoUDY6PUriwtaxhe5iGZ11aC2jV/NYbUQdUtB2EUH06DBylABI5SihspG8oKG19nELK3l2wcWkInlQIvXl7eOIpQOGgdteAJsGgMZoLTnqUu2PHwD9qjvSSi8JG+q68ATDy7LCk7GuA2qWtrZ91i+H5mdC8N6zPL4Whp4XwSV0DKj8RsrIzcw7SpxUUFLB582bKy8v7deC4O5s3b6ag4PCnrVLYSP+SWxDmdBs+ubWsaS/UrWg7CGHhndDUELcZEIZep1pAwyaFodnZ+ushXRsxYgQ1NTXU1dVl+lASV1BQwIgRIw5esRMajRZpNNoxprkJNr3edij2+ldh366wPqcg3Hyafg1IsyGIHKC7o9EUNpHCRmhphi1vxus/qVbQq9BYH9Zn5ULV+LRrQGeEz7mFmT1ukQzS0GeRQ5WVDUPGhuW0OHdrSwtsW9N2EMLy/4aX7gnrLTs8jntY2lDsqol6IqpIOwobka5kZbVOxzPh6lDmDvVr2w5CWPUYLP5N3ChO4TN0IlSdGl6HngqlwzUUW45ZChuRQ2UW7uEZOKrtjNg7NrQG0MbXQhfcsrRHKRUMDKFTNTEG0URdB5JjhsJGpCeYQWl1WE6e2lreuAM2Lgvhs+E12LAEXpoN+3aH9Vk5MOSktgE09FRNySP9jsJGJEn5JTDqnLCktDTDlrdiAC0JMyO8/T/w2v2tdYqr0gIodsWVj9VwbOmzEv2Ta2ZrgB1AM9Dk7lPM7Fbg00BqYPo/uPu8WP8W4FOx/pfcfX4snwrcDmQDv3D322L5GGAOMBh4Cfi4u+81s3zgHmAysBm41t3XJHmuIt2WlQ1DTgxL6joQhDnhNi5pDaANr7W9ITU7P3S7pQdQ1UQoHJiZ8xA5BL3xz6SL3H1Tu7IfuPt/pBeY2XjgOmACMAx4wsxOiqt/DFwC1AAvmtlcd18G/Hvc1xwz+ykhqGbG163ufqKZXRfrXZvQ+Yn0jKLBbR/NDdC8L9wPtGFJa0to5R/h5V+31ikbldYFF181LY8cZY6mNvk0YI67NwJvmdlqIDUPyWp3fxPAzOYA08xsOXAxcH2sMxu4lRA20+J7gN8DPzIzc91UJH1Ndm64ubRqAvv/veQOOze2DaCNS+D1+eDNoU5uURiSXTUeKie07mNA8g/JEulI0mHjwGNm5sDP3H1WLP+imd0ILAS+5u5bgeHA82nb1sQygLXtys8ByoFt7t7UQf3hqW3cvcnM6mP9Ni0sM5sBzAAYNWrUEZ6qSC8xg5KhYRn7/tbyfXugdjnULgsTlG5cGgIovRU0oLJdAI0PoaQbUyVhSYfN+e6+zswqgcfNbAWh5fFdQhB9F/hP4G+Bjm5AcKCjvgDvoj4HWddaEMJvFoQZBLo+FZGjXG4hDD8zLOl21obgqV0WRsbVLoWFd0HTnrDe4r1EVRNiCI2HyvHqipMelWjYuPu6+FprZg8CZ7v7s6n1ZvZzIPVUrBpgZNrmI4B18X1H5ZuAgWaWE1s36fVT+6oxsxygDNjSk+cm0mcUV4blhItay1Ij4mqXtgbQhtdg2Vz2/7sstygMSKgcH4NovLri5LAlFjZmNgDIcvcd8f2lwHfMrNrd18dqVwNL4vu5wL1m9n3CAIGxwAJCK2VsHHn2LmEQwfXu7mb2NPBhwoi06cBDafuaDjwX1z+l6zUiadJHxI2f1lq+d1eYIXtj7IqrXQorH4WXf9Vap7iqXQCpK04OLsmWTRXwYHzGQw5wr7v/0cx+ZWaTCP98WgN8BsDdl5rZ/cAyoAn4gnu42mlmXwTmE4Y+3+XuS+N33ATMMbPvAS8Dd8byO4FfxUEGWwgBJSIHkzfgwEc0QGtX3P7uuKXw4i9aH9NgWTD4hLTrQeOhYhwMHqNnBQmgWZ/306zPIocoNUt2egDVLgvdc6muuJyCMLFpxbjYJTcutIIGHqfrQf2EZn0WkWSlz5I94arW8lRXXO0KqFseRsi9/Ze2MyTkFkHFyaEbruKU1iDSZKX9lsJGRHpWZ11xDfVQtzIOz14egmj1E2mzZRMe211xClSe0rY1VFylEOrjFDYi0jsKymDk2WFJt3tLbAktC62h2uWw4pHWZwYBFA6K4XNK29aQRsb1GQobEcmsosFw3HvCkm5nXQiguhWtraElD0DDXa11BlS07YZLBVLhoN49BzkohY2IHJ2KK6D4r+D4v2otc4cd62M3XFpraPG9sHdna72S6hhC49NaQyeHWbglIxQ2ItJ3mEHpsLCc+L7W8tTTU2tXtG0Npc+UAFA2snVEXKo1NORkyCvq/XM5xihsRKTvS3966kmXtpa3NMO2t9MGJcQQevOZ1kc3YDBodFoIxdZQ+VjILcjAyfRPChsR6b+yssO8b4OPh1OubC1vbgr3CNUtb9saWvUYtMS5fVM3qrYflFB+YpiNWw6JwkZEjj3ZOVBxUljSp+tp2gubV7feH5RaVjwC3hLqZOWGwGkfQoPG6EmqXdB/GRGRlJy8MNVO1fi25fv2wKZVrfcH1a6Ad1+CpQ+21snKjTe5nhQCqOLk8Fp+AuTk9+55HIUUNiIiB5NbCNWnhSVdaraEutfj60pY/wose4j9U/ZY7MqrOLk1gCpODteEjqGBCQobEZHD1dlsCamW0KZUCMUgWvlo69NUiYMa0ltBFaeErr1+OERbYSMi0tM6awk17Y0DE2L4pF7ffDptdBxhjrj0VtCQ2CoqGty759GDFDYiIr0lJy8OLDilbXlzUxiind4KqlsJi+6Gfbtb6w2obBtCqfcDKo76ueMUNiIimZadEwYSlJ/Qdoh2S0u4WTXVCtoUQ+jV30Lj9tZ6hYMObAVVnBJufj1KQkhhIyJytMrKgkHHhSX9ZtXUtD3praC6lWFgwp6trfXyStJaQGktorJRvf48oUTDxszWADuAZqDJ3aeY2WDgt8BowpM6r3H3rRYe6Xk7cAWwG/iEu78U9zMd+Ke42++5++xYPhm4GygE5gFfjo+L7vA7kjxXEZFekz5tzwkXt5a7w65NbVtBdSsOfJRDTmF8qF0Mn4l/E0bMJag3WjYXufumtM83A0+6+21mdnP8fBNwOTA2LucAM4FzYnB8C5hCGEu4yMzmxvCYCcwAnieEzVTg0S6+Q0Sk/zKLE5hWwJgL2q7bs7XtEO26Fa0PtRtxVr8Im/amARfG97OBZwhBMA24x8Nzqp83s4FmVh3rPu7uWwDM7HFgqpk9A5S6+3Ox/B7gKkLYdPYdIiLHpsJBMOqcsKRr3AHZyd90mnSnnQOPmdkiM5sRy6rcfT1AfK2M5cOBtWnb1sSyrsprOijv6jvaMLMZZrbQzBbW1dUd5imKiPRh+SVhlFzCkm7ZnO/u68ysEnjczFZ0UbejIRN+GOXd5u6zgFkAU6ZMOaRtRUSk+xJt2bj7uvhaCzwInA1sjN1jxNfaWL0GGJm2+Qhg3UHKR3RQThffISIiGZBY2JjZADMrSb0HLgWWAHOB6bHadOCh+H4ucKMF5wL1sQtsPnCpmQ0ys0FxP/Pjuh1mdm4cyXZju3119B0iIpIBSXajVQEPhhwgB7jX3f9oZi8C95vZp4B3gI/E+vMIw55XE4Y+fxLA3beY2XeBF2O976QGCwCfo3Xo86NxAbitk+8QEZEMsDD4S6ZMmeILFy7M9GGIiPQpZrbI3accrF7v3kIqIiLHJIWNiIgkTmEjIiKJU9iIiEjiFDYiIpI4hY2IiCROYSMiIolT2IiISOIUNiIikjiFjYiIJE5hIyIiiVPYiIhI4hQ2IiKSOIWNiIgkTmEjIiKJU9iIiEjiEg8bM8s2s5fN7OH4+W4ze8vMFsdlUiw3M7vDzFab2atmdmbaPqab2aq4TE8rn2xmr8Vt7oiPh8bMBpvZ47H+4/Fx0iIikiG90bL5MrC8Xdk33H1SXBbHssuBsXGZAcyEEBzAt4BzgLOBb6WFx8xYN7Xd1Fh+M/Cku48FnoyfRUQkQxINGzMbAVwJ/KIb1acB93jwPDDQzKqBy4DH3X2Lu28FHgemxnWl7v6ch2db3wNclbav2fH97LRyERHJgKRbNj8E/jfQ0q78X2JX2Q/MLD+WDQfWptWpiWVdldd0UA5Q5e7rAeJrZUcHZ2YzzGyhmS2sq6s75JMTEZHuSSxszOwDQK27L2q36hbgFOAsYDBwU2qTDnbjh1Hebe4+y92nuPuUioqKQ9lUREQOQZItm/OBD5rZGmAOcLGZ/drd18euskbgl4TrMBBaJiPTth8BrDtI+YgOygE2xm424mttT56YiIgcmsTCxt1vcfcR7j4auA54yt1vSAsBI1xLWRI3mQvcGEelnQvUxy6w+cClZjYoDgy4FJgf1+0ws3Pjvm4EHkrbV2rU2vS0chERyYBuhY2ZfdnMSmMQ3GlmL5nZpYf5nb8xs9eA14AhwPdi+TzgTWA18HPg8wDuvgX4LvBiXL4TywA+Rxh8sBp4A3g0lt8GXGJmq4BL4mcREckQCwO5DlLJ7BV3P93MLgO+AHwT+KW7n3mQTfuMKVOm+MKFCzN9GCIifYqZLXL3KQer191utNTF+CsIIfMKHV+gFxEROUB3w2aRmT1GCJv5ZlbCgcOZRUREOpTTzXqfAiYBb7r77nhX/yeTOywREelPutuyOQ9Y6e7bzOwG4J+A+uQOS0RE+pPuhs1MYLeZnU6YEeBtwvQwIiIiB9XdsGmK849NA25399uBkuQOS0RE+pPuXrPZYWa3AB8HLjCzbCA3ucMSEZH+pLstm2uBRuBv3X0DYcLL/5vYUYmISL/SrbCJAfMboCxOsNng7rpmIyIi3dLd6WquARYAHwGuAV4wsw8neWAiItJ/dPeazT8CZ7l7LYCZVQBPAL9P6sBERKT/6O41m6xU0ESbD2FbERE5xnW3ZfNHM5sP3Bc/X0uYpVlEROSguhU27v4NM/sQ4YFoBsxy9wcTPTIREek3utuywd0fAB5I8FhERKSf6jJszGwH0NEDbwxwdy9N5KhERKRf6fIiv7uXuHtpB0tJd4PGzLLN7GUzezh+HmNmL5jZKjP7rZnlxfL8+Hl1XD86bR+3xPKV8QFuqfKpsWy1md2cVt7hd4iISGb0xoiyLwPL0z7/O/ADdx8LbCU8voD4utXdTwR+EOthZuOB64AJwFTgJzHAsoEfA5cD44GPxrpdfYeIiGRAomFjZiOAK4FfxM8GXEzr/Tmzgavi+2nxM3H9+2L9acAcd29097eA1cDZcVnt7m+6+15gDjDtIN8hIiIZkHTL5oeERxKknupZDmxz96b4uYYwzxrxdS1AXF8f6+8vb7dNZ+VdfYeIiGRAYmET51CrdfdF6cUdVPWDrOup8o6OcYaZLTSzhXV1dR1VERGRHpBky+Z84INmtobQxXUxoaUz0MxSo+BGAOvi+xpgJEBcXwZsSS9vt01n5Zu6+I423H2Wu09x9ykVFRWHf6YiItKlxMLG3W9x9xHuPppwgf8pd/8Y8DSQmsRzOvBQfD83fiaufyo+sG0ucF0crTYGGEuYFPRFYGwceZYXv2Nu3Kaz7xARkQzIxPxmNwFfNbPVhOsrd8byO4HyWP5V4GYAd18K3A8sA/4IfMHdm+M1mS8C8wmj3e6Pdbv6DhERyQALDQGZMmWKL1y4MNOHISLSp5jZInefcrB6mrlZREQSp7AREZHEKWxERCRxChsREUmcwkZERBKnsBERkcQpbEREJHEKGxERSZzCRkREEqewERGRxClsREQkcQobERFJnMJGREQSp7AREZHEKWxERCRxChsREUmcwkZERBKXWNiYWYGZLTCzV8xsqZl9O5bfbWZvmdniuEyK5WZmd5jZajN71czOTNvXdDNbFZfpaeWTzey1uM0dZmaxfLCZPR7rP25mg5I6TxERObgkWzaNwMXufjowCZhqZufGdd9w90lxWRzLLgfGxmUGMBNCcADfAs4Bzga+lRYeM2Pd1HZTY/nNwJPuPhZ4Mn4WEZEMSSxsPNgZP+bGxbvYZBpwT9zueWCgmVUDlwGPu/sWd98KPE4Irmqg1N2fc3cH7gGuStvX7Ph+dlq5iIhkQKLXbMws28wWA7WEwHghrvqX2FX2AzPLj2XDgbVpm9fEsq7KazooB6hy9/UA8bWyk+ObYWYLzWxhXV3dYZ+niIh0LdGwcfdmd58EjADONrOJwC3AKcBZwGDgpljdOtrFYZQfyvHNcvcp7j6loqLiUDYVEZFD0Cuj0dx9G/AMMNXd18euskbgl4TrMBBaJiPTNhsBrDtI+YgOygE2xm424mttj56QiIgckiRHo1WY2cD4vhB4P7AiLQSMcC1lSdxkLnBjHJV2LlAfu8DmA5ea2aA4MOBSYH5ct8PMzo37uhF4KG1fqVFr09PKRUQkA3IS3Hc1MNvMsgmhdr+7P2xmT5lZBaEbbDE9I+9SAAATOklEQVTw2Vh/HnAFsBrYDXwSwN23mNl3gRdjve+4+5b4/nPA3UAh8GhcAG4D7jezTwHvAB9J7CxFROSgLAzkkilTpvjChQszfRgiIn2KmS1y9ykHq6cZBEREJHEKGxERSZzCRkREEqewERGRxClsREQkcQobERFJnMJGREQSp7AREZHEKWxERCRxChsREUmcwkZERBKnsBERkcQpbEREJHEKGxERSZzCRkREEpfkw9OOCbP/sobn39zMJeOruPiUSgYW5WX6kEREjjpJPha6wMwWmNkrZrbUzL4dy8eY2QtmtsrMfmtmebE8P35eHdePTtvXLbF8pZldllY+NZatNrOb08o7/I4k7GtuYdHbW/nq/a8w+XtP8NFZz3PXn99i7ZbdSX2liEifk9iTOs3MgAHuvtPMcoE/A18Gvgr8wd3nmNlPgVfcfaaZfR44zd0/a2bXAVe7+7VmNh64DzgbGAY8AZwUv+Z14BKghvDY6I+6+zIzu7+j7+jqeI/kSZ0tLc6r79bz+LINPLZ0I6tqdwJwYmUx7zulkotOqWTycYPIzVavpYj0L919UmevPBbazIoIYfM54BFgqLs3mdl5wK3ufpmZzY/vnzOzHGADUAHcDODu/xb3NR+4Ne76Vne/LJbfEstuA+o6+o6ujrEnHwv91qZdPLl8I0+vrGXBW1vY1+yUFOTw3pMquPjkSi48uYLy4vwe+S4RkUzqbtgkes3GzLKBRcCJwI+BN4Bt7t4Uq9QAw+P74cBagBgS9UB5LH8+bbfp26xtV35O3Kaz72h/fDOAGQCjRo06vJPswJghA/i7C47n7y44np2NTfx5VR1Prajl6ZV1PPLqegDGVhYzZfRgzh4ziCnHDWbEoEJCY1BEpP9JNGzcvRmYZGYDgQeBcR1Vi68d/Z/WuyjvqE+qq/odHd8sYBaElk1HdY5UcX4OUydWM3ViNS0tztJ123l2VR0vrtnCw6+s474F7wBQWZLPxOFlTBhWyvjqUiYMK2PkYAWQiPQPvTIazd23mdkzwLnAQDPLiS2PEcC6WK0GGAnUxG60MmBLWnlK+jYdlW/q4jsyKivLOHVEGaeOKAOgucV5feMOXlyzhZff2cbSdfX86fU6mltC7pXk5zCuupQTKos5oWIAJ1QWc2JFMcMGFpKdpRASkb4jsbAxswpgXwyaQuD9wL8DTwMfBuYA04GH4iZz4+fn4vqn3N3NbC5wr5l9nzBAYCywgNCCGWtmY4B3geuA6+M2nX3HUSU7yxhXXcq46lJuPC+UNexrZuWGHSxdt52l6+pZsWEH815bT/2effu3y8/JYsyQED4nDBnAmIoBjBpcxMjBRVQU56s1JCJHnSRbNtXA7HjdJgu4390fNrNlwBwz+x7wMnBnrH8n8CszW01o0VwH4O5L4+iyZUAT8IXYPYeZfRGYD2QDd7n70rivmzr5jqNeQW42p48cyOkjB+4vc3e27NrLm5t28UbtTt6o28kbdbtY+m49j762nhZP3z6LUYOL9ofPqLRlxKAiCvOyM3BWInKs65XRaH1BT45G602NTc3UbN3DO1t2s3bLbt7ZvJt3trQuu/c2t6lfWZK/P4iGDyxk+KDCNq8FuQojEem+o2I0miQvPyebEyqKOaGi+IB1qRZRKnjWpoXQgre2sL5+T5tWEcCQ4ry2ITSwkOGDWoOprDC3l85MRPoThU0/ZmaUF+dTXpzPGaMGHbC+qbmFDdsbeHfrHt7dtqf1ddseVqzfwZPLa2lsammzTUl+zgGtofTXIQPyydLgBRFpR2FzDMvJzmLEoHAtpyPuzqade9OCaPf+QKrZuocFa7awo6GpzTZ52VlUleUzrKyQYQMLqS4roHpgIcPKCqguK2TYwALKCnM1iEHkGKOwkU6ZGRUl+VSU5DMpbcBCuu0N+0IAbd3Duvo9rNvWwPr6PazbtocFb21h4/YGmtr11RXlZVNdVtAaRjGEwufwvihPfzRF+hP9jZYjUlqQS2l1LuOqSztc39zibNrZyLpte1hf38C6bWmBVN/Ayg111O1spP04lbLC3DaBNGxgCKHqskKGlRVSVZZPfo4GM4j0FQobSVR2llFVWkBVaQFndFJnb1MLG7c3tAZS/R7Wx0B6d1sDL72zlW279x2w3ZDi/NAiKiukOu011TqqLCnQza8iRwmFjWRcXk4WI+Nw7M7s3tvE+voG1m9riN11e/a/X123k/+3qo5d7YZ5Z2cZQ0sL2l03Sr0PwTS4KE8DGkR6gcJG+oSivJxOh3hDGMywvaEpto5au+pSgfTK2m3MX9LA3ua2o+vysrMYWlbA0LIChpUVMLQsdR0ptJAUSCI9Q2Ej/YKZUVaYS1lh59ePWlqczbv27g+jDfV7WL89tJY21Dew8O2tbNy+nn3NbS8gpUbYVZe1DmhIBdLQsgKGlhZQXpyvLjuRLihs5JiRldU6uu60ER3XSQ+k0G0XAmlD7MJ76Z2tbKg/MJCys4zKkvx4fSqfoaUFVJUVUFUSAqmqNLwW5+uvnByb9CdfJM3hBFLt9gY2bG9gQ30jtTsaeLNuF395Y/MB9yABDMjLpiq2hlIDJ4aW5jO0rIDK0lBeUZKvp7pKv6OwETlE3QkkCIMaNm5vZEN9Axu3h2VD6rW+gQVvbaF2R8MBrSSzMNJufwtpfygVpAVVvm6OlT5FYSOSkKK8HMYMyWHMkAGd1mlpcbbs3tsaRvWNbNje2lqq2bqHRW9vZWsHQ7/zc8LghqqSVAjltwZTWWsrSZOrytFAYSOSQVlZxpDifIYU5zNhWFmn9Rr2NVO3o7FNyyi0lBrZuL2BV2u28Vh9wwFz2QEMKsrdH0CtwVTA0LJ8KuM1JY24k6QpbET6gILc7IPei+TubN/TFK4fbW9gY33brruN2xtZum47mzqYsSE326gsiYMbytp13cVuu8pSDXCQw6c/OSL9hJlRVpRLWVEuJw8t6bTevuYW6nY0pnXdNbBxRyMb60Mwrdiwg2df38TOxgMHOBTlZVMVu+eqSguoLMnfPwqvsiQEUmVpPiX5ObqeJG0k+VjokcA9wFCgBZjl7reb2a3Ap4G6WPUf3H1e3OYW4FNAM/Ald58fy6cCtxOeyPkLd78tlo8hPPp5MPAS8HF332tm+fG7JwObgWvdfU1S5yrSl+RmZ8W55gq7rLezsWl/d13tjgZqtzeycXvj/vev1Wxj4/ZG9uxrPmDbgtystDAKAZRqOaU+V5UUUFqoUDpWJPakTjOrBqrd/SUzKwEWAVcB1wA73f0/2tUfD9wHnA0MA54AToqrXwcuAWqAF4GPuvuy+LjoP7j7HDP7KfCKu880s88Dp7n7Z83sOuBqd7+2q+Ptq0/qFMkkd2dnYxO1OxqpTQuiEFCtn2t3NHbYUsrLyWoNoNhCatNqiqE0sEgj745WGX9Sp7uvB9bH9zvMbDkwvItNpgFz3L0ReMvMVhOCB2C1u78JYGZzgGlxfxcD18c6s4FbgZlxX7fG8t8DPzIzcz0DW6RHmRklBbmUFOR2OpVQyq79oRS67WpTgRRfX9+4gz+v3tTh/Um52UZFcX4cch4CqTIOP09131WU5FNRnE9eju5ROhr1yjUbMxsNnAG8AJwPfNHMbgQWAl9z962EIHo+bbMaWsNpbbvyc4ByYJu7N3VQf3hqG3dvMrP6WH9Tu+OaAcwAGDVq1JGepoh0YUB+DmPyux4KDrBnb3NoEcXrSqmWUV1sKdVs3c3L72xly+69Bwx0ABhYlJsWRG2DqfV9AaUF6sLrTYmHjZkVAw8AX3H37WY2E/gu4PH1P4G/BTr61R3o6J8p3kV9DrKutcB9FjALQjda12ciIr2hMC+b48oHcFx516G0r7mFzTv37g+h8NrY5vOLa7ZQu6ORvR0MCc/PyWoXQAeGU2VJAeXFeZrRoQckGjZmlksImt+4+x8A3H1j2vqfAw/HjzXAyLTNRwDr4vuOyjcBA80sJ7Zu0uun9lVjZjlAGbClB09NRDIsN23G7vBXvGOpGcHTQ6hufyiF17c27WLBW1s6vHnWDAYX5e0PptbuvHB/VPr7gYW5ul+pE0mORjPgTmC5u38/rbw6Xs8BuBpYEt/PBe41s+8TBgiMBRYQWilj48izd4HrgOvd3c3saeDDhBFp04GH0vY1HXgurn9K12tEjk3pM4KfWNn1daXGpmY279x7QAspNQBi085G3qzbRd3OjltLOambdEvyOg6l4nyGxLJjbXh4ki2b84GPA6+Z2eJY9g/AR81sEqFbaw3wGQB3XxpHly0DmoAvuHszgJl9EZhPGPp8l7svjfu7CZhjZt8DXiaEG/H1V3GQwRZCQImIdCk/J7tbw8LdnR2NTftbSJt2Nh74fmcjy9ZvZ/POvTS1HPhv3fycrDYto/ahVFGSR0Vx6NYrzOv7Uw4lNvS5r9HQZxFJQkuLs23Pvi5DKfV5866OBz0U5+cwpDivbSgVd9yV19uj8TI+9FlERML8d4MH5DF4QB4n0/nMDgBNzS1s2bV3fwCFENqbFkoNvL5xJ/+zejP1ew68vgRQWpCzP3iGlKSHUt7+efgqSvIpL84jP6f3WkwKGxGRo0ROdlac8qfgoHVT15fat5Q27QzBtGnHXpav286zOxs7vHcJQjANKcnnX68+lXOPL+/p02lDYSMi0gd19/oShFnDN+0MraRNO1Jh1Li/rKwwN/HjVdiIiPRzBbnZjBhUxIhBnc8anjTdqSQiIolT2IiISOIUNiIikjiFjYiIJE5hIyIiiVPYiIhI4hQ2IiKSOIWNiIgkThNxRmZWB7x9mJsPod1TQI8BOudjx7F43jrn7jvO3SsOVklh0wPMbGF3Zj3tT3TOx45j8bx1zj1P3WgiIpI4hY2IiCROYdMzZmX6ADJA53zsOBbPW+fcw3TNRkREEqeWjYiIJE5hIyIiiVPYHCEzm2pmK81stZndnOnjSYqZrTGz18xssZktjGWDzexxM1sVXwdl+jiPhJndZWa1ZrYkrazDc7Tgjvi7v2pmZ2buyA9fJ+d8q5m9G3/rxWZ2Rdq6W+I5rzSzyzJz1EfGzEaa2dNmttzMlprZl2N5v/2tuzjn3vut3V3LYS5ANvAGcDyQB7wCjM/0cSV0rmuAIe3K/g9wc3x/M/DvmT7OIzzH9wJnAksOdo7AFcCjgAHnAi9k+vh78JxvBb7eQd3x8c94PjAm/tnPzvQ5HMY5VwNnxvclwOvx3Prtb93FOffab62WzZE5G1jt7m+6+15gDjAtw8fUm6YBs+P72cBVGTyWI+buzwJb2hV3do7TgHs8eB4YaGbVvXOkPaeTc+7MNGCOuze6+1vAasLfgT7F3de7+0vx/Q5gOTCcfvxbd3HOnenx31phc2SGA2vTPtfQ9Q/YlznwmJktMrMZsazK3ddD+MMMVGbs6JLT2Tn299/+i7HL6K607tF+d85mNho4A3iBY+S3bnfO0Eu/tcLmyFgHZf11LPn57n4mcDnwBTN7b6YPKMP6828/EzgBmASsB/4zlverczazYuAB4Cvuvr2rqh2U9cnz7uCce+23VtgcmRpgZNrnEcC6DB1Lotx9XXytBR4kNKk3proT4mtt5o4wMZ2dY7/97d19o7s3u3sL8HNau0/6zTmbWS7hf7q/cfc/xOJ+/Vt3dM69+VsrbI7Mi8BYMxtjZnnAdcDcDB9TjzOzAWZWknoPXAosIZzr9FhtOvBQZo4wUZ2d41zgxjhS6VygPtUF09e1ux5xNeG3hnDO15lZvpmNAcYCC3r7+I6UmRlwJ7Dc3b+ftqrf/tadnXOv/taZHiXR1xfCSJXXCaM1/jHTx5PQOR5PGJnyCrA0dZ5AOfAksCq+Ds70sR7hed5H6ErYR/iX3ac6O0dCN8OP4+/+GjAl08ffg+f8q3hOr8b/6VSn1f/HeM4rgcszffyHec7/i9Al9CqwOC5X9Offuotz7rXfWtPViIhI4tSNJiIiiVPYiIhI4hQ2IiKSOIWNiIgkTmEjIiKJU9iI9ANmdqGZPZzp4xDpjMJGREQSp7AR6UVmdoOZLYjPDvmZmWWb2U4z+08ze8nMnjSzilh3kpk9HydJfDDt+SonmtkTZvZK3OaEuPtiM/u9ma0ws9/Eu8ZFjgoKG5FeYmbjgGsJk5pOApqBjwEDgJc8THT6J+BbcZN7gJvc/TTCXd6p8t8AP3b304H3EGYAgDCT71cIzyI5Hjg/8ZMS6aacTB+AyDHkfcBk4MXY6CgkTPbYAvw21vk18AczKwMGuvufYvls4Hdxjrrh7v4ggLs3AMT9LXD3mvh5MTAa+HPypyVycAobkd5jwGx3v6VNodk329Xrag6prrrGGtPeN6O/33IUUTeaSO95EviwmVXC/mfeH0f4e/jhWOd64M/uXg9sNbMLYvnHgT95eAZJjZldFfeRb2ZFvXoWIodB//IR6SXuvszM/onwxNMswkzLXwB2ARPMbBFQT7iuA2Ga+5/GMHkT+GQs/zjwMzP7TtzHR3rxNEQOi2Z9FskwM9vp7sWZPg6RJKkbTUREEqeWjYiIJE4tGxERSZzCRkREEqewERGRxClsREQkcQobERFJ3P8PaSu/vy/OwSwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2433f3320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b243428e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 4 увеличили шаг, добавили регуляризацию, заменили сигмоид на релу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 303360.6311 - mean_squared_error: 303358.9619 - val_loss: 612578.3923 - val_mean_squared_error: 612574.5530\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 612578.39230, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_mse` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 187us/step - loss: 278397.9463 - mean_squared_error: 278386.1578 - val_loss: 532154.6105 - val_mean_squared_error: 532117.6261\n",
      "\n",
      "Epoch 00002: val_loss improved from 612578.39230 to 532154.61049, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 202852.8522 - mean_squared_error: 202765.0696 - val_loss: 364746.9925 - val_mean_squared_error: 364544.6758\n",
      "\n",
      "Epoch 00003: val_loss improved from 532154.61049 to 364746.99247, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 100291.7488 - mean_squared_error: 99993.8313 - val_loss: 199128.5198 - val_mean_squared_error: 198528.1124\n",
      "\n",
      "Epoch 00004: val_loss improved from 364746.99247 to 199128.51981, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 54795.1360 - mean_squared_error: 54192.6334 - val_loss: 148807.0653 - val_mean_squared_error: 147943.7607\n",
      "\n",
      "Epoch 00005: val_loss improved from 199128.51981 to 148807.06529, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 46944.0153 - mean_squared_error: 46273.9927 - val_loss: 133060.6768 - val_mean_squared_error: 132126.1811\n",
      "\n",
      "Epoch 00006: val_loss improved from 148807.06529 to 133060.67676, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 42606.3462 - mean_squared_error: 41907.4913 - val_loss: 126300.4032 - val_mean_squared_error: 125367.0088\n",
      "\n",
      "Epoch 00007: val_loss improved from 133060.67676 to 126300.40318, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 40547.7311 - mean_squared_error: 39887.8761 - val_loss: 119872.4645 - val_mean_squared_error: 118897.9078\n",
      "\n",
      "Epoch 00008: val_loss improved from 126300.40318 to 119872.46449, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 39193.9862 - mean_squared_error: 38469.5807 - val_loss: 120925.1681 - val_mean_squared_error: 119989.3707\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 119872.46449\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 38608.9871 - mean_squared_error: 37958.1373 - val_loss: 114418.1367 - val_mean_squared_error: 113427.4259\n",
      "\n",
      "Epoch 00010: val_loss improved from 119872.46449 to 114418.13672, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 37727.2733 - mean_squared_error: 37037.6497 - val_loss: 112071.5572 - val_mean_squared_error: 111069.8455\n",
      "\n",
      "Epoch 00011: val_loss improved from 114418.13672 to 112071.55720, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 37631.6986 - mean_squared_error: 36953.3421 - val_loss: 110743.4929 - val_mean_squared_error: 109749.0609\n",
      "\n",
      "Epoch 00012: val_loss improved from 112071.55720 to 110743.49289, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 36572.3886 - mean_squared_error: 35890.3614 - val_loss: 110518.6399 - val_mean_squared_error: 109546.2870\n",
      "\n",
      "Epoch 00013: val_loss improved from 110743.49289 to 110518.63993, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 36344.0691 - mean_squared_error: 35684.5900 - val_loss: 108102.6988 - val_mean_squared_error: 107094.9427\n",
      "\n",
      "Epoch 00014: val_loss improved from 110518.63993 to 108102.69880, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 36223.5715 - mean_squared_error: 35548.1472 - val_loss: 107392.2521 - val_mean_squared_error: 106403.3240\n",
      "\n",
      "Epoch 00015: val_loss improved from 108102.69880 to 107392.25209, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 35422.5985 - mean_squared_error: 34755.4385 - val_loss: 108207.5905 - val_mean_squared_error: 107247.6432\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 107392.25209\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 35378.3533 - mean_squared_error: 34711.4233 - val_loss: 107620.6436 - val_mean_squared_error: 106668.1967\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 107392.25209\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 34952.5400 - mean_squared_error: 34303.0759 - val_loss: 106274.0930 - val_mean_squared_error: 105296.9789\n",
      "\n",
      "Epoch 00018: val_loss improved from 107392.25209 to 106274.09298, saving model to test.hdf5\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 34887.8097 - mean_squared_error: 34212.7741 - val_loss: 107007.3115 - val_mean_squared_error: 106064.0033\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 106274.09298\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 34398.0759 - mean_squared_error: 33761.9942 - val_loss: 106020.9588 - val_mean_squared_error: 105062.1343\n",
      "\n",
      "Epoch 00020: val_loss improved from 106274.09298 to 106020.95884, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 34115.5278 - mean_squared_error: 33444.1904 - val_loss: 106235.8725 - val_mean_squared_error: 105305.1964\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 106020.95884\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 34408.5798 - mean_squared_error: 33777.0199 - val_loss: 105083.9749 - val_mean_squared_error: 104131.1738\n",
      "\n",
      "Epoch 00022: val_loss improved from 106020.95884 to 105083.97489, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 34006.7177 - mean_squared_error: 33366.7226 - val_loss: 105638.7535 - val_mean_squared_error: 104681.5911\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 105083.97489\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 33497.9406 - mean_squared_error: 32841.7619 - val_loss: 105714.2420 - val_mean_squared_error: 104769.7635\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 105083.97489\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 33353.3730 - mean_squared_error: 32704.4855 - val_loss: 106674.1071 - val_mean_squared_error: 105757.8352\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 105083.97489\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 33405.1451 - mean_squared_error: 32774.1241 - val_loss: 106477.3684 - val_mean_squared_error: 105555.4205\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 105083.97489\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 33058.7784 - mean_squared_error: 32427.9415 - val_loss: 105894.7794 - val_mean_squared_error: 104962.8380\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 105083.97489\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 32740.0017 - mean_squared_error: 32110.6931 - val_loss: 105119.2780 - val_mean_squared_error: 104177.7139\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 105083.97489\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 33153.7302 - mean_squared_error: 32497.6182 - val_loss: 107424.9428 - val_mean_squared_error: 106517.1124\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 105083.97489\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 32751.9056 - mean_squared_error: 32133.6307 - val_loss: 104481.0935 - val_mean_squared_error: 103558.6547\n",
      "\n",
      "Epoch 00030: val_loss improved from 105083.97489 to 104481.09347, saving model to test.hdf5\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 32263.7924 - mean_squared_error: 31629.3964 - val_loss: 104303.1567 - val_mean_squared_error: 103378.9386\n",
      "\n",
      "Epoch 00031: val_loss improved from 104481.09347 to 104303.15667, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 31887.7755 - mean_squared_error: 31255.9055 - val_loss: 104873.9064 - val_mean_squared_error: 103949.9100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 104303.15667\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 32357.5829 - mean_squared_error: 31728.1949 - val_loss: 104863.7868 - val_mean_squared_error: 103944.9092\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 104303.15667\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 31868.5272 - mean_squared_error: 31238.3716 - val_loss: 104647.7158 - val_mean_squared_error: 103734.4854\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 104303.15667\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 31868.4450 - mean_squared_error: 31235.2226 - val_loss: 103286.5845 - val_mean_squared_error: 102374.4621\n",
      "\n",
      "Epoch 00035: val_loss improved from 104303.15667 to 103286.58454, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 31759.8765 - mean_squared_error: 31147.5283 - val_loss: 102837.3059 - val_mean_squared_error: 101892.0985\n",
      "\n",
      "Epoch 00036: val_loss improved from 103286.58454 to 102837.30594, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 31166.2016 - mean_squared_error: 30547.6875 - val_loss: 103228.0384 - val_mean_squared_error: 102245.2358\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 102837.30594\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 31629.7529 - mean_squared_error: 30967.2105 - val_loss: 105512.5760 - val_mean_squared_error: 104614.6673\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 102837.30594\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 31117.3956 - mean_squared_error: 30493.3078 - val_loss: 106826.8983 - val_mean_squared_error: 105939.0165\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 102837.30594\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 31158.1908 - mean_squared_error: 30542.0430 - val_loss: 104528.0534 - val_mean_squared_error: 103613.0165\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 102837.30594\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 30904.6779 - mean_squared_error: 30285.2302 - val_loss: 104204.2843 - val_mean_squared_error: 103275.2270\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 102837.30594\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 31328.4095 - mean_squared_error: 30692.2033 - val_loss: 106609.2266 - val_mean_squared_error: 105716.8906\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 102837.30594\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 30646.3468 - mean_squared_error: 30027.4871 - val_loss: 103836.7333 - val_mean_squared_error: 102943.1621\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 102837.30594\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 30803.1338 - mean_squared_error: 30198.4859 - val_loss: 103291.1597 - val_mean_squared_error: 102363.6374\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 102837.30594\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 30499.2029 - mean_squared_error: 29873.4614 - val_loss: 102793.6777 - val_mean_squared_error: 101861.9422\n",
      "\n",
      "Epoch 00045: val_loss improved from 102837.30594 to 102793.67773, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 30643.6962 - mean_squared_error: 30017.8168 - val_loss: 103207.6994 - val_mean_squared_error: 102281.5240\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 102793.67773\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 30386.2495 - mean_squared_error: 29768.5989 - val_loss: 103006.6104 - val_mean_squared_error: 102074.8828\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 102793.67773\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 30069.4570 - mean_squared_error: 29432.9396 - val_loss: 102815.5113 - val_mean_squared_error: 101901.1967\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 102793.67773\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 29897.9186 - mean_squared_error: 29282.4469 - val_loss: 102766.9929 - val_mean_squared_error: 101835.1381\n",
      "\n",
      "Epoch 00049: val_loss improved from 102793.67773 to 102766.99289, saving model to test.hdf5\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 179us/step - loss: 30049.4035 - mean_squared_error: 29413.8173 - val_loss: 103107.7377 - val_mean_squared_error: 102182.4764\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 102766.99289\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 29825.7788 - mean_squared_error: 29203.3179 - val_loss: 104049.9612 - val_mean_squared_error: 103117.3888\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 102766.99289\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 29393.7815 - mean_squared_error: 28753.5419 - val_loss: 103003.7673 - val_mean_squared_error: 102098.9167\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 102766.99289\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 29221.7331 - mean_squared_error: 28594.2677 - val_loss: 105093.3220 - val_mean_squared_error: 104209.1509\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 102766.99289\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 29436.1877 - mean_squared_error: 28812.2210 - val_loss: 104564.0113 - val_mean_squared_error: 103663.9887\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 102766.99289\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 29226.3085 - mean_squared_error: 28606.1594 - val_loss: 102411.7811 - val_mean_squared_error: 101475.7704\n",
      "\n",
      "Epoch 00055: val_loss improved from 102766.99289 to 102411.78111, saving model to test.hdf5\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 28922.0426 - mean_squared_error: 28266.9288 - val_loss: 103101.5689 - val_mean_squared_error: 102199.5264\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 102411.78111\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 29210.7095 - mean_squared_error: 28572.8315 - val_loss: 103792.4866 - val_mean_squared_error: 102875.3673\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 102411.78111\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 28917.2487 - mean_squared_error: 28285.8604 - val_loss: 103378.0903 - val_mean_squared_error: 102431.4710\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 102411.78111\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 28702.8216 - mean_squared_error: 28074.0151 - val_loss: 102610.5088 - val_mean_squared_error: 101655.4275\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 102411.78111\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 173us/step - loss: 28493.3006 - mean_squared_error: 27835.3485 - val_loss: 101990.5698 - val_mean_squared_error: 101076.1653\n",
      "\n",
      "Epoch 00060: val_loss improved from 102411.78111 to 101990.56975, saving model to test.hdf5\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 28857.8759 - mean_squared_error: 28220.1123 - val_loss: 104039.1436 - val_mean_squared_error: 103125.1310\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 101990.56975\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 165us/step - loss: 28378.0834 - mean_squared_error: 27735.0773 - val_loss: 102483.9083 - val_mean_squared_error: 101568.4436\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 101990.56975\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 27933.5758 - mean_squared_error: 27285.7012 - val_loss: 102183.0886 - val_mean_squared_error: 101260.2582\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 101990.56975\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 28282.4356 - mean_squared_error: 27637.4042 - val_loss: 103450.0554 - val_mean_squared_error: 102532.0667\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 101990.56975\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 157us/step - loss: 28021.6047 - mean_squared_error: 27386.8312 - val_loss: 102804.4955 - val_mean_squared_error: 101860.0036\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 101990.56975\n",
      "Epoch 66/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 179us/step - loss: 27714.2240 - mean_squared_error: 27049.8671 - val_loss: 102386.6875 - val_mean_squared_error: 101449.9262\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 101990.56975\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 27587.8681 - mean_squared_error: 26956.3453 - val_loss: 101283.3397 - val_mean_squared_error: 100304.0166\n",
      "\n",
      "Epoch 00067: val_loss improved from 101990.56975 to 101283.33970, saving model to test.hdf5\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 27848.4566 - mean_squared_error: 27174.2948 - val_loss: 102566.6208 - val_mean_squared_error: 101603.6123\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 101283.33970\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 27262.3032 - mean_squared_error: 26598.8928 - val_loss: 101604.3386 - val_mean_squared_error: 100659.4805\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 101283.33970\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 27114.5511 - mean_squared_error: 26462.2020 - val_loss: 100259.5710 - val_mean_squared_error: 99287.2174\n",
      "\n",
      "Epoch 00070: val_loss improved from 101283.33970 to 100259.57101, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 27592.9399 - mean_squared_error: 26917.2311 - val_loss: 104295.8232 - val_mean_squared_error: 103345.5529\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 100259.57101\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 27098.4333 - mean_squared_error: 26419.2558 - val_loss: 103102.4344 - val_mean_squared_error: 102161.0844\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 100259.57101\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 27160.6249 - mean_squared_error: 26494.8080 - val_loss: 102651.8737 - val_mean_squared_error: 101700.8537\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 100259.57101\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 26896.5953 - mean_squared_error: 26248.2398 - val_loss: 99477.8878 - val_mean_squared_error: 98463.2038\n",
      "\n",
      "Epoch 00074: val_loss improved from 100259.57101 to 99477.88783, saving model to test.hdf5\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 27327.3360 - mean_squared_error: 26636.2248 - val_loss: 102186.0008 - val_mean_squared_error: 101208.2740\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 99477.88783\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 26941.0044 - mean_squared_error: 26279.1601 - val_loss: 100716.0628 - val_mean_squared_error: 99713.8810\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 99477.88783\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 26736.3408 - mean_squared_error: 26041.9176 - val_loss: 102241.5177 - val_mean_squared_error: 101257.9669\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 99477.88783\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 26435.9188 - mean_squared_error: 25753.6546 - val_loss: 101506.3850 - val_mean_squared_error: 100514.4434\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 99477.88783\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 26417.0590 - mean_squared_error: 25724.1997 - val_loss: 103986.5728 - val_mean_squared_error: 103013.0978\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 99477.88783\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 26435.1522 - mean_squared_error: 25741.9890 - val_loss: 102702.8658 - val_mean_squared_error: 101720.9718\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 99477.88783\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 171us/step - loss: 26219.6389 - mean_squared_error: 25532.9469 - val_loss: 102595.4224 - val_mean_squared_error: 101618.9668\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 99477.88783\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 26195.8498 - mean_squared_error: 25514.1658 - val_loss: 103082.0547 - val_mean_squared_error: 102082.4184\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 99477.88783\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 177us/step - loss: 25957.5781 - mean_squared_error: 25262.8591 - val_loss: 102618.2218 - val_mean_squared_error: 101611.5073\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 99477.88783\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 26079.8953 - mean_squared_error: 25373.9552 - val_loss: 103747.7273 - val_mean_squared_error: 102747.0794\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 99477.88783\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 26404.2544 - mean_squared_error: 25688.7667 - val_loss: 101103.2232 - val_mean_squared_error: 100112.4901\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 99477.88783\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 159us/step - loss: 25752.1169 - mean_squared_error: 25049.9802 - val_loss: 105157.5953 - val_mean_squared_error: 104179.4837\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 99477.88783\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 25758.7820 - mean_squared_error: 25078.8199 - val_loss: 103428.3129 - val_mean_squared_error: 102390.1656\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 99477.88783\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 26123.5758 - mean_squared_error: 25415.6019 - val_loss: 101398.8764 - val_mean_squared_error: 100349.1978\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 99477.88783\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 161us/step - loss: 25567.7142 - mean_squared_error: 24851.6966 - val_loss: 103606.9215 - val_mean_squared_error: 102560.2660\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 99477.88783\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 25761.4256 - mean_squared_error: 25038.1497 - val_loss: 106358.5907 - val_mean_squared_error: 105330.1422\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 99477.88783\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 163us/step - loss: 25763.3966 - mean_squared_error: 25052.0853 - val_loss: 102539.8364 - val_mean_squared_error: 101481.1410\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 99477.88783\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 169us/step - loss: 25765.4785 - mean_squared_error: 25030.2876 - val_loss: 104701.3015 - val_mean_squared_error: 103679.4368\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 99477.88783\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 167us/step - loss: 25658.2950 - mean_squared_error: 24941.1049 - val_loss: 104497.3318 - val_mean_squared_error: 103463.0190\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 99477.88783\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 25633.3005 - mean_squared_error: 24902.3256 - val_loss: 105662.8963 - val_mean_squared_error: 104651.3299\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 99477.88783\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 175us/step - loss: 25341.7256 - mean_squared_error: 24627.4153 - val_loss: 102848.7203 - val_mean_squared_error: 101794.7852\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 99477.88783\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 25625.1209 - mean_squared_error: 24883.5165 - val_loss: 104870.5632 - val_mean_squared_error: 103849.1409\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 99477.88783\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 25265.9243 - mean_squared_error: 24529.7728 - val_loss: 105040.1685 - val_mean_squared_error: 104021.4683\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 99477.88783\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 25303.8269 - mean_squared_error: 24568.7997 - val_loss: 106390.1603 - val_mean_squared_error: 105374.9142\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 99477.88783\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 25022.9823 - mean_squared_error: 24283.1728 - val_loss: 107069.4135 - val_mean_squared_error: 106051.2420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00099: val_loss did not improve from 99477.88783\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 24787.3782 - mean_squared_error: 24066.1743 - val_loss: 106282.3910 - val_mean_squared_error: 105241.9622\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 99477.88783\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 24824.5295 - mean_squared_error: 24081.2608 - val_loss: 105908.0979 - val_mean_squared_error: 104881.7016\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 99477.88783\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 24660.2193 - mean_squared_error: 23932.1282 - val_loss: 105025.3531 - val_mean_squared_error: 103999.8450\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 99477.88783\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 24642.8411 - mean_squared_error: 23903.2564 - val_loss: 105079.3495 - val_mean_squared_error: 104045.1635\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 99477.88783\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 24546.5290 - mean_squared_error: 23810.7898 - val_loss: 105776.4569 - val_mean_squared_error: 104708.4729\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 99477.88783\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 24693.4964 - mean_squared_error: 23930.5817 - val_loss: 108571.0024 - val_mean_squared_error: 107529.1069\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 99477.88783\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 24598.9523 - mean_squared_error: 23852.9780 - val_loss: 105390.2605 - val_mean_squared_error: 104330.4347\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 99477.88783\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 24682.4345 - mean_squared_error: 23934.4724 - val_loss: 104793.1003 - val_mean_squared_error: 103741.7487\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 99477.88783\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 24314.6626 - mean_squared_error: 23572.2228 - val_loss: 106872.7172 - val_mean_squared_error: 105801.5748\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 99477.88783\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 24524.2332 - mean_squared_error: 23776.1174 - val_loss: 105658.9985 - val_mean_squared_error: 104567.5356\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 99477.88783\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 24659.6479 - mean_squared_error: 23892.3665 - val_loss: 106482.5102 - val_mean_squared_error: 105413.6941\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 99477.88783\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 24407.3928 - mean_squared_error: 23655.6540 - val_loss: 105489.3941 - val_mean_squared_error: 104408.5961\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 99477.88783\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 24590.6303 - mean_squared_error: 23837.2987 - val_loss: 107582.6740 - val_mean_squared_error: 106502.7794\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 99477.88783\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 24431.8551 - mean_squared_error: 23668.8648 - val_loss: 106675.7673 - val_mean_squared_error: 105587.4531\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 99477.88783\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 24059.9424 - mean_squared_error: 23284.9044 - val_loss: 110402.9096 - val_mean_squared_error: 109355.3460\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 99477.88783\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 24066.2677 - mean_squared_error: 23299.5045 - val_loss: 107766.6681 - val_mean_squared_error: 106725.7914\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 99477.88783\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 23765.6127 - mean_squared_error: 23006.5084 - val_loss: 107393.1203 - val_mean_squared_error: 106347.9884\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 99477.88783\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 24466.9690 - mean_squared_error: 23712.9137 - val_loss: 107789.1787 - val_mean_squared_error: 106709.7088\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 99477.88783\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 23701.9028 - mean_squared_error: 22923.3311 - val_loss: 109336.1388 - val_mean_squared_error: 108274.9421\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 99477.88783\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 24096.0871 - mean_squared_error: 23343.1935 - val_loss: 105841.4820 - val_mean_squared_error: 104730.2207\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 99477.88783\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 24188.8300 - mean_squared_error: 23411.7582 - val_loss: 106720.4943 - val_mean_squared_error: 105625.2196\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 99477.88783\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 23828.1206 - mean_squared_error: 23055.8416 - val_loss: 106925.8092 - val_mean_squared_error: 105825.0776\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 99477.88783\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 23409.3494 - mean_squared_error: 22631.1413 - val_loss: 106006.7713 - val_mean_squared_error: 104886.2699\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 99477.88783\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 23942.2019 - mean_squared_error: 23165.0881 - val_loss: 104258.5829 - val_mean_squared_error: 103135.9647\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 99477.88783\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 23590.5835 - mean_squared_error: 22798.8967 - val_loss: 107756.8418 - val_mean_squared_error: 106657.6835\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 99477.88783\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 23727.6635 - mean_squared_error: 22945.3831 - val_loss: 106050.4354 - val_mean_squared_error: 104946.9900\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 99477.88783\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 23622.7784 - mean_squared_error: 22837.9370 - val_loss: 107679.9131 - val_mean_squared_error: 106574.5262\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 99477.88783\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 23380.4076 - mean_squared_error: 22589.4272 - val_loss: 108255.6775 - val_mean_squared_error: 107166.0734\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 99477.88783\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 23079.8110 - mean_squared_error: 22302.4644 - val_loss: 105243.4506 - val_mean_squared_error: 104123.7397\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 99477.88783\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 23489.4509 - mean_squared_error: 22691.9321 - val_loss: 108542.2422 - val_mean_squared_error: 107448.8652\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 99477.88783\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 23812.4331 - mean_squared_error: 23027.8032 - val_loss: 108264.7320 - val_mean_squared_error: 107169.4489\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 99477.88783\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 23218.9378 - mean_squared_error: 22438.2199 - val_loss: 105099.2291 - val_mean_squared_error: 103970.8050\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 99477.88783\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 23425.9678 - mean_squared_error: 22635.8891 - val_loss: 105792.7977 - val_mean_squared_error: 104653.3442\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 99477.88783\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 23300.2789 - mean_squared_error: 22494.3122 - val_loss: 109252.8573 - val_mean_squared_error: 108171.7161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00133: val_loss did not improve from 99477.88783\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 23213.9625 - mean_squared_error: 22435.6255 - val_loss: 108741.9526 - val_mean_squared_error: 107634.2116\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 99477.88783\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 23293.3490 - mean_squared_error: 22499.6981 - val_loss: 107378.8839 - val_mean_squared_error: 106267.5585\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 99477.88783\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 22967.3164 - mean_squared_error: 22168.9658 - val_loss: 109970.9255 - val_mean_squared_error: 108887.7582\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 99477.88783\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 23164.9443 - mean_squared_error: 22370.9621 - val_loss: 110351.9501 - val_mean_squared_error: 109247.5852\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 99477.88783\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 22860.7278 - mean_squared_error: 22077.8032 - val_loss: 108265.2593 - val_mean_squared_error: 107144.7779\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 99477.88783\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 23108.7729 - mean_squared_error: 22299.1935 - val_loss: 110515.4414 - val_mean_squared_error: 109443.2181\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 99477.88783\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 23133.7578 - mean_squared_error: 22347.8810 - val_loss: 108707.2268 - val_mean_squared_error: 107607.6701\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 99477.88783\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 22695.9972 - mean_squared_error: 21901.9017 - val_loss: 108854.8362 - val_mean_squared_error: 107751.8894\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 99477.88783\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 22830.7882 - mean_squared_error: 22042.2152 - val_loss: 107788.0841 - val_mean_squared_error: 106685.8436\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 99477.88783\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 22728.1060 - mean_squared_error: 21933.5012 - val_loss: 108592.4814 - val_mean_squared_error: 107471.8910\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 99477.88783\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 22705.7310 - mean_squared_error: 21905.7485 - val_loss: 108298.9653 - val_mean_squared_error: 107176.0448\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 99477.88783\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 22512.6307 - mean_squared_error: 21710.7270 - val_loss: 109607.4081 - val_mean_squared_error: 108495.7574\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 99477.88783\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 22720.8089 - mean_squared_error: 21929.8706 - val_loss: 109593.5950 - val_mean_squared_error: 108485.6982\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 99477.88783\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 22595.6894 - mean_squared_error: 21802.3011 - val_loss: 111171.9593 - val_mean_squared_error: 110038.7450\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 99477.88783\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 22396.7005 - mean_squared_error: 21588.6072 - val_loss: 111861.5042 - val_mean_squared_error: 110758.6883\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 99477.88783\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 22333.7260 - mean_squared_error: 21555.5634 - val_loss: 106473.4821 - val_mean_squared_error: 105321.0605\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 99477.88783\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 22496.4030 - mean_squared_error: 21678.4157 - val_loss: 109655.7319 - val_mean_squared_error: 108555.7680\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 99477.88783\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 22758.0774 - mean_squared_error: 21956.2449 - val_loss: 111667.6776 - val_mean_squared_error: 110579.4605\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 99477.88783\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 22509.2661 - mean_squared_error: 21714.8877 - val_loss: 110570.0661 - val_mean_squared_error: 109456.5386\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 99477.88783\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 21728.2577 - mean_squared_error: 20937.7798 - val_loss: 107657.2020 - val_mean_squared_error: 106492.2669\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 99477.88783\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 23109.5044 - mean_squared_error: 22296.2941 - val_loss: 111485.2108 - val_mean_squared_error: 110382.7759\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 99477.88783\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 22222.3967 - mean_squared_error: 21438.8673 - val_loss: 107262.9104 - val_mean_squared_error: 106116.6773\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 99477.88783\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 22641.3026 - mean_squared_error: 21821.3340 - val_loss: 111569.5273 - val_mean_squared_error: 110475.5106\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 99477.88783\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 22162.4536 - mean_squared_error: 21370.3700 - val_loss: 108974.6476 - val_mean_squared_error: 107865.5766\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 99477.88783\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 22008.6951 - mean_squared_error: 21214.2435 - val_loss: 107711.9477 - val_mean_squared_error: 106562.4883\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 99477.88783\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 21960.3879 - mean_squared_error: 21144.4053 - val_loss: 109677.6562 - val_mean_squared_error: 108560.0640\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 99477.88783\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 21981.8507 - mean_squared_error: 21171.5975 - val_loss: 110513.5259 - val_mean_squared_error: 109406.5991\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 99477.88783\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 21971.4689 - mean_squared_error: 21178.4808 - val_loss: 106759.8781 - val_mean_squared_error: 105619.1539\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 99477.88783\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 22189.9071 - mean_squared_error: 21380.5236 - val_loss: 106420.9978 - val_mean_squared_error: 105303.3245\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 99477.88783\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 22280.2785 - mean_squared_error: 21484.3083 - val_loss: 105802.2835 - val_mean_squared_error: 104646.8235\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 99477.88783\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 21800.6787 - mean_squared_error: 20975.3363 - val_loss: 111686.9159 - val_mean_squared_error: 110598.2998\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 99477.88783\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 21951.3376 - mean_squared_error: 21153.6684 - val_loss: 110119.3963 - val_mean_squared_error: 109012.5414\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 99477.88783\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 21564.6425 - mean_squared_error: 20761.7761 - val_loss: 107071.8951 - val_mean_squared_error: 105950.4263\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 99477.88783\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 21888.4421 - mean_squared_error: 21083.2592 - val_loss: 108564.8364 - val_mean_squared_error: 107444.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00167: val_loss did not improve from 99477.88783\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 21695.4053 - mean_squared_error: 20879.7232 - val_loss: 111866.6006 - val_mean_squared_error: 110770.1667\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 99477.88783\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 21600.7537 - mean_squared_error: 20812.7444 - val_loss: 109100.8569 - val_mean_squared_error: 107958.4519\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 99477.88783\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 21633.2540 - mean_squared_error: 20817.6807 - val_loss: 111211.3691 - val_mean_squared_error: 110107.1203\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 99477.88783\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 21496.2876 - mean_squared_error: 20707.0538 - val_loss: 109881.4789 - val_mean_squared_error: 108765.1885\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 99477.88783\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 21297.7887 - mean_squared_error: 20491.5481 - val_loss: 111500.0466 - val_mean_squared_error: 110385.0924\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 99477.88783\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 21223.0500 - mean_squared_error: 20429.7512 - val_loss: 110298.3054 - val_mean_squared_error: 109142.8171\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 99477.88783\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 21709.8923 - mean_squared_error: 20893.4314 - val_loss: 111881.7814 - val_mean_squared_error: 110768.3535\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 99477.88783\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 21692.0399 - mean_squared_error: 20890.5038 - val_loss: 109558.5085 - val_mean_squared_error: 108432.1713\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 99477.88783\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 21367.9890 - mean_squared_error: 20557.3599 - val_loss: 112240.5027 - val_mean_squared_error: 111135.0718\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 99477.88783\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 21757.5367 - mean_squared_error: 20948.5595 - val_loss: 114299.0780 - val_mean_squared_error: 113208.1391\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 99477.88783\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 20999.9946 - mean_squared_error: 20204.8140 - val_loss: 106948.4774 - val_mean_squared_error: 105796.9554\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 99477.88783\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 21269.3989 - mean_squared_error: 20460.6263 - val_loss: 109467.9683 - val_mean_squared_error: 108342.5135\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 99477.88783\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 21047.6689 - mean_squared_error: 20242.9603 - val_loss: 111766.2479 - val_mean_squared_error: 110642.6805\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 99477.88783\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 20801.3092 - mean_squared_error: 19980.1035 - val_loss: 113081.8670 - val_mean_squared_error: 111998.0359\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 99477.88783\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 21193.6720 - mean_squared_error: 20411.0016 - val_loss: 109304.2006 - val_mean_squared_error: 108158.4643\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 99477.88783\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 21873.8434 - mean_squared_error: 21050.4363 - val_loss: 114110.6261 - val_mean_squared_error: 113007.3809\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 99477.88783\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 21271.2734 - mean_squared_error: 20477.1094 - val_loss: 109044.0857 - val_mean_squared_error: 107914.0847\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 99477.88783\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 21860.8395 - mean_squared_error: 21048.7586 - val_loss: 111685.6943 - val_mean_squared_error: 110566.0887\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 99477.88783\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 21067.0556 - mean_squared_error: 20266.2753 - val_loss: 112406.7147 - val_mean_squared_error: 111314.5569\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 99477.88783\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 20804.0565 - mean_squared_error: 20006.5643 - val_loss: 111969.7261 - val_mean_squared_error: 110861.2581\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 99477.88783\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20983.8761 - mean_squared_error: 20190.3760 - val_loss: 111459.0428 - val_mean_squared_error: 110343.3225\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 99477.88783\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20900.1546 - mean_squared_error: 20089.6261 - val_loss: 115061.8475 - val_mean_squared_error: 113983.2550\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 99477.88783\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 21093.8552 - mean_squared_error: 20313.2782 - val_loss: 110482.7778 - val_mean_squared_error: 109359.1016\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 99477.88783\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 20951.7593 - mean_squared_error: 20152.3253 - val_loss: 112501.6786 - val_mean_squared_error: 111381.8636\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 99477.88783\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 21144.0914 - mean_squared_error: 20342.1256 - val_loss: 110630.1069 - val_mean_squared_error: 109511.3873\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 99477.88783\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20404.9926 - mean_squared_error: 19593.7824 - val_loss: 115354.8315 - val_mean_squared_error: 114276.5557\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 99477.88783\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 21021.6849 - mean_squared_error: 20227.1420 - val_loss: 113592.8068 - val_mean_squared_error: 112496.3753\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 99477.88783\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 20785.9289 - mean_squared_error: 19995.2276 - val_loss: 111054.6327 - val_mean_squared_error: 109942.3244\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 99477.88783\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 20830.5083 - mean_squared_error: 20041.0083 - val_loss: 109601.3023 - val_mean_squared_error: 108468.5265\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 99477.88783\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20626.9026 - mean_squared_error: 19827.2745 - val_loss: 112218.5237 - val_mean_squared_error: 111105.8746\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 99477.88783\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20523.9057 - mean_squared_error: 19731.2475 - val_loss: 111112.2727 - val_mean_squared_error: 109980.0336\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 99477.88783\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 20401.0328 - mean_squared_error: 19598.1295 - val_loss: 113042.5462 - val_mean_squared_error: 111943.9482\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 99477.88783\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 20822.8633 - mean_squared_error: 20038.4826 - val_loss: 110839.4696 - val_mean_squared_error: 109731.3676\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 99477.88783\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 20523.0898 - mean_squared_error: 19729.3472 - val_loss: 109031.5251 - val_mean_squared_error: 107906.9421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00201: val_loss did not improve from 99477.88783\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 20402.3772 - mean_squared_error: 19601.5272 - val_loss: 109866.4728 - val_mean_squared_error: 108740.2938\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 99477.88783\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 20296.5578 - mean_squared_error: 19497.3127 - val_loss: 111500.3605 - val_mean_squared_error: 110395.6399\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 99477.88783\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20864.0220 - mean_squared_error: 20062.7068 - val_loss: 114222.6715 - val_mean_squared_error: 113147.8757\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 99477.88783\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 21106.3844 - mean_squared_error: 20311.6359 - val_loss: 115247.4314 - val_mean_squared_error: 114174.1123\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 99477.88783\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 20243.0262 - mean_squared_error: 19453.4793 - val_loss: 114046.9446 - val_mean_squared_error: 112960.9918\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 99477.88783\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 20005.0975 - mean_squared_error: 19219.0047 - val_loss: 111776.9315 - val_mean_squared_error: 110670.4248\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 99477.88783\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20020.8362 - mean_squared_error: 19227.1285 - val_loss: 111967.8135 - val_mean_squared_error: 110857.5695\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 99477.88783\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20317.3969 - mean_squared_error: 19532.4869 - val_loss: 112999.9255 - val_mean_squared_error: 111903.6490\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 99477.88783\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 20375.0275 - mean_squared_error: 19577.3758 - val_loss: 113434.9682 - val_mean_squared_error: 112361.2535\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 99477.88783\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20379.4297 - mean_squared_error: 19608.7275 - val_loss: 111172.1459 - val_mean_squared_error: 110060.5932\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 99477.88783\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 20054.0082 - mean_squared_error: 19267.0053 - val_loss: 111021.1363 - val_mean_squared_error: 109913.5516\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 99477.88783\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 19933.8505 - mean_squared_error: 19151.5641 - val_loss: 108091.2181 - val_mean_squared_error: 106958.9368\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 99477.88783\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20211.2507 - mean_squared_error: 19410.7482 - val_loss: 111969.7148 - val_mean_squared_error: 110873.4496\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 99477.88783\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 19937.5864 - mean_squared_error: 19145.3916 - val_loss: 116588.5481 - val_mean_squared_error: 115511.3308\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 99477.88783\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 20208.3557 - mean_squared_error: 19426.5841 - val_loss: 112598.3285 - val_mean_squared_error: 111513.3246\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 99477.88783\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 19956.5815 - mean_squared_error: 19172.1567 - val_loss: 113665.0808 - val_mean_squared_error: 112579.4672\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 99477.88783\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 19953.2708 - mean_squared_error: 19175.9195 - val_loss: 112439.3471 - val_mean_squared_error: 111337.8742\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 99477.88783\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 19801.6444 - mean_squared_error: 19019.8141 - val_loss: 112592.7900 - val_mean_squared_error: 111512.2914\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 99477.88783\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 19765.9381 - mean_squared_error: 18991.6837 - val_loss: 112229.4826 - val_mean_squared_error: 111140.8298\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 99477.88783\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 19641.2172 - mean_squared_error: 18850.7444 - val_loss: 114746.6490 - val_mean_squared_error: 113670.9884\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 99477.88783\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 19974.4946 - mean_squared_error: 19209.8759 - val_loss: 110620.1759 - val_mean_squared_error: 109500.9276\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 99477.88783\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 19624.1286 - mean_squared_error: 18823.7031 - val_loss: 116709.0859 - val_mean_squared_error: 115658.9188\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 99477.88783\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 20228.2490 - mean_squared_error: 19468.3071 - val_loss: 112029.6917 - val_mean_squared_error: 110924.8417\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 99477.88783\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 19658.6672 - mean_squared_error: 18870.5396 - val_loss: 115476.4452 - val_mean_squared_error: 114398.4199\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 99477.88783\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 19568.0118 - mean_squared_error: 18788.9939 - val_loss: 116558.8202 - val_mean_squared_error: 115493.5653\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 99477.88783\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 19727.3818 - mean_squared_error: 18950.6798 - val_loss: 114109.2196 - val_mean_squared_error: 113021.9583\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 99477.88783\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 19228.8250 - mean_squared_error: 18450.9865 - val_loss: 114479.6547 - val_mean_squared_error: 113396.1978\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 99477.88783\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 19487.4724 - mean_squared_error: 18714.0760 - val_loss: 115714.9072 - val_mean_squared_error: 114645.9625\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 99477.88783\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 20013.3319 - mean_squared_error: 19248.7419 - val_loss: 111762.6426 - val_mean_squared_error: 110655.4944\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 99477.88783\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 19648.3289 - mean_squared_error: 18856.2235 - val_loss: 116834.3842 - val_mean_squared_error: 115780.2532\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 99477.88783\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 19540.6619 - mean_squared_error: 18780.2801 - val_loss: 113981.2326 - val_mean_squared_error: 112903.4994\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 99477.88783\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 19253.0594 - mean_squared_error: 18476.9188 - val_loss: 112908.7626 - val_mean_squared_error: 111835.9122\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 99477.88783\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 19355.5929 - mean_squared_error: 18594.4658 - val_loss: 110693.4371 - val_mean_squared_error: 109595.3435\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 99477.88783\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 19027.6059 - mean_squared_error: 18245.5965 - val_loss: 112953.6496 - val_mean_squared_error: 111873.5642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00235: val_loss did not improve from 99477.88783\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 19175.0423 - mean_squared_error: 18392.6711 - val_loss: 117620.4588 - val_mean_squared_error: 116560.0525\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 99477.88783\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 19252.8294 - mean_squared_error: 18480.4263 - val_loss: 115465.2810 - val_mean_squared_error: 114407.0368\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 99477.88783\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 19338.9897 - mean_squared_error: 18569.6008 - val_loss: 115747.8722 - val_mean_squared_error: 114687.7125\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 99477.88783\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 19735.5037 - mean_squared_error: 18971.5376 - val_loss: 114882.5043 - val_mean_squared_error: 113806.6692\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 99477.88783\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 19187.9129 - mean_squared_error: 18421.8974 - val_loss: 114854.6961 - val_mean_squared_error: 113775.9661\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 99477.88783\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 19176.5287 - mean_squared_error: 18401.8734 - val_loss: 112232.2655 - val_mean_squared_error: 111164.3668\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 99477.88783\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 18905.0040 - mean_squared_error: 18139.9335 - val_loss: 113782.2641 - val_mean_squared_error: 112719.8638\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 99477.88783\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 19468.2208 - mean_squared_error: 18704.2898 - val_loss: 116784.6818 - val_mean_squared_error: 115737.0434\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 99477.88783\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 19310.4708 - mean_squared_error: 18560.9660 - val_loss: 114981.6423 - val_mean_squared_error: 113921.4704\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 99477.88783\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 19198.7822 - mean_squared_error: 18423.2213 - val_loss: 116609.4219 - val_mean_squared_error: 115578.0573\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 99477.88783\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 19224.8166 - mean_squared_error: 18478.0282 - val_loss: 114304.1332 - val_mean_squared_error: 113236.6521\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 99477.88783\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 18933.9082 - mean_squared_error: 18158.5692 - val_loss: 118879.3096 - val_mean_squared_error: 117839.9142\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 99477.88783\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 18668.4005 - mean_squared_error: 17915.0974 - val_loss: 116138.7985 - val_mean_squared_error: 115085.8068\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 99477.88783\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 18685.9005 - mean_squared_error: 17924.6313 - val_loss: 115388.9062 - val_mean_squared_error: 114337.3779\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 99477.88783\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 18941.0541 - mean_squared_error: 18180.4087 - val_loss: 115971.7134 - val_mean_squared_error: 114914.1297\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 99477.88783\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 18848.5668 - mean_squared_error: 18090.3334 - val_loss: 113260.5781 - val_mean_squared_error: 112181.9806\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 99477.88783\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 18644.3943 - mean_squared_error: 17872.3484 - val_loss: 117423.7196 - val_mean_squared_error: 116388.6341\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 99477.88783\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 18519.7440 - mean_squared_error: 17774.1933 - val_loss: 114417.6175 - val_mean_squared_error: 113357.4971\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 99477.88783\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 18663.8182 - mean_squared_error: 17914.2209 - val_loss: 112238.8093 - val_mean_squared_error: 111173.0752\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 99477.88783\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 18533.8305 - mean_squared_error: 17765.3358 - val_loss: 118607.4106 - val_mean_squared_error: 117597.1274\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 99477.88783\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 18647.1851 - mean_squared_error: 17912.6369 - val_loss: 116321.1917 - val_mean_squared_error: 115264.0278\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 99477.88783\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 18955.1583 - mean_squared_error: 18190.9541 - val_loss: 118090.7575 - val_mean_squared_error: 117058.0592\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 99477.88783\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 18673.1550 - mean_squared_error: 17930.4215 - val_loss: 114796.5166 - val_mean_squared_error: 113756.2932\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 99477.88783\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 18699.1189 - mean_squared_error: 17947.9719 - val_loss: 114141.9604 - val_mean_squared_error: 113099.8368\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 99477.88783\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 18390.0715 - mean_squared_error: 17651.5890 - val_loss: 112201.2372 - val_mean_squared_error: 111146.3128\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 99477.88783\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 18503.7818 - mean_squared_error: 17758.1721 - val_loss: 113947.7794 - val_mean_squared_error: 112909.3546\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 99477.88783\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 18345.0599 - mean_squared_error: 17588.5999 - val_loss: 120575.4062 - val_mean_squared_error: 119564.3057\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 99477.88783\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 18378.9799 - mean_squared_error: 17641.8674 - val_loss: 116555.9148 - val_mean_squared_error: 115528.1381\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 99477.88783\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 18419.2009 - mean_squared_error: 17676.9142 - val_loss: 115793.9429 - val_mean_squared_error: 114754.6363\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 99477.88783\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 18138.7061 - mean_squared_error: 17401.6340 - val_loss: 114577.6543 - val_mean_squared_error: 113532.5339\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 99477.88783\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 18259.7479 - mean_squared_error: 17510.8202 - val_loss: 114158.4816 - val_mean_squared_error: 113107.3983\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 99477.88783\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 18021.2452 - mean_squared_error: 17263.1742 - val_loss: 121096.9499 - val_mean_squared_error: 120098.7137\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 99477.88783\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 18112.4268 - mean_squared_error: 17388.6016 - val_loss: 111748.4342 - val_mean_squared_error: 110683.9018\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 99477.88783\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 18931.8818 - mean_squared_error: 18169.3861 - val_loss: 117711.9489 - val_mean_squared_error: 116691.3344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00269: val_loss did not improve from 99477.88783\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 18397.2583 - mean_squared_error: 17667.3641 - val_loss: 112944.9844 - val_mean_squared_error: 111908.9570\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 99477.88783\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 18384.6842 - mean_squared_error: 17639.0940 - val_loss: 118797.4983 - val_mean_squared_error: 117786.7789\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 99477.88783\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 18333.9580 - mean_squared_error: 17607.6485 - val_loss: 116634.7620 - val_mean_squared_error: 115613.7150\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 99477.88783\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 17918.9372 - mean_squared_error: 17180.6949 - val_loss: 117186.7508 - val_mean_squared_error: 116183.0385\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 99477.88783\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 18202.4971 - mean_squared_error: 17476.6011 - val_loss: 116000.2499 - val_mean_squared_error: 114985.2914\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 99477.88783\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 18089.5295 - mean_squared_error: 17340.3750 - val_loss: 124307.7454 - val_mean_squared_error: 123327.5198\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 99477.88783\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 18713.9920 - mean_squared_error: 18000.8903 - val_loss: 115521.1551 - val_mean_squared_error: 114500.9159\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 99477.88783\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 17871.0693 - mean_squared_error: 17139.6063 - val_loss: 116590.6242 - val_mean_squared_error: 115581.5532\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 99477.88783\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 17943.2570 - mean_squared_error: 17208.7487 - val_loss: 118238.1677 - val_mean_squared_error: 117246.7274\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 99477.88783\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 17864.5338 - mean_squared_error: 17140.0353 - val_loss: 114984.8725 - val_mean_squared_error: 113962.7977\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 99477.88783\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 18168.8790 - mean_squared_error: 17435.3110 - val_loss: 115936.7447 - val_mean_squared_error: 114921.9540\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 99477.88783\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 18186.6415 - mean_squared_error: 17453.1302 - val_loss: 120386.5737 - val_mean_squared_error: 119405.3412\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 99477.88783\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 17955.0691 - mean_squared_error: 17232.5520 - val_loss: 118830.0958 - val_mean_squared_error: 117828.5430\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 99477.88783\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 17852.4887 - mean_squared_error: 17129.7783 - val_loss: 117596.1189 - val_mean_squared_error: 116604.1398\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 99477.88783\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 17721.6036 - mean_squared_error: 17012.1147 - val_loss: 113528.5239 - val_mean_squared_error: 112505.3266\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 99477.88783\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 18013.3501 - mean_squared_error: 17281.9939 - val_loss: 117350.1981 - val_mean_squared_error: 116351.5707\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 99477.88783\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 17514.7802 - mean_squared_error: 16794.8653 - val_loss: 117984.3975 - val_mean_squared_error: 116979.2476\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 99477.88783\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 17653.9215 - mean_squared_error: 16919.6375 - val_loss: 118240.6918 - val_mean_squared_error: 117261.8559\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 99477.88783\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 17698.4569 - mean_squared_error: 16986.5048 - val_loss: 114522.3341 - val_mean_squared_error: 113506.7128\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 99477.88783\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 17757.6782 - mean_squared_error: 17027.3589 - val_loss: 117782.4881 - val_mean_squared_error: 116797.3304\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 99477.88783\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 17598.3564 - mean_squared_error: 16889.8832 - val_loss: 116400.0257 - val_mean_squared_error: 115398.1388\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 99477.88783\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 17844.6873 - mean_squared_error: 17127.1940 - val_loss: 116297.3484 - val_mean_squared_error: 115305.8133\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 99477.88783\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 17459.0525 - mean_squared_error: 16749.4529 - val_loss: 115940.5078 - val_mean_squared_error: 114947.8698\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 99477.88783\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 17675.2178 - mean_squared_error: 16957.9206 - val_loss: 117434.9848 - val_mean_squared_error: 116449.4838\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 99477.88783\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 17886.3557 - mean_squared_error: 17169.4872 - val_loss: 119084.2581 - val_mean_squared_error: 118114.3715\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 99477.88783\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 17632.5625 - mean_squared_error: 16930.8659 - val_loss: 114468.0875 - val_mean_squared_error: 113481.7768\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 99477.88783\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 17543.6718 - mean_squared_error: 16825.2764 - val_loss: 116706.5667 - val_mean_squared_error: 115723.7563\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 99477.88783\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 17530.2142 - mean_squared_error: 16819.4886 - val_loss: 118058.1282 - val_mean_squared_error: 117089.4989\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 99477.88783\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 17319.6321 - mean_squared_error: 16620.9749 - val_loss: 117305.4523 - val_mean_squared_error: 116317.3666\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 99477.88783\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 17436.4072 - mean_squared_error: 16725.4392 - val_loss: 116666.6536 - val_mean_squared_error: 115688.2365\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 99477.88783\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 17559.8181 - mean_squared_error: 16854.8105 - val_loss: 116444.6885 - val_mean_squared_error: 115465.2038\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 99477.88783\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 17680.9205 - mean_squared_error: 16977.7871 - val_loss: 119585.1724 - val_mean_squared_error: 118623.1288\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 99477.88783\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 17461.8896 - mean_squared_error: 16751.8495 - val_loss: 117057.6215 - val_mean_squared_error: 116082.8754\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 99477.88783\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 17300.1559 - mean_squared_error: 16599.1820 - val_loss: 116949.5470 - val_mean_squared_error: 115970.7658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00303: val_loss did not improve from 99477.88783\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 17174.1383 - mean_squared_error: 16468.6597 - val_loss: 116844.9487 - val_mean_squared_error: 115864.1676\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 99477.88783\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 17473.8552 - mean_squared_error: 16766.4535 - val_loss: 121599.1342 - val_mean_squared_error: 120641.5028\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 99477.88783\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 16993.9823 - mean_squared_error: 16299.4425 - val_loss: 119954.0257 - val_mean_squared_error: 119002.7871\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 99477.88783\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 17119.8241 - mean_squared_error: 16421.1011 - val_loss: 118391.0091 - val_mean_squared_error: 117436.2101\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 99477.88783\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 16963.8255 - mean_squared_error: 16262.3614 - val_loss: 122805.3263 - val_mean_squared_error: 121862.3845\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 99477.88783\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 17130.2315 - mean_squared_error: 16431.2585 - val_loss: 122132.3189 - val_mean_squared_error: 121189.4277\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 99477.88783\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 17010.7487 - mean_squared_error: 16318.3944 - val_loss: 119231.9429 - val_mean_squared_error: 118262.0506\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 99477.88783\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16947.6908 - mean_squared_error: 16243.8285 - val_loss: 120091.6705 - val_mean_squared_error: 119145.2033\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 99477.88783\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 16793.6454 - mean_squared_error: 16102.8135 - val_loss: 122305.0244 - val_mean_squared_error: 121365.3062\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 99477.88783\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 17085.5631 - mean_squared_error: 16394.6297 - val_loss: 118246.1719 - val_mean_squared_error: 117291.8883\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 99477.88783\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 17406.6093 - mean_squared_error: 16715.8538 - val_loss: 117534.4662 - val_mean_squared_error: 116580.8707\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 99477.88783\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 16872.8138 - mean_squared_error: 16180.2157 - val_loss: 120444.6518 - val_mean_squared_error: 119490.3697\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 99477.88783\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 16860.8464 - mean_squared_error: 16171.4003 - val_loss: 117186.1740 - val_mean_squared_error: 116236.1134\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 99477.88783\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 16872.0302 - mean_squared_error: 16177.0863 - val_loss: 120553.0509 - val_mean_squared_error: 119617.0227\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 99477.88783\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 16922.7053 - mean_squared_error: 16244.0492 - val_loss: 116542.2232 - val_mean_squared_error: 115586.9953\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 99477.88783\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 17150.2439 - mean_squared_error: 16462.5945 - val_loss: 118243.7540 - val_mean_squared_error: 117295.8650\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 99477.88783\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 16887.9894 - mean_squared_error: 16199.9534 - val_loss: 115554.2027 - val_mean_squared_error: 114600.1039\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 99477.88783\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 17053.8693 - mean_squared_error: 16365.0595 - val_loss: 117292.3504 - val_mean_squared_error: 116341.3032\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 99477.88783\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 16841.9943 - mean_squared_error: 16155.5659 - val_loss: 118376.1069 - val_mean_squared_error: 117420.9789\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 99477.88783\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 16901.0698 - mean_squared_error: 16212.7534 - val_loss: 117054.2150 - val_mean_squared_error: 116101.4978\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 99477.88783\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16781.5506 - mean_squared_error: 16100.3547 - val_loss: 118030.7605 - val_mean_squared_error: 117080.6477\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 99477.88783\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16854.6657 - mean_squared_error: 16165.2654 - val_loss: 122880.5441 - val_mean_squared_error: 121970.1034\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 99477.88783\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 16609.8921 - mean_squared_error: 15934.5175 - val_loss: 119845.9142 - val_mean_squared_error: 118920.6254\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 99477.88783\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 16498.7038 - mean_squared_error: 15826.1142 - val_loss: 119579.9503 - val_mean_squared_error: 118645.3488\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 99477.88783\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 16587.6477 - mean_squared_error: 15902.8942 - val_loss: 122300.2992 - val_mean_squared_error: 121372.3419\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 99477.88783\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 16665.0535 - mean_squared_error: 15984.0742 - val_loss: 117750.8457 - val_mean_squared_error: 116819.4912\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 99477.88783\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 16335.4774 - mean_squared_error: 15663.6473 - val_loss: 116436.9824 - val_mean_squared_error: 115491.0513\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 99477.88783\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 16443.4963 - mean_squared_error: 15757.6783 - val_loss: 122373.8517 - val_mean_squared_error: 121465.2649\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 99477.88783\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 16574.5013 - mean_squared_error: 15903.8191 - val_loss: 118079.2748 - val_mean_squared_error: 117140.7434\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 99477.88783\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 16442.8724 - mean_squared_error: 15758.7160 - val_loss: 118789.8312 - val_mean_squared_error: 117869.6497\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 99477.88783\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 186us/step - loss: 16737.6815 - mean_squared_error: 16064.4307 - val_loss: 117568.4406 - val_mean_squared_error: 116635.4455\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 99477.88783\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 16622.8645 - mean_squared_error: 15952.1204 - val_loss: 116501.8701 - val_mean_squared_error: 115574.0871\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 99477.88783\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 16635.9981 - mean_squared_error: 15961.5585 - val_loss: 119060.0728 - val_mean_squared_error: 118139.1401\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 99477.88783\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 16210.7184 - mean_squared_error: 15538.2064 - val_loss: 120510.4062 - val_mean_squared_error: 119594.1309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00337: val_loss did not improve from 99477.88783\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16125.9227 - mean_squared_error: 15457.6100 - val_loss: 120494.1836 - val_mean_squared_error: 119576.0237\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 99477.88783\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16280.2907 - mean_squared_error: 15611.8277 - val_loss: 120236.0406 - val_mean_squared_error: 119325.9441\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 99477.88783\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16265.9614 - mean_squared_error: 15604.1336 - val_loss: 120075.0426 - val_mean_squared_error: 119160.7136\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 99477.88783\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 16501.7103 - mean_squared_error: 15831.5301 - val_loss: 119778.0576 - val_mean_squared_error: 118870.8142\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 99477.88783\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 16078.6991 - mean_squared_error: 15408.9083 - val_loss: 121015.6511 - val_mean_squared_error: 120124.3835\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 99477.88783\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16158.5683 - mean_squared_error: 15508.5399 - val_loss: 117233.6874 - val_mean_squared_error: 116288.0059\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 99477.88783\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 16817.9475 - mean_squared_error: 16147.3213 - val_loss: 121068.0678 - val_mean_squared_error: 120156.2158\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 99477.88783\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 16151.7389 - mean_squared_error: 15484.0622 - val_loss: 121640.8182 - val_mean_squared_error: 120735.0110\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 99477.88783\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 16316.0775 - mean_squared_error: 15648.6742 - val_loss: 122780.4276 - val_mean_squared_error: 121892.2462\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 99477.88783\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 16398.3475 - mean_squared_error: 15750.2016 - val_loss: 120447.2606 - val_mean_squared_error: 119533.2333\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 99477.88783\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 16069.2256 - mean_squared_error: 15412.8593 - val_loss: 118369.6698 - val_mean_squared_error: 117443.3186\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 99477.88783\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 16114.0655 - mean_squared_error: 15441.0932 - val_loss: 124292.3693 - val_mean_squared_error: 123405.2105\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 99477.88783\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 16118.6434 - mean_squared_error: 15462.8346 - val_loss: 118984.9535 - val_mean_squared_error: 118082.4011\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 99477.88783\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 15962.2509 - mean_squared_error: 15299.6223 - val_loss: 119802.5766 - val_mean_squared_error: 118898.1000\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 99477.88783\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 16648.3653 - mean_squared_error: 15990.7499 - val_loss: 121098.1211 - val_mean_squared_error: 120206.8866\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 99477.88783\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 15803.1849 - mean_squared_error: 15146.0792 - val_loss: 123055.8707 - val_mean_squared_error: 122158.2402\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 99477.88783\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 15986.8893 - mean_squared_error: 15326.6929 - val_loss: 122521.4443 - val_mean_squared_error: 121633.8196\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 99477.88783\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 15910.4643 - mean_squared_error: 15255.4013 - val_loss: 124174.6242 - val_mean_squared_error: 123291.9166\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 99477.88783\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 15835.6223 - mean_squared_error: 15184.8794 - val_loss: 120771.3770 - val_mean_squared_error: 119863.7347\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 99477.88783\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 16744.2255 - mean_squared_error: 16088.7329 - val_loss: 121494.6057 - val_mean_squared_error: 120617.8267\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 99477.88783\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 15833.2363 - mean_squared_error: 15170.3889 - val_loss: 125254.5296 - val_mean_squared_error: 124387.4276\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 99477.88783\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 16042.4299 - mean_squared_error: 15395.2378 - val_loss: 125997.5039 - val_mean_squared_error: 125133.5146\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 99477.88783\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 15839.3566 - mean_squared_error: 15199.6557 - val_loss: 118367.3679 - val_mean_squared_error: 117472.2627\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 99477.88783\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 15920.9195 - mean_squared_error: 15271.2865 - val_loss: 118078.8301 - val_mean_squared_error: 117181.0744\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 99477.88783\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 16235.0566 - mean_squared_error: 15585.3009 - val_loss: 119241.4614 - val_mean_squared_error: 118373.1449\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 99477.88783\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 15809.4256 - mean_squared_error: 15173.5050 - val_loss: 119697.6064 - val_mean_squared_error: 118809.8291\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 99477.88783\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 15762.3727 - mean_squared_error: 15114.8563 - val_loss: 118868.3922 - val_mean_squared_error: 117991.0329\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 99477.88783\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 15454.2719 - mean_squared_error: 14819.5726 - val_loss: 118104.8888 - val_mean_squared_error: 117199.1763\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 99477.88783\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16230.6672 - mean_squared_error: 15570.3502 - val_loss: 129351.4150 - val_mean_squared_error: 128508.4835\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 99477.88783\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 16142.9699 - mean_squared_error: 15501.1683 - val_loss: 122177.9445 - val_mean_squared_error: 121321.7139\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 99477.88783\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 16065.6552 - mean_squared_error: 15417.4670 - val_loss: 123658.5670 - val_mean_squared_error: 122802.9368\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 99477.88783\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 15663.7604 - mean_squared_error: 15029.3741 - val_loss: 121320.0527 - val_mean_squared_error: 120437.5896\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 99477.88783\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 15382.0443 - mean_squared_error: 14744.1266 - val_loss: 119826.7900 - val_mean_squared_error: 118933.6662\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 99477.88783\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 15768.1338 - mean_squared_error: 15118.7066 - val_loss: 122750.8888 - val_mean_squared_error: 121887.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00371: val_loss did not improve from 99477.88783\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 15649.7459 - mean_squared_error: 15010.3192 - val_loss: 123139.9030 - val_mean_squared_error: 122285.8938\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 99477.88783\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 15322.6649 - mean_squared_error: 14683.6864 - val_loss: 123334.0844 - val_mean_squared_error: 122478.9177\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 99477.88783\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 15626.9915 - mean_squared_error: 14992.5199 - val_loss: 120935.3909 - val_mean_squared_error: 120069.3090\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 99477.88783\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 15476.8290 - mean_squared_error: 14837.6045 - val_loss: 122531.1915 - val_mean_squared_error: 121668.5426\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 99477.88783\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 15406.5365 - mean_squared_error: 14771.1738 - val_loss: 120615.5709 - val_mean_squared_error: 119761.1476\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 99477.88783\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 15651.8125 - mean_squared_error: 15020.4578 - val_loss: 122193.7270 - val_mean_squared_error: 121332.5194\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 99477.88783\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 15435.3050 - mean_squared_error: 14806.5597 - val_loss: 124461.1744 - val_mean_squared_error: 123611.5545\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 99477.88783\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 15234.8670 - mean_squared_error: 14601.2086 - val_loss: 122164.4181 - val_mean_squared_error: 121304.9268\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 99477.88783\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 15264.7977 - mean_squared_error: 14632.9822 - val_loss: 120979.9096 - val_mean_squared_error: 120125.0919\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 99477.88783\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 15324.2957 - mean_squared_error: 14690.0496 - val_loss: 123991.2444 - val_mean_squared_error: 123151.5972\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 99477.88783\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 15195.5715 - mean_squared_error: 14573.8955 - val_loss: 120038.6134 - val_mean_squared_error: 119175.5169\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 99477.88783\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 15313.5597 - mean_squared_error: 14677.2974 - val_loss: 122928.1052 - val_mean_squared_error: 122084.4566\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 99477.88783\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 15363.1120 - mean_squared_error: 14736.6700 - val_loss: 123457.7995 - val_mean_squared_error: 122623.6487\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 99477.88783\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 15383.2390 - mean_squared_error: 14753.4696 - val_loss: 123558.1694 - val_mean_squared_error: 122719.7114\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 99477.88783\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 15402.4128 - mean_squared_error: 14776.9197 - val_loss: 122246.5872 - val_mean_squared_error: 121412.6786\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 99477.88783\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 15450.7512 - mean_squared_error: 14832.8138 - val_loss: 121321.1310 - val_mean_squared_error: 120467.4406\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 99477.88783\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 15074.3553 - mean_squared_error: 14448.6508 - val_loss: 119545.9727 - val_mean_squared_error: 118697.5589\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 99477.88783\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 15059.1663 - mean_squared_error: 14433.8049 - val_loss: 120114.7773 - val_mean_squared_error: 119273.2130\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 99477.88783\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 14971.7947 - mean_squared_error: 14340.2933 - val_loss: 125651.3859 - val_mean_squared_error: 124826.9654\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 99477.88783\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 15342.2252 - mean_squared_error: 14720.6294 - val_loss: 124759.5078 - val_mean_squared_error: 123930.5798\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 99477.88783\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 14759.5118 - mean_squared_error: 14144.6119 - val_loss: 120914.7116 - val_mean_squared_error: 120075.5564\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 99477.88783\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 15081.8674 - mean_squared_error: 14460.2034 - val_loss: 124262.1560 - val_mean_squared_error: 123430.0886\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 99477.88783\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 14702.7597 - mean_squared_error: 14085.6798 - val_loss: 119617.0484 - val_mean_squared_error: 118769.8474\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 99477.88783\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 15074.5419 - mean_squared_error: 14456.0532 - val_loss: 118661.8518 - val_mean_squared_error: 117804.6480\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 99477.88783\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 15586.5329 - mean_squared_error: 14970.5629 - val_loss: 120007.3186 - val_mean_squared_error: 119166.7111\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 99477.88783\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 14871.7494 - mean_squared_error: 14245.6592 - val_loss: 125912.6507 - val_mean_squared_error: 125096.2215\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 99477.88783\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 15730.2915 - mean_squared_error: 15115.4559 - val_loss: 127698.9050 - val_mean_squared_error: 126893.0105\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 99477.88783\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 15180.3545 - mean_squared_error: 14576.5470 - val_loss: 119598.9347 - val_mean_squared_error: 118764.3859\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 99477.88783\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 14970.3022 - mean_squared_error: 14364.1988 - val_loss: 119946.5219 - val_mean_squared_error: 119113.9548\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 99477.88783\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 14870.2789 - mean_squared_error: 14251.9205 - val_loss: 122326.4801 - val_mean_squared_error: 121505.4590\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 99477.88783\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14641.7877 - mean_squared_error: 14029.1990 - val_loss: 120966.9524 - val_mean_squared_error: 120139.4496\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 99477.88783\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 15328.3722 - mean_squared_error: 14716.7151 - val_loss: 120862.4273 - val_mean_squared_error: 120033.3764\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 99477.88783\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 14723.3118 - mean_squared_error: 14113.5896 - val_loss: 122087.7467 - val_mean_squared_error: 121257.6662\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 99477.88783\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14645.4200 - mean_squared_error: 14037.0695 - val_loss: 122857.2441 - val_mean_squared_error: 122031.2496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00405: val_loss did not improve from 99477.88783\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 14774.0572 - mean_squared_error: 14161.1843 - val_loss: 123441.3451 - val_mean_squared_error: 122616.0783\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 99477.88783\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 14619.5441 - mean_squared_error: 14008.4087 - val_loss: 122282.4422 - val_mean_squared_error: 121462.7870\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 99477.88783\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 14776.2689 - mean_squared_error: 14163.0988 - val_loss: 127311.7814 - val_mean_squared_error: 126510.4502\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 99477.88783\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 14523.3126 - mean_squared_error: 13919.0227 - val_loss: 121303.4770 - val_mean_squared_error: 120481.4262\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 99477.88783\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 14349.9792 - mean_squared_error: 13748.5010 - val_loss: 120535.3605 - val_mean_squared_error: 119736.7937\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 99477.88783\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 14941.9122 - mean_squared_error: 14339.6989 - val_loss: 123682.8876 - val_mean_squared_error: 122890.1814\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 99477.88783\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14531.0020 - mean_squared_error: 13930.3077 - val_loss: 123094.7003 - val_mean_squared_error: 122282.0791\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 99477.88783\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 14401.3609 - mean_squared_error: 13800.2854 - val_loss: 120730.6122 - val_mean_squared_error: 119914.0059\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 99477.88783\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14241.5928 - mean_squared_error: 13631.6926 - val_loss: 126840.3482 - val_mean_squared_error: 126050.9418\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 99477.88783\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14890.8640 - mean_squared_error: 14294.1722 - val_loss: 122354.9643 - val_mean_squared_error: 121561.7234\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 99477.88783\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14664.6511 - mean_squared_error: 14063.8885 - val_loss: 123741.3252 - val_mean_squared_error: 122940.2201\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 99477.88783\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14396.4713 - mean_squared_error: 13793.9142 - val_loss: 124283.9760 - val_mean_squared_error: 123486.7380\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 99477.88783\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14625.6102 - mean_squared_error: 14029.6620 - val_loss: 122612.9088 - val_mean_squared_error: 121794.3458\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 99477.88783\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 14707.7311 - mean_squared_error: 14109.5614 - val_loss: 120797.6582 - val_mean_squared_error: 119993.3359\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 99477.88783\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14811.3642 - mean_squared_error: 14217.0005 - val_loss: 123430.6196 - val_mean_squared_error: 122625.1560\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 99477.88783\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 14222.0058 - mean_squared_error: 13614.1132 - val_loss: 126011.8680 - val_mean_squared_error: 125221.6730\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 99477.88783\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14686.1590 - mean_squared_error: 14085.7785 - val_loss: 121896.5223 - val_mean_squared_error: 121098.2708\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 99477.88783\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 14754.3689 - mean_squared_error: 14162.1017 - val_loss: 124056.2021 - val_mean_squared_error: 123263.7923\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 99477.88783\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 14479.1222 - mean_squared_error: 13889.8113 - val_loss: 121814.7210 - val_mean_squared_error: 121002.2829\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 99477.88783\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 14449.6229 - mean_squared_error: 13851.6496 - val_loss: 123823.1653 - val_mean_squared_error: 123028.8302\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 99477.88783\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14206.2579 - mean_squared_error: 13609.1528 - val_loss: 130049.5449 - val_mean_squared_error: 129272.0022\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 99477.88783\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14568.6850 - mean_squared_error: 13968.5346 - val_loss: 127677.8164 - val_mean_squared_error: 126900.8767\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 99477.88783\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 14375.3217 - mean_squared_error: 13790.3217 - val_loss: 123290.5640 - val_mean_squared_error: 122494.3523\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 99477.88783\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 14302.1498 - mean_squared_error: 13702.8865 - val_loss: 125906.9700 - val_mean_squared_error: 125132.6274\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 99477.88783\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 14112.2900 - mean_squared_error: 13523.5868 - val_loss: 126801.6896 - val_mean_squared_error: 126025.1419\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 99477.88783\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 14111.1634 - mean_squared_error: 13524.6684 - val_loss: 123456.5289 - val_mean_squared_error: 122672.6769\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 99477.88783\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 14017.6766 - mean_squared_error: 13427.8808 - val_loss: 125862.2852 - val_mean_squared_error: 125081.4365\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 99477.88783\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 14308.8183 - mean_squared_error: 13719.0102 - val_loss: 125162.1915 - val_mean_squared_error: 124382.7988\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 99477.88783\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 14136.7671 - mean_squared_error: 13552.7533 - val_loss: 124128.5172 - val_mean_squared_error: 123347.2574\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 99477.88783\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13874.3875 - mean_squared_error: 13288.4040 - val_loss: 122150.8200 - val_mean_squared_error: 121361.7847\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 99477.88783\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 13809.5252 - mean_squared_error: 13223.0447 - val_loss: 123838.9651 - val_mean_squared_error: 123057.4315\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 99477.88783\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13864.0984 - mean_squared_error: 13275.5144 - val_loss: 128301.5509 - val_mean_squared_error: 127535.4033\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 99477.88783\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 14034.0436 - mean_squared_error: 13459.3780 - val_loss: 119533.1346 - val_mean_squared_error: 118731.4096\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 99477.88783\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 14294.1289 - mean_squared_error: 13707.2979 - val_loss: 124275.4026 - val_mean_squared_error: 123492.6328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00439: val_loss did not improve from 99477.88783\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13964.6360 - mean_squared_error: 13382.0495 - val_loss: 123080.7155 - val_mean_squared_error: 122303.5194\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 99477.88783\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13655.1835 - mean_squared_error: 13067.7762 - val_loss: 126346.2729 - val_mean_squared_error: 125577.5485\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 99477.88783\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13913.5519 - mean_squared_error: 13336.1215 - val_loss: 125739.0566 - val_mean_squared_error: 124964.1556\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 99477.88783\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13939.7558 - mean_squared_error: 13349.1202 - val_loss: 129656.4425 - val_mean_squared_error: 128909.4011\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 99477.88783\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 14011.8289 - mean_squared_error: 13440.1149 - val_loss: 122490.0042 - val_mean_squared_error: 121704.4015\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 99477.88783\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 13772.9487 - mean_squared_error: 13190.2975 - val_loss: 123959.8604 - val_mean_squared_error: 123178.4651\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 99477.88783\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13588.1841 - mean_squared_error: 13005.0675 - val_loss: 123386.0568 - val_mean_squared_error: 122600.5894\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 99477.88783\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 181us/step - loss: 13778.9798 - mean_squared_error: 13200.9245 - val_loss: 122909.9992 - val_mean_squared_error: 122126.1384\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 99477.88783\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13834.2368 - mean_squared_error: 13253.2365 - val_loss: 126324.9725 - val_mean_squared_error: 125549.9729\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 99477.88783\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 13697.3473 - mean_squared_error: 13122.3709 - val_loss: 124289.1069 - val_mean_squared_error: 123519.0134\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 99477.88783\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 13461.9750 - mean_squared_error: 12889.2971 - val_loss: 123054.2653 - val_mean_squared_error: 122274.5333\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 99477.88783\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 13939.6036 - mean_squared_error: 13362.4298 - val_loss: 123782.7469 - val_mean_squared_error: 123015.0428\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 99477.88783\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13706.2490 - mean_squared_error: 13132.9612 - val_loss: 124375.2154 - val_mean_squared_error: 123606.6094\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 99477.88783\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13680.1763 - mean_squared_error: 13116.1519 - val_loss: 120830.1038 - val_mean_squared_error: 120044.2554\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 99477.88783\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 13880.8472 - mean_squared_error: 13302.1878 - val_loss: 120923.2942 - val_mean_squared_error: 120146.5505\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 99477.88783\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 13548.3525 - mean_squared_error: 12973.3178 - val_loss: 123552.9523 - val_mean_squared_error: 122793.6371\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 99477.88783\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 13467.2546 - mean_squared_error: 12887.2739 - val_loss: 130276.9371 - val_mean_squared_error: 129533.0539\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 99477.88783\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13690.4680 - mean_squared_error: 13131.5177 - val_loss: 119958.6390 - val_mean_squared_error: 119168.2292\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 99477.88783\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 14441.7483 - mean_squared_error: 13864.8995 - val_loss: 124899.1250 - val_mean_squared_error: 124148.7912\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 99477.88783\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 13518.0886 - mean_squared_error: 12948.6449 - val_loss: 129203.5063 - val_mean_squared_error: 128468.5086\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 99477.88783\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13660.7434 - mean_squared_error: 13095.1667 - val_loss: 122551.2224 - val_mean_squared_error: 121790.9355\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 99477.88783\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 13410.6496 - mean_squared_error: 12840.5815 - val_loss: 127425.7550 - val_mean_squared_error: 126683.0957\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 99477.88783\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 13307.3505 - mean_squared_error: 12746.1125 - val_loss: 121952.8199 - val_mean_squared_error: 121180.3018\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 99477.88783\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13585.4562 - mean_squared_error: 13009.2879 - val_loss: 124311.6203 - val_mean_squared_error: 123572.6815\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 99477.88783\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13267.5306 - mean_squared_error: 12706.8028 - val_loss: 121926.4587 - val_mean_squared_error: 121167.4634\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 99477.88783\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 13378.0683 - mean_squared_error: 12806.3127 - val_loss: 126305.6377 - val_mean_squared_error: 125562.9122\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 99477.88783\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 13429.4478 - mean_squared_error: 12865.7527 - val_loss: 122791.5052 - val_mean_squared_error: 122038.3673\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 99477.88783\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 13049.9006 - mean_squared_error: 12484.3818 - val_loss: 120608.1512 - val_mean_squared_error: 119840.1046\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 99477.88783\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 13496.0954 - mean_squared_error: 12931.0016 - val_loss: 123342.4700 - val_mean_squared_error: 122592.8623\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 99477.88783\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 13039.0982 - mean_squared_error: 12472.9445 - val_loss: 122790.7613 - val_mean_squared_error: 122053.3661\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 99477.88783\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13475.1683 - mean_squared_error: 12912.5940 - val_loss: 123219.7794 - val_mean_squared_error: 122467.2256\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 99477.88783\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 13446.4657 - mean_squared_error: 12889.1021 - val_loss: 122003.0763 - val_mean_squared_error: 121255.2698\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 99477.88783\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 13039.4012 - mean_squared_error: 12472.9532 - val_loss: 126849.1959 - val_mean_squared_error: 126122.2744\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 99477.88783\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 13300.1834 - mean_squared_error: 12744.9169 - val_loss: 121142.6791 - val_mean_squared_error: 120383.0306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00473: val_loss did not improve from 99477.88783\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 14306.5733 - mean_squared_error: 13750.8486 - val_loss: 122739.1663 - val_mean_squared_error: 121987.2144\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 99477.88783\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13684.1343 - mean_squared_error: 13123.0905 - val_loss: 122276.3881 - val_mean_squared_error: 121524.7063\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 99477.88783\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 188us/step - loss: 13161.3826 - mean_squared_error: 12603.7858 - val_loss: 125157.8984 - val_mean_squared_error: 124425.1945\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 99477.88783\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 185us/step - loss: 12789.5899 - mean_squared_error: 12236.9134 - val_loss: 125441.4608 - val_mean_squared_error: 124695.0439\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 99477.88783\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 12866.5933 - mean_squared_error: 12308.9837 - val_loss: 123443.0077 - val_mean_squared_error: 122699.7808\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 99477.88783\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 183us/step - loss: 12905.7030 - mean_squared_error: 12347.2072 - val_loss: 126942.4858 - val_mean_squared_error: 126219.2987\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 99477.88783\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 13142.4480 - mean_squared_error: 12589.5236 - val_loss: 123088.4968 - val_mean_squared_error: 122362.0160\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 99477.88783\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 13263.4399 - mean_squared_error: 12711.3742 - val_loss: 124060.1914 - val_mean_squared_error: 123325.2100\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 99477.88783\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 12841.5270 - mean_squared_error: 12289.2974 - val_loss: 122892.4789 - val_mean_squared_error: 122151.2766\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 99477.88783\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 13113.9095 - mean_squared_error: 12562.4780 - val_loss: 122977.8376 - val_mean_squared_error: 122244.2073\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 99477.88783\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 12987.2317 - mean_squared_error: 12438.7356 - val_loss: 123940.3172 - val_mean_squared_error: 123207.7273\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 99477.88783\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 12732.4252 - mean_squared_error: 12182.4107 - val_loss: 121150.1162 - val_mean_squared_error: 120407.4570\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 99477.88783\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 12742.1832 - mean_squared_error: 12184.8502 - val_loss: 127560.5706 - val_mean_squared_error: 126846.6159\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 99477.88783\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 13021.3998 - mean_squared_error: 12477.6238 - val_loss: 123157.3567 - val_mean_squared_error: 122420.0191\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 99477.88783\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 12326.4760 - mean_squared_error: 11775.4337 - val_loss: 128534.5300 - val_mean_squared_error: 127821.7727\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 99477.88783\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 12679.1943 - mean_squared_error: 12133.7945 - val_loss: 125443.3892 - val_mean_squared_error: 124716.1037\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 99477.88783\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 12815.0702 - mean_squared_error: 12258.7593 - val_loss: 128176.6415 - val_mean_squared_error: 127469.6722\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 99477.88783\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 13042.2886 - mean_squared_error: 12499.1377 - val_loss: 119261.1170 - val_mean_squared_error: 118517.1265\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 99477.88783\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 12568.1979 - mean_squared_error: 12016.8466 - val_loss: 125321.8938 - val_mean_squared_error: 124615.6537\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 99477.88783\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12723.7294 - mean_squared_error: 12182.8261 - val_loss: 124321.8742 - val_mean_squared_error: 123602.2253\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 99477.88783\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 12702.5315 - mean_squared_error: 12157.0902 - val_loss: 121784.9160 - val_mean_squared_error: 121053.6162\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 99477.88783\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12510.9736 - mean_squared_error: 11965.0759 - val_loss: 126051.7690 - val_mean_squared_error: 125333.9307\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 99477.88783\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12581.4468 - mean_squared_error: 12029.6158 - val_loss: 127236.4461 - val_mean_squared_error: 126526.0456\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 99477.88783\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12543.0271 - mean_squared_error: 11996.3181 - val_loss: 123352.3218 - val_mean_squared_error: 122633.5001\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 99477.88783\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 12715.4913 - mean_squared_error: 12170.9512 - val_loss: 124352.4997 - val_mean_squared_error: 123630.3605\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 99477.88783\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12457.4063 - mean_squared_error: 11915.6012 - val_loss: 125522.3006 - val_mean_squared_error: 124793.4259\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 99477.88783\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12978.7347 - mean_squared_error: 12437.2221 - val_loss: 124018.5197 - val_mean_squared_error: 123300.8774\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 99477.88783\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 12102.6925 - mean_squared_error: 11559.7388 - val_loss: 122255.6423 - val_mean_squared_error: 121531.9153\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 99477.88783\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 12371.5377 - mean_squared_error: 11835.5348 - val_loss: 120943.6610 - val_mean_squared_error: 120211.4148\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 99477.88783\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 12582.9845 - mean_squared_error: 12040.7876 - val_loss: 126009.3627 - val_mean_squared_error: 125296.4520\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 99477.88783\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 12201.4854 - mean_squared_error: 11662.7907 - val_loss: 122751.0084 - val_mean_squared_error: 122038.0654\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 99477.88783\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 12294.4546 - mean_squared_error: 11754.4016 - val_loss: 122476.0399 - val_mean_squared_error: 121760.1730\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 99477.88783\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12143.6446 - mean_squared_error: 11600.6905 - val_loss: 127390.1105 - val_mean_squared_error: 126689.3075\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 99477.88783\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 12329.7576 - mean_squared_error: 11792.0659 - val_loss: 122888.9752 - val_mean_squared_error: 122175.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00507: val_loss did not improve from 99477.88783\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 12377.6562 - mean_squared_error: 11836.0962 - val_loss: 128297.0230 - val_mean_squared_error: 127604.1073\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 99477.88783\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12825.6650 - mean_squared_error: 12292.7407 - val_loss: 123771.4746 - val_mean_squared_error: 123066.6567\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 99477.88783\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12074.1481 - mean_squared_error: 11537.7160 - val_loss: 125786.1512 - val_mean_squared_error: 125076.9311\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 99477.88783\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 12456.9485 - mean_squared_error: 11926.2659 - val_loss: 121020.4262 - val_mean_squared_error: 120293.4930\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 99477.88783\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 12509.3216 - mean_squared_error: 11969.7207 - val_loss: 130003.4326 - val_mean_squared_error: 129316.9452\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 99477.88783\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 12594.0981 - mean_squared_error: 12059.4968 - val_loss: 126214.1144 - val_mean_squared_error: 125516.6258\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 99477.88783\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 12073.1039 - mean_squared_error: 11542.7663 - val_loss: 125211.1957 - val_mean_squared_error: 124516.6059\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 99477.88783\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 12136.1473 - mean_squared_error: 11608.1437 - val_loss: 119795.4867 - val_mean_squared_error: 119074.1281\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 99477.88783\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12141.4299 - mean_squared_error: 11604.3410 - val_loss: 126502.4427 - val_mean_squared_error: 125805.0410\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 99477.88783\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 11805.4747 - mean_squared_error: 11277.0745 - val_loss: 121415.5416 - val_mean_squared_error: 120700.5059\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 99477.88783\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 11649.2751 - mean_squared_error: 11110.7882 - val_loss: 130156.7048 - val_mean_squared_error: 129470.9628\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 99477.88783\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 12105.3015 - mean_squared_error: 11579.9103 - val_loss: 124766.0822 - val_mean_squared_error: 124058.6390\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 99477.88783\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 11834.0813 - mean_squared_error: 11303.7769 - val_loss: 123298.9418 - val_mean_squared_error: 122601.0511\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 99477.88783\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12218.4044 - mean_squared_error: 11688.1675 - val_loss: 121483.4628 - val_mean_squared_error: 120779.8006\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 99477.88783\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 11786.1621 - mean_squared_error: 11255.7590 - val_loss: 127480.4415 - val_mean_squared_error: 126782.9657\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 99477.88783\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 11922.5473 - mean_squared_error: 11396.8138 - val_loss: 122452.3179 - val_mean_squared_error: 121745.9962\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 99477.88783\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 11861.7958 - mean_squared_error: 11330.6869 - val_loss: 123520.1692 - val_mean_squared_error: 122817.6204\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 99477.88783\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 11829.3126 - mean_squared_error: 11304.5882 - val_loss: 122615.1129 - val_mean_squared_error: 121902.9474\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 99477.88783\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 11871.3444 - mean_squared_error: 11338.1128 - val_loss: 130525.3365 - val_mean_squared_error: 129855.0559\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 99477.88783\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 12229.8190 - mean_squared_error: 11707.8449 - val_loss: 120408.9368 - val_mean_squared_error: 119708.1855\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 99477.88783\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 11743.6563 - mean_squared_error: 11211.5276 - val_loss: 129009.7705 - val_mean_squared_error: 128336.7155\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 99477.88783\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 12781.2750 - mean_squared_error: 12251.7165 - val_loss: 124823.0086 - val_mean_squared_error: 124147.0769\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 99477.88783\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 11919.0310 - mean_squared_error: 11398.5268 - val_loss: 124428.0325 - val_mean_squared_error: 123741.5417\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 99477.88783\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 11739.9138 - mean_squared_error: 11219.8360 - val_loss: 121912.4845 - val_mean_squared_error: 121207.8424\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 99477.88783\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 11356.2058 - mean_squared_error: 10827.0878 - val_loss: 127296.3781 - val_mean_squared_error: 126624.3898\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 99477.88783\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 12835.9486 - mean_squared_error: 12309.5516 - val_loss: 125522.5652 - val_mean_squared_error: 124839.7979\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 99477.88783\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 12047.8003 - mean_squared_error: 11531.4501 - val_loss: 122144.4936 - val_mean_squared_error: 121456.8778\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 99477.88783\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 11975.6317 - mean_squared_error: 11455.9104 - val_loss: 121396.7941 - val_mean_squared_error: 120697.6486\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 99477.88783\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 11557.8790 - mean_squared_error: 11034.6675 - val_loss: 123533.9056 - val_mean_squared_error: 122847.1793\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 99477.88783\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 11352.0677 - mean_squared_error: 10827.1055 - val_loss: 125707.4032 - val_mean_squared_error: 125032.4131\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 99477.88783\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 11507.5578 - mean_squared_error: 10992.8619 - val_loss: 121340.5398 - val_mean_squared_error: 120628.9294\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 99477.88783\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 11352.6580 - mean_squared_error: 10821.5230 - val_loss: 132207.6941 - val_mean_squared_error: 131541.9477\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 99477.88783\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 11874.4618 - mean_squared_error: 11358.0783 - val_loss: 124220.7808 - val_mean_squared_error: 123532.3179\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 99477.88783\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 11337.8545 - mean_squared_error: 10821.5605 - val_loss: 121999.2584 - val_mean_squared_error: 121300.6434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00541: val_loss did not improve from 99477.88783\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 11663.5002 - mean_squared_error: 11143.4943 - val_loss: 123243.3177 - val_mean_squared_error: 122545.1381\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 99477.88783\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 11831.3588 - mean_squared_error: 11308.2905 - val_loss: 128098.1200 - val_mean_squared_error: 127436.3647\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 99477.88783\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 11393.7557 - mean_squared_error: 10875.4790 - val_loss: 121381.5964 - val_mean_squared_error: 120685.1512\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 99477.88783\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 11360.5353 - mean_squared_error: 10840.7155 - val_loss: 122959.5173 - val_mean_squared_error: 122267.4574\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 99477.88783\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 10998.0303 - mean_squared_error: 10477.0538 - val_loss: 131782.0077 - val_mean_squared_error: 131120.1353\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 99477.88783\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 11506.6146 - mean_squared_error: 10990.4909 - val_loss: 122771.2866 - val_mean_squared_error: 122076.3920\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 99477.88783\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 11015.4830 - mean_squared_error: 10497.7328 - val_loss: 122640.3827 - val_mean_squared_error: 121943.0435\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 99477.88783\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 190us/step - loss: 11671.7447 - mean_squared_error: 11151.1787 - val_loss: 123386.3983 - val_mean_squared_error: 122705.4530\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 99477.88783\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 11224.3279 - mean_squared_error: 10707.8734 - val_loss: 122980.4965 - val_mean_squared_error: 122292.4563\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 99477.88783\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b25bb997f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b25bb99e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 5 добавили batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 4s 14ms/step - loss: 302328.4731 - mean_squared_error: 302325.9606 - val_loss: 610087.6568 - val_mean_squared_error: 610084.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_mse` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 610087.65681, saving model to test.hdf5\n",
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 295476.2434 - mean_squared_error: 295472.7667 - val_loss: 593811.8538 - val_mean_squared_error: 593807.3945\n",
      "\n",
      "Epoch 00002: val_loss improved from 610087.65681 to 593811.85379, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 290246.2569 - mean_squared_error: 290241.8172 - val_loss: 581979.6869 - val_mean_squared_error: 581974.1122\n",
      "\n",
      "Epoch 00003: val_loss improved from 593811.85379 to 581979.68694, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 285718.2616 - mean_squared_error: 285713.0841 - val_loss: 570319.9989 - val_mean_squared_error: 570313.3666\n",
      "\n",
      "Epoch 00004: val_loss improved from 581979.68694 to 570319.99888, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 281189.6394 - mean_squared_error: 281183.7414 - val_loss: 562223.5580 - val_mean_squared_error: 562216.5737\n",
      "\n",
      "Epoch 00005: val_loss improved from 570319.99888 to 562223.55804, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 275177.0928 - mean_squared_error: 275170.8959 - val_loss: 551738.7974 - val_mean_squared_error: 551731.1819\n",
      "\n",
      "Epoch 00006: val_loss improved from 562223.55804 to 551738.79743, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 268718.7169 - mean_squared_error: 268712.0078 - val_loss: 539013.9665 - val_mean_squared_error: 539005.6055\n",
      "\n",
      "Epoch 00007: val_loss improved from 551738.79743 to 539013.96652, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 264459.3381 - mean_squared_error: 264451.9092 - val_loss: 520209.8767 - val_mean_squared_error: 520200.6535\n",
      "\n",
      "Epoch 00008: val_loss improved from 539013.96652 to 520209.87667, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 256677.3298 - mean_squared_error: 256668.8553 - val_loss: 498843.9648 - val_mean_squared_error: 498831.8153\n",
      "\n",
      "Epoch 00009: val_loss improved from 520209.87667 to 498843.96484, saving model to test.hdf5\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 251180.6966 - mean_squared_error: 251171.6753 - val_loss: 490419.4448 - val_mean_squared_error: 490407.5357\n",
      "\n",
      "Epoch 00010: val_loss improved from 498843.96484 to 490419.44475, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 244300.9080 - mean_squared_error: 244291.6945 - val_loss: 472849.4693 - val_mean_squared_error: 472836.0965\n",
      "\n",
      "Epoch 00011: val_loss improved from 490419.44475 to 472849.46931, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 236789.5350 - mean_squared_error: 236779.5866 - val_loss: 464269.8862 - val_mean_squared_error: 464256.8331\n",
      "\n",
      "Epoch 00012: val_loss improved from 472849.46931 to 464269.88616, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 230911.8864 - mean_squared_error: 230901.9675 - val_loss: 447229.7227 - val_mean_squared_error: 447215.3125\n",
      "\n",
      "Epoch 00013: val_loss improved from 464269.88616 to 447229.72266, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 220976.7571 - mean_squared_error: 220966.0788 - val_loss: 436020.5084 - val_mean_squared_error: 436005.8823\n",
      "\n",
      "Epoch 00014: val_loss improved from 447229.72266 to 436020.50837, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 212883.4209 - mean_squared_error: 212872.4676 - val_loss: 423541.4704 - val_mean_squared_error: 423525.8823\n",
      "\n",
      "Epoch 00015: val_loss improved from 436020.50837 to 423541.47042, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 203580.9900 - mean_squared_error: 203569.8112 - val_loss: 404249.8013 - val_mean_squared_error: 404233.1345\n",
      "\n",
      "Epoch 00016: val_loss improved from 423541.47042 to 404249.80134, saving model to test.hdf5\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 194579.6852 - mean_squared_error: 194567.1782 - val_loss: 396874.8465 - val_mean_squared_error: 396859.0569\n",
      "\n",
      "Epoch 00017: val_loss improved from 404249.80134 to 396874.84654, saving model to test.hdf5\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 186465.0850 - mean_squared_error: 186453.7299 - val_loss: 398425.4665 - val_mean_squared_error: 398411.7868\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 396874.84654\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 178057.1205 - mean_squared_error: 178044.8821 - val_loss: 364182.0084 - val_mean_squared_error: 364165.7249\n",
      "\n",
      "Epoch 00019: val_loss improved from 396874.84654 to 364182.00837, saving model to test.hdf5\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 168838.2079 - mean_squared_error: 168825.9962 - val_loss: 356820.0564 - val_mean_squared_error: 356804.1406\n",
      "\n",
      "Epoch 00020: val_loss improved from 364182.00837 to 356820.05636, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 164391.9495 - mean_squared_error: 164379.2514 - val_loss: 347513.6429 - val_mean_squared_error: 347498.3298\n",
      "\n",
      "Epoch 00021: val_loss improved from 356820.05636 to 347513.64286, saving model to test.hdf5\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 152450.6038 - mean_squared_error: 152438.1472 - val_loss: 344460.5195 - val_mean_squared_error: 344445.7589\n",
      "\n",
      "Epoch 00022: val_loss improved from 347513.64286 to 344460.51953, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 141954.7545 - mean_squared_error: 141942.7111 - val_loss: 332075.4420 - val_mean_squared_error: 332060.7227\n",
      "\n",
      "Epoch 00023: val_loss improved from 344460.51953 to 332075.44196, saving model to test.hdf5\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 135896.0991 - mean_squared_error: 135884.2549 - val_loss: 304003.9788 - val_mean_squared_error: 303987.6624\n",
      "\n",
      "Epoch 00024: val_loss improved from 332075.44196 to 304003.97879, saving model to test.hdf5\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 125522.3464 - mean_squared_error: 125510.2800 - val_loss: 284465.6434 - val_mean_squared_error: 284449.1183\n",
      "\n",
      "Epoch 00025: val_loss improved from 304003.97879 to 284465.64342, saving model to test.hdf5\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 120343.0377 - mean_squared_error: 120329.9336 - val_loss: 273236.6883 - val_mean_squared_error: 273219.4891\n",
      "\n",
      "Epoch 00026: val_loss improved from 284465.64342 to 273236.68834, saving model to test.hdf5\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 110179.1839 - mean_squared_error: 110167.5583 - val_loss: 275949.4367 - val_mean_squared_error: 275934.2793\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 273236.68834\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 107723.6020 - mean_squared_error: 107711.4745 - val_loss: 262768.3278 - val_mean_squared_error: 262754.1130\n",
      "\n",
      "Epoch 00028: val_loss improved from 273236.68834 to 262768.32785, saving model to test.hdf5\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 98251.5949 - mean_squared_error: 98239.9787 - val_loss: 252366.5926 - val_mean_squared_error: 252352.9255\n",
      "\n",
      "Epoch 00029: val_loss improved from 262768.32785 to 252366.59263, saving model to test.hdf5\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 92670.9187 - mean_squared_error: 92658.6914 - val_loss: 255528.7397 - val_mean_squared_error: 255515.3292\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 252366.59263\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 86565.2502 - mean_squared_error: 86554.1325 - val_loss: 244428.2034 - val_mean_squared_error: 244415.1652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss improved from 252366.59263 to 244428.20340, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 85021.3628 - mean_squared_error: 85009.9765 - val_loss: 219860.4651 - val_mean_squared_error: 219848.4191\n",
      "\n",
      "Epoch 00032: val_loss improved from 244428.20340 to 219860.46512, saving model to test.hdf5\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 79255.9430 - mean_squared_error: 79243.9383 - val_loss: 226308.5379 - val_mean_squared_error: 226295.3033\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 219860.46512\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 79591.8680 - mean_squared_error: 79580.0399 - val_loss: 212520.3114 - val_mean_squared_error: 212507.0109\n",
      "\n",
      "Epoch 00034: val_loss improved from 219860.46512 to 212520.31138, saving model to test.hdf5\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 64948.2396 - mean_squared_error: 64935.7006 - val_loss: 202173.5935 - val_mean_squared_error: 202161.6470\n",
      "\n",
      "Epoch 00035: val_loss improved from 212520.31138 to 202173.59347, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 69087.6555 - mean_squared_error: 69076.7375 - val_loss: 200669.6091 - val_mean_squared_error: 200659.8580\n",
      "\n",
      "Epoch 00036: val_loss improved from 202173.59347 to 200669.60910, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 65376.9958 - mean_squared_error: 65366.0434 - val_loss: 197316.9501 - val_mean_squared_error: 197305.8474\n",
      "\n",
      "Epoch 00037: val_loss improved from 200669.60910 to 197316.95006, saving model to test.hdf5\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 54986.2265 - mean_squared_error: 54974.6965 - val_loss: 191501.8142 - val_mean_squared_error: 191491.3728\n",
      "\n",
      "Epoch 00038: val_loss improved from 197316.95006 to 191501.81417, saving model to test.hdf5\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 58732.1637 - mean_squared_error: 58721.5839 - val_loss: 190681.2573 - val_mean_squared_error: 190673.4802\n",
      "\n",
      "Epoch 00039: val_loss improved from 191501.81417 to 190681.25725, saving model to test.hdf5\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 58689.6918 - mean_squared_error: 58680.8987 - val_loss: 180944.2391 - val_mean_squared_error: 180935.3694\n",
      "\n",
      "Epoch 00040: val_loss improved from 190681.25725 to 180944.23912, saving model to test.hdf5\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 50055.2100 - mean_squared_error: 50045.7215 - val_loss: 169715.5692 - val_mean_squared_error: 169706.9682\n",
      "\n",
      "Epoch 00041: val_loss improved from 180944.23912 to 169715.56920, saving model to test.hdf5\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 39859.7823 - mean_squared_error: 39849.7151 - val_loss: 147138.5598 - val_mean_squared_error: 147128.6685\n",
      "\n",
      "Epoch 00042: val_loss improved from 169715.56920 to 147138.55985, saving model to test.hdf5\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 43951.8062 - mean_squared_error: 43942.1694 - val_loss: 163938.6348 - val_mean_squared_error: 163931.0698\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 147138.55985\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 43982.1314 - mean_squared_error: 43972.8523 - val_loss: 138253.0419 - val_mean_squared_error: 138242.9473\n",
      "\n",
      "Epoch 00044: val_loss improved from 147138.55985 to 138253.04185, saving model to test.hdf5\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 40600.9344 - mean_squared_error: 40591.2030 - val_loss: 120975.5106 - val_mean_squared_error: 120966.6092\n",
      "\n",
      "Epoch 00045: val_loss improved from 138253.04185 to 120975.51060, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 35342.5483 - mean_squared_error: 35333.1051 - val_loss: 135893.7146 - val_mean_squared_error: 135886.0921\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 120975.51060\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 37386.0218 - mean_squared_error: 37376.3442 - val_loss: 118281.6215 - val_mean_squared_error: 118273.5180\n",
      "\n",
      "Epoch 00047: val_loss improved from 120975.51060 to 118281.62151, saving model to test.hdf5\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 48857.2300 - mean_squared_error: 48848.2394 - val_loss: 135151.9427 - val_mean_squared_error: 135144.7787\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 118281.62151\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 33557.5372 - mean_squared_error: 33548.3405 - val_loss: 140726.1147 - val_mean_squared_error: 140716.9060\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 118281.62151\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 38489.9439 - mean_squared_error: 38480.0709 - val_loss: 152586.5368 - val_mean_squared_error: 152579.8072\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 118281.62151\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 38743.5141 - mean_squared_error: 38733.3023 - val_loss: 118205.6602 - val_mean_squared_error: 118196.3577\n",
      "\n",
      "Epoch 00051: val_loss improved from 118281.62151 to 118205.66016, saving model to test.hdf5\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 46608.2910 - mean_squared_error: 46598.1698 - val_loss: 115543.8064 - val_mean_squared_error: 115533.2973\n",
      "\n",
      "Epoch 00052: val_loss improved from 118205.66016 to 115543.80636, saving model to test.hdf5\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 37617.1453 - mean_squared_error: 37605.3463 - val_loss: 105936.2497 - val_mean_squared_error: 105925.2640\n",
      "\n",
      "Epoch 00053: val_loss improved from 115543.80636 to 105936.24972, saving model to test.hdf5\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 37396.7174 - mean_squared_error: 37385.3442 - val_loss: 105227.5174 - val_mean_squared_error: 105217.9262\n",
      "\n",
      "Epoch 00054: val_loss improved from 105936.24972 to 105227.51744, saving model to test.hdf5\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 35448.9862 - mean_squared_error: 35439.0714 - val_loss: 113836.4487 - val_mean_squared_error: 113827.7267\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 105227.51744\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 29447.2057 - mean_squared_error: 29437.7917 - val_loss: 122273.1067 - val_mean_squared_error: 122265.8278\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 105227.51744\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 33437.6367 - mean_squared_error: 33429.2486 - val_loss: 119578.3179 - val_mean_squared_error: 119570.4803\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 105227.51744\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 34806.1820 - mean_squared_error: 34797.4163 - val_loss: 123504.1260 - val_mean_squared_error: 123493.7634\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 105227.51744\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 34991.2778 - mean_squared_error: 34980.9965 - val_loss: 102272.4177 - val_mean_squared_error: 102263.4428\n",
      "\n",
      "Epoch 00059: val_loss improved from 105227.51744 to 102272.41769, saving model to test.hdf5\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 34784.4513 - mean_squared_error: 34774.5142 - val_loss: 114807.5958 - val_mean_squared_error: 114798.9124\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 102272.41769\n",
      "Epoch 61/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 26203.6961 - mean_squared_error: 26194.1232 - val_loss: 99942.9718 - val_mean_squared_error: 99934.6391\n",
      "\n",
      "Epoch 00061: val_loss improved from 102272.41769 to 99942.97182, saving model to test.hdf5\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 34857.2609 - mean_squared_error: 34847.2752 - val_loss: 107504.9128 - val_mean_squared_error: 107495.7759\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 99942.97182\n",
      "Epoch 63/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 228us/step - loss: 38014.8450 - mean_squared_error: 38004.7029 - val_loss: 109861.5202 - val_mean_squared_error: 109852.1948\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 99942.97182\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 31979.4434 - mean_squared_error: 31969.3403 - val_loss: 101040.1523 - val_mean_squared_error: 101030.3910\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 99942.97182\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 31999.0336 - mean_squared_error: 31989.2210 - val_loss: 101367.2426 - val_mean_squared_error: 101357.9664\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 99942.97182\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 31161.9141 - mean_squared_error: 31152.3419 - val_loss: 97741.1910 - val_mean_squared_error: 97731.2234\n",
      "\n",
      "Epoch 00066: val_loss improved from 99942.97182 to 97741.19099, saving model to test.hdf5\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 29959.8025 - mean_squared_error: 29950.0011 - val_loss: 108862.8313 - val_mean_squared_error: 108853.7934\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 97741.19099\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 25814.0799 - mean_squared_error: 25804.4399 - val_loss: 109235.8750 - val_mean_squared_error: 109227.8468\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 97741.19099\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 31272.3121 - mean_squared_error: 31263.2257 - val_loss: 103572.9920 - val_mean_squared_error: 103563.9129\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 97741.19099\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 35105.9511 - mean_squared_error: 35096.4509 - val_loss: 97445.4088 - val_mean_squared_error: 97435.0859\n",
      "\n",
      "Epoch 00070: val_loss improved from 97741.19099 to 97445.40876, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 33964.5641 - mean_squared_error: 33954.5043 - val_loss: 102120.0113 - val_mean_squared_error: 102109.0439\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 97445.40876\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 30765.9278 - mean_squared_error: 30756.1739 - val_loss: 98015.0446 - val_mean_squared_error: 98005.2961\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 97445.40876\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 26424.0119 - mean_squared_error: 26414.8492 - val_loss: 95351.4676 - val_mean_squared_error: 95340.2969\n",
      "\n",
      "Epoch 00073: val_loss improved from 97445.40876 to 95351.46763, saving model to test.hdf5\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 35229.5229 - mean_squared_error: 35218.5910 - val_loss: 99864.6412 - val_mean_squared_error: 99854.0908\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 95351.46763\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 24852.1195 - mean_squared_error: 24842.6859 - val_loss: 93213.5568 - val_mean_squared_error: 93202.7623\n",
      "\n",
      "Epoch 00075: val_loss improved from 95351.46763 to 93213.55685, saving model to test.hdf5\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 35469.8238 - mean_squared_error: 35460.5240 - val_loss: 96515.4028 - val_mean_squared_error: 96503.2898\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 93213.55685\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 33192.8498 - mean_squared_error: 33182.3852 - val_loss: 97934.5430 - val_mean_squared_error: 97922.1509\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 93213.55685\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 32042.2805 - mean_squared_error: 32032.1952 - val_loss: 92106.2727 - val_mean_squared_error: 92096.1571\n",
      "\n",
      "Epoch 00078: val_loss improved from 93213.55685 to 92106.27274, saving model to test.hdf5\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 33048.7982 - mean_squared_error: 33039.5737 - val_loss: 102402.9305 - val_mean_squared_error: 102392.4912\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 92106.27274\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 32240.6548 - mean_squared_error: 32230.9342 - val_loss: 100354.9218 - val_mean_squared_error: 100344.1062\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 92106.27274\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 35322.0621 - mean_squared_error: 35312.4015 - val_loss: 102383.4035 - val_mean_squared_error: 102373.7826\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 92106.27274\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 25944.9876 - mean_squared_error: 25935.2676 - val_loss: 88045.7057 - val_mean_squared_error: 88035.2368\n",
      "\n",
      "Epoch 00082: val_loss improved from 92106.27274 to 88045.70571, saving model to test.hdf5\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 32387.4851 - mean_squared_error: 32378.5011 - val_loss: 91042.8834 - val_mean_squared_error: 91032.7709\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 88045.70571\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 24444.5929 - mean_squared_error: 24435.6284 - val_loss: 99473.0096 - val_mean_squared_error: 99463.5223\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 88045.70571\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 31262.8028 - mean_squared_error: 31254.0140 - val_loss: 97277.9028 - val_mean_squared_error: 97267.2217\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 88045.70571\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 25312.8833 - mean_squared_error: 25303.6315 - val_loss: 93368.0900 - val_mean_squared_error: 93357.1890\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 88045.70571\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 30723.5471 - mean_squared_error: 30714.0971 - val_loss: 97505.7287 - val_mean_squared_error: 97495.7405\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 88045.70571\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 24895.8905 - mean_squared_error: 24887.0525 - val_loss: 92236.3138 - val_mean_squared_error: 92225.8907\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 88045.70571\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 33976.6975 - mean_squared_error: 33967.3646 - val_loss: 101395.8329 - val_mean_squared_error: 101385.2900\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 88045.70571\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 28036.9528 - mean_squared_error: 28027.8651 - val_loss: 95427.5904 - val_mean_squared_error: 95417.3472\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 88045.70571\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 29813.8773 - mean_squared_error: 29804.7006 - val_loss: 98819.2670 - val_mean_squared_error: 98808.7254\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 88045.70571\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 31124.2595 - mean_squared_error: 31114.8194 - val_loss: 91198.6858 - val_mean_squared_error: 91186.8133\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 88045.70571\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 25079.3256 - mean_squared_error: 25068.9932 - val_loss: 100009.4704 - val_mean_squared_error: 99998.6512\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 88045.70571\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 24006.1948 - mean_squared_error: 23996.8931 - val_loss: 99533.3765 - val_mean_squared_error: 99523.3787\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 88045.70571\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 31722.4470 - mean_squared_error: 31713.6925 - val_loss: 89841.2900 - val_mean_squared_error: 89830.3716\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 88045.70571\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 21329.0796 - mean_squared_error: 21320.1906 - val_loss: 94597.4161 - val_mean_squared_error: 94586.9242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_loss did not improve from 88045.70571\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 28234.1670 - mean_squared_error: 28225.0413 - val_loss: 91955.5262 - val_mean_squared_error: 91945.8351\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 88045.70571\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 29194.4650 - mean_squared_error: 29185.9820 - val_loss: 102218.1682 - val_mean_squared_error: 102208.7453\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 88045.70571\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 23991.9736 - mean_squared_error: 23983.6322 - val_loss: 93738.4754 - val_mean_squared_error: 93729.6858\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 88045.70571\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 23607.7223 - mean_squared_error: 23599.4152 - val_loss: 91104.2639 - val_mean_squared_error: 91094.1656\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 88045.70571\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 28126.3159 - mean_squared_error: 28117.4632 - val_loss: 87410.0038 - val_mean_squared_error: 87399.5587\n",
      "\n",
      "Epoch 00101: val_loss improved from 88045.70571 to 87410.00377, saving model to test.hdf5\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 21108.6181 - mean_squared_error: 21099.4685 - val_loss: 87041.3567 - val_mean_squared_error: 87031.0067\n",
      "\n",
      "Epoch 00102: val_loss improved from 87410.00377 to 87041.35665, saving model to test.hdf5\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 29006.2459 - mean_squared_error: 28997.3765 - val_loss: 96218.6600 - val_mean_squared_error: 96208.6950\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 87041.35665\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 24616.6109 - mean_squared_error: 24608.0589 - val_loss: 89653.6961 - val_mean_squared_error: 89643.5831\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 87041.35665\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 23762.2022 - mean_squared_error: 23753.5932 - val_loss: 87918.6301 - val_mean_squared_error: 87909.0134\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 87041.35665\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 22504.3138 - mean_squared_error: 22495.9520 - val_loss: 97882.4654 - val_mean_squared_error: 97873.2423\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 87041.35665\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 27415.9050 - mean_squared_error: 27407.2825 - val_loss: 89272.7136 - val_mean_squared_error: 89262.3857\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 87041.35665\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 23611.3002 - mean_squared_error: 23602.1204 - val_loss: 90596.1498 - val_mean_squared_error: 90585.3617\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 87041.35665\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 20677.2901 - mean_squared_error: 20668.5246 - val_loss: 91966.6705 - val_mean_squared_error: 91957.4955\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 87041.35665\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 26092.9579 - mean_squared_error: 26084.5864 - val_loss: 87542.1476 - val_mean_squared_error: 87531.4331\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 87041.35665\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 24170.1779 - mean_squared_error: 24161.8013 - val_loss: 89947.4215 - val_mean_squared_error: 89937.8036\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 87041.35665\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 30006.8926 - mean_squared_error: 29999.0645 - val_loss: 87228.9568 - val_mean_squared_error: 87218.1360\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 87041.35665\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 29820.9455 - mean_squared_error: 29811.8462 - val_loss: 88410.5958 - val_mean_squared_error: 88399.4582\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 87041.35665\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 25229.8032 - mean_squared_error: 25220.9440 - val_loss: 96675.4387 - val_mean_squared_error: 96665.9733\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 87041.35665\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 31503.1662 - mean_squared_error: 31494.9147 - val_loss: 100652.9536 - val_mean_squared_error: 100643.6999\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 87041.35665\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 28052.2439 - mean_squared_error: 28044.1480 - val_loss: 90368.1654 - val_mean_squared_error: 90358.2724\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 87041.35665\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 30181.1482 - mean_squared_error: 30172.5040 - val_loss: 87360.9743 - val_mean_squared_error: 87350.9909\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 87041.35665\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 28309.1397 - mean_squared_error: 28300.6216 - val_loss: 81790.8029 - val_mean_squared_error: 81780.7705\n",
      "\n",
      "Epoch 00118: val_loss improved from 87041.35665 to 81790.80287, saving model to test.hdf5\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 25146.3233 - mean_squared_error: 25137.5457 - val_loss: 87727.2583 - val_mean_squared_error: 87717.4343\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 81790.80287\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 25974.4526 - mean_squared_error: 25965.4445 - val_loss: 90225.6940 - val_mean_squared_error: 90216.2784\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 81790.80287\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 30234.4520 - mean_squared_error: 30226.1042 - val_loss: 80616.2819 - val_mean_squared_error: 80606.3999\n",
      "\n",
      "Epoch 00121: val_loss improved from 81790.80287 to 80616.28191, saving model to test.hdf5\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 28107.3878 - mean_squared_error: 28099.3556 - val_loss: 94452.1685 - val_mean_squared_error: 94443.4573\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 80616.28191\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 20154.3987 - mean_squared_error: 20146.4378 - val_loss: 78872.9242 - val_mean_squared_error: 78863.8643\n",
      "\n",
      "Epoch 00123: val_loss improved from 80616.28191 to 78872.92418, saving model to test.hdf5\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 25964.2474 - mean_squared_error: 25956.8032 - val_loss: 80341.1033 - val_mean_squared_error: 80331.8244\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 78872.92418\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 26055.6782 - mean_squared_error: 26047.7922 - val_loss: 91912.0318 - val_mean_squared_error: 91902.6565\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 78872.92418\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 21460.0949 - mean_squared_error: 21451.6790 - val_loss: 91884.9072 - val_mean_squared_error: 91875.5589\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 78872.92418\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 22882.8190 - mean_squared_error: 22874.6863 - val_loss: 82859.8952 - val_mean_squared_error: 82850.2686\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 78872.92418\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 28009.6492 - mean_squared_error: 28001.4167 - val_loss: 87143.8265 - val_mean_squared_error: 87133.8312\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 78872.92418\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 21410.0579 - mean_squared_error: 21401.7375 - val_loss: 102456.7003 - val_mean_squared_error: 102448.6466\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 78872.92418\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 24914.8169 - mean_squared_error: 24907.0838 - val_loss: 88431.8154 - val_mean_squared_error: 88422.9468\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 78872.92418\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 27330.1828 - mean_squared_error: 27321.9575 - val_loss: 86991.9234 - val_mean_squared_error: 86981.5103\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 78872.92418\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 25001.5829 - mean_squared_error: 24992.9459 - val_loss: 84624.6091 - val_mean_squared_error: 84615.3830\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 78872.92418\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 27591.9476 - mean_squared_error: 27583.6418 - val_loss: 100104.4109 - val_mean_squared_error: 100096.1373\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 78872.92418\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 25560.8169 - mean_squared_error: 25553.1977 - val_loss: 82689.7348 - val_mean_squared_error: 82680.4844\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 78872.92418\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 22972.0691 - mean_squared_error: 22964.3830 - val_loss: 74596.3243 - val_mean_squared_error: 74586.3991\n",
      "\n",
      "Epoch 00135: val_loss improved from 78872.92418 to 74596.32432, saving model to test.hdf5\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 23481.2227 - mean_squared_error: 23473.4106 - val_loss: 86938.9502 - val_mean_squared_error: 86930.8258\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 74596.32432\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 25343.5232 - mean_squared_error: 25336.0296 - val_loss: 78207.3834 - val_mean_squared_error: 78198.2564\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 74596.32432\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 25106.4122 - mean_squared_error: 25098.4346 - val_loss: 86415.8980 - val_mean_squared_error: 86405.8221\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 74596.32432\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 26561.8862 - mean_squared_error: 26553.4233 - val_loss: 84317.1855 - val_mean_squared_error: 84307.2987\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 74596.32432\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 21654.6938 - mean_squared_error: 21646.4536 - val_loss: 81877.6837 - val_mean_squared_error: 81868.1420\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 74596.32432\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 29905.1974 - mean_squared_error: 29897.2899 - val_loss: 84585.4843 - val_mean_squared_error: 84575.3184\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 74596.32432\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 24631.7025 - mean_squared_error: 24623.4883 - val_loss: 82610.8170 - val_mean_squared_error: 82601.5308\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 74596.32432\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 22520.7436 - mean_squared_error: 22512.8093 - val_loss: 83023.9308 - val_mean_squared_error: 83015.0573\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 74596.32432\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 33507.4944 - mean_squared_error: 33499.5423 - val_loss: 88419.9609 - val_mean_squared_error: 88410.6719\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 74596.32432\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 25348.5094 - mean_squared_error: 25341.0155 - val_loss: 86811.6385 - val_mean_squared_error: 86803.6687\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 74596.32432\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 19830.9849 - mean_squared_error: 19823.8822 - val_loss: 91781.8475 - val_mean_squared_error: 91773.8202\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 74596.32432\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 31067.9544 - mean_squared_error: 31060.6525 - val_loss: 85629.1055 - val_mean_squared_error: 85620.2623\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 74596.32432\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 19063.5409 - mean_squared_error: 19055.5600 - val_loss: 86246.2137 - val_mean_squared_error: 86238.1565\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 74596.32432\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 23606.6015 - mean_squared_error: 23599.2608 - val_loss: 92203.1023 - val_mean_squared_error: 92195.2272\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 74596.32432\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 23105.5312 - mean_squared_error: 23098.5333 - val_loss: 82226.2241 - val_mean_squared_error: 82217.7876\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 74596.32432\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 23301.7919 - mean_squared_error: 23294.4305 - val_loss: 91524.3253 - val_mean_squared_error: 91516.0490\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 74596.32432\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 29134.7506 - mean_squared_error: 29127.7564 - val_loss: 88443.7081 - val_mean_squared_error: 88435.1458\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 74596.32432\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 20804.5958 - mean_squared_error: 20796.6119 - val_loss: 77843.4083 - val_mean_squared_error: 77833.4804\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 74596.32432\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 24457.2343 - mean_squared_error: 24449.5094 - val_loss: 82136.2554 - val_mean_squared_error: 82127.6660\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 74596.32432\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 30178.9914 - mean_squared_error: 30171.8894 - val_loss: 80522.2212 - val_mean_squared_error: 80512.4285\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 74596.32432\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 23138.5020 - mean_squared_error: 23130.0971 - val_loss: 76354.9526 - val_mean_squared_error: 76346.0259\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 74596.32432\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 22723.4374 - mean_squared_error: 22715.3104 - val_loss: 81762.5257 - val_mean_squared_error: 81753.3832\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 74596.32432\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 26562.8113 - mean_squared_error: 26555.2626 - val_loss: 78679.3305 - val_mean_squared_error: 78669.7154\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 74596.32432\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 16716.7196 - mean_squared_error: 16709.1621 - val_loss: 82083.8076 - val_mean_squared_error: 82075.4306\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 74596.32432\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 23400.5113 - mean_squared_error: 23393.5432 - val_loss: 85675.9040 - val_mean_squared_error: 85668.4974\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 74596.32432\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 22080.3197 - mean_squared_error: 22073.2793 - val_loss: 103850.1803 - val_mean_squared_error: 103842.3149\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 74596.32432\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 19274.7961 - mean_squared_error: 19267.8617 - val_loss: 83417.0140 - val_mean_squared_error: 83409.3594\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 74596.32432\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 26259.9099 - mean_squared_error: 26253.0792 - val_loss: 87473.8278 - val_mean_squared_error: 87465.4167\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 74596.32432\n",
      "Epoch 164/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 272us/step - loss: 20897.7947 - mean_squared_error: 20890.3204 - val_loss: 78511.0519 - val_mean_squared_error: 78502.3087\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 74596.32432\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 24997.9720 - mean_squared_error: 24990.6395 - val_loss: 84615.1933 - val_mean_squared_error: 84606.3745\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 74596.32432\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 22975.1833 - mean_squared_error: 22967.5297 - val_loss: 85424.9329 - val_mean_squared_error: 85416.6824\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 74596.32432\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 19396.1912 - mean_squared_error: 19388.7716 - val_loss: 83828.9487 - val_mean_squared_error: 83820.7400\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 74596.32432\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 21641.2132 - mean_squared_error: 21634.1034 - val_loss: 81960.1408 - val_mean_squared_error: 81952.0791\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 74596.32432\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 28086.8144 - mean_squared_error: 28079.8819 - val_loss: 78668.0027 - val_mean_squared_error: 78659.1419\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 74596.32432\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 27014.0275 - mean_squared_error: 27006.7171 - val_loss: 85608.1997 - val_mean_squared_error: 85599.3562\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 74596.32432\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 23130.6812 - mean_squared_error: 23123.0139 - val_loss: 72719.5140 - val_mean_squared_error: 72710.5598\n",
      "\n",
      "Epoch 00171: val_loss improved from 74596.32432 to 72719.51395, saving model to test.hdf5\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 26090.4385 - mean_squared_error: 26082.6211 - val_loss: 71215.5795 - val_mean_squared_error: 71206.3699\n",
      "\n",
      "Epoch 00172: val_loss improved from 72719.51395 to 71215.57949, saving model to test.hdf5\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 28826.8644 - mean_squared_error: 28818.8356 - val_loss: 77203.0255 - val_mean_squared_error: 77194.6760\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 71215.57949\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 18270.2757 - mean_squared_error: 18262.5497 - val_loss: 69092.1150 - val_mean_squared_error: 69082.4248\n",
      "\n",
      "Epoch 00174: val_loss improved from 71215.57949 to 69092.11499, saving model to test.hdf5\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 21052.0443 - mean_squared_error: 21044.7722 - val_loss: 74616.5735 - val_mean_squared_error: 74607.8444\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 69092.11499\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 18322.4856 - mean_squared_error: 18315.1541 - val_loss: 72938.8193 - val_mean_squared_error: 72930.7315\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 69092.11499\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 20613.5328 - mean_squared_error: 20606.2152 - val_loss: 73041.5369 - val_mean_squared_error: 73032.7480\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 69092.11499\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 313us/step - loss: 17902.1924 - mean_squared_error: 17894.6414 - val_loss: 68694.0066 - val_mean_squared_error: 68686.2228\n",
      "\n",
      "Epoch 00178: val_loss improved from 69092.11499 to 68694.00659, saving model to test.hdf5\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 284us/step - loss: 23344.3925 - mean_squared_error: 23337.3099 - val_loss: 79049.4163 - val_mean_squared_error: 79041.0886\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 68694.00659\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 292us/step - loss: 18992.2904 - mean_squared_error: 18984.9333 - val_loss: 76377.3982 - val_mean_squared_error: 76369.5571\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 68694.00659\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 296us/step - loss: 27389.1671 - mean_squared_error: 27382.2146 - val_loss: 79734.5978 - val_mean_squared_error: 79726.3405\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 68694.00659\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 16241.2963 - mean_squared_error: 16234.2374 - val_loss: 79823.3744 - val_mean_squared_error: 79814.7495\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 68694.00659\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 27598.9286 - mean_squared_error: 27592.1301 - val_loss: 88151.5120 - val_mean_squared_error: 88144.0664\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 68694.00659\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 17730.7919 - mean_squared_error: 17723.8754 - val_loss: 76477.2768 - val_mean_squared_error: 76468.6333\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 68694.00659\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 20686.6666 - mean_squared_error: 20679.4437 - val_loss: 88371.0490 - val_mean_squared_error: 88363.7086\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 68694.00659\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 20885.9817 - mean_squared_error: 20879.3107 - val_loss: 77821.5583 - val_mean_squared_error: 77813.7442\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 68694.00659\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 19240.0793 - mean_squared_error: 19233.3327 - val_loss: 82506.6141 - val_mean_squared_error: 82498.3277\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 68694.00659\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 19042.8919 - mean_squared_error: 19035.7070 - val_loss: 69203.0750 - val_mean_squared_error: 69194.4767\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 68694.00659\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 18988.2701 - mean_squared_error: 18980.8522 - val_loss: 79473.1110 - val_mean_squared_error: 79465.2049\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 68694.00659\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 20263.7224 - mean_squared_error: 20256.6607 - val_loss: 75688.7313 - val_mean_squared_error: 75681.0793\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 68694.00659\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 18949.7977 - mean_squared_error: 18942.9680 - val_loss: 80263.9546 - val_mean_squared_error: 80256.3356\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 68694.00659\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 27457.5345 - mean_squared_error: 27450.5935 - val_loss: 72930.8684 - val_mean_squared_error: 72923.2027\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 68694.00659\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 18381.3194 - mean_squared_error: 18374.4198 - val_loss: 77351.8395 - val_mean_squared_error: 77344.2099\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 68694.00659\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 294us/step - loss: 19534.3413 - mean_squared_error: 19527.2716 - val_loss: 77500.4776 - val_mean_squared_error: 77492.4269\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 68694.00659\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 286us/step - loss: 20738.7962 - mean_squared_error: 20731.6923 - val_loss: 77255.0955 - val_mean_squared_error: 77246.4074\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 68694.00659\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 21303.9415 - mean_squared_error: 21296.6915 - val_loss: 78847.4346 - val_mean_squared_error: 78838.3414\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 68694.00659\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 23473.1484 - mean_squared_error: 23465.9103 - val_loss: 63830.0202 - val_mean_squared_error: 63820.7192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00197: val_loss improved from 68694.00659 to 63830.02019, saving model to test.hdf5\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 21065.2389 - mean_squared_error: 21057.1022 - val_loss: 68133.1210 - val_mean_squared_error: 68123.4879\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 63830.02019\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 13255.9623 - mean_squared_error: 13248.0193 - val_loss: 73417.1910 - val_mean_squared_error: 73408.0386\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 63830.02019\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 15700.5869 - mean_squared_error: 15692.9884 - val_loss: 78946.3426 - val_mean_squared_error: 78938.2285\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 63830.02019\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 28198.7185 - mean_squared_error: 28191.5972 - val_loss: 79951.2247 - val_mean_squared_error: 79942.1880\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 63830.02019\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 18598.1486 - mean_squared_error: 18590.5714 - val_loss: 72080.0349 - val_mean_squared_error: 72071.1170\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 63830.02019\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 21478.6129 - mean_squared_error: 21470.8098 - val_loss: 84884.6539 - val_mean_squared_error: 84876.1992\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 63830.02019\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 21548.3415 - mean_squared_error: 21540.7340 - val_loss: 73922.2723 - val_mean_squared_error: 73913.6876\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 63830.02019\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 19732.5446 - mean_squared_error: 19725.5336 - val_loss: 71416.5392 - val_mean_squared_error: 71407.6805\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 63830.02019\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 23852.6578 - mean_squared_error: 23845.0905 - val_loss: 72780.9349 - val_mean_squared_error: 72772.0692\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 63830.02019\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 23180.4477 - mean_squared_error: 23173.1542 - val_loss: 77074.4689 - val_mean_squared_error: 77066.2402\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 63830.02019\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 19612.3753 - mean_squared_error: 19605.4030 - val_loss: 80572.2048 - val_mean_squared_error: 80563.6466\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 63830.02019\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 286us/step - loss: 13907.0807 - mean_squared_error: 13899.4476 - val_loss: 77236.4832 - val_mean_squared_error: 77228.0615\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 63830.02019\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 26625.9734 - mean_squared_error: 26618.7837 - val_loss: 74304.6764 - val_mean_squared_error: 74295.7150\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 63830.02019\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 21798.2703 - mean_squared_error: 21790.7016 - val_loss: 82087.4504 - val_mean_squared_error: 82079.4061\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 63830.02019\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 17640.2298 - mean_squared_error: 17633.3154 - val_loss: 88947.0957 - val_mean_squared_error: 88939.6799\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 63830.02019\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 23480.4731 - mean_squared_error: 23473.8725 - val_loss: 71080.6941 - val_mean_squared_error: 71072.8873\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 63830.02019\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 20810.0196 - mean_squared_error: 20802.9837 - val_loss: 82640.5589 - val_mean_squared_error: 82632.1462\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 63830.02019\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 24863.1063 - mean_squared_error: 24855.5228 - val_loss: 70197.1439 - val_mean_squared_error: 70188.0673\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 63830.02019\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 20176.1856 - mean_squared_error: 20168.8983 - val_loss: 78455.4590 - val_mean_squared_error: 78447.9841\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 63830.02019\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 17380.0538 - mean_squared_error: 17372.4906 - val_loss: 79179.1371 - val_mean_squared_error: 79171.0659\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 63830.02019\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 15458.6408 - mean_squared_error: 15451.2275 - val_loss: 73606.6291 - val_mean_squared_error: 73598.7031\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 63830.02019\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 16348.8582 - mean_squared_error: 16341.6884 - val_loss: 78250.0363 - val_mean_squared_error: 78242.8330\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 63830.02019\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 18868.6750 - mean_squared_error: 18861.5305 - val_loss: 75880.4900 - val_mean_squared_error: 75873.3320\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 63830.02019\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 19268.5977 - mean_squared_error: 19262.4465 - val_loss: 71146.4137 - val_mean_squared_error: 71138.3514\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 63830.02019\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17474.8853 - mean_squared_error: 17467.9571 - val_loss: 88579.8791 - val_mean_squared_error: 88573.2866\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 63830.02019\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 23654.1304 - mean_squared_error: 23647.4585 - val_loss: 76992.4154 - val_mean_squared_error: 76985.0127\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 63830.02019\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 24999.2867 - mean_squared_error: 24992.5694 - val_loss: 70278.1882 - val_mean_squared_error: 70270.6877\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 63830.02019\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 19952.2220 - mean_squared_error: 19945.3147 - val_loss: 79338.5640 - val_mean_squared_error: 79330.0148\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 63830.02019\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 16669.3477 - mean_squared_error: 16661.7532 - val_loss: 76986.6538 - val_mean_squared_error: 76978.8487\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 63830.02019\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 17106.5878 - mean_squared_error: 17099.7147 - val_loss: 75649.6770 - val_mean_squared_error: 75641.6361\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 63830.02019\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 20263.3089 - mean_squared_error: 20256.2965 - val_loss: 79301.4518 - val_mean_squared_error: 79292.8028\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 63830.02019\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 16292.9217 - mean_squared_error: 16285.7375 - val_loss: 79818.2955 - val_mean_squared_error: 79810.4381\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 63830.02019\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 19509.6789 - mean_squared_error: 19502.8613 - val_loss: 72812.0033 - val_mean_squared_error: 72803.8834\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 63830.02019\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 21312.1457 - mean_squared_error: 21305.1999 - val_loss: 74984.8062 - val_mean_squared_error: 74976.2971\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 63830.02019\n",
      "Epoch 232/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 250us/step - loss: 23736.5421 - mean_squared_error: 23729.7523 - val_loss: 77544.3080 - val_mean_squared_error: 77535.6816\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 63830.02019\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 21135.5398 - mean_squared_error: 21128.4306 - val_loss: 75585.0656 - val_mean_squared_error: 75576.9934\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 63830.02019\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16365.6324 - mean_squared_error: 16358.3602 - val_loss: 76097.6874 - val_mean_squared_error: 76088.5078\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 63830.02019\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 19906.6515 - mean_squared_error: 19899.5251 - val_loss: 74415.3692 - val_mean_squared_error: 74406.6387\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 63830.02019\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 18354.8215 - mean_squared_error: 18347.3432 - val_loss: 76577.2210 - val_mean_squared_error: 76568.8927\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 63830.02019\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 19916.7362 - mean_squared_error: 19909.4838 - val_loss: 74831.9237 - val_mean_squared_error: 74823.2618\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 63830.02019\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16224.0007 - mean_squared_error: 16216.7141 - val_loss: 78152.3380 - val_mean_squared_error: 78143.5325\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 63830.02019\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 18761.7293 - mean_squared_error: 18754.6994 - val_loss: 75221.8451 - val_mean_squared_error: 75213.3355\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 63830.02019\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 18288.6772 - mean_squared_error: 18281.3139 - val_loss: 74047.2968 - val_mean_squared_error: 74038.5624\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 63830.02019\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 20843.6146 - mean_squared_error: 20836.6701 - val_loss: 69143.3301 - val_mean_squared_error: 69134.6202\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 63830.02019\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 24637.4989 - mean_squared_error: 24630.5229 - val_loss: 76677.4871 - val_mean_squared_error: 76668.1053\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 63830.02019\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 23182.8192 - mean_squared_error: 23175.6618 - val_loss: 77527.7616 - val_mean_squared_error: 77519.0842\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 63830.02019\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17395.1514 - mean_squared_error: 17387.8799 - val_loss: 72957.9316 - val_mean_squared_error: 72949.8499\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 63830.02019\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 23011.1106 - mean_squared_error: 23004.0223 - val_loss: 74138.0181 - val_mean_squared_error: 74129.3642\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 63830.02019\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 25178.1378 - mean_squared_error: 25170.9939 - val_loss: 76874.4171 - val_mean_squared_error: 76865.9460\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 63830.02019\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 18267.2742 - mean_squared_error: 18260.2483 - val_loss: 70776.8866 - val_mean_squared_error: 70768.5289\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 63830.02019\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 23024.6573 - mean_squared_error: 23017.7007 - val_loss: 70346.9983 - val_mean_squared_error: 70338.4540\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 63830.02019\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17912.8268 - mean_squared_error: 17905.6380 - val_loss: 77775.3704 - val_mean_squared_error: 77767.4908\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 63830.02019\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 15877.2363 - mean_squared_error: 15870.0791 - val_loss: 74548.2482 - val_mean_squared_error: 74540.5768\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 63830.02019\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 21238.8115 - mean_squared_error: 21232.0742 - val_loss: 79124.1677 - val_mean_squared_error: 79116.9388\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 63830.02019\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 16943.6868 - mean_squared_error: 16937.3529 - val_loss: 72233.4987 - val_mean_squared_error: 72225.7352\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 63830.02019\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 15196.8800 - mean_squared_error: 15190.2818 - val_loss: 73375.6131 - val_mean_squared_error: 73368.1154\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 63830.02019\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 12456.7086 - mean_squared_error: 12450.1635 - val_loss: 69769.5654 - val_mean_squared_error: 69762.2281\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 63830.02019\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 17078.5757 - mean_squared_error: 17072.1946 - val_loss: 69362.1973 - val_mean_squared_error: 69354.6779\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 63830.02019\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 24583.1516 - mean_squared_error: 24576.5188 - val_loss: 68984.3824 - val_mean_squared_error: 68976.2319\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 63830.02019\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 23102.2814 - mean_squared_error: 23095.5547 - val_loss: 69968.0951 - val_mean_squared_error: 69960.4460\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 63830.02019\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 16637.8935 - mean_squared_error: 16631.2323 - val_loss: 73498.2814 - val_mean_squared_error: 73490.3900\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 63830.02019\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 17010.4045 - mean_squared_error: 17003.4499 - val_loss: 69779.6349 - val_mean_squared_error: 69771.5899\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 63830.02019\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 21032.8799 - mean_squared_error: 21026.1777 - val_loss: 70932.8608 - val_mean_squared_error: 70924.1982\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 63830.02019\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 20065.1265 - mean_squared_error: 20057.7461 - val_loss: 71435.8920 - val_mean_squared_error: 71426.9683\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 63830.02019\n",
      "Epoch 262/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16549.8731 - mean_squared_error: 16542.8010 - val_loss: 68466.6963 - val_mean_squared_error: 68458.4411\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 63830.02019\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 16314.4183 - mean_squared_error: 16307.5021 - val_loss: 66706.3809 - val_mean_squared_error: 66698.8949\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 63830.02019\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 16938.8845 - mean_squared_error: 16932.2082 - val_loss: 70248.6975 - val_mean_squared_error: 70240.5395\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 63830.02019\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 16037.5019 - mean_squared_error: 16030.3362 - val_loss: 71349.6723 - val_mean_squared_error: 71341.6024\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 63830.02019\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 23021.5075 - mean_squared_error: 23014.5655 - val_loss: 70302.5987 - val_mean_squared_error: 70294.5543\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 63830.02019\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 15966.6043 - mean_squared_error: 15958.9265 - val_loss: 72836.4056 - val_mean_squared_error: 72828.2312\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 63830.02019\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 11619.6152 - mean_squared_error: 11612.2546 - val_loss: 79479.7980 - val_mean_squared_error: 79470.1473\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 63830.02019\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 15382.8503 - mean_squared_error: 15375.2258 - val_loss: 75721.7725 - val_mean_squared_error: 75712.9632\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 63830.02019\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 33191.8033 - mean_squared_error: 33184.5418 - val_loss: 76550.3555 - val_mean_squared_error: 76541.4937\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 63830.02019\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 18618.0055 - mean_squared_error: 18610.2000 - val_loss: 77163.9074 - val_mean_squared_error: 77153.9984\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 63830.02019\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 16537.1637 - mean_squared_error: 16529.4824 - val_loss: 67446.0437 - val_mean_squared_error: 67436.8757\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 63830.02019\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 18184.8592 - mean_squared_error: 18177.4116 - val_loss: 69646.5338 - val_mean_squared_error: 69638.1077\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 63830.02019\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 10601.4914 - mean_squared_error: 10594.1606 - val_loss: 72771.7570 - val_mean_squared_error: 72763.7965\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 63830.02019\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 21558.3496 - mean_squared_error: 21551.1987 - val_loss: 76062.4037 - val_mean_squared_error: 76054.5883\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 63830.02019\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 16269.8460 - mean_squared_error: 16262.8832 - val_loss: 66182.4404 - val_mean_squared_error: 66173.6967\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 63830.02019\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 31850.5027 - mean_squared_error: 31843.4906 - val_loss: 72252.8088 - val_mean_squared_error: 72244.2597\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 63830.02019\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 14398.5335 - mean_squared_error: 14391.7674 - val_loss: 74123.6023 - val_mean_squared_error: 74114.4731\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 63830.02019\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 30798.1232 - mean_squared_error: 30791.3869 - val_loss: 71275.5830 - val_mean_squared_error: 71267.7636\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 63830.02019\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 18237.2027 - mean_squared_error: 18230.7527 - val_loss: 69694.3387 - val_mean_squared_error: 69686.3795\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 63830.02019\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 17138.8204 - mean_squared_error: 17132.4699 - val_loss: 67528.5608 - val_mean_squared_error: 67521.3028\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 63830.02019\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 21888.0890 - mean_squared_error: 21881.7214 - val_loss: 69644.4087 - val_mean_squared_error: 69636.6988\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 63830.02019\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 22022.6598 - mean_squared_error: 22016.1587 - val_loss: 63217.3090 - val_mean_squared_error: 63208.8244\n",
      "\n",
      "Epoch 00283: val_loss improved from 63830.02019 to 63217.30901, saving model to test.hdf5\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 18043.7896 - mean_squared_error: 18036.7407 - val_loss: 72781.0149 - val_mean_squared_error: 72772.9190\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 63217.30901\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 14881.1703 - mean_squared_error: 14874.4256 - val_loss: 74216.5181 - val_mean_squared_error: 74209.1062\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 63217.30901\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 16918.4081 - mean_squared_error: 16911.8779 - val_loss: 76402.0346 - val_mean_squared_error: 76394.5461\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 63217.30901\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 16638.3596 - mean_squared_error: 16631.9420 - val_loss: 73521.3775 - val_mean_squared_error: 73513.8472\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 63217.30901\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 20634.9496 - mean_squared_error: 20628.1346 - val_loss: 70919.8870 - val_mean_squared_error: 70912.3817\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 63217.30901\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 13707.0129 - mean_squared_error: 13699.8619 - val_loss: 66204.0418 - val_mean_squared_error: 66195.9106\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 63217.30901\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 20945.5016 - mean_squared_error: 20938.7618 - val_loss: 71982.1739 - val_mean_squared_error: 71973.7719\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 63217.30901\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 26013.7973 - mean_squared_error: 26006.8272 - val_loss: 69201.6027 - val_mean_squared_error: 69192.8177\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 63217.30901\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 15540.6294 - mean_squared_error: 15532.9486 - val_loss: 70141.4816 - val_mean_squared_error: 70133.1426\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 63217.30901\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16946.4918 - mean_squared_error: 16939.5714 - val_loss: 77774.2403 - val_mean_squared_error: 77766.3348\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 63217.30901\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 15746.7230 - mean_squared_error: 15739.8257 - val_loss: 75248.6688 - val_mean_squared_error: 75241.0744\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 63217.30901\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 16944.6059 - mean_squared_error: 16937.4132 - val_loss: 72276.6670 - val_mean_squared_error: 72268.0094\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 63217.30901\n",
      "Epoch 296/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 19101.7087 - mean_squared_error: 19094.4959 - val_loss: 60832.7776 - val_mean_squared_error: 60824.8027\n",
      "\n",
      "Epoch 00296: val_loss improved from 63217.30901 to 60832.77759, saving model to test.hdf5\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 33870.3261 - mean_squared_error: 33863.2950 - val_loss: 81244.6535 - val_mean_squared_error: 81236.8073\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 60832.77759\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 13297.5882 - mean_squared_error: 13290.0880 - val_loss: 69863.7844 - val_mean_squared_error: 69855.2742\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 60832.77759\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 16279.7132 - mean_squared_error: 16272.2683 - val_loss: 71258.9061 - val_mean_squared_error: 71250.7578\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 60832.77759\n",
      "Epoch 300/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 232us/step - loss: 17667.3541 - mean_squared_error: 17660.1243 - val_loss: 70987.1994 - val_mean_squared_error: 70978.1165\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 60832.77759\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 20895.8801 - mean_squared_error: 20888.4230 - val_loss: 66114.7245 - val_mean_squared_error: 66105.8849\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 60832.77759\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 14724.9445 - mean_squared_error: 14717.8519 - val_loss: 69245.0917 - val_mean_squared_error: 69236.4810\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 60832.77759\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 12717.9423 - mean_squared_error: 12710.8937 - val_loss: 66288.5951 - val_mean_squared_error: 66279.3652\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 60832.77759\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 15986.0741 - mean_squared_error: 15978.8706 - val_loss: 72185.0655 - val_mean_squared_error: 72175.9817\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 60832.77759\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 16819.9283 - mean_squared_error: 16812.7305 - val_loss: 67758.7885 - val_mean_squared_error: 67749.5713\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 60832.77759\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 15473.1567 - mean_squared_error: 15465.9147 - val_loss: 71164.3017 - val_mean_squared_error: 71155.3380\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 60832.77759\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 22400.2448 - mean_squared_error: 22393.0672 - val_loss: 72331.8657 - val_mean_squared_error: 72323.6058\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 60832.77759\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 16452.7529 - mean_squared_error: 16445.6080 - val_loss: 68857.2773 - val_mean_squared_error: 68849.0754\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 60832.77759\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 13453.6667 - mean_squared_error: 13446.6011 - val_loss: 66435.7718 - val_mean_squared_error: 66427.5563\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 60832.77759\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 12270.5026 - mean_squared_error: 12263.4569 - val_loss: 73313.4522 - val_mean_squared_error: 73306.0951\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 60832.77759\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 17944.2888 - mean_squared_error: 17937.5729 - val_loss: 68013.9758 - val_mean_squared_error: 68004.9789\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 60832.77759\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 13782.5091 - mean_squared_error: 13775.4467 - val_loss: 68776.9205 - val_mean_squared_error: 68769.6258\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 60832.77759\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 17968.3258 - mean_squared_error: 17961.8016 - val_loss: 71894.5817 - val_mean_squared_error: 71885.7155\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 60832.77759\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 17496.6179 - mean_squared_error: 17489.6770 - val_loss: 76440.7357 - val_mean_squared_error: 76432.9819\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 60832.77759\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 12910.7103 - mean_squared_error: 12904.0570 - val_loss: 67999.7644 - val_mean_squared_error: 67991.1658\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 60832.77759\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 14198.8350 - mean_squared_error: 14191.7357 - val_loss: 68298.0227 - val_mean_squared_error: 68290.3477\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 60832.77759\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 25302.4634 - mean_squared_error: 25295.9412 - val_loss: 67770.3004 - val_mean_squared_error: 67761.2080\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 60832.77759\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 14382.9558 - mean_squared_error: 14375.9037 - val_loss: 63639.2002 - val_mean_squared_error: 63630.8918\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 60832.77759\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 21782.4181 - mean_squared_error: 21775.4396 - val_loss: 66786.0042 - val_mean_squared_error: 66777.4353\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 60832.77759\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 15886.5541 - mean_squared_error: 15879.3494 - val_loss: 85486.5180 - val_mean_squared_error: 85478.0405\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 60832.77759\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 19905.3322 - mean_squared_error: 19898.2098 - val_loss: 69908.7042 - val_mean_squared_error: 69900.3414\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 60832.77759\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 17060.4682 - mean_squared_error: 17052.7998 - val_loss: 67786.5800 - val_mean_squared_error: 67777.1229\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 60832.77759\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 22158.1358 - mean_squared_error: 22150.6177 - val_loss: 68399.3216 - val_mean_squared_error: 68389.8093\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 60832.77759\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 13641.4623 - mean_squared_error: 13634.0263 - val_loss: 76143.7745 - val_mean_squared_error: 76134.5991\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 60832.77759\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 22637.7291 - mean_squared_error: 22630.4296 - val_loss: 74000.9774 - val_mean_squared_error: 73992.8937\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 60832.77759\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 13601.1583 - mean_squared_error: 13593.7977 - val_loss: 68973.4897 - val_mean_squared_error: 68965.6806\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 60832.77759\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 17913.0498 - mean_squared_error: 17905.9886 - val_loss: 67140.8988 - val_mean_squared_error: 67132.6875\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 60832.77759\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16503.3881 - mean_squared_error: 16496.2467 - val_loss: 77452.1685 - val_mean_squared_error: 77443.5271\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 60832.77759\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 19709.0448 - mean_squared_error: 19701.7322 - val_loss: 74421.1207 - val_mean_squared_error: 74413.0417\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 60832.77759\n",
      "Epoch 330/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 13717.9014 - mean_squared_error: 13710.7200 - val_loss: 80977.1405 - val_mean_squared_error: 80970.0203\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 60832.77759\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 18177.0089 - mean_squared_error: 18170.0461 - val_loss: 71481.7084 - val_mean_squared_error: 71473.9071\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 60832.77759\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 18427.9681 - mean_squared_error: 18421.1223 - val_loss: 70459.4962 - val_mean_squared_error: 70450.5497\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 60832.77759\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 16012.4524 - mean_squared_error: 16004.8707 - val_loss: 72554.0141 - val_mean_squared_error: 72545.7283\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 60832.77759\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 18011.8864 - mean_squared_error: 18004.4725 - val_loss: 72139.8313 - val_mean_squared_error: 72130.4972\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 60832.77759\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 15243.4374 - mean_squared_error: 15236.0684 - val_loss: 72653.5210 - val_mean_squared_error: 72645.2025\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 60832.77759\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 13338.1562 - mean_squared_error: 13330.9641 - val_loss: 68720.8247 - val_mean_squared_error: 68712.2672\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 60832.77759\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17049.9025 - mean_squared_error: 17042.5058 - val_loss: 72387.7900 - val_mean_squared_error: 72379.8308\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 60832.77759\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 17838.7416 - mean_squared_error: 17831.6820 - val_loss: 63946.5958 - val_mean_squared_error: 63937.3754\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 60832.77759\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 15980.3467 - mean_squared_error: 15972.9690 - val_loss: 63897.0200 - val_mean_squared_error: 63888.8628\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 60832.77759\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 16414.3281 - mean_squared_error: 16406.9597 - val_loss: 65608.2168 - val_mean_squared_error: 65599.1974\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 60832.77759\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 21250.0253 - mean_squared_error: 21242.5672 - val_loss: 64812.1723 - val_mean_squared_error: 64803.9970\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 60832.77759\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 14480.4616 - mean_squared_error: 14473.0239 - val_loss: 69248.4518 - val_mean_squared_error: 69240.4572\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 60832.77759\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 15394.6210 - mean_squared_error: 15387.4013 - val_loss: 69322.2554 - val_mean_squared_error: 69314.0212\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 60832.77759\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 14548.5164 - mean_squared_error: 14541.5597 - val_loss: 73675.0458 - val_mean_squared_error: 73666.5893\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 60832.77759\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16511.4073 - mean_squared_error: 16504.3521 - val_loss: 69178.0688 - val_mean_squared_error: 69170.2607\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 60832.77759\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 12898.2173 - mean_squared_error: 12890.8505 - val_loss: 69949.6186 - val_mean_squared_error: 69940.8571\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 60832.77759\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 14583.9147 - mean_squared_error: 14576.7196 - val_loss: 73072.1040 - val_mean_squared_error: 73064.4426\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 60832.77759\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 17473.5492 - mean_squared_error: 17466.3790 - val_loss: 69765.8078 - val_mean_squared_error: 69757.8187\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 60832.77759\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20665.1830 - mean_squared_error: 20658.0786 - val_loss: 71545.3529 - val_mean_squared_error: 71536.0356\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 60832.77759\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 19844.3027 - mean_squared_error: 19836.9390 - val_loss: 68356.7281 - val_mean_squared_error: 68348.0764\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 60832.77759\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17005.1006 - mean_squared_error: 16998.1431 - val_loss: 74326.9334 - val_mean_squared_error: 74318.5900\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 60832.77759\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 17191.1853 - mean_squared_error: 17183.7382 - val_loss: 67042.6276 - val_mean_squared_error: 67034.2306\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 60832.77759\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 14117.8670 - mean_squared_error: 14110.4234 - val_loss: 70313.0770 - val_mean_squared_error: 70305.2703\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 60832.77759\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 20148.9268 - mean_squared_error: 20141.6637 - val_loss: 64136.3805 - val_mean_squared_error: 64128.4043\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 60832.77759\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 20753.3862 - mean_squared_error: 20746.2762 - val_loss: 71350.4288 - val_mean_squared_error: 71341.7501\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 60832.77759\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 13505.0157 - mean_squared_error: 13497.5482 - val_loss: 68910.6324 - val_mean_squared_error: 68902.6930\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 60832.77759\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 13084.0296 - mean_squared_error: 13076.6833 - val_loss: 71200.0077 - val_mean_squared_error: 71191.6334\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 60832.77759\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16814.9462 - mean_squared_error: 16807.8602 - val_loss: 71351.7839 - val_mean_squared_error: 71343.9368\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 60832.77759\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 11834.1634 - mean_squared_error: 11826.7353 - val_loss: 69820.3573 - val_mean_squared_error: 69811.7550\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 60832.77759\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 17119.1436 - mean_squared_error: 17111.6783 - val_loss: 71929.1749 - val_mean_squared_error: 71920.4782\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 60832.77759\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 16172.1542 - mean_squared_error: 16164.8840 - val_loss: 66631.2101 - val_mean_squared_error: 66621.9959\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 60832.77759\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16487.8189 - mean_squared_error: 16480.2271 - val_loss: 75575.8045 - val_mean_squared_error: 75567.1683\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 60832.77759\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 20509.3709 - mean_squared_error: 20501.8888 - val_loss: 67188.3089 - val_mean_squared_error: 67179.1111\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 60832.77759\n",
      "Epoch 364/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16991.3257 - mean_squared_error: 16983.5167 - val_loss: 73629.1071 - val_mean_squared_error: 73620.5813\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 60832.77759\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 14640.3420 - mean_squared_error: 14632.8463 - val_loss: 70436.8600 - val_mean_squared_error: 70428.4663\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 60832.77759\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 12929.4355 - mean_squared_error: 12922.0656 - val_loss: 69092.9457 - val_mean_squared_error: 69084.5241\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 60832.77759\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 13369.6272 - mean_squared_error: 13362.6290 - val_loss: 76754.9168 - val_mean_squared_error: 76747.5252\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 60832.77759\n",
      "Epoch 368/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 226us/step - loss: 22100.7823 - mean_squared_error: 22093.9867 - val_loss: 66732.0371 - val_mean_squared_error: 66723.9623\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 60832.77759\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 17820.2879 - mean_squared_error: 17813.0325 - val_loss: 69417.4083 - val_mean_squared_error: 69409.6146\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 60832.77759\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 17602.3363 - mean_squared_error: 17595.1737 - val_loss: 74156.9038 - val_mean_squared_error: 74149.5467\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 60832.77759\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 13906.7562 - mean_squared_error: 13899.5748 - val_loss: 67131.7631 - val_mean_squared_error: 67123.6640\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 60832.77759\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 15045.7465 - mean_squared_error: 15038.4968 - val_loss: 70672.3674 - val_mean_squared_error: 70662.9778\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 60832.77759\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 19330.3214 - mean_squared_error: 19322.9211 - val_loss: 73844.0398 - val_mean_squared_error: 73835.8467\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 60832.77759\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 16853.0857 - mean_squared_error: 16845.6703 - val_loss: 71186.7882 - val_mean_squared_error: 71178.4678\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 60832.77759\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 18886.8337 - mean_squared_error: 18879.5931 - val_loss: 69536.9580 - val_mean_squared_error: 69528.0854\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 60832.77759\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 22001.1344 - mean_squared_error: 21993.4623 - val_loss: 73286.5874 - val_mean_squared_error: 73277.8558\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 60832.77759\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 12217.8036 - mean_squared_error: 12210.2490 - val_loss: 61660.0336 - val_mean_squared_error: 61650.6887\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 60832.77759\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 18135.5957 - mean_squared_error: 18127.9430 - val_loss: 61541.3576 - val_mean_squared_error: 61532.2537\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 60832.77759\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 13790.3328 - mean_squared_error: 13782.6734 - val_loss: 69599.4021 - val_mean_squared_error: 69590.5562\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 60832.77759\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 18650.3490 - mean_squared_error: 18642.7471 - val_loss: 67275.9678 - val_mean_squared_error: 67266.8747\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 60832.77759\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 15250.6840 - mean_squared_error: 15242.8307 - val_loss: 67762.1998 - val_mean_squared_error: 67752.1492\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 60832.77759\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 14454.5998 - mean_squared_error: 14446.2717 - val_loss: 68169.5966 - val_mean_squared_error: 68159.7273\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 60832.77759\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 14358.3113 - mean_squared_error: 14350.3993 - val_loss: 69139.0025 - val_mean_squared_error: 69130.4038\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 60832.77759\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 15418.8996 - mean_squared_error: 15411.4099 - val_loss: 68478.7397 - val_mean_squared_error: 68468.9397\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 60832.77759\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 18876.8650 - mean_squared_error: 18869.1886 - val_loss: 70413.4567 - val_mean_squared_error: 70405.2039\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 60832.77759\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 18675.3355 - mean_squared_error: 18667.8419 - val_loss: 72563.2830 - val_mean_squared_error: 72554.6955\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 60832.77759\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 16288.1409 - mean_squared_error: 16280.8729 - val_loss: 68719.1669 - val_mean_squared_error: 68710.7719\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 60832.77759\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 16548.4854 - mean_squared_error: 16540.6204 - val_loss: 72256.9960 - val_mean_squared_error: 72248.1062\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 60832.77759\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 20386.4876 - mean_squared_error: 20379.2819 - val_loss: 74455.7636 - val_mean_squared_error: 74446.4960\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 60832.77759\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 14278.9629 - mean_squared_error: 14271.2724 - val_loss: 68117.0338 - val_mean_squared_error: 68108.2657\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 60832.77759\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 18879.3577 - mean_squared_error: 18871.8629 - val_loss: 65849.9013 - val_mean_squared_error: 65840.5239\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 60832.77759\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 19722.4627 - mean_squared_error: 19714.8070 - val_loss: 69958.8254 - val_mean_squared_error: 69949.4176\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 60832.77759\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 17891.7252 - mean_squared_error: 17884.0508 - val_loss: 68776.9388 - val_mean_squared_error: 68768.0044\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 60832.77759\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 17920.7645 - mean_squared_error: 17912.6740 - val_loss: 61761.7684 - val_mean_squared_error: 61752.4841\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 60832.77759\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 16759.9931 - mean_squared_error: 16752.3796 - val_loss: 73031.2215 - val_mean_squared_error: 73021.7134\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 60832.77759\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 18560.7632 - mean_squared_error: 18553.0340 - val_loss: 71649.7994 - val_mean_squared_error: 71640.3949\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 60832.77759\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 16271.6164 - mean_squared_error: 16263.5838 - val_loss: 73311.3745 - val_mean_squared_error: 73301.2487\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 60832.77759\n",
      "Epoch 398/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 15160.6631 - mean_squared_error: 15152.2566 - val_loss: 66270.4377 - val_mean_squared_error: 66260.7640\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 60832.77759\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 25566.1712 - mean_squared_error: 25558.7275 - val_loss: 72490.9034 - val_mean_squared_error: 72481.6869\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 60832.77759\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 14032.3634 - mean_squared_error: 14024.4546 - val_loss: 67688.1758 - val_mean_squared_error: 67678.5730\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 60832.77759\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 16608.7579 - mean_squared_error: 16600.8271 - val_loss: 76170.8899 - val_mean_squared_error: 76161.7892\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 60832.77759\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 15104.2701 - mean_squared_error: 15096.5324 - val_loss: 64179.7746 - val_mean_squared_error: 64170.4828\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 60832.77759\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 22809.6160 - mean_squared_error: 22801.5973 - val_loss: 71257.3393 - val_mean_squared_error: 71248.2447\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 60832.77759\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 14044.5075 - mean_squared_error: 14036.6256 - val_loss: 69642.6089 - val_mean_squared_error: 69633.5209\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 60832.77759\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 16470.6035 - mean_squared_error: 16462.8182 - val_loss: 65528.5879 - val_mean_squared_error: 65518.8217\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 60832.77759\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 17257.4650 - mean_squared_error: 17249.3865 - val_loss: 77827.0911 - val_mean_squared_error: 77817.9587\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 60832.77759\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 30777.8957 - mean_squared_error: 30770.3421 - val_loss: 71354.4453 - val_mean_squared_error: 71344.5408\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 60832.77759\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 18865.3898 - mean_squared_error: 18857.6156 - val_loss: 73493.4532 - val_mean_squared_error: 73482.6842\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 60832.77759\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 302us/step - loss: 17630.0676 - mean_squared_error: 17621.6225 - val_loss: 73142.7802 - val_mean_squared_error: 73133.2245\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 60832.77759\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 15222.5259 - mean_squared_error: 15214.2540 - val_loss: 66292.8160 - val_mean_squared_error: 66283.5132\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 60832.77759\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 16458.2838 - mean_squared_error: 16450.2688 - val_loss: 73538.0499 - val_mean_squared_error: 73528.8073\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 60832.77759\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 19161.7894 - mean_squared_error: 19153.9475 - val_loss: 80024.5188 - val_mean_squared_error: 80015.2184\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 60832.77759\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 11503.3984 - mean_squared_error: 11495.2762 - val_loss: 70629.4028 - val_mean_squared_error: 70620.7622\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 60832.77759\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 17535.1077 - mean_squared_error: 17527.1636 - val_loss: 66850.0181 - val_mean_squared_error: 66840.5866\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 60832.77759\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 12315.1255 - mean_squared_error: 12307.1766 - val_loss: 79926.2559 - val_mean_squared_error: 79916.2110\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 60832.77759\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 19736.3203 - mean_squared_error: 19728.0882 - val_loss: 74387.1951 - val_mean_squared_error: 74377.7131\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 60832.77759\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 16009.7913 - mean_squared_error: 16001.6581 - val_loss: 75906.1654 - val_mean_squared_error: 75897.9922\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 60832.77759\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 19792.1675 - mean_squared_error: 19784.3528 - val_loss: 71559.2326 - val_mean_squared_error: 71549.8691\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 60832.77759\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 16335.9479 - mean_squared_error: 16327.4929 - val_loss: 77613.7426 - val_mean_squared_error: 77604.3827\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 60832.77759\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 14849.1244 - mean_squared_error: 14840.9452 - val_loss: 72148.4553 - val_mean_squared_error: 72138.9327\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 60832.77759\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 20675.2257 - mean_squared_error: 20667.3186 - val_loss: 78605.2213 - val_mean_squared_error: 78595.9579\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 60832.77759\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 22239.0167 - mean_squared_error: 22231.2409 - val_loss: 84357.3397 - val_mean_squared_error: 84347.7872\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 60832.77759\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 12641.6645 - mean_squared_error: 12633.1456 - val_loss: 67263.2106 - val_mean_squared_error: 67253.6343\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 60832.77759\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 14391.4133 - mean_squared_error: 14383.3887 - val_loss: 66683.3181 - val_mean_squared_error: 66674.4003\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 60832.77759\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 18930.5333 - mean_squared_error: 18922.8437 - val_loss: 75199.2984 - val_mean_squared_error: 75189.7041\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 60832.77759\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 13995.6240 - mean_squared_error: 13987.5807 - val_loss: 69040.3479 - val_mean_squared_error: 69031.1367\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 60832.77759\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 13718.4271 - mean_squared_error: 13710.7355 - val_loss: 76833.4897 - val_mean_squared_error: 76824.7071\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 60832.77759\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 15020.7571 - mean_squared_error: 15012.6343 - val_loss: 77042.8694 - val_mean_squared_error: 77034.0513\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 60832.77759\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 286us/step - loss: 12495.3797 - mean_squared_error: 12487.3926 - val_loss: 68416.3501 - val_mean_squared_error: 68406.5152\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 60832.77759\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 292us/step - loss: 20498.7933 - mean_squared_error: 20490.7459 - val_loss: 69063.8540 - val_mean_squared_error: 69054.1931\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 60832.77759\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 310us/step - loss: 14458.3042 - mean_squared_error: 14450.0300 - val_loss: 65854.0042 - val_mean_squared_error: 65844.8379\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 60832.77759\n",
      "Epoch 432/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 17315.1675 - mean_squared_error: 17307.2072 - val_loss: 67746.6282 - val_mean_squared_error: 67737.9365\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 60832.77759\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 302us/step - loss: 13377.1730 - mean_squared_error: 13369.2539 - val_loss: 60914.0752 - val_mean_squared_error: 60904.3913\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 60832.77759\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 23770.5962 - mean_squared_error: 23762.2651 - val_loss: 72737.0016 - val_mean_squared_error: 72726.6957\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 60832.77759\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 10646.2574 - mean_squared_error: 10637.8400 - val_loss: 66381.4475 - val_mean_squared_error: 66371.3125\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 60832.77759\n",
      "Epoch 436/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 272us/step - loss: 14692.5113 - mean_squared_error: 14684.3396 - val_loss: 73348.6937 - val_mean_squared_error: 73338.2887\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 60832.77759\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 24191.3512 - mean_squared_error: 24183.3392 - val_loss: 66035.4420 - val_mean_squared_error: 66024.9100\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 60832.77759\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 26677.4057 - mean_squared_error: 26668.9881 - val_loss: 75197.6646 - val_mean_squared_error: 75187.4552\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 60832.77759\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 14254.8026 - mean_squared_error: 14246.3203 - val_loss: 73316.2889 - val_mean_squared_error: 73306.8845\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 60832.77759\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 12341.9412 - mean_squared_error: 12333.7252 - val_loss: 72645.4492 - val_mean_squared_error: 72635.7164\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 60832.77759\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 12748.4545 - mean_squared_error: 12740.2579 - val_loss: 67253.5789 - val_mean_squared_error: 67244.0172\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 60832.77759\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 15750.9362 - mean_squared_error: 15742.5790 - val_loss: 64793.7587 - val_mean_squared_error: 64783.5311\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 60832.77759\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 14148.0033 - mean_squared_error: 14139.6267 - val_loss: 73228.9660 - val_mean_squared_error: 73218.2606\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 60832.77759\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 13313.8048 - mean_squared_error: 13305.1541 - val_loss: 75821.5612 - val_mean_squared_error: 75811.5944\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 60832.77759\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 18708.9150 - mean_squared_error: 18700.9378 - val_loss: 72557.9023 - val_mean_squared_error: 72548.3651\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 60832.77759\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 11631.5342 - mean_squared_error: 11623.3900 - val_loss: 62532.1273 - val_mean_squared_error: 62522.1019\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 60832.77759\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 19693.4368 - mean_squared_error: 19685.1361 - val_loss: 61279.2714 - val_mean_squared_error: 61269.0289\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 60832.77759\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 25736.3897 - mean_squared_error: 25727.9388 - val_loss: 61322.5193 - val_mean_squared_error: 61311.5916\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 60832.77759\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 10793.5074 - mean_squared_error: 10784.5436 - val_loss: 70514.8267 - val_mean_squared_error: 70504.6102\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 60832.77759\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 13720.5644 - mean_squared_error: 13712.1215 - val_loss: 64775.6699 - val_mean_squared_error: 64765.5499\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 60832.77759\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 13234.8105 - mean_squared_error: 13226.3161 - val_loss: 68118.1855 - val_mean_squared_error: 68108.0418\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 60832.77759\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 15931.5861 - mean_squared_error: 15922.8820 - val_loss: 76869.7291 - val_mean_squared_error: 76860.5660\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 60832.77759\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 14479.9972 - mean_squared_error: 14471.6091 - val_loss: 71708.7257 - val_mean_squared_error: 71699.4600\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 60832.77759\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 9735.5046 - mean_squared_error: 9727.4600 - val_loss: 75778.5909 - val_mean_squared_error: 75769.6685\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 60832.77759\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 13632.0289 - mean_squared_error: 13623.7719 - val_loss: 71111.8321 - val_mean_squared_error: 71102.6540\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 60832.77759\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 13325.2446 - mean_squared_error: 13316.9297 - val_loss: 73570.3525 - val_mean_squared_error: 73561.5239\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 60832.77759\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 17575.0242 - mean_squared_error: 17566.9361 - val_loss: 82114.3412 - val_mean_squared_error: 82105.4474\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 60832.77759\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 14440.3984 - mean_squared_error: 14432.3006 - val_loss: 73492.1112 - val_mean_squared_error: 73481.1766\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 60832.77759\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 14900.1104 - mean_squared_error: 14891.1920 - val_loss: 69167.6954 - val_mean_squared_error: 69157.5931\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 60832.77759\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 15317.5330 - mean_squared_error: 15309.1645 - val_loss: 74505.5688 - val_mean_squared_error: 74496.6104\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 60832.77759\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 14560.1778 - mean_squared_error: 14552.0301 - val_loss: 73214.4966 - val_mean_squared_error: 73205.0437\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 60832.77759\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 18669.7496 - mean_squared_error: 18661.3987 - val_loss: 74744.8969 - val_mean_squared_error: 74735.5769\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 60832.77759\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 14421.7115 - mean_squared_error: 14413.3139 - val_loss: 68482.7461 - val_mean_squared_error: 68472.8656\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 60832.77759\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 19710.4778 - mean_squared_error: 19702.2348 - val_loss: 68930.8115 - val_mean_squared_error: 68921.3282\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 60832.77759\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 11492.6595 - mean_squared_error: 11484.3829 - val_loss: 71780.6365 - val_mean_squared_error: 71770.5787\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 60832.77759\n",
      "Epoch 466/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 13848.5728 - mean_squared_error: 13840.2643 - val_loss: 70982.4438 - val_mean_squared_error: 70972.8885\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 60832.77759\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 10813.6802 - mean_squared_error: 10805.6730 - val_loss: 72045.8035 - val_mean_squared_error: 72036.3997\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 60832.77759\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 17603.2287 - mean_squared_error: 17595.3080 - val_loss: 71252.5383 - val_mean_squared_error: 71242.7541\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 60832.77759\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 13617.4685 - mean_squared_error: 13609.0908 - val_loss: 70288.6079 - val_mean_squared_error: 70278.9176\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 60832.77759\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 11491.5780 - mean_squared_error: 11483.2513 - val_loss: 66090.4276 - val_mean_squared_error: 66080.6495\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 60832.77759\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 15185.2784 - mean_squared_error: 15177.4025 - val_loss: 71805.7890 - val_mean_squared_error: 71796.4566\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 60832.77759\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 11540.3377 - mean_squared_error: 11532.0931 - val_loss: 64918.5208 - val_mean_squared_error: 64909.0765\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 60832.77759\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 18034.8873 - mean_squared_error: 18026.8995 - val_loss: 68287.2487 - val_mean_squared_error: 68277.3959\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 60832.77759\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 20038.0436 - mean_squared_error: 20030.2795 - val_loss: 71412.7240 - val_mean_squared_error: 71403.8646\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 60832.77759\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 14828.0005 - mean_squared_error: 14820.2268 - val_loss: 74376.6631 - val_mean_squared_error: 74368.6144\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 60832.77759\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 12127.9462 - mean_squared_error: 12120.1890 - val_loss: 67674.4761 - val_mean_squared_error: 67665.3416\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 60832.77759\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 12993.8095 - mean_squared_error: 12985.6440 - val_loss: 66888.5587 - val_mean_squared_error: 66878.7266\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 60832.77759\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 15542.3276 - mean_squared_error: 15534.1063 - val_loss: 65869.2242 - val_mean_squared_error: 65859.5946\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 60832.77759\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 11988.7279 - mean_squared_error: 11980.3851 - val_loss: 64800.3883 - val_mean_squared_error: 64790.5587\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 60832.77759\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 12254.3494 - mean_squared_error: 12246.3153 - val_loss: 69070.4095 - val_mean_squared_error: 69060.7161\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 60832.77759\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 19328.9865 - mean_squared_error: 19320.6684 - val_loss: 63929.9175 - val_mean_squared_error: 63920.6334\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 60832.77759\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16044.7807 - mean_squared_error: 16036.7214 - val_loss: 71182.9276 - val_mean_squared_error: 71173.1789\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 60832.77759\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 12536.4775 - mean_squared_error: 12527.8796 - val_loss: 67268.5693 - val_mean_squared_error: 67258.5261\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 60832.77759\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 12849.0621 - mean_squared_error: 12840.6308 - val_loss: 61635.5029 - val_mean_squared_error: 61625.5519\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 60832.77759\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 11064.9106 - mean_squared_error: 11056.1030 - val_loss: 69135.7487 - val_mean_squared_error: 69125.3784\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 60832.77759\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 17611.8675 - mean_squared_error: 17603.3284 - val_loss: 69049.6291 - val_mean_squared_error: 69039.3303\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 60832.77759\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 13660.4362 - mean_squared_error: 13652.0800 - val_loss: 84028.6666 - val_mean_squared_error: 84019.4489\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 60832.77759\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16178.9661 - mean_squared_error: 16170.8015 - val_loss: 69209.8763 - val_mean_squared_error: 69201.0065\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 60832.77759\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 19953.5706 - mean_squared_error: 19945.6328 - val_loss: 65905.0791 - val_mean_squared_error: 65895.1707\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 60832.77759\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 15027.5322 - mean_squared_error: 15019.2359 - val_loss: 65230.5142 - val_mean_squared_error: 65221.4818\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 60832.77759\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 9945.4803 - mean_squared_error: 9937.4296 - val_loss: 64557.9950 - val_mean_squared_error: 64548.8862\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 60832.77759\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 14994.4403 - mean_squared_error: 14986.5006 - val_loss: 65187.5202 - val_mean_squared_error: 65177.7184\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 60832.77759\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 12162.7539 - mean_squared_error: 12154.4241 - val_loss: 78570.3609 - val_mean_squared_error: 78561.7620\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 60832.77759\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 16215.2034 - mean_squared_error: 16207.2717 - val_loss: 62057.4325 - val_mean_squared_error: 62048.7545\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 60832.77759\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 16950.1785 - mean_squared_error: 16942.5373 - val_loss: 65908.1952 - val_mean_squared_error: 65898.9984\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 60832.77759\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 14912.2852 - mean_squared_error: 14904.5671 - val_loss: 66601.2577 - val_mean_squared_error: 66591.8597\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 60832.77759\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 14844.1263 - mean_squared_error: 14835.7252 - val_loss: 67127.2397 - val_mean_squared_error: 67117.9143\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 60832.77759\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 15845.3735 - mean_squared_error: 15837.0856 - val_loss: 77603.6965 - val_mean_squared_error: 77594.1447\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 60832.77759\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 16545.5944 - mean_squared_error: 16537.2184 - val_loss: 70957.1221 - val_mean_squared_error: 70947.1586\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 60832.77759\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 20492.1856 - mean_squared_error: 20483.7590 - val_loss: 77469.4044 - val_mean_squared_error: 77460.8440\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 60832.77759\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 12682.3336 - mean_squared_error: 12674.1105 - val_loss: 66298.8674 - val_mean_squared_error: 66289.8653\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 60832.77759\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 14563.7839 - mean_squared_error: 14555.5870 - val_loss: 59346.9376 - val_mean_squared_error: 59337.0210\n",
      "\n",
      "Epoch 00502: val_loss improved from 60832.77759 to 59346.93757, saving model to test.hdf5\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 12688.5787 - mean_squared_error: 12680.1216 - val_loss: 67120.1702 - val_mean_squared_error: 67110.2486\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 59346.93757\n",
      "Epoch 504/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 230us/step - loss: 13914.2754 - mean_squared_error: 13905.7106 - val_loss: 67574.7479 - val_mean_squared_error: 67564.8543\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 59346.93757\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 15231.1964 - mean_squared_error: 15222.9103 - val_loss: 71355.1078 - val_mean_squared_error: 71345.8117\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 59346.93757\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 18818.2654 - mean_squared_error: 18809.6490 - val_loss: 70823.5521 - val_mean_squared_error: 70812.8404\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 59346.93757\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 13765.9580 - mean_squared_error: 13757.4374 - val_loss: 66067.3942 - val_mean_squared_error: 66056.7926\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 59346.93757\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 10724.4979 - mean_squared_error: 10715.8614 - val_loss: 60942.5825 - val_mean_squared_error: 60932.4541\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 59346.93757\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 11689.4909 - mean_squared_error: 11681.2877 - val_loss: 73704.4587 - val_mean_squared_error: 73695.5570\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 59346.93757\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 9868.0794 - mean_squared_error: 9859.5541 - val_loss: 62300.4418 - val_mean_squared_error: 62289.7381\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 59346.93757\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 13752.8297 - mean_squared_error: 13744.1419 - val_loss: 67719.9519 - val_mean_squared_error: 67709.3666\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 59346.93757\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 13951.9044 - mean_squared_error: 13942.7975 - val_loss: 71203.3054 - val_mean_squared_error: 71193.0514\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 59346.93757\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 21554.7970 - mean_squared_error: 21546.4762 - val_loss: 75148.8567 - val_mean_squared_error: 75139.1838\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 59346.93757\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 14614.7572 - mean_squared_error: 14606.1727 - val_loss: 59731.9987 - val_mean_squared_error: 59721.2958\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 59346.93757\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 22460.9292 - mean_squared_error: 22452.0384 - val_loss: 62167.9903 - val_mean_squared_error: 62157.2354\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 59346.93757\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 20205.7162 - mean_squared_error: 20196.9502 - val_loss: 66641.1935 - val_mean_squared_error: 66631.1783\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 59346.93757\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 14625.5211 - mean_squared_error: 14617.0443 - val_loss: 68582.3872 - val_mean_squared_error: 68571.6768\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 59346.93757\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 16969.0551 - mean_squared_error: 16960.1825 - val_loss: 68590.7327 - val_mean_squared_error: 68579.7155\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 59346.93757\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 17004.7526 - mean_squared_error: 16995.7737 - val_loss: 74094.0343 - val_mean_squared_error: 74083.1752\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 59346.93757\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 13250.2767 - mean_squared_error: 13241.5447 - val_loss: 66343.2041 - val_mean_squared_error: 66332.5127\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 59346.93757\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 14976.8232 - mean_squared_error: 14968.0340 - val_loss: 71223.7183 - val_mean_squared_error: 71213.9331\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 59346.93757\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 16117.8807 - mean_squared_error: 16109.4929 - val_loss: 69833.3633 - val_mean_squared_error: 69823.7013\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 59346.93757\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 10217.0998 - mean_squared_error: 10208.8657 - val_loss: 68525.1529 - val_mean_squared_error: 68515.2821\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 59346.93757\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 11785.5937 - mean_squared_error: 11777.1229 - val_loss: 69820.4264 - val_mean_squared_error: 69810.8698\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 59346.93757\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 16220.1396 - mean_squared_error: 16211.8751 - val_loss: 67645.7351 - val_mean_squared_error: 67636.3014\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 59346.93757\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 19891.4387 - mean_squared_error: 19883.2492 - val_loss: 72609.5037 - val_mean_squared_error: 72599.9212\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 59346.93757\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 15770.4984 - mean_squared_error: 15761.7807 - val_loss: 68518.5684 - val_mean_squared_error: 68507.8975\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 59346.93757\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 14158.8269 - mean_squared_error: 14149.8271 - val_loss: 83785.8511 - val_mean_squared_error: 83775.2088\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 59346.93757\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 12724.4202 - mean_squared_error: 12715.3158 - val_loss: 75972.0563 - val_mean_squared_error: 75959.6994\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 59346.93757\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 19341.8531 - mean_squared_error: 19332.7923 - val_loss: 73690.0536 - val_mean_squared_error: 73679.7174\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 59346.93757\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 10074.6812 - mean_squared_error: 10065.9288 - val_loss: 66925.6230 - val_mean_squared_error: 66914.6413\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 59346.93757\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 11798.0083 - mean_squared_error: 11788.8780 - val_loss: 66505.7864 - val_mean_squared_error: 66495.1572\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 59346.93757\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 13211.2039 - mean_squared_error: 13202.1154 - val_loss: 63732.7922 - val_mean_squared_error: 63722.0248\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 59346.93757\n",
      "Epoch 534/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 22531.2151 - mean_squared_error: 22522.1679 - val_loss: 69549.6588 - val_mean_squared_error: 69538.0229\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 59346.93757\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 17751.1627 - mean_squared_error: 17742.2461 - val_loss: 72221.9596 - val_mean_squared_error: 72209.6870\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 59346.93757\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 22491.4609 - mean_squared_error: 22482.2227 - val_loss: 73232.4721 - val_mean_squared_error: 73220.7777\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 59346.93757\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 9511.8848 - mean_squared_error: 9502.6814 - val_loss: 70555.6665 - val_mean_squared_error: 70544.5597\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 59346.93757\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 18718.7893 - mean_squared_error: 18710.1723 - val_loss: 73241.3921 - val_mean_squared_error: 73230.3118\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 59346.93757\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 16058.5496 - mean_squared_error: 16050.1792 - val_loss: 68034.2227 - val_mean_squared_error: 68024.4097\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 59346.93757\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 13844.9451 - mean_squared_error: 13836.2233 - val_loss: 67400.9541 - val_mean_squared_error: 67391.0686\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 59346.93757\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 15364.2079 - mean_squared_error: 15355.7713 - val_loss: 71468.2460 - val_mean_squared_error: 71459.1348\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 59346.93757\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 13032.7840 - mean_squared_error: 13024.4270 - val_loss: 65647.1430 - val_mean_squared_error: 65636.7697\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 59346.93757\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 14837.9279 - mean_squared_error: 14829.3871 - val_loss: 66803.4037 - val_mean_squared_error: 66793.9393\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 59346.93757\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 12769.0637 - mean_squared_error: 12760.4607 - val_loss: 70715.8592 - val_mean_squared_error: 70705.7795\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 59346.93757\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 15636.6866 - mean_squared_error: 15627.9989 - val_loss: 68631.3860 - val_mean_squared_error: 68621.6946\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 59346.93757\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 14453.1610 - mean_squared_error: 14444.7360 - val_loss: 80291.2954 - val_mean_squared_error: 80282.1438\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 59346.93757\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 19478.2057 - mean_squared_error: 19469.6559 - val_loss: 65841.8651 - val_mean_squared_error: 65831.6446\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 59346.93757\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 17155.4931 - mean_squared_error: 17146.9751 - val_loss: 60547.0837 - val_mean_squared_error: 60537.1000\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 59346.93757\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 11516.1009 - mean_squared_error: 11507.3136 - val_loss: 63062.7803 - val_mean_squared_error: 63052.7476\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 59346.93757\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 21102.9847 - mean_squared_error: 21094.2919 - val_loss: 75045.2621 - val_mean_squared_error: 75034.6883\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 59346.93757\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2563df0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2563d9860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 6, заменили relu на leaky relu, увеличили вес регуляризаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/550\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 304243.0286 - mean_squared_error: 303938.0913 - val_loss: 618311.4102 - val_mean_squared_error: 618120.7556\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 618311.41016, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_mse` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/550\n",
      "250/250 [==============================] - 0s 204us/step - loss: 297477.1981 - mean_squared_error: 297023.7381 - val_loss: 602628.0686 - val_mean_squared_error: 602235.9375\n",
      "\n",
      "Epoch 00002: val_loss improved from 618311.41016 to 602628.06864, saving model to test.hdf5\n",
      "Epoch 3/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 292609.8230 - mean_squared_error: 291958.8232 - val_loss: 590501.4062 - val_mean_squared_error: 589934.1122\n",
      "\n",
      "Epoch 00003: val_loss improved from 602628.06864 to 590501.40625, saving model to test.hdf5\n",
      "Epoch 4/550\n",
      "250/250 [==============================] - 0s 192us/step - loss: 287559.1014 - mean_squared_error: 286745.7081 - val_loss: 581016.4983 - val_mean_squared_error: 580290.4235\n",
      "\n",
      "Epoch 00004: val_loss improved from 590501.40625 to 581016.49833, saving model to test.hdf5\n",
      "Epoch 5/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 282682.0800 - mean_squared_error: 281760.7388 - val_loss: 571484.6953 - val_mean_squared_error: 570652.3114\n",
      "\n",
      "Epoch 00005: val_loss improved from 581016.49833 to 571484.69531, saving model to test.hdf5\n",
      "Epoch 6/550\n",
      "250/250 [==============================] - 0s 203us/step - loss: 278305.8194 - mean_squared_error: 277346.2791 - val_loss: 560117.4358 - val_mean_squared_error: 559156.9537\n",
      "\n",
      "Epoch 00006: val_loss improved from 571484.69531 to 560117.43583, saving model to test.hdf5\n",
      "Epoch 7/550\n",
      "250/250 [==============================] - 0s 214us/step - loss: 273440.7636 - mean_squared_error: 272413.9147 - val_loss: 548041.9665 - val_mean_squared_error: 546986.8834\n",
      "\n",
      "Epoch 00007: val_loss improved from 560117.43583 to 548041.96652, saving model to test.hdf5\n",
      "Epoch 8/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 269200.2327 - mean_squared_error: 268148.3816 - val_loss: 539170.7500 - val_mean_squared_error: 538127.1300\n",
      "\n",
      "Epoch 00008: val_loss improved from 548041.96652 to 539170.75000, saving model to test.hdf5\n",
      "Epoch 9/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 262290.1731 - mean_squared_error: 261238.6114 - val_loss: 528112.3728 - val_mean_squared_error: 526951.8376\n",
      "\n",
      "Epoch 00009: val_loss improved from 539170.75000 to 528112.37277, saving model to test.hdf5\n",
      "Epoch 10/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 255439.6772 - mean_squared_error: 254331.6839 - val_loss: 521085.7037 - val_mean_squared_error: 519987.4671\n",
      "\n",
      "Epoch 00010: val_loss improved from 528112.37277 to 521085.70368, saving model to test.hdf5\n",
      "Epoch 11/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 251036.9477 - mean_squared_error: 249927.7816 - val_loss: 511045.9191 - val_mean_squared_error: 509898.5926\n",
      "\n",
      "Epoch 00011: val_loss improved from 521085.70368 to 511045.91908, saving model to test.hdf5\n",
      "Epoch 12/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 244497.5206 - mean_squared_error: 243428.3214 - val_loss: 497339.5312 - val_mean_squared_error: 496127.7673\n",
      "\n",
      "Epoch 00012: val_loss improved from 511045.91908 to 497339.53125, saving model to test.hdf5\n",
      "Epoch 13/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 238087.3931 - mean_squared_error: 236981.0359 - val_loss: 482802.1166 - val_mean_squared_error: 481540.2171\n",
      "\n",
      "Epoch 00013: val_loss improved from 497339.53125 to 482802.11663, saving model to test.hdf5\n",
      "Epoch 14/550\n",
      "250/250 [==============================] - 0s 210us/step - loss: 230583.8373 - mean_squared_error: 229433.6573 - val_loss: 473700.1602 - val_mean_squared_error: 472487.7483\n",
      "\n",
      "Epoch 00014: val_loss improved from 482802.11663 to 473700.16016, saving model to test.hdf5\n",
      "Epoch 15/550\n",
      "250/250 [==============================] - 0s 200us/step - loss: 225371.9877 - mean_squared_error: 224298.7023 - val_loss: 460310.6412 - val_mean_squared_error: 459103.5318\n",
      "\n",
      "Epoch 00015: val_loss improved from 473700.16016 to 460310.64118, saving model to test.hdf5\n",
      "Epoch 16/550\n",
      "250/250 [==============================] - 0s 209us/step - loss: 218474.5297 - mean_squared_error: 217353.0645 - val_loss: 444677.9475 - val_mean_squared_error: 443338.3164\n",
      "\n",
      "Epoch 00016: val_loss improved from 460310.64118 to 444677.94754, saving model to test.hdf5\n",
      "Epoch 17/550\n",
      "250/250 [==============================] - 0s 208us/step - loss: 213425.2309 - mean_squared_error: 212272.3731 - val_loss: 434168.4342 - val_mean_squared_error: 432835.3410\n",
      "\n",
      "Epoch 00017: val_loss improved from 444677.94754 to 434168.43415, saving model to test.hdf5\n",
      "Epoch 18/550\n",
      "250/250 [==============================] - 0s 194us/step - loss: 205073.1861 - mean_squared_error: 203937.4136 - val_loss: 424240.4046 - val_mean_squared_error: 423011.4403\n",
      "\n",
      "Epoch 00018: val_loss improved from 434168.43415 to 424240.40458, saving model to test.hdf5\n",
      "Epoch 19/550\n",
      "250/250 [==============================] - 0s 216us/step - loss: 198259.5639 - mean_squared_error: 197206.4181 - val_loss: 413046.9459 - val_mean_squared_error: 411785.9833\n",
      "\n",
      "Epoch 00019: val_loss improved from 424240.40458 to 413046.94587, saving model to test.hdf5\n",
      "Epoch 20/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 193229.6670 - mean_squared_error: 192122.3702 - val_loss: 395955.2467 - val_mean_squared_error: 394659.4888\n",
      "\n",
      "Epoch 00020: val_loss improved from 413046.94587 to 395955.24665, saving model to test.hdf5\n",
      "Epoch 21/550\n",
      "250/250 [==============================] - 0s 205us/step - loss: 184129.2588 - mean_squared_error: 183024.4983 - val_loss: 384269.8521 - val_mean_squared_error: 382996.7807\n",
      "\n",
      "Epoch 00021: val_loss improved from 395955.24665 to 384269.85212, saving model to test.hdf5\n",
      "Epoch 22/550\n",
      "250/250 [==============================] - 0s 199us/step - loss: 180344.0239 - mean_squared_error: 179254.9188 - val_loss: 375440.9107 - val_mean_squared_error: 374152.5078\n",
      "\n",
      "Epoch 00022: val_loss improved from 384269.85212 to 375440.91071, saving model to test.hdf5\n",
      "Epoch 23/550\n",
      "250/250 [==============================] - 0s 205us/step - loss: 169541.9247 - mean_squared_error: 168446.1218 - val_loss: 374353.9051 - val_mean_squared_error: 373253.4866\n",
      "\n",
      "Epoch 00023: val_loss improved from 375440.91071 to 374353.90513, saving model to test.hdf5\n",
      "Epoch 24/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 167398.3653 - mean_squared_error: 166440.8509 - val_loss: 361735.6702 - val_mean_squared_error: 360578.4838\n",
      "\n",
      "Epoch 00024: val_loss improved from 374353.90513 to 361735.67020, saving model to test.hdf5\n",
      "Epoch 25/550\n",
      "250/250 [==============================] - 0s 212us/step - loss: 154674.1491 - mean_squared_error: 153622.1899 - val_loss: 350947.1194 - val_mean_squared_error: 349841.1942\n",
      "\n",
      "Epoch 00025: val_loss improved from 361735.67020 to 350947.11942, saving model to test.hdf5\n",
      "Epoch 26/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 150373.2495 - mean_squared_error: 149335.3361 - val_loss: 336548.6060 - val_mean_squared_error: 335410.3382\n",
      "\n",
      "Epoch 00026: val_loss improved from 350947.11942 to 336548.60603, saving model to test.hdf5\n",
      "Epoch 27/550\n",
      "250/250 [==============================] - 0s 202us/step - loss: 145986.1698 - mean_squared_error: 144884.2178 - val_loss: 320904.7768 - val_mean_squared_error: 319773.4933\n",
      "\n",
      "Epoch 00027: val_loss improved from 336548.60603 to 320904.77679, saving model to test.hdf5\n",
      "Epoch 28/550\n",
      "250/250 [==============================] - 0s 198us/step - loss: 140358.1891 - mean_squared_error: 139285.8216 - val_loss: 309505.6144 - val_mean_squared_error: 308315.0497\n",
      "\n",
      "Epoch 00028: val_loss improved from 320904.77679 to 309505.61440, saving model to test.hdf5\n",
      "Epoch 29/550\n",
      "250/250 [==============================] - 0s 193us/step - loss: 132755.6388 - mean_squared_error: 131643.3556 - val_loss: 298795.3767 - val_mean_squared_error: 297638.2433\n",
      "\n",
      "Epoch 00029: val_loss improved from 309505.61440 to 298795.37667, saving model to test.hdf5\n",
      "Epoch 30/550\n",
      "250/250 [==============================] - 0s 196us/step - loss: 129383.9039 - mean_squared_error: 128327.5999 - val_loss: 293236.7567 - val_mean_squared_error: 292098.1434\n",
      "\n",
      "Epoch 00030: val_loss improved from 298795.37667 to 293236.75670, saving model to test.hdf5\n",
      "Epoch 31/550\n",
      "250/250 [==============================] - 0s 206us/step - loss: 124534.0568 - mean_squared_error: 123571.3938 - val_loss: 278725.6440 - val_mean_squared_error: 277539.8956\n",
      "\n",
      "Epoch 00031: val_loss improved from 293236.75670 to 278725.64397, saving model to test.hdf5\n",
      "Epoch 32/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 119225.8055 - mean_squared_error: 118155.1667 - val_loss: 266344.8312 - val_mean_squared_error: 265233.1691\n",
      "\n",
      "Epoch 00032: val_loss improved from 278725.64397 to 266344.83119, saving model to test.hdf5\n",
      "Epoch 33/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 113394.6771 - mean_squared_error: 112367.9423 - val_loss: 259894.1928 - val_mean_squared_error: 258801.4018\n",
      "\n",
      "Epoch 00033: val_loss improved from 266344.83119 to 259894.19280, saving model to test.hdf5\n",
      "Epoch 34/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 106929.0711 - mean_squared_error: 105945.6970 - val_loss: 258010.6847 - val_mean_squared_error: 256961.6412\n",
      "\n",
      "Epoch 00034: val_loss improved from 259894.19280 to 258010.68471, saving model to test.hdf5\n",
      "Epoch 35/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 102312.6801 - mean_squared_error: 101396.9352 - val_loss: 251995.0399 - val_mean_squared_error: 251032.1297\n",
      "\n",
      "Epoch 00035: val_loss improved from 258010.68471 to 251995.03990, saving model to test.hdf5\n",
      "Epoch 36/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 111002.0374 - mean_squared_error: 110082.5571 - val_loss: 238125.2528 - val_mean_squared_error: 237010.8100\n",
      "\n",
      "Epoch 00036: val_loss improved from 251995.03990 to 238125.25279, saving model to test.hdf5\n",
      "Epoch 37/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 87206.7754 - mean_squared_error: 86205.5375 - val_loss: 235888.7009 - val_mean_squared_error: 234869.9216\n",
      "\n",
      "Epoch 00037: val_loss improved from 238125.25279 to 235888.70089, saving model to test.hdf5\n",
      "Epoch 38/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 94441.0239 - mean_squared_error: 93474.7018 - val_loss: 221020.0259 - val_mean_squared_error: 220048.3446\n",
      "\n",
      "Epoch 00038: val_loss improved from 235888.70089 to 221020.02595, saving model to test.hdf5\n",
      "Epoch 39/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 91836.9265 - mean_squared_error: 90790.4308 - val_loss: 217138.6716 - val_mean_squared_error: 216088.8281\n",
      "\n",
      "Epoch 00039: val_loss improved from 221020.02595 to 217138.67160, saving model to test.hdf5\n",
      "Epoch 40/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 89810.8825 - mean_squared_error: 88841.7736 - val_loss: 201719.1261 - val_mean_squared_error: 200649.1621\n",
      "\n",
      "Epoch 00040: val_loss improved from 217138.67160 to 201719.12612, saving model to test.hdf5\n",
      "Epoch 41/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 90787.0401 - mean_squared_error: 89722.6559 - val_loss: 193465.6258 - val_mean_squared_error: 192355.1607\n",
      "\n",
      "Epoch 00041: val_loss improved from 201719.12612 to 193465.62584, saving model to test.hdf5\n",
      "Epoch 42/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 83211.1939 - mean_squared_error: 82181.1048 - val_loss: 190416.9662 - val_mean_squared_error: 189353.8387\n",
      "\n",
      "Epoch 00042: val_loss improved from 193465.62584 to 190416.96624, saving model to test.hdf5\n",
      "Epoch 43/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 85498.7535 - mean_squared_error: 84543.1533 - val_loss: 185835.7628 - val_mean_squared_error: 184782.8845\n",
      "\n",
      "Epoch 00043: val_loss improved from 190416.96624 to 185835.76283, saving model to test.hdf5\n",
      "Epoch 44/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 72845.0516 - mean_squared_error: 71867.6045 - val_loss: 178520.4160 - val_mean_squared_error: 177539.8859\n",
      "\n",
      "Epoch 00044: val_loss improved from 185835.76283 to 178520.41602, saving model to test.hdf5\n",
      "Epoch 45/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 68729.3786 - mean_squared_error: 67733.6662 - val_loss: 168857.9877 - val_mean_squared_error: 167829.0432\n",
      "\n",
      "Epoch 00045: val_loss improved from 178520.41602 to 168857.98772, saving model to test.hdf5\n",
      "Epoch 46/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 68140.6098 - mean_squared_error: 67136.7155 - val_loss: 164678.5795 - val_mean_squared_error: 163554.2079\n",
      "\n",
      "Epoch 00046: val_loss improved from 168857.98772 to 164678.57952, saving model to test.hdf5\n",
      "Epoch 47/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 63678.7341 - mean_squared_error: 62606.5260 - val_loss: 161753.6624 - val_mean_squared_error: 160606.4657\n",
      "\n",
      "Epoch 00047: val_loss improved from 164678.57952 to 161753.66239, saving model to test.hdf5\n",
      "Epoch 48/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 67475.0769 - mean_squared_error: 66400.6116 - val_loss: 156618.3435 - val_mean_squared_error: 155511.5391\n",
      "\n",
      "Epoch 00048: val_loss improved from 161753.66239 to 156618.34347, saving model to test.hdf5\n",
      "Epoch 49/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 65685.0828 - mean_squared_error: 64595.9308 - val_loss: 154291.7737 - val_mean_squared_error: 153188.1328\n",
      "\n",
      "Epoch 00049: val_loss improved from 156618.34347 to 154291.77372, saving model to test.hdf5\n",
      "Epoch 50/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 64072.2227 - mean_squared_error: 63011.4835 - val_loss: 151847.5932 - val_mean_squared_error: 150806.3691\n",
      "\n",
      "Epoch 00050: val_loss improved from 154291.77372 to 151847.59319, saving model to test.hdf5\n",
      "Epoch 51/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 65196.3029 - mean_squared_error: 64233.5060 - val_loss: 150259.4526 - val_mean_squared_error: 149213.2704\n",
      "\n",
      "Epoch 00051: val_loss improved from 151847.59319 to 150259.45257, saving model to test.hdf5\n",
      "Epoch 52/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 61588.3394 - mean_squared_error: 60590.3103 - val_loss: 146790.6150 - val_mean_squared_error: 145780.2536\n",
      "\n",
      "Epoch 00052: val_loss improved from 150259.45257 to 146790.61496, saving model to test.hdf5\n",
      "Epoch 53/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 56794.0478 - mean_squared_error: 55746.6455 - val_loss: 138869.6715 - val_mean_squared_error: 137879.3958\n",
      "\n",
      "Epoch 00053: val_loss improved from 146790.61496 to 138869.67146, saving model to test.hdf5\n",
      "Epoch 54/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 59751.2025 - mean_squared_error: 58697.9422 - val_loss: 141612.0516 - val_mean_squared_error: 140547.8705\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 138869.67146\n",
      "Epoch 55/550\n",
      "250/250 [==============================] - 0s 237us/step - loss: 60914.5277 - mean_squared_error: 59941.1831 - val_loss: 139988.1042 - val_mean_squared_error: 139030.1629\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 138869.67146\n",
      "Epoch 56/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 57712.0053 - mean_squared_error: 56745.2785 - val_loss: 133751.7374 - val_mean_squared_error: 132804.3891\n",
      "\n",
      "Epoch 00056: val_loss improved from 138869.67146 to 133751.73744, saving model to test.hdf5\n",
      "Epoch 57/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 50914.3771 - mean_squared_error: 49862.7469 - val_loss: 136364.0831 - val_mean_squared_error: 135439.0883\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 133751.73744\n",
      "Epoch 58/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 50558.5698 - mean_squared_error: 49588.8302 - val_loss: 134851.0318 - val_mean_squared_error: 133937.4669\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 133751.73744\n",
      "Epoch 59/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 60446.6353 - mean_squared_error: 59524.0953 - val_loss: 137809.8203 - val_mean_squared_error: 136913.0301\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 133751.73744\n",
      "Epoch 60/550\n",
      "250/250 [==============================] - 0s 253us/step - loss: 51765.1667 - mean_squared_error: 50852.7243 - val_loss: 137444.6564 - val_mean_squared_error: 136589.0837\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 133751.73744\n",
      "Epoch 61/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 230us/step - loss: 58138.1586 - mean_squared_error: 57255.9795 - val_loss: 138102.7455 - val_mean_squared_error: 137320.8493\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 133751.73744\n",
      "Epoch 62/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 49828.5521 - mean_squared_error: 48988.0795 - val_loss: 132396.0444 - val_mean_squared_error: 131587.5370\n",
      "\n",
      "Epoch 00062: val_loss improved from 133751.73744 to 132396.04436, saving model to test.hdf5\n",
      "Epoch 63/550\n",
      "250/250 [==============================] - 0s 237us/step - loss: 50104.3531 - mean_squared_error: 49234.9511 - val_loss: 125508.3185 - val_mean_squared_error: 124719.8039\n",
      "\n",
      "Epoch 00063: val_loss improved from 132396.04436 to 125508.31850, saving model to test.hdf5\n",
      "Epoch 64/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 52959.8014 - mean_squared_error: 52155.2970 - val_loss: 125165.0848 - val_mean_squared_error: 124400.7570\n",
      "\n",
      "Epoch 00064: val_loss improved from 125508.31850 to 125165.08482, saving model to test.hdf5\n",
      "Epoch 65/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 51088.7514 - mean_squared_error: 50272.6179 - val_loss: 116711.8855 - val_mean_squared_error: 115930.6862\n",
      "\n",
      "Epoch 00065: val_loss improved from 125165.08482 to 116711.88546, saving model to test.hdf5\n",
      "Epoch 66/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 51519.3141 - mean_squared_error: 50660.1839 - val_loss: 124852.5770 - val_mean_squared_error: 124104.0958\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 116711.88546\n",
      "Epoch 67/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 59370.4320 - mean_squared_error: 58578.8928 - val_loss: 119739.8348 - val_mean_squared_error: 118996.4295\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 116711.88546\n",
      "Epoch 68/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 50616.5004 - mean_squared_error: 49736.6758 - val_loss: 117716.0432 - val_mean_squared_error: 116899.1988\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 116711.88546\n",
      "Epoch 69/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 54455.2247 - mean_squared_error: 53593.9463 - val_loss: 117612.2946 - val_mean_squared_error: 116765.5437\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 116711.88546\n",
      "Epoch 70/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 47591.4024 - mean_squared_error: 46676.0973 - val_loss: 114084.3407 - val_mean_squared_error: 113203.3145\n",
      "\n",
      "Epoch 00070: val_loss improved from 116711.88546 to 114084.34068, saving model to test.hdf5\n",
      "Epoch 71/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 49072.5874 - mean_squared_error: 48196.0585 - val_loss: 112407.8587 - val_mean_squared_error: 111556.1829\n",
      "\n",
      "Epoch 00071: val_loss improved from 114084.34068 to 112407.85868, saving model to test.hdf5\n",
      "Epoch 72/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 48257.8851 - mean_squared_error: 47347.1408 - val_loss: 112456.5258 - val_mean_squared_error: 111679.9453\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 112407.85868\n",
      "Epoch 73/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 48310.6628 - mean_squared_error: 47392.7016 - val_loss: 113007.6733 - val_mean_squared_error: 112208.1754\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 112407.85868\n",
      "Epoch 74/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 48601.4197 - mean_squared_error: 47750.7746 - val_loss: 115131.5075 - val_mean_squared_error: 114362.7871\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 112407.85868\n",
      "Epoch 75/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 50688.3395 - mean_squared_error: 49817.8516 - val_loss: 115971.0093 - val_mean_squared_error: 115206.6229\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 112407.85868\n",
      "Epoch 76/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 51568.7787 - mean_squared_error: 50706.8883 - val_loss: 116404.5831 - val_mean_squared_error: 115618.4961\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 112407.85868\n",
      "Epoch 77/550\n",
      "250/250 [==============================] - 0s 237us/step - loss: 46041.3898 - mean_squared_error: 45164.0252 - val_loss: 114788.0550 - val_mean_squared_error: 114013.4778\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 112407.85868\n",
      "Epoch 78/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 49371.1458 - mean_squared_error: 48536.3466 - val_loss: 111519.3111 - val_mean_squared_error: 110786.8143\n",
      "\n",
      "Epoch 00078: val_loss improved from 112407.85868 to 111519.31110, saving model to test.hdf5\n",
      "Epoch 79/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 46177.4546 - mean_squared_error: 45370.2544 - val_loss: 111277.4873 - val_mean_squared_error: 110527.2598\n",
      "\n",
      "Epoch 00079: val_loss improved from 111519.31110 to 111277.48730, saving model to test.hdf5\n",
      "Epoch 80/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 52686.8241 - mean_squared_error: 51852.4388 - val_loss: 113640.8002 - val_mean_squared_error: 112903.0006\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 111277.48730\n",
      "Epoch 81/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 45065.9062 - mean_squared_error: 44253.0105 - val_loss: 113272.8478 - val_mean_squared_error: 112588.2420\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 111277.48730\n",
      "Epoch 82/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 39618.7720 - mean_squared_error: 38827.2474 - val_loss: 113241.9090 - val_mean_squared_error: 112523.8449\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 111277.48730\n",
      "Epoch 83/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 38040.2522 - mean_squared_error: 37225.2906 - val_loss: 110302.1099 - val_mean_squared_error: 109587.7167\n",
      "\n",
      "Epoch 00083: val_loss improved from 111277.48730 to 110302.10993, saving model to test.hdf5\n",
      "Epoch 84/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 40867.7266 - mean_squared_error: 40020.4620 - val_loss: 107347.0551 - val_mean_squared_error: 106586.2134\n",
      "\n",
      "Epoch 00084: val_loss improved from 110302.10993 to 107347.05511, saving model to test.hdf5\n",
      "Epoch 85/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 45734.2964 - mean_squared_error: 44915.1208 - val_loss: 106712.5949 - val_mean_squared_error: 105953.2097\n",
      "\n",
      "Epoch 00085: val_loss improved from 107347.05511 to 106712.59487, saving model to test.hdf5\n",
      "Epoch 86/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 47196.7197 - mean_squared_error: 46380.3290 - val_loss: 109966.0211 - val_mean_squared_error: 109179.6219\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 106712.59487\n",
      "Epoch 87/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 42917.9204 - mean_squared_error: 42070.4985 - val_loss: 110692.3165 - val_mean_squared_error: 109961.7140\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 106712.59487\n",
      "Epoch 88/550\n",
      "250/250 [==============================] - 0s 237us/step - loss: 43269.1749 - mean_squared_error: 42433.9969 - val_loss: 112274.0158 - val_mean_squared_error: 111547.7870\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 106712.59487\n",
      "Epoch 89/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 47842.5093 - mean_squared_error: 47090.3504 - val_loss: 112689.1392 - val_mean_squared_error: 111942.9820\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 106712.59487\n",
      "Epoch 90/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 54968.9553 - mean_squared_error: 54178.7345 - val_loss: 113226.4637 - val_mean_squared_error: 112499.0975\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 106712.59487\n",
      "Epoch 91/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 35245.6197 - mean_squared_error: 34424.2834 - val_loss: 110047.5204 - val_mean_squared_error: 109363.9711\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 106712.59487\n",
      "Epoch 92/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 47739.2478 - mean_squared_error: 46936.8068 - val_loss: 108843.7049 - val_mean_squared_error: 108154.9439\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 106712.59487\n",
      "Epoch 93/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 45393.1497 - mean_squared_error: 44652.2947 - val_loss: 109894.2826 - val_mean_squared_error: 109187.0017\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 106712.59487\n",
      "Epoch 94/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 39238.9482 - mean_squared_error: 38447.2569 - val_loss: 109281.5587 - val_mean_squared_error: 108562.2585\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 106712.59487\n",
      "Epoch 95/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 40566.8734 - mean_squared_error: 39784.8474 - val_loss: 106736.5379 - val_mean_squared_error: 106035.9647\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 106712.59487\n",
      "Epoch 96/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 48490.1846 - mean_squared_error: 47694.9188 - val_loss: 109446.9056 - val_mean_squared_error: 108706.2307\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 106712.59487\n",
      "Epoch 97/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 38850.2909 - mean_squared_error: 38034.2989 - val_loss: 108688.5354 - val_mean_squared_error: 107938.3977\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 106712.59487\n",
      "Epoch 98/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 39486.8357 - mean_squared_error: 38703.9904 - val_loss: 109201.4138 - val_mean_squared_error: 108483.1037\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 106712.59487\n",
      "Epoch 99/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 43868.6152 - mean_squared_error: 43084.2138 - val_loss: 109840.6592 - val_mean_squared_error: 109124.3796\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 106712.59487\n",
      "Epoch 100/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 46005.3695 - mean_squared_error: 45232.9070 - val_loss: 108247.2744 - val_mean_squared_error: 107542.0971\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 106712.59487\n",
      "Epoch 101/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 60194.9425 - mean_squared_error: 59407.5792 - val_loss: 111619.8454 - val_mean_squared_error: 110913.0850\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 106712.59487\n",
      "Epoch 102/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 47675.7095 - mean_squared_error: 46875.6556 - val_loss: 110600.9189 - val_mean_squared_error: 109880.7066\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 106712.59487\n",
      "Epoch 103/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 48678.9423 - mean_squared_error: 47890.6896 - val_loss: 107247.8410 - val_mean_squared_error: 106499.8757\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 106712.59487\n",
      "Epoch 104/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 43466.9337 - mean_squared_error: 42646.3543 - val_loss: 107566.4750 - val_mean_squared_error: 106852.8083\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 106712.59487\n",
      "Epoch 105/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 39972.0771 - mean_squared_error: 39208.7014 - val_loss: 107106.7956 - val_mean_squared_error: 106382.4212\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 106712.59487\n",
      "Epoch 106/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 38800.5978 - mean_squared_error: 37954.0306 - val_loss: 106252.1837 - val_mean_squared_error: 105500.4920\n",
      "\n",
      "Epoch 00106: val_loss improved from 106712.59487 to 106252.18373, saving model to test.hdf5\n",
      "Epoch 107/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 42549.8287 - mean_squared_error: 41722.0722 - val_loss: 106937.8789 - val_mean_squared_error: 106194.6924\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 106252.18373\n",
      "Epoch 108/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 46606.2984 - mean_squared_error: 45811.4275 - val_loss: 110966.5166 - val_mean_squared_error: 110239.7970\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 106252.18373\n",
      "Epoch 109/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 41315.7559 - mean_squared_error: 40523.5883 - val_loss: 111718.6974 - val_mean_squared_error: 111042.2326\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 106252.18373\n",
      "Epoch 110/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 46369.6498 - mean_squared_error: 45615.8248 - val_loss: 116147.7747 - val_mean_squared_error: 115500.1419\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 106252.18373\n",
      "Epoch 111/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 44080.5327 - mean_squared_error: 43335.0287 - val_loss: 113315.7249 - val_mean_squared_error: 112676.3424\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 106252.18373\n",
      "Epoch 112/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 43554.4890 - mean_squared_error: 42831.8378 - val_loss: 104696.4682 - val_mean_squared_error: 104004.2699\n",
      "\n",
      "Epoch 00112: val_loss improved from 106252.18373 to 104696.46819, saving model to test.hdf5\n",
      "Epoch 113/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 45750.9259 - mean_squared_error: 45002.5720 - val_loss: 102361.2254 - val_mean_squared_error: 101643.5498\n",
      "\n",
      "Epoch 00113: val_loss improved from 104696.46819 to 102361.22545, saving model to test.hdf5\n",
      "Epoch 114/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 39593.2651 - mean_squared_error: 38789.0484 - val_loss: 104912.4750 - val_mean_squared_error: 104210.4464\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 102361.22545\n",
      "Epoch 115/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45236.6179 - mean_squared_error: 44468.3826 - val_loss: 106483.8057 - val_mean_squared_error: 105770.8052\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 102361.22545\n",
      "Epoch 116/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 49488.8696 - mean_squared_error: 48739.0777 - val_loss: 110629.9994 - val_mean_squared_error: 109954.8259\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 102361.22545\n",
      "Epoch 117/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 42787.4864 - mean_squared_error: 42044.0552 - val_loss: 110910.6176 - val_mean_squared_error: 110269.2673\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 102361.22545\n",
      "Epoch 118/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 45069.2631 - mean_squared_error: 44351.8550 - val_loss: 110834.5172 - val_mean_squared_error: 110204.6069\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 102361.22545\n",
      "Epoch 119/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45517.5367 - mean_squared_error: 44794.1205 - val_loss: 109918.1236 - val_mean_squared_error: 109278.0681\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 102361.22545\n",
      "Epoch 120/550\n",
      "250/250 [==============================] - 0s 229us/step - loss: 41284.8706 - mean_squared_error: 40590.3590 - val_loss: 107019.7815 - val_mean_squared_error: 106391.6558\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 102361.22545\n",
      "Epoch 121/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 49184.0477 - mean_squared_error: 48475.1765 - val_loss: 103673.9519 - val_mean_squared_error: 103046.5063\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 102361.22545\n",
      "Epoch 122/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 42789.2322 - mean_squared_error: 42093.2050 - val_loss: 102622.4647 - val_mean_squared_error: 101953.3213\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 102361.22545\n",
      "Epoch 123/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 42582.0789 - mean_squared_error: 41820.9159 - val_loss: 104140.4395 - val_mean_squared_error: 103428.6477\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 102361.22545\n",
      "Epoch 124/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 49204.9946 - mean_squared_error: 48459.6761 - val_loss: 105839.6113 - val_mean_squared_error: 105140.4304\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 102361.22545\n",
      "Epoch 125/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 48387.6318 - mean_squared_error: 47652.4869 - val_loss: 108434.5579 - val_mean_squared_error: 107812.8997\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 102361.22545\n",
      "Epoch 126/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 49817.9321 - mean_squared_error: 49082.6163 - val_loss: 109345.2365 - val_mean_squared_error: 108691.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00126: val_loss did not improve from 102361.22545\n",
      "Epoch 127/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 39357.8285 - mean_squared_error: 38621.9564 - val_loss: 108485.8669 - val_mean_squared_error: 107862.5537\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 102361.22545\n",
      "Epoch 128/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 45691.1408 - mean_squared_error: 44979.4567 - val_loss: 107709.0446 - val_mean_squared_error: 107073.6221\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 102361.22545\n",
      "Epoch 129/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 39077.1315 - mean_squared_error: 38365.4741 - val_loss: 108430.8259 - val_mean_squared_error: 107773.3809\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 102361.22545\n",
      "Epoch 130/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 48490.3332 - mean_squared_error: 47757.8105 - val_loss: 109211.2190 - val_mean_squared_error: 108537.3020\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 102361.22545\n",
      "Epoch 131/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 40139.1672 - mean_squared_error: 39404.2229 - val_loss: 104749.8167 - val_mean_squared_error: 104092.6454\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 102361.22545\n",
      "Epoch 132/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 47017.8986 - mean_squared_error: 46306.3276 - val_loss: 105243.3495 - val_mean_squared_error: 104599.8203\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 102361.22545\n",
      "Epoch 133/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 40864.4547 - mean_squared_error: 40097.7695 - val_loss: 102352.8733 - val_mean_squared_error: 101658.3251\n",
      "\n",
      "Epoch 00133: val_loss improved from 102361.22545 to 102352.87333, saving model to test.hdf5\n",
      "Epoch 134/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 37556.0271 - mean_squared_error: 36793.7550 - val_loss: 104720.5730 - val_mean_squared_error: 104041.3966\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 102352.87333\n",
      "Epoch 135/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 47785.2797 - mean_squared_error: 47058.6796 - val_loss: 103522.9198 - val_mean_squared_error: 102863.7888\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 102352.87333\n",
      "Epoch 136/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 46361.7487 - mean_squared_error: 45581.2390 - val_loss: 102455.8366 - val_mean_squared_error: 101774.3284\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 102352.87333\n",
      "Epoch 137/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 37560.7996 - mean_squared_error: 36811.1042 - val_loss: 102071.7586 - val_mean_squared_error: 101392.7653\n",
      "\n",
      "Epoch 00137: val_loss improved from 102352.87333 to 102071.75865, saving model to test.hdf5\n",
      "Epoch 138/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 38163.0599 - mean_squared_error: 37432.3229 - val_loss: 100281.8280 - val_mean_squared_error: 99578.0554\n",
      "\n",
      "Epoch 00138: val_loss improved from 102071.75865 to 100281.82799, saving model to test.hdf5\n",
      "Epoch 139/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 40644.8555 - mean_squared_error: 39899.5235 - val_loss: 100512.2073 - val_mean_squared_error: 99809.7012\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 100281.82799\n",
      "Epoch 140/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 35439.2029 - mean_squared_error: 34699.3732 - val_loss: 101825.0047 - val_mean_squared_error: 101142.5017\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 100281.82799\n",
      "Epoch 141/550\n",
      "250/250 [==============================] - 0s 265us/step - loss: 39583.3908 - mean_squared_error: 38830.9724 - val_loss: 104177.3630 - val_mean_squared_error: 103477.0184\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 100281.82799\n",
      "Epoch 142/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 41251.7401 - mean_squared_error: 40504.9098 - val_loss: 105520.3037 - val_mean_squared_error: 104835.5287\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 100281.82799\n",
      "Epoch 143/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 38215.1727 - mean_squared_error: 37438.1918 - val_loss: 105139.0749 - val_mean_squared_error: 104425.7174\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 100281.82799\n",
      "Epoch 144/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 44778.1256 - mean_squared_error: 44010.1471 - val_loss: 105916.2852 - val_mean_squared_error: 105230.5096\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 100281.82799\n",
      "Epoch 145/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 45755.8954 - mean_squared_error: 44998.6997 - val_loss: 105876.3514 - val_mean_squared_error: 105203.0040\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 100281.82799\n",
      "Epoch 146/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 42518.0473 - mean_squared_error: 41779.6506 - val_loss: 106056.7291 - val_mean_squared_error: 105362.4641\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 100281.82799\n",
      "Epoch 147/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 40425.2140 - mean_squared_error: 39690.8827 - val_loss: 106411.3640 - val_mean_squared_error: 105696.2683\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 100281.82799\n",
      "Epoch 148/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 36109.1194 - mean_squared_error: 35377.1397 - val_loss: 106095.5412 - val_mean_squared_error: 105400.4099\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 100281.82799\n",
      "Epoch 149/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 38248.5048 - mean_squared_error: 37496.8751 - val_loss: 107914.1710 - val_mean_squared_error: 107218.0958\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 100281.82799\n",
      "Epoch 150/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 41995.0248 - mean_squared_error: 41272.0412 - val_loss: 108389.9397 - val_mean_squared_error: 107693.2902\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 100281.82799\n",
      "Epoch 151/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 37666.5144 - mean_squared_error: 36938.6089 - val_loss: 102616.3866 - val_mean_squared_error: 101960.6222\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 100281.82799\n",
      "Epoch 152/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 38507.4525 - mean_squared_error: 37786.8162 - val_loss: 104347.8207 - val_mean_squared_error: 103673.3771\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 100281.82799\n",
      "Epoch 153/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 37726.7938 - mean_squared_error: 37006.9323 - val_loss: 107348.6670 - val_mean_squared_error: 106698.4201\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 100281.82799\n",
      "Epoch 154/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 48051.7809 - mean_squared_error: 47363.0087 - val_loss: 108079.1154 - val_mean_squared_error: 107434.7659\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 100281.82799\n",
      "Epoch 155/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 49839.0560 - mean_squared_error: 49158.5338 - val_loss: 109735.8002 - val_mean_squared_error: 109096.0349\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 100281.82799\n",
      "Epoch 156/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 40133.2506 - mean_squared_error: 39467.2566 - val_loss: 110624.9414 - val_mean_squared_error: 110002.2146\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 100281.82799\n",
      "Epoch 157/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 41175.6377 - mean_squared_error: 40483.7887 - val_loss: 110796.9208 - val_mean_squared_error: 110171.2203\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 100281.82799\n",
      "Epoch 158/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 50175.2242 - mean_squared_error: 49475.8649 - val_loss: 108425.1913 - val_mean_squared_error: 107794.6589\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 100281.82799\n",
      "Epoch 159/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 37056.2469 - mean_squared_error: 36329.6874 - val_loss: 109373.3220 - val_mean_squared_error: 108721.2383\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 100281.82799\n",
      "Epoch 160/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 51237.3722 - mean_squared_error: 50522.5848 - val_loss: 108456.0306 - val_mean_squared_error: 107841.8588\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 100281.82799\n",
      "Epoch 161/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 46655.0615 - mean_squared_error: 45981.5738 - val_loss: 110846.6741 - val_mean_squared_error: 110250.8223\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 100281.82799\n",
      "Epoch 162/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 47126.0889 - mean_squared_error: 46435.1537 - val_loss: 110433.3142 - val_mean_squared_error: 109824.5504\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 100281.82799\n",
      "Epoch 163/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 33341.0918 - mean_squared_error: 32634.4736 - val_loss: 111249.6359 - val_mean_squared_error: 110642.2319\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 100281.82799\n",
      "Epoch 164/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 46553.2319 - mean_squared_error: 45871.0320 - val_loss: 108739.4943 - val_mean_squared_error: 108125.0453\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 100281.82799\n",
      "Epoch 165/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 42886.2153 - mean_squared_error: 42207.8596 - val_loss: 111938.9194 - val_mean_squared_error: 111333.0153\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 100281.82799\n",
      "Epoch 166/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 43914.4711 - mean_squared_error: 43259.5196 - val_loss: 112673.9555 - val_mean_squared_error: 112110.8054\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 100281.82799\n",
      "Epoch 167/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 41791.3620 - mean_squared_error: 41166.0397 - val_loss: 108978.8517 - val_mean_squared_error: 108408.8539\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 100281.82799\n",
      "Epoch 168/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 44088.4217 - mean_squared_error: 43412.5681 - val_loss: 109582.6236 - val_mean_squared_error: 108988.8728\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 100281.82799\n",
      "Epoch 169/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 42500.1570 - mean_squared_error: 41792.4696 - val_loss: 105254.0426 - val_mean_squared_error: 104651.4754\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 100281.82799\n",
      "Epoch 170/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 40072.3438 - mean_squared_error: 39389.6838 - val_loss: 103704.1959 - val_mean_squared_error: 103105.0317\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 100281.82799\n",
      "Epoch 171/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 46053.9946 - mean_squared_error: 45418.8047 - val_loss: 102991.8739 - val_mean_squared_error: 102409.6583\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 100281.82799\n",
      "Epoch 172/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45235.8630 - mean_squared_error: 44539.7018 - val_loss: 108409.8770 - val_mean_squared_error: 107826.9925\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 100281.82799\n",
      "Epoch 173/550\n",
      "250/250 [==============================] - 0s 288us/step - loss: 44947.3307 - mean_squared_error: 44314.4896 - val_loss: 108261.9619 - val_mean_squared_error: 107688.7945\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 100281.82799\n",
      "Epoch 174/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 36729.4505 - mean_squared_error: 36070.9301 - val_loss: 106192.8631 - val_mean_squared_error: 105602.1561\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 100281.82799\n",
      "Epoch 175/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 41534.1907 - mean_squared_error: 40889.4817 - val_loss: 105465.4453 - val_mean_squared_error: 104862.2642\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 100281.82799\n",
      "Epoch 176/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 36545.4368 - mean_squared_error: 35833.3728 - val_loss: 107662.2087 - val_mean_squared_error: 107054.9470\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 100281.82799\n",
      "Epoch 177/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 44223.6380 - mean_squared_error: 43533.8557 - val_loss: 108249.4669 - val_mean_squared_error: 107627.4562\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 100281.82799\n",
      "Epoch 178/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 46692.1279 - mean_squared_error: 46039.5751 - val_loss: 108677.2217 - val_mean_squared_error: 108083.7563\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 100281.82799\n",
      "Epoch 179/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 49939.7658 - mean_squared_error: 49291.9713 - val_loss: 103451.7896 - val_mean_squared_error: 102860.1080\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 100281.82799\n",
      "Epoch 180/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 39388.7791 - mean_squared_error: 38716.2949 - val_loss: 99296.7063 - val_mean_squared_error: 98671.3154\n",
      "\n",
      "Epoch 00180: val_loss improved from 100281.82799 to 99296.70633, saving model to test.hdf5\n",
      "Epoch 181/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 42762.4552 - mean_squared_error: 42076.9642 - val_loss: 100136.1236 - val_mean_squared_error: 99490.8790\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 99296.70633\n",
      "Epoch 182/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 45750.6155 - mean_squared_error: 45074.0467 - val_loss: 98876.8859 - val_mean_squared_error: 98231.0543\n",
      "\n",
      "Epoch 00182: val_loss improved from 99296.70633 to 98876.88588, saving model to test.hdf5\n",
      "Epoch 183/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 38093.3667 - mean_squared_error: 37399.3249 - val_loss: 104528.4170 - val_mean_squared_error: 103893.3366\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 98876.88588\n",
      "Epoch 184/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 36206.9508 - mean_squared_error: 35484.2611 - val_loss: 104827.9496 - val_mean_squared_error: 104186.0477\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 98876.88588\n",
      "Epoch 185/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 32786.6194 - mean_squared_error: 32078.0299 - val_loss: 104020.4406 - val_mean_squared_error: 103383.0377\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 98876.88588\n",
      "Epoch 186/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 46820.1105 - mean_squared_error: 46133.8398 - val_loss: 105053.7289 - val_mean_squared_error: 104428.4481\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 98876.88588\n",
      "Epoch 187/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 35167.9047 - mean_squared_error: 34504.2395 - val_loss: 104578.5827 - val_mean_squared_error: 103999.6797\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 98876.88588\n",
      "Epoch 188/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 45452.1661 - mean_squared_error: 44817.9933 - val_loss: 103520.4227 - val_mean_squared_error: 102939.1638\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 98876.88588\n",
      "Epoch 189/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 43989.7539 - mean_squared_error: 43333.3598 - val_loss: 106463.2162 - val_mean_squared_error: 105868.3079\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 98876.88588\n",
      "Epoch 190/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 43142.6471 - mean_squared_error: 42518.9512 - val_loss: 110372.5710 - val_mean_squared_error: 109785.2698\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 98876.88588\n",
      "Epoch 191/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 39130.4397 - mean_squared_error: 38466.3424 - val_loss: 106543.9496 - val_mean_squared_error: 105977.9544\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 98876.88588\n",
      "Epoch 192/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 45940.2332 - mean_squared_error: 45313.9550 - val_loss: 107292.1127 - val_mean_squared_error: 106747.4848\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 98876.88588\n",
      "Epoch 193/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 49239.3942 - mean_squared_error: 48641.7436 - val_loss: 108696.5234 - val_mean_squared_error: 108140.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00193: val_loss did not improve from 98876.88588\n",
      "Epoch 194/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 40099.2354 - mean_squared_error: 39443.5732 - val_loss: 109455.8354 - val_mean_squared_error: 108901.7118\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 98876.88588\n",
      "Epoch 195/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 40692.7380 - mean_squared_error: 40088.1521 - val_loss: 107891.6126 - val_mean_squared_error: 107338.2386\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 98876.88588\n",
      "Epoch 196/550\n",
      "250/250 [==============================] - 0s 269us/step - loss: 37934.4261 - mean_squared_error: 37299.5067 - val_loss: 106830.5276 - val_mean_squared_error: 106249.0791\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 98876.88588\n",
      "Epoch 197/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 42986.0368 - mean_squared_error: 42357.0575 - val_loss: 106520.2107 - val_mean_squared_error: 105931.9735\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 98876.88588\n",
      "Epoch 198/550\n",
      "250/250 [==============================] - 0s 302us/step - loss: 47141.3819 - mean_squared_error: 46543.9968 - val_loss: 104757.5241 - val_mean_squared_error: 104178.1928\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 98876.88588\n",
      "Epoch 199/550\n",
      "250/250 [==============================] - 0s 288us/step - loss: 39252.6521 - mean_squared_error: 38608.0310 - val_loss: 103124.6751 - val_mean_squared_error: 102531.0321\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 98876.88588\n",
      "Epoch 200/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 40135.1837 - mean_squared_error: 39537.0633 - val_loss: 104247.9967 - val_mean_squared_error: 103640.2669\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 98876.88588\n",
      "Epoch 201/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 47881.8476 - mean_squared_error: 47179.2049 - val_loss: 105216.8630 - val_mean_squared_error: 104616.7642\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 98876.88588\n",
      "Epoch 202/550\n",
      "250/250 [==============================] - 0s 284us/step - loss: 38122.3209 - mean_squared_error: 37476.6064 - val_loss: 104891.9527 - val_mean_squared_error: 104285.0212\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 98876.88588\n",
      "Epoch 203/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 35511.2716 - mean_squared_error: 34854.3979 - val_loss: 103479.4854 - val_mean_squared_error: 102884.6377\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 98876.88588\n",
      "Epoch 204/550\n",
      "250/250 [==============================] - 0s 285us/step - loss: 44280.0855 - mean_squared_error: 43667.7411 - val_loss: 105083.4731 - val_mean_squared_error: 104506.2246\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 98876.88588\n",
      "Epoch 205/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 40705.6163 - mean_squared_error: 40090.1510 - val_loss: 105126.3676 - val_mean_squared_error: 104526.9203\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 98876.88588\n",
      "Epoch 206/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 32341.7521 - mean_squared_error: 31693.3575 - val_loss: 105217.8012 - val_mean_squared_error: 104647.6889\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 98876.88588\n",
      "Epoch 207/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 49420.1015 - mean_squared_error: 48781.3979 - val_loss: 105495.0756 - val_mean_squared_error: 104919.3058\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 98876.88588\n",
      "Epoch 208/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 40259.5619 - mean_squared_error: 39634.6754 - val_loss: 104041.0543 - val_mean_squared_error: 103450.5092\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 98876.88588\n",
      "Epoch 209/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 41646.3647 - mean_squared_error: 41022.9217 - val_loss: 106343.3107 - val_mean_squared_error: 105759.5961\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 98876.88588\n",
      "Epoch 210/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 55240.5086 - mean_squared_error: 54606.2643 - val_loss: 107125.5607 - val_mean_squared_error: 106520.3394\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 98876.88588\n",
      "Epoch 211/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 47578.4519 - mean_squared_error: 46925.0324 - val_loss: 110161.6314 - val_mean_squared_error: 109568.5847\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 98876.88588\n",
      "Epoch 212/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 52218.3171 - mean_squared_error: 51575.3704 - val_loss: 110284.4446 - val_mean_squared_error: 109703.2807\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 98876.88588\n",
      "Epoch 213/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 38223.7175 - mean_squared_error: 37571.0393 - val_loss: 109053.3495 - val_mean_squared_error: 108467.0748\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 98876.88588\n",
      "Epoch 214/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 51140.0689 - mean_squared_error: 50491.0268 - val_loss: 108311.9715 - val_mean_squared_error: 107732.8729\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 98876.88588\n",
      "Epoch 215/550\n",
      "250/250 [==============================] - 0s 286us/step - loss: 46597.5877 - mean_squared_error: 45972.5672 - val_loss: 112833.3184 - val_mean_squared_error: 112276.3665\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 98876.88588\n",
      "Epoch 216/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 40662.9168 - mean_squared_error: 40000.8141 - val_loss: 108049.6927 - val_mean_squared_error: 107466.4604\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 98876.88588\n",
      "Epoch 217/550\n",
      "250/250 [==============================] - 0s 291us/step - loss: 40498.5924 - mean_squared_error: 39864.2193 - val_loss: 107073.2747 - val_mean_squared_error: 106480.4781\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 98876.88588\n",
      "Epoch 218/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 45964.5371 - mean_squared_error: 45332.6525 - val_loss: 104533.9747 - val_mean_squared_error: 103926.7515\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 98876.88588\n",
      "Epoch 219/550\n",
      "250/250 [==============================] - 0s 333us/step - loss: 45234.7224 - mean_squared_error: 44609.6607 - val_loss: 105533.3278 - val_mean_squared_error: 104904.6692\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 98876.88588\n",
      "Epoch 220/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 47718.0329 - mean_squared_error: 47065.1473 - val_loss: 106076.8414 - val_mean_squared_error: 105464.3876\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 98876.88588\n",
      "Epoch 221/550\n",
      "250/250 [==============================] - 0s 291us/step - loss: 50686.0529 - mean_squared_error: 50052.7563 - val_loss: 110126.9348 - val_mean_squared_error: 109566.4326\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 98876.88588\n",
      "Epoch 222/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 34214.8596 - mean_squared_error: 33594.5745 - val_loss: 105542.6973 - val_mean_squared_error: 104968.4106\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 98876.88588\n",
      "Epoch 223/550\n",
      "250/250 [==============================] - 0s 289us/step - loss: 36512.4146 - mean_squared_error: 35920.3446 - val_loss: 103702.8428 - val_mean_squared_error: 103116.2857\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 98876.88588\n",
      "Epoch 224/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 38844.5763 - mean_squared_error: 38195.1828 - val_loss: 104950.7401 - val_mean_squared_error: 104349.7531\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 98876.88588\n",
      "Epoch 225/550\n",
      "250/250 [==============================] - 0s 286us/step - loss: 40177.0506 - mean_squared_error: 39531.8377 - val_loss: 102125.3644 - val_mean_squared_error: 101548.6639\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 98876.88588\n",
      "Epoch 226/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 40714.3737 - mean_squared_error: 40089.6320 - val_loss: 101570.6523 - val_mean_squared_error: 101015.2144\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 98876.88588\n",
      "Epoch 227/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 41712.3258 - mean_squared_error: 41094.2946 - val_loss: 105036.1205 - val_mean_squared_error: 104489.0459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00227: val_loss did not improve from 98876.88588\n",
      "Epoch 228/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 47266.4970 - mean_squared_error: 46607.7114 - val_loss: 110940.2256 - val_mean_squared_error: 110406.3570\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 98876.88588\n",
      "Epoch 229/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 43531.1013 - mean_squared_error: 42960.9091 - val_loss: 112544.4205 - val_mean_squared_error: 112029.0232\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 98876.88588\n",
      "Epoch 230/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 48029.0651 - mean_squared_error: 47426.3979 - val_loss: 107679.8878 - val_mean_squared_error: 107147.8744\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 98876.88588\n",
      "Epoch 231/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 37623.0471 - mean_squared_error: 36994.7185 - val_loss: 104684.8751 - val_mean_squared_error: 104145.0070\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 98876.88588\n",
      "Epoch 232/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 36942.6671 - mean_squared_error: 36311.6661 - val_loss: 101969.1214 - val_mean_squared_error: 101414.0557\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 98876.88588\n",
      "Epoch 233/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 38099.5562 - mean_squared_error: 37449.5599 - val_loss: 101978.6908 - val_mean_squared_error: 101415.7379\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 98876.88588\n",
      "Epoch 234/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 44472.2493 - mean_squared_error: 43848.5424 - val_loss: 102866.4249 - val_mean_squared_error: 102306.7006\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 98876.88588\n",
      "Epoch 235/550\n",
      "250/250 [==============================] - 0s 263us/step - loss: 33718.3695 - mean_squared_error: 33078.9080 - val_loss: 100679.8834 - val_mean_squared_error: 100099.5942\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 98876.88588\n",
      "Epoch 236/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 43949.6205 - mean_squared_error: 43278.4557 - val_loss: 102269.7807 - val_mean_squared_error: 101700.0487\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 98876.88588\n",
      "Epoch 237/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 43003.8995 - mean_squared_error: 42374.6814 - val_loss: 106285.3658 - val_mean_squared_error: 105715.7868\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 98876.88588\n",
      "Epoch 238/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 47498.0712 - mean_squared_error: 46849.5179 - val_loss: 105851.6454 - val_mean_squared_error: 105261.8803\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 98876.88588\n",
      "Epoch 239/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 40450.9871 - mean_squared_error: 39800.8383 - val_loss: 104945.6931 - val_mean_squared_error: 104354.9203\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 98876.88588\n",
      "Epoch 240/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 48063.9618 - mean_squared_error: 47436.4678 - val_loss: 106531.0133 - val_mean_squared_error: 105940.0838\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 98876.88588\n",
      "Epoch 241/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 42254.0227 - mean_squared_error: 41588.6923 - val_loss: 106832.2028 - val_mean_squared_error: 106234.2965\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 98876.88588\n",
      "Epoch 242/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 43507.6919 - mean_squared_error: 42845.3423 - val_loss: 103019.0134 - val_mean_squared_error: 102402.0382\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 98876.88588\n",
      "Epoch 243/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 34412.2275 - mean_squared_error: 33762.4799 - val_loss: 101695.3470 - val_mean_squared_error: 101072.0296\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 98876.88588\n",
      "Epoch 244/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 48603.0564 - mean_squared_error: 47989.3243 - val_loss: 99881.5293 - val_mean_squared_error: 99260.7418\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 98876.88588\n",
      "Epoch 245/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 34174.5847 - mean_squared_error: 33488.3229 - val_loss: 99697.7133 - val_mean_squared_error: 99069.4503\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 98876.88588\n",
      "Epoch 246/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 35261.2373 - mean_squared_error: 34617.1875 - val_loss: 99954.3986 - val_mean_squared_error: 99343.4752\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 98876.88588\n",
      "Epoch 247/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 40964.3433 - mean_squared_error: 40342.0859 - val_loss: 102886.3415 - val_mean_squared_error: 102299.9275\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 98876.88588\n",
      "Epoch 248/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 45672.0555 - mean_squared_error: 45053.8456 - val_loss: 105872.8320 - val_mean_squared_error: 105305.7132\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 98876.88588\n",
      "Epoch 249/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 50235.4451 - mean_squared_error: 49639.4490 - val_loss: 108294.5262 - val_mean_squared_error: 107718.3820\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 98876.88588\n",
      "Epoch 250/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 38185.5982 - mean_squared_error: 37547.7143 - val_loss: 105540.2169 - val_mean_squared_error: 104959.4562\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 98876.88588\n",
      "Epoch 251/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 42524.3289 - mean_squared_error: 41904.3691 - val_loss: 102430.6773 - val_mean_squared_error: 101850.5073\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 98876.88588\n",
      "Epoch 252/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 42628.5640 - mean_squared_error: 41998.8684 - val_loss: 107307.6487 - val_mean_squared_error: 106728.6882\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 98876.88588\n",
      "Epoch 253/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 40738.7352 - mean_squared_error: 40124.4825 - val_loss: 104987.7988 - val_mean_squared_error: 104397.7101\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 98876.88588\n",
      "Epoch 254/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 37276.6479 - mean_squared_error: 36669.3169 - val_loss: 103134.0240 - val_mean_squared_error: 102542.4446\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 98876.88588\n",
      "Epoch 255/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 46156.4639 - mean_squared_error: 45546.3125 - val_loss: 104300.9089 - val_mean_squared_error: 103716.2859\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 98876.88588\n",
      "Epoch 256/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 35850.0118 - mean_squared_error: 35257.9722 - val_loss: 106029.9242 - val_mean_squared_error: 105464.9127\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 98876.88588\n",
      "Epoch 257/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 38442.1624 - mean_squared_error: 37837.8848 - val_loss: 108469.6131 - val_mean_squared_error: 107908.3672\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 98876.88588\n",
      "Epoch 258/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 38858.6046 - mean_squared_error: 38260.5048 - val_loss: 109341.4976 - val_mean_squared_error: 108785.2143\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 98876.88588\n",
      "Epoch 259/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 37984.8091 - mean_squared_error: 37367.3504 - val_loss: 105936.8838 - val_mean_squared_error: 105370.8417\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 98876.88588\n",
      "Epoch 260/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45505.2512 - mean_squared_error: 44914.7003 - val_loss: 106322.0424 - val_mean_squared_error: 105761.6885\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 98876.88588\n",
      "Epoch 261/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 38057.7102 - mean_squared_error: 37468.9632 - val_loss: 105157.2217 - val_mean_squared_error: 104587.2905\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 98876.88588\n",
      "Epoch 262/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 264us/step - loss: 38599.0717 - mean_squared_error: 37994.1915 - val_loss: 105326.2267 - val_mean_squared_error: 104761.4367\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 98876.88588\n",
      "Epoch 263/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 43556.0154 - mean_squared_error: 42951.4527 - val_loss: 105417.8806 - val_mean_squared_error: 104830.2080\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 98876.88588\n",
      "Epoch 264/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 36413.9397 - mean_squared_error: 35791.2895 - val_loss: 107411.4918 - val_mean_squared_error: 106847.7586\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 98876.88588\n",
      "Epoch 265/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 40354.6864 - mean_squared_error: 39778.4845 - val_loss: 108371.9051 - val_mean_squared_error: 107846.2102\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 98876.88588\n",
      "Epoch 266/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 42198.9559 - mean_squared_error: 41632.5182 - val_loss: 110439.2418 - val_mean_squared_error: 109910.7161\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 98876.88588\n",
      "Epoch 267/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 44725.8143 - mean_squared_error: 44141.6723 - val_loss: 110773.8083 - val_mean_squared_error: 110246.1985\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 98876.88588\n",
      "Epoch 268/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 37346.1412 - mean_squared_error: 36765.6498 - val_loss: 108070.5029 - val_mean_squared_error: 107518.2586\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 98876.88588\n",
      "Epoch 269/550\n",
      "250/250 [==============================] - 0s 229us/step - loss: 37587.7578 - mean_squared_error: 36957.2724 - val_loss: 103791.3186 - val_mean_squared_error: 103209.5573\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 98876.88588\n",
      "Epoch 270/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 40820.9111 - mean_squared_error: 40216.7652 - val_loss: 101358.7444 - val_mean_squared_error: 100795.9280\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 98876.88588\n",
      "Epoch 271/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 32848.6981 - mean_squared_error: 32224.2553 - val_loss: 102863.0865 - val_mean_squared_error: 102299.2186\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 98876.88588\n",
      "Epoch 272/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 39452.2489 - mean_squared_error: 38847.7222 - val_loss: 98820.8018 - val_mean_squared_error: 98267.7321\n",
      "\n",
      "Epoch 00272: val_loss improved from 98876.88588 to 98820.80176, saving model to test.hdf5\n",
      "Epoch 273/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 43212.2531 - mean_squared_error: 42624.7276 - val_loss: 106193.2599 - val_mean_squared_error: 105662.4967\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 98820.80176\n",
      "Epoch 274/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 45089.9198 - mean_squared_error: 44479.4743 - val_loss: 107039.5134 - val_mean_squared_error: 106504.8015\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 98820.80176\n",
      "Epoch 275/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 38936.4918 - mean_squared_error: 38353.2945 - val_loss: 105519.8750 - val_mean_squared_error: 104995.3435\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 98820.80176\n",
      "Epoch 276/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 40086.7309 - mean_squared_error: 39507.6302 - val_loss: 105981.5551 - val_mean_squared_error: 105459.9690\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 98820.80176\n",
      "Epoch 277/550\n",
      "250/250 [==============================] - 0s 255us/step - loss: 43565.8166 - mean_squared_error: 42978.5125 - val_loss: 102088.7356 - val_mean_squared_error: 101520.2453\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 98820.80176\n",
      "Epoch 278/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 47282.7114 - mean_squared_error: 46666.1553 - val_loss: 104526.8874 - val_mean_squared_error: 103988.9399\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 98820.80176\n",
      "Epoch 279/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 42051.6297 - mean_squared_error: 41491.9990 - val_loss: 107723.4103 - val_mean_squared_error: 107183.2051\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 98820.80176\n",
      "Epoch 280/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 44712.4636 - mean_squared_error: 44134.2459 - val_loss: 105645.7476 - val_mean_squared_error: 105087.5766\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 98820.80176\n",
      "Epoch 281/550\n",
      "250/250 [==============================] - 0s 229us/step - loss: 45174.1170 - mean_squared_error: 44576.1818 - val_loss: 106536.5332 - val_mean_squared_error: 105969.0467\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 98820.80176\n",
      "Epoch 282/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 44906.1860 - mean_squared_error: 44295.6607 - val_loss: 106378.5423 - val_mean_squared_error: 105819.2312\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 98820.80176\n",
      "Epoch 283/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 40665.0003 - mean_squared_error: 40057.1176 - val_loss: 109584.2070 - val_mean_squared_error: 109011.0409\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 98820.80176\n",
      "Epoch 284/550\n",
      "250/250 [==============================] - 0s 308us/step - loss: 52406.5586 - mean_squared_error: 51818.9017 - val_loss: 107021.9484 - val_mean_squared_error: 106470.4036\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 98820.80176\n",
      "Epoch 285/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 40577.7831 - mean_squared_error: 39960.0365 - val_loss: 109483.0900 - val_mean_squared_error: 108922.8866\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 98820.80176\n",
      "Epoch 286/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 47201.5331 - mean_squared_error: 46585.8876 - val_loss: 111035.3009 - val_mean_squared_error: 110496.8800\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 98820.80176\n",
      "Epoch 287/550\n",
      "250/250 [==============================] - 0s 253us/step - loss: 41946.3744 - mean_squared_error: 41381.9873 - val_loss: 107585.8668 - val_mean_squared_error: 107047.3270\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 98820.80176\n",
      "Epoch 288/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 44710.4247 - mean_squared_error: 44115.4187 - val_loss: 107153.3280 - val_mean_squared_error: 106590.4519\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 98820.80176\n",
      "Epoch 289/550\n",
      "250/250 [==============================] - 0s 259us/step - loss: 37367.4418 - mean_squared_error: 36774.5569 - val_loss: 102692.6208 - val_mean_squared_error: 102123.3025\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 98820.80176\n",
      "Epoch 290/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 35354.2492 - mean_squared_error: 34755.8413 - val_loss: 100540.1579 - val_mean_squared_error: 99975.1182\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 98820.80176\n",
      "Epoch 291/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 39205.0828 - mean_squared_error: 38578.2192 - val_loss: 102791.4347 - val_mean_squared_error: 102253.9796\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 98820.80176\n",
      "Epoch 292/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 38570.5813 - mean_squared_error: 37948.2168 - val_loss: 103870.7422 - val_mean_squared_error: 103316.4789\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 98820.80176\n",
      "Epoch 293/550\n",
      "250/250 [==============================] - 0s 253us/step - loss: 40621.2611 - mean_squared_error: 39977.6422 - val_loss: 106173.7607 - val_mean_squared_error: 105613.4129\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 98820.80176\n",
      "Epoch 294/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 36152.7905 - mean_squared_error: 35528.2170 - val_loss: 107734.8647 - val_mean_squared_error: 107200.2713\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 98820.80176\n",
      "Epoch 295/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 36887.2268 - mean_squared_error: 36278.1329 - val_loss: 106243.5130 - val_mean_squared_error: 105735.3680\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 98820.80176\n",
      "Epoch 296/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 233us/step - loss: 37650.6643 - mean_squared_error: 37059.3807 - val_loss: 108191.0956 - val_mean_squared_error: 107703.9000\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 98820.80176\n",
      "Epoch 297/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 40343.6717 - mean_squared_error: 39773.3457 - val_loss: 112743.2260 - val_mean_squared_error: 112244.4925\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 98820.80176\n",
      "Epoch 298/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 39946.1078 - mean_squared_error: 39366.9068 - val_loss: 106474.6023 - val_mean_squared_error: 105963.3153\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 98820.80176\n",
      "Epoch 299/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 40000.9622 - mean_squared_error: 39423.4319 - val_loss: 105936.4118 - val_mean_squared_error: 105376.4347\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 98820.80176\n",
      "Epoch 300/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 37811.2929 - mean_squared_error: 37206.8675 - val_loss: 104178.1410 - val_mean_squared_error: 103608.8252\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 98820.80176\n",
      "Epoch 301/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 39863.8132 - mean_squared_error: 39230.5160 - val_loss: 104081.1285 - val_mean_squared_error: 103501.8333\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 98820.80176\n",
      "Epoch 302/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 43125.4077 - mean_squared_error: 42511.9975 - val_loss: 105661.0707 - val_mean_squared_error: 105103.9948\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 98820.80176\n",
      "Epoch 303/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 35843.2800 - mean_squared_error: 35233.8749 - val_loss: 106371.5642 - val_mean_squared_error: 105814.3436\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 98820.80176\n",
      "Epoch 304/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 48759.2332 - mean_squared_error: 48171.5685 - val_loss: 107936.7660 - val_mean_squared_error: 107423.2148\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 98820.80176\n",
      "Epoch 305/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 40247.9862 - mean_squared_error: 39667.3131 - val_loss: 108871.3725 - val_mean_squared_error: 108322.9888\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 98820.80176\n",
      "Epoch 306/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 41291.6819 - mean_squared_error: 40654.8875 - val_loss: 106970.4628 - val_mean_squared_error: 106404.3976\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 98820.80176\n",
      "Epoch 307/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 40611.6181 - mean_squared_error: 39990.6268 - val_loss: 105851.9425 - val_mean_squared_error: 105302.7257\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 98820.80176\n",
      "Epoch 308/550\n",
      "250/250 [==============================] - 0s 241us/step - loss: 40340.4856 - mean_squared_error: 39741.3670 - val_loss: 108616.1204 - val_mean_squared_error: 108063.6317\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 98820.80176\n",
      "Epoch 309/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 37800.1632 - mean_squared_error: 37199.1135 - val_loss: 107488.4787 - val_mean_squared_error: 106944.5844\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 98820.80176\n",
      "Epoch 310/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 36811.3004 - mean_squared_error: 36219.0789 - val_loss: 101587.2857 - val_mean_squared_error: 101018.6152\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 98820.80176\n",
      "Epoch 311/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 39954.7260 - mean_squared_error: 39327.7975 - val_loss: 103101.0080 - val_mean_squared_error: 102537.2330\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 98820.80176\n",
      "Epoch 312/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 44821.6634 - mean_squared_error: 44211.5675 - val_loss: 105007.7499 - val_mean_squared_error: 104471.7860\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 98820.80176\n",
      "Epoch 313/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 39377.8107 - mean_squared_error: 38794.8954 - val_loss: 104016.2593 - val_mean_squared_error: 103485.1438\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 98820.80176\n",
      "Epoch 314/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 45534.1639 - mean_squared_error: 44976.9837 - val_loss: 104502.3931 - val_mean_squared_error: 103964.6772\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 98820.80176\n",
      "Epoch 315/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 41611.7368 - mean_squared_error: 41026.4970 - val_loss: 105241.8068 - val_mean_squared_error: 104694.8730\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 98820.80176\n",
      "Epoch 316/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 40484.5860 - mean_squared_error: 39909.6819 - val_loss: 104794.2016 - val_mean_squared_error: 104257.3538\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 98820.80176\n",
      "Epoch 317/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 50915.4880 - mean_squared_error: 50313.4888 - val_loss: 109924.1635 - val_mean_squared_error: 109379.5823\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 98820.80176\n",
      "Epoch 318/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 39976.6866 - mean_squared_error: 39380.3901 - val_loss: 105980.3869 - val_mean_squared_error: 105416.8516\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 98820.80176\n",
      "Epoch 319/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 35455.6909 - mean_squared_error: 34848.7944 - val_loss: 104164.1821 - val_mean_squared_error: 103622.8439\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 98820.80176\n",
      "Epoch 320/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 43304.5628 - mean_squared_error: 42718.2725 - val_loss: 101296.1868 - val_mean_squared_error: 100724.3842\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 98820.80176\n",
      "Epoch 321/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 44334.0024 - mean_squared_error: 43714.9767 - val_loss: 103428.4410 - val_mean_squared_error: 102851.0480\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 98820.80176\n",
      "Epoch 322/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 40655.0599 - mean_squared_error: 40037.6135 - val_loss: 102861.1119 - val_mean_squared_error: 102296.3001\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 98820.80176\n",
      "Epoch 323/550\n",
      "250/250 [==============================] - 0s 245us/step - loss: 36494.3749 - mean_squared_error: 35883.2966 - val_loss: 107316.8387 - val_mean_squared_error: 106775.2896\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 98820.80176\n",
      "Epoch 324/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 46824.9971 - mean_squared_error: 46238.6426 - val_loss: 106241.5773 - val_mean_squared_error: 105721.0730\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 98820.80176\n",
      "Epoch 325/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 34484.7036 - mean_squared_error: 33902.1841 - val_loss: 105911.6381 - val_mean_squared_error: 105368.8196\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 98820.80176\n",
      "Epoch 326/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 33870.5476 - mean_squared_error: 33273.5295 - val_loss: 105929.5804 - val_mean_squared_error: 105386.3124\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 98820.80176\n",
      "Epoch 327/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 38292.0700 - mean_squared_error: 37657.9736 - val_loss: 104868.6776 - val_mean_squared_error: 104313.2123\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 98820.80176\n",
      "Epoch 328/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 47898.3022 - mean_squared_error: 47301.6385 - val_loss: 104341.5127 - val_mean_squared_error: 103780.8581\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 98820.80176\n",
      "Epoch 329/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 41428.2155 - mean_squared_error: 40795.4138 - val_loss: 100511.2165 - val_mean_squared_error: 99931.4908\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 98820.80176\n",
      "Epoch 330/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 252us/step - loss: 33103.8726 - mean_squared_error: 32495.2972 - val_loss: 96698.7665 - val_mean_squared_error: 96118.8677\n",
      "\n",
      "Epoch 00330: val_loss improved from 98820.80176 to 96698.76646, saving model to test.hdf5\n",
      "Epoch 331/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 33817.5284 - mean_squared_error: 33199.3512 - val_loss: 99662.9668 - val_mean_squared_error: 99119.2598\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 96698.76646\n",
      "Epoch 332/550\n",
      "250/250 [==============================] - 0s 218us/step - loss: 33869.2861 - mean_squared_error: 33265.1376 - val_loss: 106372.0074 - val_mean_squared_error: 105860.3651\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 96698.76646\n",
      "Epoch 333/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 41042.2532 - mean_squared_error: 40479.3393 - val_loss: 106556.5593 - val_mean_squared_error: 106037.5776\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 96698.76646\n",
      "Epoch 334/550\n",
      "250/250 [==============================] - 0s 239us/step - loss: 36037.5082 - mean_squared_error: 35450.6524 - val_loss: 105357.7048 - val_mean_squared_error: 104826.0604\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 96698.76646\n",
      "Epoch 335/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 43009.2920 - mean_squared_error: 42427.9548 - val_loss: 105661.6465 - val_mean_squared_error: 105144.8086\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 96698.76646\n",
      "Epoch 336/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 50639.4977 - mean_squared_error: 50043.3983 - val_loss: 105159.0199 - val_mean_squared_error: 104638.9570\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 96698.76646\n",
      "Epoch 337/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 37251.1104 - mean_squared_error: 36676.4529 - val_loss: 105886.7056 - val_mean_squared_error: 105353.5679\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 96698.76646\n",
      "Epoch 338/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 38218.8975 - mean_squared_error: 37583.6161 - val_loss: 102204.1251 - val_mean_squared_error: 101645.4541\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 96698.76646\n",
      "Epoch 339/550\n",
      "250/250 [==============================] - 0s 245us/step - loss: 34423.9627 - mean_squared_error: 33823.9949 - val_loss: 103177.6959 - val_mean_squared_error: 102640.5162\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 96698.76646\n",
      "Epoch 340/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 33390.3382 - mean_squared_error: 32789.9447 - val_loss: 101695.1449 - val_mean_squared_error: 101165.9389\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 96698.76646\n",
      "Epoch 341/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 35704.7889 - mean_squared_error: 35113.6767 - val_loss: 103903.5176 - val_mean_squared_error: 103382.6544\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 96698.76646\n",
      "Epoch 342/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 47074.0824 - mean_squared_error: 46508.7025 - val_loss: 106541.3581 - val_mean_squared_error: 105999.7694\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 96698.76646\n",
      "Epoch 343/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 37553.9681 - mean_squared_error: 36924.6939 - val_loss: 109310.9434 - val_mean_squared_error: 108781.2850\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 96698.76646\n",
      "Epoch 344/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 33646.6248 - mean_squared_error: 33062.5807 - val_loss: 108661.9076 - val_mean_squared_error: 108128.8698\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 96698.76646\n",
      "Epoch 345/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 42958.7266 - mean_squared_error: 42375.2737 - val_loss: 104526.4982 - val_mean_squared_error: 103984.4693\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 96698.76646\n",
      "Epoch 346/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 41033.7029 - mean_squared_error: 40423.8011 - val_loss: 103951.9170 - val_mean_squared_error: 103399.1279\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 96698.76646\n",
      "Epoch 347/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 33766.9056 - mean_squared_error: 33163.4042 - val_loss: 99056.2999 - val_mean_squared_error: 98484.2179\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 96698.76646\n",
      "Epoch 348/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 43186.4960 - mean_squared_error: 42569.9433 - val_loss: 101820.3196 - val_mean_squared_error: 101227.8634\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 96698.76646\n",
      "Epoch 349/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 48081.3397 - mean_squared_error: 47446.5312 - val_loss: 102283.0617 - val_mean_squared_error: 101692.3185\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 96698.76646\n",
      "Epoch 350/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 47231.3256 - mean_squared_error: 46631.5988 - val_loss: 107494.9792 - val_mean_squared_error: 106932.0308\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 96698.76646\n",
      "Epoch 351/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 39886.9973 - mean_squared_error: 39301.6209 - val_loss: 106355.1572 - val_mean_squared_error: 105783.0589\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 96698.76646\n",
      "Epoch 352/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 31513.7344 - mean_squared_error: 30896.9525 - val_loss: 106064.7924 - val_mean_squared_error: 105500.0857\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 96698.76646\n",
      "Epoch 353/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 40149.2497 - mean_squared_error: 39563.6348 - val_loss: 102481.5020 - val_mean_squared_error: 101932.4863\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 96698.76646\n",
      "Epoch 354/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 36727.6078 - mean_squared_error: 36128.6006 - val_loss: 104478.7101 - val_mean_squared_error: 103925.1516\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 96698.76646\n",
      "Epoch 355/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 35495.6629 - mean_squared_error: 34889.7341 - val_loss: 104240.2319 - val_mean_squared_error: 103690.0922\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 96698.76646\n",
      "Epoch 356/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 33131.0603 - mean_squared_error: 32507.6706 - val_loss: 102292.5753 - val_mean_squared_error: 101729.0696\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 96698.76646\n",
      "Epoch 357/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 42257.5804 - mean_squared_error: 41630.7633 - val_loss: 107415.2354 - val_mean_squared_error: 106888.6436\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 96698.76646\n",
      "Epoch 358/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 42691.9860 - mean_squared_error: 42098.0734 - val_loss: 108816.3627 - val_mean_squared_error: 108304.1687\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 96698.76646\n",
      "Epoch 359/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 40136.9996 - mean_squared_error: 39558.5929 - val_loss: 107914.3269 - val_mean_squared_error: 107390.7091\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 96698.76646\n",
      "Epoch 360/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 49412.8640 - mean_squared_error: 48860.1111 - val_loss: 109295.1948 - val_mean_squared_error: 108776.7557\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 96698.76646\n",
      "Epoch 361/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 38600.4559 - mean_squared_error: 38020.6864 - val_loss: 104436.2295 - val_mean_squared_error: 103908.8495\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 96698.76646\n",
      "Epoch 362/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 39226.6942 - mean_squared_error: 38599.7138 - val_loss: 103469.6452 - val_mean_squared_error: 102926.8948\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 96698.76646\n",
      "Epoch 363/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 35316.3060 - mean_squared_error: 34728.4371 - val_loss: 105386.2768 - val_mean_squared_error: 104850.6522\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 96698.76646\n",
      "Epoch 364/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 232us/step - loss: 45900.0335 - mean_squared_error: 45334.0997 - val_loss: 106435.0891 - val_mean_squared_error: 105919.6383\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 96698.76646\n",
      "Epoch 365/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 36340.0881 - mean_squared_error: 35761.6046 - val_loss: 107146.9665 - val_mean_squared_error: 106628.5668\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 96698.76646\n",
      "Epoch 366/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 42281.6237 - mean_squared_error: 41709.4342 - val_loss: 106789.2426 - val_mean_squared_error: 106279.2268\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 96698.76646\n",
      "Epoch 367/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 42076.6767 - mean_squared_error: 41508.4068 - val_loss: 104866.4231 - val_mean_squared_error: 104356.4166\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 96698.76646\n",
      "Epoch 368/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 34788.6252 - mean_squared_error: 34208.3123 - val_loss: 103709.8956 - val_mean_squared_error: 103183.5576\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 96698.76646\n",
      "Epoch 369/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 38096.8080 - mean_squared_error: 37507.2551 - val_loss: 105878.0188 - val_mean_squared_error: 105339.6090\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 96698.76646\n",
      "Epoch 370/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 44275.8065 - mean_squared_error: 43666.7435 - val_loss: 108003.4343 - val_mean_squared_error: 107451.1031\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 96698.76646\n",
      "Epoch 371/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 31971.1375 - mean_squared_error: 31386.7771 - val_loss: 108421.8902 - val_mean_squared_error: 107894.9579\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 96698.76646\n",
      "Epoch 372/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 38433.5312 - mean_squared_error: 37857.1718 - val_loss: 107889.2440 - val_mean_squared_error: 107353.7732\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 96698.76646\n",
      "Epoch 373/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 35262.8547 - mean_squared_error: 34669.7984 - val_loss: 107069.8394 - val_mean_squared_error: 106518.7659\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 96698.76646\n",
      "Epoch 374/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 41840.4691 - mean_squared_error: 41238.1560 - val_loss: 109790.0926 - val_mean_squared_error: 109251.3556\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 96698.76646\n",
      "Epoch 375/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 34933.4296 - mean_squared_error: 34337.0740 - val_loss: 109937.6888 - val_mean_squared_error: 109403.2344\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 96698.76646\n",
      "Epoch 376/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 38154.3881 - mean_squared_error: 37564.4022 - val_loss: 109976.0225 - val_mean_squared_error: 109450.2932\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 96698.76646\n",
      "Epoch 377/550\n",
      "250/250 [==============================] - 0s 223us/step - loss: 40990.9352 - mean_squared_error: 40414.7956 - val_loss: 108155.2983 - val_mean_squared_error: 107643.2817\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 96698.76646\n",
      "Epoch 378/550\n",
      "250/250 [==============================] - 0s 251us/step - loss: 33973.2026 - mean_squared_error: 33390.8232 - val_loss: 105509.6217 - val_mean_squared_error: 104996.0947\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 96698.76646\n",
      "Epoch 379/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 32372.7261 - mean_squared_error: 31801.0361 - val_loss: 105095.6325 - val_mean_squared_error: 104579.8439\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 96698.76646\n",
      "Epoch 380/550\n",
      "250/250 [==============================] - 0s 253us/step - loss: 37180.7362 - mean_squared_error: 36608.7177 - val_loss: 106707.9277 - val_mean_squared_error: 106183.0972\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 96698.76646\n",
      "Epoch 381/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 37538.6837 - mean_squared_error: 36912.9572 - val_loss: 103316.2832 - val_mean_squared_error: 102794.4549\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 96698.76646\n",
      "Epoch 382/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 40310.3156 - mean_squared_error: 39741.1906 - val_loss: 104000.5836 - val_mean_squared_error: 103485.3548\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 96698.76646\n",
      "Epoch 383/550\n",
      "250/250 [==============================] - 0s 220us/step - loss: 36753.2592 - mean_squared_error: 36193.9536 - val_loss: 104906.4542 - val_mean_squared_error: 104398.1775\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 96698.76646\n",
      "Epoch 384/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 45630.7265 - mean_squared_error: 45057.6306 - val_loss: 110886.7112 - val_mean_squared_error: 110388.5629\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 96698.76646\n",
      "Epoch 385/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 36250.4463 - mean_squared_error: 35658.5155 - val_loss: 107060.7699 - val_mean_squared_error: 106553.0844\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 96698.76646\n",
      "Epoch 386/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 38686.7884 - mean_squared_error: 38118.2920 - val_loss: 105484.4406 - val_mean_squared_error: 104971.7238\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 96698.76646\n",
      "Epoch 387/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 41028.5342 - mean_squared_error: 40470.5882 - val_loss: 104584.8771 - val_mean_squared_error: 104062.4999\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 96698.76646\n",
      "Epoch 388/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 33054.5964 - mean_squared_error: 32439.9286 - val_loss: 103891.9383 - val_mean_squared_error: 103351.0559\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 96698.76646\n",
      "Epoch 389/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 38487.5474 - mean_squared_error: 37870.4995 - val_loss: 104595.0335 - val_mean_squared_error: 104043.2903\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 96698.76646\n",
      "Epoch 390/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 45529.3803 - mean_squared_error: 44937.0348 - val_loss: 109940.7560 - val_mean_squared_error: 109412.9982\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 96698.76646\n",
      "Epoch 391/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 41302.9881 - mean_squared_error: 40734.5024 - val_loss: 108051.8488 - val_mean_squared_error: 107528.8336\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 96698.76646\n",
      "Epoch 392/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 31202.3927 - mean_squared_error: 30606.4429 - val_loss: 105477.3940 - val_mean_squared_error: 104946.6041\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 96698.76646\n",
      "Epoch 393/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 39252.7540 - mean_squared_error: 38683.4850 - val_loss: 100668.6493 - val_mean_squared_error: 100139.6169\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 96698.76646\n",
      "Epoch 394/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 41002.0599 - mean_squared_error: 40409.9993 - val_loss: 102640.6652 - val_mean_squared_error: 102099.9711\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 96698.76646\n",
      "Epoch 395/550\n",
      "250/250 [==============================] - 0s 252us/step - loss: 39179.9927 - mean_squared_error: 38578.2145 - val_loss: 103495.2354 - val_mean_squared_error: 102950.2402\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 96698.76646\n",
      "Epoch 396/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 36593.1715 - mean_squared_error: 35983.2680 - val_loss: 106570.7437 - val_mean_squared_error: 106030.7790\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 96698.76646\n",
      "Epoch 397/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 34706.3652 - mean_squared_error: 34113.8465 - val_loss: 107786.8107 - val_mean_squared_error: 107259.2443\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 96698.76646\n",
      "Epoch 398/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 246us/step - loss: 31953.2907 - mean_squared_error: 31340.3568 - val_loss: 104994.7478 - val_mean_squared_error: 104458.3521\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 96698.76646\n",
      "Epoch 399/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 39813.8214 - mean_squared_error: 39226.2768 - val_loss: 107514.6297 - val_mean_squared_error: 106996.6491\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 96698.76646\n",
      "Epoch 400/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 37287.2197 - mean_squared_error: 36708.7825 - val_loss: 106586.4632 - val_mean_squared_error: 106057.6742\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 96698.76646\n",
      "Epoch 401/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 46696.2344 - mean_squared_error: 46109.9279 - val_loss: 108226.6769 - val_mean_squared_error: 107697.2218\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 96698.76646\n",
      "Epoch 402/550\n",
      "250/250 [==============================] - 0s 257us/step - loss: 40176.7332 - mean_squared_error: 39577.7780 - val_loss: 106018.6380 - val_mean_squared_error: 105488.7344\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 96698.76646\n",
      "Epoch 403/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 36962.3722 - mean_squared_error: 36404.2554 - val_loss: 102888.7988 - val_mean_squared_error: 102360.1021\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 96698.76646\n",
      "Epoch 404/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 39337.5086 - mean_squared_error: 38769.3388 - val_loss: 106399.3071 - val_mean_squared_error: 105892.1067\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 96698.76646\n",
      "Epoch 405/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 39213.7534 - mean_squared_error: 38666.3397 - val_loss: 107391.0647 - val_mean_squared_error: 106882.1426\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 96698.76646\n",
      "Epoch 406/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 40653.0988 - mean_squared_error: 40082.4778 - val_loss: 106038.4679 - val_mean_squared_error: 105515.4946\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 96698.76646\n",
      "Epoch 407/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 47819.9225 - mean_squared_error: 47237.2509 - val_loss: 106397.3239 - val_mean_squared_error: 105890.6394\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 96698.76646\n",
      "Epoch 408/550\n",
      "250/250 [==============================] - 0s 262us/step - loss: 43409.7351 - mean_squared_error: 42859.5555 - val_loss: 109331.9632 - val_mean_squared_error: 108820.4548\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 96698.76646\n",
      "Epoch 409/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 43918.0657 - mean_squared_error: 43333.4396 - val_loss: 103317.8394 - val_mean_squared_error: 102796.4728\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 96698.76646\n",
      "Epoch 410/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45667.0076 - mean_squared_error: 45071.9175 - val_loss: 109160.8245 - val_mean_squared_error: 108657.2128\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 96698.76646\n",
      "Epoch 411/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 34184.9171 - mean_squared_error: 33602.7271 - val_loss: 107746.8513 - val_mean_squared_error: 107230.5707\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 96698.76646\n",
      "Epoch 412/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 34360.0054 - mean_squared_error: 33739.4480 - val_loss: 104958.3830 - val_mean_squared_error: 104442.0474\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 96698.76646\n",
      "Epoch 413/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 48879.5220 - mean_squared_error: 48318.7766 - val_loss: 105562.8157 - val_mean_squared_error: 105070.9602\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 96698.76646\n",
      "Epoch 414/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 45899.1569 - mean_squared_error: 45329.9094 - val_loss: 103161.7090 - val_mean_squared_error: 102647.7787\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 96698.76646\n",
      "Epoch 415/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 38011.1144 - mean_squared_error: 37412.2423 - val_loss: 104587.4314 - val_mean_squared_error: 104063.2268\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 96698.76646\n",
      "Epoch 416/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 40812.7464 - mean_squared_error: 40235.0673 - val_loss: 107467.2570 - val_mean_squared_error: 106946.9841\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 96698.76646\n",
      "Epoch 417/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 47889.3906 - mean_squared_error: 47317.6958 - val_loss: 108662.0597 - val_mean_squared_error: 108160.8774\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 96698.76646\n",
      "Epoch 418/550\n",
      "250/250 [==============================] - 0s 221us/step - loss: 45643.1378 - mean_squared_error: 45080.8362 - val_loss: 105924.2139 - val_mean_squared_error: 105409.6166\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 96698.76646\n",
      "Epoch 419/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 36906.4226 - mean_squared_error: 36322.6710 - val_loss: 102984.4014 - val_mean_squared_error: 102482.3481\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 96698.76646\n",
      "Epoch 420/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 39508.7654 - mean_squared_error: 38917.2590 - val_loss: 101803.5219 - val_mean_squared_error: 101298.1345\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 96698.76646\n",
      "Epoch 421/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 39877.8313 - mean_squared_error: 39263.7539 - val_loss: 105219.3454 - val_mean_squared_error: 104716.5490\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 96698.76646\n",
      "Epoch 422/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 45195.1523 - mean_squared_error: 44629.2791 - val_loss: 104504.5318 - val_mean_squared_error: 103989.9270\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 96698.76646\n",
      "Epoch 423/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 45431.2963 - mean_squared_error: 44852.1480 - val_loss: 107235.0569 - val_mean_squared_error: 106713.5989\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 96698.76646\n",
      "Epoch 424/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 38921.7165 - mean_squared_error: 38347.3800 - val_loss: 105843.8948 - val_mean_squared_error: 105320.3009\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 96698.76646\n",
      "Epoch 425/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 41115.1780 - mean_squared_error: 40510.1830 - val_loss: 103544.3410 - val_mean_squared_error: 103016.0243\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 96698.76646\n",
      "Epoch 426/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 33637.9902 - mean_squared_error: 33046.3261 - val_loss: 103647.9633 - val_mean_squared_error: 103111.1535\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 96698.76646\n",
      "Epoch 427/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 38137.9907 - mean_squared_error: 37557.6361 - val_loss: 105844.4858 - val_mean_squared_error: 105338.4085\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 96698.76646\n",
      "Epoch 428/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 44787.6947 - mean_squared_error: 44217.8924 - val_loss: 104540.4817 - val_mean_squared_error: 104034.2552\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 96698.76646\n",
      "Epoch 429/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 41433.6941 - mean_squared_error: 40869.8540 - val_loss: 102281.6286 - val_mean_squared_error: 101780.2321\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 96698.76646\n",
      "Epoch 430/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 35040.2665 - mean_squared_error: 34439.3634 - val_loss: 101522.5463 - val_mean_squared_error: 100991.6175\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 96698.76646\n",
      "Epoch 431/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 33340.2923 - mean_squared_error: 32738.1024 - val_loss: 105678.1194 - val_mean_squared_error: 105166.3578\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 96698.76646\n",
      "Epoch 432/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 220us/step - loss: 38975.8445 - mean_squared_error: 38381.0882 - val_loss: 103574.8193 - val_mean_squared_error: 103070.9985\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 96698.76646\n",
      "Epoch 433/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 35246.6427 - mean_squared_error: 34650.2887 - val_loss: 103185.6932 - val_mean_squared_error: 102668.5686\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 96698.76646\n",
      "Epoch 434/550\n",
      "250/250 [==============================] - 0s 222us/step - loss: 42952.4408 - mean_squared_error: 42387.8035 - val_loss: 103133.7157 - val_mean_squared_error: 102607.2641\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 96698.76646\n",
      "Epoch 435/550\n",
      "250/250 [==============================] - 0s 225us/step - loss: 38405.0404 - mean_squared_error: 37809.2704 - val_loss: 101685.2833 - val_mean_squared_error: 101141.5547\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 96698.76646\n",
      "Epoch 436/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 40159.9299 - mean_squared_error: 39570.3577 - val_loss: 105893.4157 - val_mean_squared_error: 105372.3175\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 96698.76646\n",
      "Epoch 437/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 38545.7672 - mean_squared_error: 37949.8601 - val_loss: 105442.5142 - val_mean_squared_error: 104909.4450\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 96698.76646\n",
      "Epoch 438/550\n",
      "250/250 [==============================] - 0s 226us/step - loss: 45003.8367 - mean_squared_error: 44440.5433 - val_loss: 105265.3249 - val_mean_squared_error: 104750.0395\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 96698.76646\n",
      "Epoch 439/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 37358.4551 - mean_squared_error: 36780.6043 - val_loss: 103499.1848 - val_mean_squared_error: 102980.3570\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 96698.76646\n",
      "Epoch 440/550\n",
      "250/250 [==============================] - 0s 267us/step - loss: 35716.6328 - mean_squared_error: 35114.2188 - val_loss: 102824.3749 - val_mean_squared_error: 102292.8664\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 96698.76646\n",
      "Epoch 441/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 32871.4723 - mean_squared_error: 32272.7103 - val_loss: 103395.7810 - val_mean_squared_error: 102872.9096\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 96698.76646\n",
      "Epoch 442/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 40465.4184 - mean_squared_error: 39848.3431 - val_loss: 106021.9376 - val_mean_squared_error: 105514.9626\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 96698.76646\n",
      "Epoch 443/550\n",
      "250/250 [==============================] - 0s 264us/step - loss: 36306.1082 - mean_squared_error: 35717.8360 - val_loss: 107038.9568 - val_mean_squared_error: 106525.9178\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 96698.76646\n",
      "Epoch 444/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 41013.3500 - mean_squared_error: 40428.0114 - val_loss: 104616.0472 - val_mean_squared_error: 104088.5661\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 96698.76646\n",
      "Epoch 445/550\n",
      "250/250 [==============================] - 0s 279us/step - loss: 48610.0188 - mean_squared_error: 48051.1872 - val_loss: 107763.3676 - val_mean_squared_error: 107258.7946\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 96698.76646\n",
      "Epoch 446/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 37995.4817 - mean_squared_error: 37421.8637 - val_loss: 107374.5318 - val_mean_squared_error: 106859.4694\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 96698.76646\n",
      "Epoch 447/550\n",
      "250/250 [==============================] - 0s 272us/step - loss: 44285.2633 - mean_squared_error: 43706.8962 - val_loss: 105971.3871 - val_mean_squared_error: 105444.5798\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 96698.76646\n",
      "Epoch 448/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 34762.4788 - mean_squared_error: 34194.1037 - val_loss: 105071.3156 - val_mean_squared_error: 104538.7398\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 96698.76646\n",
      "Epoch 449/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 41938.5825 - mean_squared_error: 41343.3649 - val_loss: 107766.1642 - val_mean_squared_error: 107239.9355\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 96698.76646\n",
      "Epoch 450/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 40980.9799 - mean_squared_error: 40366.0297 - val_loss: 106819.0208 - val_mean_squared_error: 106284.3895\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 96698.76646\n",
      "Epoch 451/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 41638.4208 - mean_squared_error: 41061.9199 - val_loss: 105789.8963 - val_mean_squared_error: 105273.1959\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 96698.76646\n",
      "Epoch 452/550\n",
      "250/250 [==============================] - 0s 284us/step - loss: 44321.1014 - mean_squared_error: 43756.4311 - val_loss: 104231.8615 - val_mean_squared_error: 103703.1848\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 96698.76646\n",
      "Epoch 453/550\n",
      "250/250 [==============================] - 0s 290us/step - loss: 31763.6479 - mean_squared_error: 31184.2458 - val_loss: 101153.9308 - val_mean_squared_error: 100623.3313\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 96698.76646\n",
      "Epoch 454/550\n",
      "250/250 [==============================] - 0s 269us/step - loss: 44180.7215 - mean_squared_error: 43607.8267 - val_loss: 101448.3803 - val_mean_squared_error: 100926.4566\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 96698.76646\n",
      "Epoch 455/550\n",
      "250/250 [==============================] - 0s 284us/step - loss: 47241.7711 - mean_squared_error: 46644.8666 - val_loss: 103691.0611 - val_mean_squared_error: 103180.5594\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 96698.76646\n",
      "Epoch 456/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 34363.5268 - mean_squared_error: 33785.5107 - val_loss: 103035.2796 - val_mean_squared_error: 102507.9760\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 96698.76646\n",
      "Epoch 457/550\n",
      "250/250 [==============================] - 0s 269us/step - loss: 34593.5722 - mean_squared_error: 34016.8569 - val_loss: 100001.4016 - val_mean_squared_error: 99481.6797\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 96698.76646\n",
      "Epoch 458/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 38627.2078 - mean_squared_error: 38032.2248 - val_loss: 101327.3804 - val_mean_squared_error: 100832.4445\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 96698.76646\n",
      "Epoch 459/550\n",
      "250/250 [==============================] - 0s 278us/step - loss: 37897.0871 - mean_squared_error: 37334.2692 - val_loss: 100622.2228 - val_mean_squared_error: 100132.8320\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 96698.76646\n",
      "Epoch 460/550\n",
      "250/250 [==============================] - 0s 273us/step - loss: 36468.3010 - mean_squared_error: 35880.4143 - val_loss: 100765.0193 - val_mean_squared_error: 100279.7878\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 96698.76646\n",
      "Epoch 461/550\n",
      "250/250 [==============================] - 0s 277us/step - loss: 38408.0425 - mean_squared_error: 37850.9393 - val_loss: 104169.2899 - val_mean_squared_error: 103695.0099\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 96698.76646\n",
      "Epoch 462/550\n",
      "250/250 [==============================] - 0s 273us/step - loss: 43000.0297 - mean_squared_error: 42426.8269 - val_loss: 102484.9463 - val_mean_squared_error: 102006.4639\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 96698.76646\n",
      "Epoch 463/550\n",
      "250/250 [==============================] - 0s 266us/step - loss: 40259.9615 - mean_squared_error: 39706.0930 - val_loss: 102155.0135 - val_mean_squared_error: 101665.1487\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 96698.76646\n",
      "Epoch 464/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 33823.2933 - mean_squared_error: 33233.9431 - val_loss: 101566.7854 - val_mean_squared_error: 101054.5837\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 96698.76646\n",
      "Epoch 465/550\n",
      "250/250 [==============================] - 0s 284us/step - loss: 41979.4137 - mean_squared_error: 41392.0500 - val_loss: 102386.3712 - val_mean_squared_error: 101907.1159\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 96698.76646\n",
      "Epoch 466/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 268us/step - loss: 42731.1732 - mean_squared_error: 42176.8017 - val_loss: 106050.0826 - val_mean_squared_error: 105587.9734\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 96698.76646\n",
      "Epoch 467/550\n",
      "250/250 [==============================] - 0s 290us/step - loss: 47780.8624 - mean_squared_error: 47228.8260 - val_loss: 104459.3337 - val_mean_squared_error: 103985.5349\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 96698.76646\n",
      "Epoch 468/550\n",
      "250/250 [==============================] - 0s 282us/step - loss: 47552.4233 - mean_squared_error: 47023.4356 - val_loss: 102470.2939 - val_mean_squared_error: 101971.9103\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 96698.76646\n",
      "Epoch 469/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 46870.1050 - mean_squared_error: 46306.0025 - val_loss: 102404.2271 - val_mean_squared_error: 101888.1030\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 96698.76646\n",
      "Epoch 470/550\n",
      "250/250 [==============================] - 0s 273us/step - loss: 33846.0553 - mean_squared_error: 33273.9996 - val_loss: 103773.4090 - val_mean_squared_error: 103254.5855\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 96698.76646\n",
      "Epoch 471/550\n",
      "250/250 [==============================] - 0s 271us/step - loss: 42975.0465 - mean_squared_error: 42414.8534 - val_loss: 103338.5163 - val_mean_squared_error: 102823.9538\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 96698.76646\n",
      "Epoch 472/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 34110.9969 - mean_squared_error: 33545.3267 - val_loss: 103193.9919 - val_mean_squared_error: 102669.2875\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 96698.76646\n",
      "Epoch 473/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 39155.7392 - mean_squared_error: 38563.1945 - val_loss: 104698.1879 - val_mean_squared_error: 104179.6359\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 96698.76646\n",
      "Epoch 474/550\n",
      "250/250 [==============================] - 0s 270us/step - loss: 43089.2601 - mean_squared_error: 42509.5499 - val_loss: 105285.1203 - val_mean_squared_error: 104771.0377\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 96698.76646\n",
      "Epoch 475/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 40315.7603 - mean_squared_error: 39738.4649 - val_loss: 106225.8890 - val_mean_squared_error: 105707.9289\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 96698.76646\n",
      "Epoch 476/550\n",
      "250/250 [==============================] - 0s 268us/step - loss: 43836.8718 - mean_squared_error: 43281.8843 - val_loss: 105229.7002 - val_mean_squared_error: 104702.9166\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 96698.76646\n",
      "Epoch 477/550\n",
      "250/250 [==============================] - 0s 281us/step - loss: 42203.5323 - mean_squared_error: 41602.3931 - val_loss: 103119.4943 - val_mean_squared_error: 102595.9157\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 96698.76646\n",
      "Epoch 478/550\n",
      "250/250 [==============================] - 0s 274us/step - loss: 37784.2111 - mean_squared_error: 37181.0481 - val_loss: 103575.4854 - val_mean_squared_error: 103053.9794\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 96698.76646\n",
      "Epoch 479/550\n",
      "250/250 [==============================] - 0s 276us/step - loss: 43928.5216 - mean_squared_error: 43352.1591 - val_loss: 103521.2776 - val_mean_squared_error: 102999.4918\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 96698.76646\n",
      "Epoch 480/550\n",
      "250/250 [==============================] - 0s 280us/step - loss: 37861.0882 - mean_squared_error: 37294.5244 - val_loss: 102482.7447 - val_mean_squared_error: 101973.7162\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 96698.76646\n",
      "Epoch 481/550\n",
      "250/250 [==============================] - 0s 256us/step - loss: 36603.6994 - mean_squared_error: 36003.9225 - val_loss: 105624.8871 - val_mean_squared_error: 105095.1959\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 96698.76646\n",
      "Epoch 482/550\n",
      "250/250 [==============================] - 0s 265us/step - loss: 43319.5467 - mean_squared_error: 42726.7566 - val_loss: 103191.9174 - val_mean_squared_error: 102655.9964\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 96698.76646\n",
      "Epoch 483/550\n",
      "250/250 [==============================] - 0s 254us/step - loss: 45401.7651 - mean_squared_error: 44838.5163 - val_loss: 100673.9449 - val_mean_squared_error: 100139.6649\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 96698.76646\n",
      "Epoch 484/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 38211.9329 - mean_squared_error: 37611.8965 - val_loss: 103302.9256 - val_mean_squared_error: 102783.7766\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 96698.76646\n",
      "Epoch 485/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 36148.6531 - mean_squared_error: 35598.1205 - val_loss: 103093.9962 - val_mean_squared_error: 102580.3566\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 96698.76646\n",
      "Epoch 486/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 43704.3038 - mean_squared_error: 43153.8541 - val_loss: 102622.4512 - val_mean_squared_error: 102113.5053\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 96698.76646\n",
      "Epoch 487/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 33008.9169 - mean_squared_error: 32418.8013 - val_loss: 100593.2903 - val_mean_squared_error: 100070.6077\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 96698.76646\n",
      "Epoch 488/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 39523.7735 - mean_squared_error: 38951.1659 - val_loss: 98359.9448 - val_mean_squared_error: 97854.2109\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 96698.76646\n",
      "Epoch 489/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 36186.7498 - mean_squared_error: 35625.2509 - val_loss: 98140.3574 - val_mean_squared_error: 97631.6677\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 96698.76646\n",
      "Epoch 490/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 34152.3641 - mean_squared_error: 33554.0184 - val_loss: 99677.5331 - val_mean_squared_error: 99155.7672\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 96698.76646\n",
      "Epoch 491/550\n",
      "250/250 [==============================] - 0s 245us/step - loss: 44450.2051 - mean_squared_error: 43855.4871 - val_loss: 101009.8520 - val_mean_squared_error: 100499.3064\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 96698.76646\n",
      "Epoch 492/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 30781.3326 - mean_squared_error: 30156.6629 - val_loss: 103056.1369 - val_mean_squared_error: 102534.5116\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 96698.76646\n",
      "Epoch 493/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 47537.7343 - mean_squared_error: 46951.0085 - val_loss: 101098.0080 - val_mean_squared_error: 100578.3284\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 96698.76646\n",
      "Epoch 494/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 32314.7600 - mean_squared_error: 31693.2529 - val_loss: 102335.6795 - val_mean_squared_error: 101814.1129\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 96698.76646\n",
      "Epoch 495/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 33638.1536 - mean_squared_error: 33072.3615 - val_loss: 99025.1924 - val_mean_squared_error: 98507.6102\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 96698.76646\n",
      "Epoch 496/550\n",
      "250/250 [==============================] - 0s 227us/step - loss: 31456.9074 - mean_squared_error: 30843.3892 - val_loss: 97981.3184 - val_mean_squared_error: 97472.6021\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 96698.76646\n",
      "Epoch 497/550\n",
      "250/250 [==============================] - 0s 228us/step - loss: 46782.6546 - mean_squared_error: 46186.7954 - val_loss: 101669.5483 - val_mean_squared_error: 101160.5811\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 96698.76646\n",
      "Epoch 498/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 36216.6726 - mean_squared_error: 35635.8684 - val_loss: 101486.3040 - val_mean_squared_error: 100968.0831\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 96698.76646\n",
      "Epoch 499/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 33377.2337 - mean_squared_error: 32754.0290 - val_loss: 100065.3707 - val_mean_squared_error: 99545.4847\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 96698.76646\n",
      "Epoch 500/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 40334.3047 - mean_squared_error: 39748.9326 - val_loss: 101593.6482 - val_mean_squared_error: 101067.7613\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 96698.76646\n",
      "Epoch 501/550\n",
      "250/250 [==============================] - 0s 242us/step - loss: 35739.6700 - mean_squared_error: 35132.0081 - val_loss: 100054.7366 - val_mean_squared_error: 99518.8775\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 96698.76646\n",
      "Epoch 502/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 48574.7087 - mean_squared_error: 47957.2756 - val_loss: 102685.0766 - val_mean_squared_error: 102144.6482\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 96698.76646\n",
      "Epoch 503/550\n",
      "250/250 [==============================] - 0s 250us/step - loss: 39626.3864 - mean_squared_error: 39041.7059 - val_loss: 101306.3133 - val_mean_squared_error: 100769.3523\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 96698.76646\n",
      "Epoch 504/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 45460.2055 - mean_squared_error: 44842.1696 - val_loss: 102472.3966 - val_mean_squared_error: 101942.2367\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 96698.76646\n",
      "Epoch 505/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 42049.6856 - mean_squared_error: 41474.5995 - val_loss: 104226.1763 - val_mean_squared_error: 103703.5163\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 96698.76646\n",
      "Epoch 506/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 41327.0426 - mean_squared_error: 40750.8156 - val_loss: 102321.2747 - val_mean_squared_error: 101799.1264\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 96698.76646\n",
      "Epoch 507/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 42850.7368 - mean_squared_error: 42256.5066 - val_loss: 103769.4075 - val_mean_squared_error: 103245.2351\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 96698.76646\n",
      "Epoch 508/550\n",
      "250/250 [==============================] - 0s 233us/step - loss: 39155.0337 - mean_squared_error: 38551.3188 - val_loss: 101259.9992 - val_mean_squared_error: 100718.7786\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 96698.76646\n",
      "Epoch 509/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 35644.5771 - mean_squared_error: 35062.9186 - val_loss: 101969.4434 - val_mean_squared_error: 101440.6367\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 96698.76646\n",
      "Epoch 510/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 32506.4003 - mean_squared_error: 31908.4677 - val_loss: 101282.6786 - val_mean_squared_error: 100768.4042\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 96698.76646\n",
      "Epoch 511/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 40069.1208 - mean_squared_error: 39493.4066 - val_loss: 103109.0385 - val_mean_squared_error: 102595.5668\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 96698.76646\n",
      "Epoch 512/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 40293.6751 - mean_squared_error: 39714.3718 - val_loss: 103694.2031 - val_mean_squared_error: 103184.7771\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 96698.76646\n",
      "Epoch 513/550\n",
      "250/250 [==============================] - 0s 260us/step - loss: 36821.4454 - mean_squared_error: 36239.9757 - val_loss: 104217.1184 - val_mean_squared_error: 103691.8076\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 96698.76646\n",
      "Epoch 514/550\n",
      "250/250 [==============================] - 0s 258us/step - loss: 36454.6146 - mean_squared_error: 35869.1922 - val_loss: 102933.0444 - val_mean_squared_error: 102406.3636\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 96698.76646\n",
      "Epoch 515/550\n",
      "250/250 [==============================] - 0s 249us/step - loss: 43374.2443 - mean_squared_error: 42794.9078 - val_loss: 106667.4238 - val_mean_squared_error: 106163.7098\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 96698.76646\n",
      "Epoch 516/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 32902.6056 - mean_squared_error: 32295.4992 - val_loss: 107605.4372 - val_mean_squared_error: 107106.0905\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 96698.76646\n",
      "Epoch 517/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 37944.3636 - mean_squared_error: 37367.1721 - val_loss: 106575.1468 - val_mean_squared_error: 106073.7295\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 96698.76646\n",
      "Epoch 518/550\n",
      "250/250 [==============================] - 0s 224us/step - loss: 38463.0062 - mean_squared_error: 37893.7643 - val_loss: 109395.0280 - val_mean_squared_error: 108898.7188\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 96698.76646\n",
      "Epoch 519/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 55601.4801 - mean_squared_error: 55002.4893 - val_loss: 106945.2038 - val_mean_squared_error: 106432.4742\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 96698.76646\n",
      "Epoch 520/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 32151.6930 - mean_squared_error: 31566.9637 - val_loss: 104034.3001 - val_mean_squared_error: 103532.3090\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 96698.76646\n",
      "Epoch 521/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 38637.8619 - mean_squared_error: 38078.9304 - val_loss: 104374.2458 - val_mean_squared_error: 103877.6215\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 96698.76646\n",
      "Epoch 522/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 36112.1177 - mean_squared_error: 35519.5471 - val_loss: 103429.4900 - val_mean_squared_error: 102921.9788\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 96698.76646\n",
      "Epoch 523/550\n",
      "250/250 [==============================] - 0s 246us/step - loss: 39938.0676 - mean_squared_error: 39365.8918 - val_loss: 102145.5967 - val_mean_squared_error: 101627.7927\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 96698.76646\n",
      "Epoch 524/550\n",
      "250/250 [==============================] - 0s 231us/step - loss: 42488.4069 - mean_squared_error: 41912.6805 - val_loss: 103513.9573 - val_mean_squared_error: 102968.0008\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 96698.76646\n",
      "Epoch 525/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 41130.5353 - mean_squared_error: 40551.8372 - val_loss: 102706.6017 - val_mean_squared_error: 102183.0900\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 96698.76646\n",
      "Epoch 526/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 31889.0050 - mean_squared_error: 31316.6301 - val_loss: 100968.8292 - val_mean_squared_error: 100460.9311\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 96698.76646\n",
      "Epoch 527/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 38433.7571 - mean_squared_error: 37867.8464 - val_loss: 101427.6537 - val_mean_squared_error: 100911.1198\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 96698.76646\n",
      "Epoch 528/550\n",
      "250/250 [==============================] - 0s 244us/step - loss: 41704.6497 - mean_squared_error: 41089.7225 - val_loss: 101426.0951 - val_mean_squared_error: 100906.1857\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 96698.76646\n",
      "Epoch 529/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 38656.7027 - mean_squared_error: 38055.6938 - val_loss: 105802.4524 - val_mean_squared_error: 105273.3774\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 96698.76646\n",
      "Epoch 530/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 34568.8408 - mean_squared_error: 33953.8404 - val_loss: 102389.3376 - val_mean_squared_error: 101857.5566\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 96698.76646\n",
      "Epoch 531/550\n",
      "250/250 [==============================] - 0s 240us/step - loss: 34222.1599 - mean_squared_error: 33600.9890 - val_loss: 103297.8792 - val_mean_squared_error: 102762.0557\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 96698.76646\n",
      "Epoch 532/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 45925.0482 - mean_squared_error: 45320.5701 - val_loss: 107799.5180 - val_mean_squared_error: 107266.5201\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 96698.76646\n",
      "Epoch 533/550\n",
      "250/250 [==============================] - 0s 237us/step - loss: 34343.1443 - mean_squared_error: 33746.0743 - val_loss: 104218.3763 - val_mean_squared_error: 103673.0724\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 96698.76646\n",
      "Epoch 534/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 234us/step - loss: 37235.3115 - mean_squared_error: 36645.0720 - val_loss: 102522.6532 - val_mean_squared_error: 101984.0257\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 96698.76646\n",
      "Epoch 535/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 38681.0798 - mean_squared_error: 38082.7724 - val_loss: 100644.1197 - val_mean_squared_error: 100111.8899\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 96698.76646\n",
      "Epoch 536/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 31478.8498 - mean_squared_error: 30881.3381 - val_loss: 98955.3883 - val_mean_squared_error: 98408.2412\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 96698.76646\n",
      "Epoch 537/550\n",
      "250/250 [==============================] - 0s 232us/step - loss: 36603.3013 - mean_squared_error: 35963.6448 - val_loss: 99188.6204 - val_mean_squared_error: 98639.5562\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 96698.76646\n",
      "Epoch 538/550\n",
      "250/250 [==============================] - 0s 238us/step - loss: 42285.8516 - mean_squared_error: 41685.0483 - val_loss: 98668.3917 - val_mean_squared_error: 98110.1582\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 96698.76646\n",
      "Epoch 539/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 36052.3356 - mean_squared_error: 35445.7922 - val_loss: 99226.8383 - val_mean_squared_error: 98660.8956\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 96698.76646\n",
      "Epoch 540/550\n",
      "250/250 [==============================] - 0s 230us/step - loss: 30004.1528 - mean_squared_error: 29368.7186 - val_loss: 100871.4047 - val_mean_squared_error: 100317.5512\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 96698.76646\n",
      "Epoch 541/550\n",
      "250/250 [==============================] - 0s 243us/step - loss: 37482.0916 - mean_squared_error: 36847.6982 - val_loss: 103487.7698 - val_mean_squared_error: 102933.8955\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 96698.76646\n",
      "Epoch 542/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 47048.8520 - mean_squared_error: 46437.4496 - val_loss: 104171.8661 - val_mean_squared_error: 103646.1592\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 96698.76646\n",
      "Epoch 543/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 42723.8258 - mean_squared_error: 42118.0474 - val_loss: 101841.4222 - val_mean_squared_error: 101300.5078\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 96698.76646\n",
      "Epoch 544/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 34518.0926 - mean_squared_error: 33900.4591 - val_loss: 103291.3710 - val_mean_squared_error: 102762.0610\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 96698.76646\n",
      "Epoch 545/550\n",
      "250/250 [==============================] - 0s 248us/step - loss: 38668.5807 - mean_squared_error: 38088.5799 - val_loss: 101801.7189 - val_mean_squared_error: 101275.7475\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 96698.76646\n",
      "Epoch 546/550\n",
      "250/250 [==============================] - 0s 235us/step - loss: 36357.7878 - mean_squared_error: 35742.7353 - val_loss: 104617.8841 - val_mean_squared_error: 104086.2355\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 96698.76646\n",
      "Epoch 547/550\n",
      "250/250 [==============================] - 0s 247us/step - loss: 39049.7403 - mean_squared_error: 38452.8732 - val_loss: 104742.7355 - val_mean_squared_error: 104210.6484\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 96698.76646\n",
      "Epoch 548/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 43036.0266 - mean_squared_error: 42429.7945 - val_loss: 107917.2607 - val_mean_squared_error: 107382.6129\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 96698.76646\n",
      "Epoch 549/550\n",
      "250/250 [==============================] - 0s 234us/step - loss: 41080.0230 - mean_squared_error: 40457.1030 - val_loss: 105975.6244 - val_mean_squared_error: 105435.2041\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 96698.76646\n",
      "Epoch 550/550\n",
      "250/250 [==============================] - 0s 236us/step - loss: 30697.1116 - mean_squared_error: 30079.1104 - val_loss: 101253.8623 - val_mean_squared_error: 100711.9001\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 96698.76646\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 550, \n",
    "          batch_size = 15, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b24ded5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b24ded92e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### модель посложнее 6, модель переобучилась, уменьшили кол-во эпох"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. непонятно на что влияет параметр verbose, но изменение его с 1 на 2 увеличило стабильность\n",
    "2. побольше почитать про reducelronPlateau\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(164, input_dim=WINDOW,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.65))\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250 samples, validate on 28 samples\n",
      "Epoch 1/350\n",
      " - 2s - loss: 303378.5072 - mean_squared_error: 303065.5887 - val_loss: 616338.1256 - val_mean_squared_error: 616156.7517\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 616338.12556, saving model to test.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:972: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_mse` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/350\n",
      " - 0s - loss: 297166.1620 - mean_squared_error: 296715.0109 - val_loss: 598270.5921 - val_mean_squared_error: 597839.2132\n",
      "\n",
      "Epoch 00002: val_loss improved from 616338.12556 to 598270.59208, saving model to test.hdf5\n",
      "Epoch 3/350\n",
      " - 0s - loss: 291691.8453 - mean_squared_error: 291024.1237 - val_loss: 584815.1624 - val_mean_squared_error: 584184.3744\n",
      "\n",
      "Epoch 00003: val_loss improved from 598270.59208 to 584815.16239, saving model to test.hdf5\n",
      "Epoch 4/350\n",
      " - 0s - loss: 286852.4126 - mean_squared_error: 286026.0280 - val_loss: 573870.4420 - val_mean_squared_error: 573102.0575\n",
      "\n",
      "Epoch 00004: val_loss improved from 584815.16239 to 573870.44196, saving model to test.hdf5\n",
      "Epoch 5/350\n",
      " - 0s - loss: 281740.5975 - mean_squared_error: 280816.3535 - val_loss: 563652.8092 - val_mean_squared_error: 562706.2556\n",
      "\n",
      "Epoch 00005: val_loss improved from 573870.44196 to 563652.80915, saving model to test.hdf5\n",
      "Epoch 6/350\n",
      " - 0s - loss: 277485.1901 - mean_squared_error: 276469.2164 - val_loss: 554253.4777 - val_mean_squared_error: 553227.8694\n",
      "\n",
      "Epoch 00006: val_loss improved from 563652.80915 to 554253.47768, saving model to test.hdf5\n",
      "Epoch 7/350\n",
      " - 0s - loss: 271023.1547 - mean_squared_error: 269989.3442 - val_loss: 543554.7338 - val_mean_squared_error: 542495.5441\n",
      "\n",
      "Epoch 00007: val_loss improved from 554253.47768 to 543554.73382, saving model to test.hdf5\n",
      "Epoch 8/350\n",
      " - 0s - loss: 267264.8691 - mean_squared_error: 266179.1374 - val_loss: 532984.4526 - val_mean_squared_error: 531839.3398\n",
      "\n",
      "Epoch 00008: val_loss improved from 543554.73382 to 532984.45257, saving model to test.hdf5\n",
      "Epoch 9/350\n",
      " - 0s - loss: 260528.4321 - mean_squared_error: 259404.7324 - val_loss: 523173.7193 - val_mean_squared_error: 521988.9933\n",
      "\n",
      "Epoch 00009: val_loss improved from 532984.45257 to 523173.71931, saving model to test.hdf5\n",
      "Epoch 10/350\n",
      " - 0s - loss: 254240.8737 - mean_squared_error: 253140.4198 - val_loss: 512854.2070 - val_mean_squared_error: 511659.1272\n",
      "\n",
      "Epoch 00010: val_loss improved from 523173.71931 to 512854.20703, saving model to test.hdf5\n",
      "Epoch 11/350\n",
      " - 0s - loss: 250090.7432 - mean_squared_error: 248928.9792 - val_loss: 501428.9007 - val_mean_squared_error: 500143.9102\n",
      "\n",
      "Epoch 00011: val_loss improved from 512854.20703 to 501428.90067, saving model to test.hdf5\n",
      "Epoch 12/350\n",
      " - 0s - loss: 241491.6411 - mean_squared_error: 240358.5691 - val_loss: 489628.9442 - val_mean_squared_error: 488403.5485\n",
      "\n",
      "Epoch 00012: val_loss improved from 501428.90067 to 489628.94420, saving model to test.hdf5\n",
      "Epoch 13/350\n",
      " - 0s - loss: 235701.1786 - mean_squared_error: 234636.6781 - val_loss: 481802.1998 - val_mean_squared_error: 480656.7612\n",
      "\n",
      "Epoch 00013: val_loss improved from 489628.94420 to 481802.19978, saving model to test.hdf5\n",
      "Epoch 14/350\n",
      " - 0s - loss: 226574.3700 - mean_squared_error: 225517.6498 - val_loss: 468233.5006 - val_mean_squared_error: 467033.0910\n",
      "\n",
      "Epoch 00014: val_loss improved from 481802.19978 to 468233.50056, saving model to test.hdf5\n",
      "Epoch 15/350\n",
      " - 0s - loss: 222197.3788 - mean_squared_error: 221060.9110 - val_loss: 453028.4163 - val_mean_squared_error: 451774.5977\n",
      "\n",
      "Epoch 00015: val_loss improved from 468233.50056 to 453028.41629, saving model to test.hdf5\n",
      "Epoch 16/350\n",
      " - 0s - loss: 212696.5736 - mean_squared_error: 211573.7450 - val_loss: 439537.8426 - val_mean_squared_error: 438283.8410\n",
      "\n",
      "Epoch 00016: val_loss improved from 453028.41629 to 439537.84263, saving model to test.hdf5\n",
      "Epoch 17/350\n",
      " - 0s - loss: 208355.6706 - mean_squared_error: 207222.5377 - val_loss: 430256.8248 - val_mean_squared_error: 429045.7093\n",
      "\n",
      "Epoch 00017: val_loss improved from 439537.84263 to 430256.82478, saving model to test.hdf5\n",
      "Epoch 18/350\n",
      " - 0s - loss: 200883.0430 - mean_squared_error: 199738.9509 - val_loss: 422211.4436 - val_mean_squared_error: 420984.8772\n",
      "\n",
      "Epoch 00018: val_loss improved from 430256.82478 to 422211.44364, saving model to test.hdf5\n",
      "Epoch 19/350\n",
      " - 0s - loss: 197027.7228 - mean_squared_error: 195908.3407 - val_loss: 409912.3644 - val_mean_squared_error: 408684.8114\n",
      "\n",
      "Epoch 00019: val_loss improved from 422211.44364 to 409912.36440, saving model to test.hdf5\n",
      "Epoch 20/350\n",
      " - 0s - loss: 185671.8037 - mean_squared_error: 184573.8020 - val_loss: 395359.4732 - val_mean_squared_error: 394194.0519\n",
      "\n",
      "Epoch 00020: val_loss improved from 409912.36440 to 395359.47321, saving model to test.hdf5\n",
      "Epoch 21/350\n",
      " - 0s - loss: 179012.9437 - mean_squared_error: 177888.4755 - val_loss: 383133.3633 - val_mean_squared_error: 381931.8131\n",
      "\n",
      "Epoch 00021: val_loss improved from 395359.47321 to 383133.36328, saving model to test.hdf5\n",
      "Epoch 22/350\n",
      " - 0s - loss: 175604.3496 - mean_squared_error: 174453.9332 - val_loss: 369045.9291 - val_mean_squared_error: 367795.5452\n",
      "\n",
      "Epoch 00022: val_loss improved from 383133.36328 to 369045.92913, saving model to test.hdf5\n",
      "Epoch 23/350\n",
      " - 0s - loss: 168058.7336 - mean_squared_error: 166916.3764 - val_loss: 357054.0854 - val_mean_squared_error: 355779.8454\n",
      "\n",
      "Epoch 00023: val_loss improved from 369045.92913 to 357054.08538, saving model to test.hdf5\n",
      "Epoch 24/350\n",
      " - 0s - loss: 157954.8609 - mean_squared_error: 156824.9306 - val_loss: 351433.7578 - val_mean_squared_error: 350254.9291\n",
      "\n",
      "Epoch 00024: val_loss improved from 357054.08538 to 351433.75781, saving model to test.hdf5\n",
      "Epoch 25/350\n",
      " - 0s - loss: 154058.5945 - mean_squared_error: 152964.7803 - val_loss: 337302.7171 - val_mean_squared_error: 336127.1557\n",
      "\n",
      "Epoch 00025: val_loss improved from 351433.75781 to 337302.71708, saving model to test.hdf5\n",
      "Epoch 26/350\n",
      " - 0s - loss: 150750.1215 - mean_squared_error: 149695.4188 - val_loss: 329309.5234 - val_mean_squared_error: 328184.3510\n",
      "\n",
      "Epoch 00026: val_loss improved from 337302.71708 to 329309.52344, saving model to test.hdf5\n",
      "Epoch 27/350\n",
      " - 0s - loss: 142161.0652 - mean_squared_error: 141129.9393 - val_loss: 318137.2310 - val_mean_squared_error: 317044.5419\n",
      "\n",
      "Epoch 00027: val_loss improved from 329309.52344 to 318137.23103, saving model to test.hdf5\n",
      "Epoch 28/350\n",
      " - 0s - loss: 137379.4498 - mean_squared_error: 136411.6911 - val_loss: 302004.8644 - val_mean_squared_error: 300886.6629\n",
      "\n",
      "Epoch 00028: val_loss improved from 318137.23103 to 302004.86440, saving model to test.hdf5\n",
      "Epoch 29/350\n",
      " - 0s - loss: 133871.0627 - mean_squared_error: 132933.4805 - val_loss: 284677.1429 - val_mean_squared_error: 283457.1699\n",
      "\n",
      "Epoch 00029: val_loss improved from 302004.86440 to 284677.14286, saving model to test.hdf5\n",
      "Epoch 30/350\n",
      " - 0s - loss: 124391.3609 - mean_squared_error: 123258.7770 - val_loss: 280086.1685 - val_mean_squared_error: 278932.2528\n",
      "\n",
      "Epoch 00030: val_loss improved from 284677.14286 to 280086.16853, saving model to test.hdf5\n",
      "Epoch 31/350\n",
      " - 0s - loss: 117849.8909 - mean_squared_error: 116885.1185 - val_loss: 272558.3011 - val_mean_squared_error: 271403.0304\n",
      "\n",
      "Epoch 00031: val_loss improved from 280086.16853 to 272558.30106, saving model to test.hdf5\n",
      "Epoch 32/350\n",
      " - 0s - loss: 114036.3829 - mean_squared_error: 112995.9589 - val_loss: 261653.2190 - val_mean_squared_error: 260476.0530\n",
      "\n",
      "Epoch 00032: val_loss improved from 272558.30106 to 261653.21903, saving model to test.hdf5\n",
      "Epoch 33/350\n",
      " - 0s - loss: 114061.6314 - mean_squared_error: 113050.3405 - val_loss: 250840.7160 - val_mean_squared_error: 249640.8881\n",
      "\n",
      "Epoch 00033: val_loss improved from 261653.21903 to 250840.71596, saving model to test.hdf5\n",
      "Epoch 34/350\n",
      " - 0s - loss: 114638.7950 - mean_squared_error: 113583.4084 - val_loss: 236586.3636 - val_mean_squared_error: 235280.9269\n",
      "\n",
      "Epoch 00034: val_loss improved from 250840.71596 to 236586.36356, saving model to test.hdf5\n",
      "Epoch 35/350\n",
      " - 0s - loss: 99477.6671 - mean_squared_error: 98341.1783 - val_loss: 229428.3142 - val_mean_squared_error: 228238.6560\n",
      "\n",
      "Epoch 00035: val_loss improved from 236586.36356 to 229428.31417, saving model to test.hdf5\n",
      "Epoch 36/350\n",
      " - 0s - loss: 98429.3810 - mean_squared_error: 97405.5246 - val_loss: 226457.9540 - val_mean_squared_error: 225317.7453\n",
      "\n",
      "Epoch 00036: val_loss improved from 229428.31417 to 226457.95396, saving model to test.hdf5\n",
      "Epoch 37/350\n",
      " - 0s - loss: 106477.3683 - mean_squared_error: 105352.4795 - val_loss: 216043.9316 - val_mean_squared_error: 214873.2182\n",
      "\n",
      "Epoch 00037: val_loss improved from 226457.95396 to 216043.93164, saving model to test.hdf5\n",
      "Epoch 38/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 92894.5422 - mean_squared_error: 91762.1895 - val_loss: 206333.9007 - val_mean_squared_error: 205127.1713\n",
      "\n",
      "Epoch 00038: val_loss improved from 216043.93164 to 206333.90067, saving model to test.hdf5\n",
      "Epoch 39/350\n",
      " - 0s - loss: 86236.1068 - mean_squared_error: 85116.2433 - val_loss: 195839.6144 - val_mean_squared_error: 194611.3616\n",
      "\n",
      "Epoch 00039: val_loss improved from 206333.90067 to 195839.61440, saving model to test.hdf5\n",
      "Epoch 40/350\n",
      " - 0s - loss: 83790.5183 - mean_squared_error: 82686.7742 - val_loss: 192360.7302 - val_mean_squared_error: 191181.2564\n",
      "\n",
      "Epoch 00040: val_loss improved from 195839.61440 to 192360.73019, saving model to test.hdf5\n",
      "Epoch 41/350\n",
      " - 0s - loss: 78879.5955 - mean_squared_error: 77749.1210 - val_loss: 189325.7840 - val_mean_squared_error: 188092.2985\n",
      "\n",
      "Epoch 00041: val_loss improved from 192360.73019 to 189325.78404, saving model to test.hdf5\n",
      "Epoch 42/350\n",
      " - 0s - loss: 78132.0481 - mean_squared_error: 77031.5318 - val_loss: 183757.0045 - val_mean_squared_error: 182599.4222\n",
      "\n",
      "Epoch 00042: val_loss improved from 189325.78404 to 183757.00446, saving model to test.hdf5\n",
      "Epoch 43/350\n",
      " - 0s - loss: 81687.7480 - mean_squared_error: 80626.4292 - val_loss: 177144.3619 - val_mean_squared_error: 175974.6412\n",
      "\n",
      "Epoch 00043: val_loss improved from 183757.00446 to 177144.36189, saving model to test.hdf5\n",
      "Epoch 44/350\n",
      " - 0s - loss: 69850.6630 - mean_squared_error: 68782.9183 - val_loss: 178154.3644 - val_mean_squared_error: 177004.7930\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 177144.36189\n",
      "Epoch 45/350\n",
      " - 0s - loss: 72425.9903 - mean_squared_error: 71310.3092 - val_loss: 171334.6348 - val_mean_squared_error: 170236.7369\n",
      "\n",
      "Epoch 00045: val_loss improved from 177144.36189 to 171334.63477, saving model to test.hdf5\n",
      "Epoch 46/350\n",
      " - 0s - loss: 63921.0287 - mean_squared_error: 62874.4970 - val_loss: 167271.3719 - val_mean_squared_error: 166226.0924\n",
      "\n",
      "Epoch 00046: val_loss improved from 171334.63477 to 167271.37193, saving model to test.hdf5\n",
      "Epoch 47/350\n",
      " - 0s - loss: 62265.0146 - mean_squared_error: 61258.3941 - val_loss: 162304.8485 - val_mean_squared_error: 161302.6908\n",
      "\n",
      "Epoch 00047: val_loss improved from 167271.37193 to 162304.84849, saving model to test.hdf5\n",
      "Epoch 48/350\n",
      " - 0s - loss: 66854.9379 - mean_squared_error: 65818.4767 - val_loss: 157549.0223 - val_mean_squared_error: 156561.1191\n",
      "\n",
      "Epoch 00048: val_loss improved from 162304.84849 to 157549.02232, saving model to test.hdf5\n",
      "Epoch 49/350\n",
      " - 0s - loss: 68931.9236 - mean_squared_error: 67922.3696 - val_loss: 153300.0837 - val_mean_squared_error: 152276.0670\n",
      "\n",
      "Epoch 00049: val_loss improved from 157549.02232 to 153300.08371, saving model to test.hdf5\n",
      "Epoch 50/350\n",
      " - 0s - loss: 56159.9437 - mean_squared_error: 55159.8794 - val_loss: 149983.4975 - val_mean_squared_error: 149049.6666\n",
      "\n",
      "Epoch 00050: val_loss improved from 153300.08371 to 149983.49749, saving model to test.hdf5\n",
      "Epoch 51/350\n",
      " - 0s - loss: 74892.3661 - mean_squared_error: 73948.1863 - val_loss: 146960.9358 - val_mean_squared_error: 145964.7352\n",
      "\n",
      "Epoch 00051: val_loss improved from 149983.49749 to 146960.93583, saving model to test.hdf5\n",
      "Epoch 52/350\n",
      " - 0s - loss: 53394.6872 - mean_squared_error: 52352.5130 - val_loss: 146556.9662 - val_mean_squared_error: 145627.7637\n",
      "\n",
      "Epoch 00052: val_loss improved from 146960.93583 to 146556.96624, saving model to test.hdf5\n",
      "Epoch 53/350\n",
      " - 0s - loss: 59658.5066 - mean_squared_error: 58672.6996 - val_loss: 142309.8055 - val_mean_squared_error: 141350.5140\n",
      "\n",
      "Epoch 00053: val_loss improved from 146556.96624 to 142309.80552, saving model to test.hdf5\n",
      "Epoch 54/350\n",
      " - 0s - loss: 49957.6959 - mean_squared_error: 48925.0709 - val_loss: 142623.1599 - val_mean_squared_error: 141665.7028\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 142309.80552\n",
      "Epoch 55/350\n",
      " - 0s - loss: 55327.0070 - mean_squared_error: 54314.4917 - val_loss: 139922.8888 - val_mean_squared_error: 138990.8210\n",
      "\n",
      "Epoch 00055: val_loss improved from 142309.80552 to 139922.88881, saving model to test.hdf5\n",
      "Epoch 56/350\n",
      " - 0s - loss: 52487.1633 - mean_squared_error: 51523.8337 - val_loss: 133958.6084 - val_mean_squared_error: 132990.0723\n",
      "\n",
      "Epoch 00056: val_loss improved from 139922.88881 to 133958.60840, saving model to test.hdf5\n",
      "Epoch 57/350\n",
      " - 0s - loss: 49192.6236 - mean_squared_error: 48236.5376 - val_loss: 127556.4860 - val_mean_squared_error: 126628.1258\n",
      "\n",
      "Epoch 00057: val_loss improved from 133958.60840 to 127556.48605, saving model to test.hdf5\n",
      "Epoch 58/350\n",
      " - 0s - loss: 52200.0939 - mean_squared_error: 51260.7131 - val_loss: 125282.9399 - val_mean_squared_error: 124394.7693\n",
      "\n",
      "Epoch 00058: val_loss improved from 127556.48605 to 125282.93987, saving model to test.hdf5\n",
      "Epoch 59/350\n",
      " - 0s - loss: 48474.8187 - mean_squared_error: 47579.7401 - val_loss: 122366.1599 - val_mean_squared_error: 121452.2155\n",
      "\n",
      "Epoch 00059: val_loss improved from 125282.93987 to 122366.15988, saving model to test.hdf5\n",
      "Epoch 60/350\n",
      " - 0s - loss: 46941.6909 - mean_squared_error: 45950.7811 - val_loss: 121511.7656 - val_mean_squared_error: 120630.8789\n",
      "\n",
      "Epoch 00060: val_loss improved from 122366.15988 to 121511.76562, saving model to test.hdf5\n",
      "Epoch 61/350\n",
      " - 0s - loss: 57370.3612 - mean_squared_error: 56446.2917 - val_loss: 123814.0407 - val_mean_squared_error: 122989.3477\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 121511.76562\n",
      "Epoch 62/350\n",
      " - 0s - loss: 48528.4661 - mean_squared_error: 47599.0819 - val_loss: 125175.8567 - val_mean_squared_error: 124363.3489\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 121511.76562\n",
      "Epoch 63/350\n",
      " - 0s - loss: 49769.3045 - mean_squared_error: 48954.0845 - val_loss: 127068.7780 - val_mean_squared_error: 126270.9357\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 121511.76562\n",
      "Epoch 64/350\n",
      " - 0s - loss: 48507.8980 - mean_squared_error: 47614.6232 - val_loss: 122823.8652 - val_mean_squared_error: 122039.1260\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 121511.76562\n",
      "Epoch 65/350\n",
      " - 0s - loss: 45190.4055 - mean_squared_error: 44299.2102 - val_loss: 118876.1373 - val_mean_squared_error: 118041.1617\n",
      "\n",
      "Epoch 00065: val_loss improved from 121511.76562 to 118876.13728, saving model to test.hdf5\n",
      "Epoch 66/350\n",
      " - 0s - loss: 44913.6055 - mean_squared_error: 44017.6898 - val_loss: 121648.4102 - val_mean_squared_error: 120837.2390\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 118876.13728\n",
      "Epoch 67/350\n",
      " - 0s - loss: 45229.4931 - mean_squared_error: 44380.5373 - val_loss: 119871.2646 - val_mean_squared_error: 119111.2218\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 118876.13728\n",
      "Epoch 68/350\n",
      " - 0s - loss: 43571.3300 - mean_squared_error: 42724.3528 - val_loss: 126574.2155 - val_mean_squared_error: 125863.7525\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 118876.13728\n",
      "Epoch 69/350\n",
      " - 0s - loss: 51960.8136 - mean_squared_error: 51137.6210 - val_loss: 129048.4414 - val_mean_squared_error: 128318.6402\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 118876.13728\n",
      "Epoch 70/350\n",
      " - 0s - loss: 49843.4070 - mean_squared_error: 49019.4437 - val_loss: 120892.2309 - val_mean_squared_error: 120152.9482\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 118876.13728\n",
      "Epoch 71/350\n",
      " - 0s - loss: 45842.9272 - mean_squared_error: 44963.2805 - val_loss: 116231.1229 - val_mean_squared_error: 115482.9912\n",
      "\n",
      "Epoch 00071: val_loss improved from 118876.13728 to 116231.12291, saving model to test.hdf5\n",
      "Epoch 72/350\n",
      " - 0s - loss: 48021.8636 - mean_squared_error: 47131.3043 - val_loss: 114238.5539 - val_mean_squared_error: 113490.2210\n",
      "\n",
      "Epoch 00072: val_loss improved from 116231.12291 to 114238.55385, saving model to test.hdf5\n",
      "Epoch 73/350\n",
      " - 0s - loss: 44499.4010 - mean_squared_error: 43627.3097 - val_loss: 113492.5279 - val_mean_squared_error: 112725.5566\n",
      "\n",
      "Epoch 00073: val_loss improved from 114238.55385 to 113492.52790, saving model to test.hdf5\n",
      "Epoch 74/350\n",
      " - 0s - loss: 47636.2864 - mean_squared_error: 46801.6300 - val_loss: 111641.3191 - val_mean_squared_error: 110921.7906\n",
      "\n",
      "Epoch 00074: val_loss improved from 113492.52790 to 111641.31906, saving model to test.hdf5\n",
      "Epoch 75/350\n",
      " - 0s - loss: 49266.3908 - mean_squared_error: 48442.7629 - val_loss: 110959.7426 - val_mean_squared_error: 110218.7444\n",
      "\n",
      "Epoch 00075: val_loss improved from 111641.31906 to 110959.74261, saving model to test.hdf5\n",
      "Epoch 76/350\n",
      " - 0s - loss: 49315.0562 - mean_squared_error: 48448.7167 - val_loss: 110646.5431 - val_mean_squared_error: 109910.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: val_loss improved from 110959.74261 to 110646.54311, saving model to test.hdf5\n",
      "Epoch 77/350\n",
      " - 0s - loss: 50699.1269 - mean_squared_error: 49842.2387 - val_loss: 108114.8899 - val_mean_squared_error: 107375.7457\n",
      "\n",
      "Epoch 00077: val_loss improved from 110646.54311 to 108114.88993, saving model to test.hdf5\n",
      "Epoch 78/350\n",
      " - 0s - loss: 45307.7615 - mean_squared_error: 44455.6159 - val_loss: 107153.9641 - val_mean_squared_error: 106409.7528\n",
      "\n",
      "Epoch 00078: val_loss improved from 108114.88993 to 107153.96415, saving model to test.hdf5\n",
      "Epoch 79/350\n",
      " - 0s - loss: 34927.7847 - mean_squared_error: 34021.8156 - val_loss: 110234.6381 - val_mean_squared_error: 109471.3954\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 107153.96415\n",
      "Epoch 80/350\n",
      " - 0s - loss: 49444.4335 - mean_squared_error: 48627.7202 - val_loss: 109000.1415 - val_mean_squared_error: 108300.8859\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 107153.96415\n",
      "Epoch 81/350\n",
      " - 0s - loss: 41870.0749 - mean_squared_error: 41060.0250 - val_loss: 109499.2111 - val_mean_squared_error: 108805.8814\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 107153.96415\n",
      "Epoch 82/350\n",
      " - 0s - loss: 40432.7065 - mean_squared_error: 39581.6043 - val_loss: 109820.9283 - val_mean_squared_error: 109092.3209\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 107153.96415\n",
      "Epoch 83/350\n",
      " - 0s - loss: 44598.5833 - mean_squared_error: 43765.0983 - val_loss: 107744.2182 - val_mean_squared_error: 106989.6101\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 107153.96415\n",
      "Epoch 84/350\n",
      " - 0s - loss: 45668.0421 - mean_squared_error: 44809.3863 - val_loss: 108470.9655 - val_mean_squared_error: 107701.0879\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 107153.96415\n",
      "Epoch 85/350\n",
      " - 0s - loss: 47780.1349 - mean_squared_error: 46937.2755 - val_loss: 106615.7042 - val_mean_squared_error: 105887.9311\n",
      "\n",
      "Epoch 00085: val_loss improved from 107153.96415 to 106615.70424, saving model to test.hdf5\n",
      "Epoch 86/350\n",
      " - 0s - loss: 45507.8971 - mean_squared_error: 44715.4811 - val_loss: 109205.4162 - val_mean_squared_error: 108475.2003\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 106615.70424\n",
      "Epoch 87/350\n",
      " - 0s - loss: 50090.0616 - mean_squared_error: 49266.0650 - val_loss: 112220.2937 - val_mean_squared_error: 111519.5928\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 106615.70424\n",
      "Epoch 88/350\n",
      " - 0s - loss: 44284.3874 - mean_squared_error: 43520.6619 - val_loss: 109137.7828 - val_mean_squared_error: 108465.3468\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 106615.70424\n",
      "Epoch 89/350\n",
      " - 0s - loss: 48311.7674 - mean_squared_error: 47540.3802 - val_loss: 110224.0064 - val_mean_squared_error: 109536.7017\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 106615.70424\n",
      "Epoch 90/350\n",
      " - 0s - loss: 44013.6074 - mean_squared_error: 43244.9270 - val_loss: 110211.3807 - val_mean_squared_error: 109503.0628\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 106615.70424\n",
      "Epoch 91/350\n",
      " - 0s - loss: 46759.6584 - mean_squared_error: 45947.2853 - val_loss: 106726.8640 - val_mean_squared_error: 106043.0695\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 106615.70424\n",
      "Epoch 92/350\n",
      " - 0s - loss: 44909.7460 - mean_squared_error: 44093.1938 - val_loss: 104295.6780 - val_mean_squared_error: 103561.0917\n",
      "\n",
      "Epoch 00092: val_loss improved from 106615.70424 to 104295.67801, saving model to test.hdf5\n",
      "Epoch 93/350\n",
      " - 0s - loss: 40924.2018 - mean_squared_error: 40071.8141 - val_loss: 105210.6046 - val_mean_squared_error: 104487.0601\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 104295.67801\n",
      "Epoch 94/350\n",
      " - 0s - loss: 35277.1864 - mean_squared_error: 34435.5133 - val_loss: 104150.1780 - val_mean_squared_error: 103437.0004\n",
      "\n",
      "Epoch 00094: val_loss improved from 104295.67801 to 104150.17801, saving model to test.hdf5\n",
      "Epoch 95/350\n",
      " - 0s - loss: 40641.6114 - mean_squared_error: 39817.7691 - val_loss: 102736.1306 - val_mean_squared_error: 101990.5512\n",
      "\n",
      "Epoch 00095: val_loss improved from 104150.17801 to 102736.13058, saving model to test.hdf5\n",
      "Epoch 96/350\n",
      " - 0s - loss: 47071.8967 - mean_squared_error: 46194.8505 - val_loss: 100022.5398 - val_mean_squared_error: 99218.7038\n",
      "\n",
      "Epoch 00096: val_loss improved from 102736.13058 to 100022.53976, saving model to test.hdf5\n",
      "Epoch 97/350\n",
      " - 0s - loss: 46074.3588 - mean_squared_error: 45231.9898 - val_loss: 101592.5705 - val_mean_squared_error: 100779.5053\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 100022.53976\n",
      "Epoch 98/350\n",
      " - 0s - loss: 42408.0852 - mean_squared_error: 41530.5124 - val_loss: 99796.8425 - val_mean_squared_error: 99034.1461\n",
      "\n",
      "Epoch 00098: val_loss improved from 100022.53976 to 99796.84249, saving model to test.hdf5\n",
      "Epoch 99/350\n",
      " - 0s - loss: 48524.3497 - mean_squared_error: 47718.8166 - val_loss: 104866.9294 - val_mean_squared_error: 104128.1410\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 99796.84249\n",
      "Epoch 100/350\n",
      " - 0s - loss: 44208.2482 - mean_squared_error: 43362.3611 - val_loss: 109108.8610 - val_mean_squared_error: 108385.6300\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 99796.84249\n",
      "Epoch 101/350\n",
      " - 0s - loss: 43366.4988 - mean_squared_error: 42537.6622 - val_loss: 106275.4958 - val_mean_squared_error: 105558.8337\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 99796.84249\n",
      "Epoch 102/350\n",
      " - 0s - loss: 42274.5055 - mean_squared_error: 41412.6525 - val_loss: 104044.2824 - val_mean_squared_error: 103315.0381\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 99796.84249\n",
      "Epoch 103/350\n",
      " - 0s - loss: 41762.2481 - mean_squared_error: 40870.8073 - val_loss: 103546.4874 - val_mean_squared_error: 102763.4269\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 99796.84249\n",
      "Epoch 104/350\n",
      " - 0s - loss: 57098.9061 - mean_squared_error: 56304.4458 - val_loss: 109474.0434 - val_mean_squared_error: 108726.4277\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 99796.84249\n",
      "Epoch 105/350\n",
      " - 0s - loss: 48437.8193 - mean_squared_error: 47600.2356 - val_loss: 108027.9195 - val_mean_squared_error: 107305.5293\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 99796.84249\n",
      "Epoch 106/350\n",
      " - 0s - loss: 43334.1423 - mean_squared_error: 42550.0607 - val_loss: 105780.2676 - val_mean_squared_error: 105071.7324\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 99796.84249\n",
      "Epoch 107/350\n",
      " - 0s - loss: 45265.5081 - mean_squared_error: 44464.5146 - val_loss: 107230.1401 - val_mean_squared_error: 106566.7981\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 99796.84249\n",
      "Epoch 108/350\n",
      " - 0s - loss: 38548.6357 - mean_squared_error: 37707.1725 - val_loss: 105628.3753 - val_mean_squared_error: 104923.0838\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 99796.84249\n",
      "Epoch 109/350\n",
      " - 0s - loss: 52290.7026 - mean_squared_error: 51460.3145 - val_loss: 108778.0594 - val_mean_squared_error: 108081.3032\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 99796.84249\n",
      "Epoch 110/350\n",
      " - 0s - loss: 37440.3870 - mean_squared_error: 36669.4225 - val_loss: 105323.2307 - val_mean_squared_error: 104657.3534\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 99796.84249\n",
      "Epoch 111/350\n",
      " - 0s - loss: 38792.6478 - mean_squared_error: 38006.9173 - val_loss: 106533.9936 - val_mean_squared_error: 105848.7634\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 99796.84249\n",
      "Epoch 112/350\n",
      " - 0s - loss: 45583.0220 - mean_squared_error: 44780.3036 - val_loss: 104257.8834 - val_mean_squared_error: 103575.3669\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 99796.84249\n",
      "Epoch 113/350\n",
      " - 0s - loss: 39714.3194 - mean_squared_error: 38958.3013 - val_loss: 101195.4789 - val_mean_squared_error: 100506.6150\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 99796.84249\n",
      "Epoch 114/350\n",
      " - 0s - loss: 47786.1401 - mean_squared_error: 46991.6161 - val_loss: 103666.4090 - val_mean_squared_error: 102996.3291\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 99796.84249\n",
      "Epoch 115/350\n",
      " - 0s - loss: 50188.7669 - mean_squared_error: 49428.5373 - val_loss: 105299.9559 - val_mean_squared_error: 104656.4679\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 99796.84249\n",
      "Epoch 116/350\n",
      " - 0s - loss: 56064.2834 - mean_squared_error: 55291.3256 - val_loss: 107501.8683 - val_mean_squared_error: 106840.1895\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 99796.84249\n",
      "Epoch 117/350\n",
      " - 0s - loss: 44829.3013 - mean_squared_error: 44048.2217 - val_loss: 107715.3548 - val_mean_squared_error: 107083.6127\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 99796.84249\n",
      "Epoch 118/350\n",
      " - 0s - loss: 45736.1146 - mean_squared_error: 45048.3292 - val_loss: 107910.7899 - val_mean_squared_error: 107284.6807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00118: val_loss did not improve from 99796.84249\n",
      "Epoch 119/350\n",
      " - 0s - loss: 39775.2527 - mean_squared_error: 39047.7063 - val_loss: 104528.0340 - val_mean_squared_error: 103892.4803\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 99796.84249\n",
      "Epoch 120/350\n",
      " - 0s - loss: 31254.5766 - mean_squared_error: 30521.8377 - val_loss: 103781.4103 - val_mean_squared_error: 103125.0040\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 99796.84249\n",
      "Epoch 121/350\n",
      " - 0s - loss: 49642.0360 - mean_squared_error: 48912.7890 - val_loss: 103226.4739 - val_mean_squared_error: 102551.2688\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 99796.84249\n",
      "Epoch 122/350\n",
      " - 0s - loss: 39843.1444 - mean_squared_error: 39117.1638 - val_loss: 105380.2515 - val_mean_squared_error: 104754.0841\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 99796.84249\n",
      "Epoch 123/350\n",
      " - 0s - loss: 49086.9259 - mean_squared_error: 48444.8064 - val_loss: 109195.8696 - val_mean_squared_error: 108592.5824\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 99796.84249\n",
      "Epoch 124/350\n",
      " - 0s - loss: 45233.3582 - mean_squared_error: 44548.4589 - val_loss: 109359.5795 - val_mean_squared_error: 108787.2384\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 99796.84249\n",
      "Epoch 125/350\n",
      " - 0s - loss: 41265.9538 - mean_squared_error: 40590.8812 - val_loss: 101621.1657 - val_mean_squared_error: 100993.7038\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 99796.84249\n",
      "Epoch 126/350\n",
      " - 0s - loss: 39935.0356 - mean_squared_error: 39222.3733 - val_loss: 99154.6027 - val_mean_squared_error: 98527.6860\n",
      "\n",
      "Epoch 00126: val_loss improved from 99796.84249 to 99154.60268, saving model to test.hdf5\n",
      "Epoch 127/350\n",
      " - 0s - loss: 49905.2218 - mean_squared_error: 49195.5400 - val_loss: 103734.1858 - val_mean_squared_error: 103090.1208\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 99154.60268\n",
      "Epoch 128/350\n",
      " - 0s - loss: 48908.4584 - mean_squared_error: 48209.4250 - val_loss: 103170.2554 - val_mean_squared_error: 102508.3659\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 99154.60268\n",
      "Epoch 129/350\n",
      " - 0s - loss: 44511.2809 - mean_squared_error: 43814.4078 - val_loss: 102145.4900 - val_mean_squared_error: 101497.8622\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 99154.60268\n",
      "Epoch 130/350\n",
      " - 0s - loss: 42134.7198 - mean_squared_error: 41366.4254 - val_loss: 103249.3178 - val_mean_squared_error: 102618.0035\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 99154.60268\n",
      "Epoch 131/350\n",
      " - 0s - loss: 38212.8480 - mean_squared_error: 37471.0847 - val_loss: 104950.5802 - val_mean_squared_error: 104305.9622\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 99154.60268\n",
      "Epoch 132/350\n",
      " - 0s - loss: 41611.4402 - mean_squared_error: 40843.2299 - val_loss: 101577.0698 - val_mean_squared_error: 100901.9182\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 99154.60268\n",
      "Epoch 133/350\n",
      " - 0s - loss: 36030.3706 - mean_squared_error: 35291.2002 - val_loss: 100797.2319 - val_mean_squared_error: 100090.7444\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 99154.60268\n",
      "Epoch 134/350\n",
      " - 0s - loss: 39757.8908 - mean_squared_error: 39007.7891 - val_loss: 100175.8993 - val_mean_squared_error: 99479.5070\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 99154.60268\n",
      "Epoch 135/350\n",
      " - 0s - loss: 48722.7827 - mean_squared_error: 47986.6533 - val_loss: 101185.6328 - val_mean_squared_error: 100516.8052\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 99154.60268\n",
      "Epoch 136/350\n",
      " - 0s - loss: 36730.4158 - mean_squared_error: 35985.3202 - val_loss: 102599.2935 - val_mean_squared_error: 101937.6978\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 99154.60268\n",
      "Epoch 137/350\n",
      " - 0s - loss: 49236.5415 - mean_squared_error: 48506.4101 - val_loss: 106360.7199 - val_mean_squared_error: 105717.6433\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 99154.60268\n",
      "Epoch 138/350\n",
      " - 0s - loss: 50432.4415 - mean_squared_error: 49721.0894 - val_loss: 107319.3895 - val_mean_squared_error: 106679.7457\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 99154.60268\n",
      "Epoch 139/350\n",
      " - 0s - loss: 42297.4225 - mean_squared_error: 41563.1466 - val_loss: 106445.6310 - val_mean_squared_error: 105824.8126\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 99154.60268\n",
      "Epoch 140/350\n",
      " - 0s - loss: 43440.5499 - mean_squared_error: 42735.5217 - val_loss: 106493.2561 - val_mean_squared_error: 105863.6342\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 99154.60268\n",
      "Epoch 141/350\n",
      " - 0s - loss: 49313.5459 - mean_squared_error: 48597.1344 - val_loss: 103994.0646 - val_mean_squared_error: 103343.3996\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 99154.60268\n",
      "Epoch 142/350\n",
      " - 0s - loss: 39768.6042 - mean_squared_error: 39050.5258 - val_loss: 103916.6491 - val_mean_squared_error: 103265.5723\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 99154.60268\n",
      "Epoch 143/350\n",
      " - 0s - loss: 34916.5374 - mean_squared_error: 34196.4861 - val_loss: 100668.4291 - val_mean_squared_error: 99997.3066\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 99154.60268\n",
      "Epoch 144/350\n",
      " - 0s - loss: 48088.3042 - mean_squared_error: 47352.2814 - val_loss: 100790.8548 - val_mean_squared_error: 100119.8239\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 99154.60268\n",
      "Epoch 145/350\n",
      " - 0s - loss: 44747.8946 - mean_squared_error: 44005.8807 - val_loss: 102941.0812 - val_mean_squared_error: 102264.6137\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 99154.60268\n",
      "Epoch 146/350\n",
      " - 0s - loss: 41241.6952 - mean_squared_error: 40494.5638 - val_loss: 103185.4464 - val_mean_squared_error: 102525.4807\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 99154.60268\n",
      "Epoch 147/350\n",
      " - 0s - loss: 52920.3602 - mean_squared_error: 52207.9870 - val_loss: 103387.4920 - val_mean_squared_error: 102746.9036\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 99154.60268\n",
      "Epoch 148/350\n",
      " - 0s - loss: 50923.7458 - mean_squared_error: 50235.4611 - val_loss: 104540.0865 - val_mean_squared_error: 103925.0497\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 99154.60268\n",
      "Epoch 149/350\n",
      " - 0s - loss: 45009.5827 - mean_squared_error: 44292.9585 - val_loss: 107287.4012 - val_mean_squared_error: 106662.1004\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 99154.60268\n",
      "Epoch 150/350\n",
      " - 0s - loss: 37008.9522 - mean_squared_error: 36316.3154 - val_loss: 108856.4655 - val_mean_squared_error: 108252.3507\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 99154.60268\n",
      "Epoch 151/350\n",
      " - 0s - loss: 42270.3639 - mean_squared_error: 41568.6890 - val_loss: 107812.0515 - val_mean_squared_error: 107190.8062\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 99154.60268\n",
      "Epoch 152/350\n",
      " - 0s - loss: 44556.5979 - mean_squared_error: 43888.3607 - val_loss: 106576.0183 - val_mean_squared_error: 105963.6735\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 99154.60268\n",
      "Epoch 153/350\n",
      " - 0s - loss: 41970.7825 - mean_squared_error: 41316.8689 - val_loss: 104131.1733 - val_mean_squared_error: 103533.8171\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 99154.60268\n",
      "Epoch 154/350\n",
      " - 0s - loss: 39197.8078 - mean_squared_error: 38526.4051 - val_loss: 99793.4492 - val_mean_squared_error: 99179.0091\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 99154.60268\n",
      "Epoch 155/350\n",
      " - 0s - loss: 40343.0513 - mean_squared_error: 39633.1277 - val_loss: 102012.7634 - val_mean_squared_error: 101370.8597\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 99154.60268\n",
      "Epoch 156/350\n",
      " - 0s - loss: 37439.5695 - mean_squared_error: 36750.4697 - val_loss: 101895.7783 - val_mean_squared_error: 101287.3933\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 99154.60268\n",
      "Epoch 157/350\n",
      " - 0s - loss: 38723.3958 - mean_squared_error: 38055.3132 - val_loss: 101663.6070 - val_mean_squared_error: 101065.7688\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 99154.60268\n",
      "Epoch 158/350\n",
      " - 0s - loss: 37159.9917 - mean_squared_error: 36475.1058 - val_loss: 103042.2395 - val_mean_squared_error: 102446.9187\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 99154.60268\n",
      "Epoch 159/350\n",
      " - 0s - loss: 38809.0707 - mean_squared_error: 38131.1723 - val_loss: 101582.9562 - val_mean_squared_error: 100974.6804\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 99154.60268\n",
      "Epoch 160/350\n",
      " - 0s - loss: 54768.1459 - mean_squared_error: 54105.3019 - val_loss: 107122.0145 - val_mean_squared_error: 106540.4717\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 99154.60268\n",
      "Epoch 161/350\n",
      " - 0s - loss: 39160.1373 - mean_squared_error: 38479.4639 - val_loss: 108206.2962 - val_mean_squared_error: 107621.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00161: val_loss did not improve from 99154.60268\n",
      "Epoch 162/350\n",
      " - 0s - loss: 45768.3760 - mean_squared_error: 45105.0980 - val_loss: 108550.1140 - val_mean_squared_error: 107974.3386\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 99154.60268\n",
      "Epoch 163/350\n",
      " - 0s - loss: 41714.8998 - mean_squared_error: 41061.5119 - val_loss: 109000.3849 - val_mean_squared_error: 108423.4898\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 99154.60268\n",
      "Epoch 164/350\n",
      " - 0s - loss: 47969.3206 - mean_squared_error: 47336.5810 - val_loss: 110747.1170 - val_mean_squared_error: 110160.6094\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 99154.60268\n",
      "Epoch 165/350\n",
      " - 0s - loss: 42784.3328 - mean_squared_error: 42131.1799 - val_loss: 106189.3640 - val_mean_squared_error: 105623.4605\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 99154.60268\n",
      "Epoch 166/350\n",
      " - 0s - loss: 41847.0296 - mean_squared_error: 41197.5484 - val_loss: 105888.3804 - val_mean_squared_error: 105317.5308\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 99154.60268\n",
      "Epoch 167/350\n",
      " - 0s - loss: 46018.7309 - mean_squared_error: 45359.1467 - val_loss: 104100.5011 - val_mean_squared_error: 103524.8834\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 99154.60268\n",
      "Epoch 168/350\n",
      " - 0s - loss: 50346.1526 - mean_squared_error: 49675.8285 - val_loss: 106471.8517 - val_mean_squared_error: 105902.0470\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 99154.60268\n",
      "Epoch 169/350\n",
      " - 0s - loss: 39990.5332 - mean_squared_error: 39338.9209 - val_loss: 104073.2506 - val_mean_squared_error: 103478.5636\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 99154.60268\n",
      "Epoch 170/350\n",
      " - 0s - loss: 33486.6931 - mean_squared_error: 32801.0495 - val_loss: 101751.0890 - val_mean_squared_error: 101148.6961\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 99154.60268\n",
      "Epoch 171/350\n",
      " - 0s - loss: 36214.2338 - mean_squared_error: 35520.4993 - val_loss: 101940.1028 - val_mean_squared_error: 101312.5419\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 99154.60268\n",
      "Epoch 172/350\n",
      " - 0s - loss: 38571.3561 - mean_squared_error: 37905.3283 - val_loss: 103060.9788 - val_mean_squared_error: 102434.1540\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 99154.60268\n",
      "Epoch 173/350\n",
      " - 0s - loss: 42268.9109 - mean_squared_error: 41582.7028 - val_loss: 106949.3609 - val_mean_squared_error: 106349.4791\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 99154.60268\n",
      "Epoch 174/350\n",
      " - 0s - loss: 41289.3836 - mean_squared_error: 40659.3604 - val_loss: 104031.6989 - val_mean_squared_error: 103438.7112\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 99154.60268\n",
      "Epoch 175/350\n",
      " - 0s - loss: 41559.6617 - mean_squared_error: 40913.9742 - val_loss: 104925.7441 - val_mean_squared_error: 104303.2690\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 99154.60268\n",
      "Epoch 176/350\n",
      " - 0s - loss: 38369.2978 - mean_squared_error: 37679.1126 - val_loss: 105807.5964 - val_mean_squared_error: 105184.6051\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 99154.60268\n",
      "Epoch 177/350\n",
      " - 0s - loss: 41313.3074 - mean_squared_error: 40647.8076 - val_loss: 105967.3045 - val_mean_squared_error: 105380.6960\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 99154.60268\n",
      "Epoch 178/350\n",
      " - 0s - loss: 40130.2813 - mean_squared_error: 39479.8461 - val_loss: 102433.5078 - val_mean_squared_error: 101830.1448\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 99154.60268\n",
      "Epoch 179/350\n",
      " - 0s - loss: 47338.5771 - mean_squared_error: 46682.4145 - val_loss: 102099.2923 - val_mean_squared_error: 101469.4316\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 99154.60268\n",
      "Epoch 180/350\n",
      " - 0s - loss: 38657.7916 - mean_squared_error: 37991.0032 - val_loss: 101937.6897 - val_mean_squared_error: 101323.9747\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 99154.60268\n",
      "Epoch 181/350\n",
      " - 0s - loss: 41633.0770 - mean_squared_error: 40965.7646 - val_loss: 104331.0956 - val_mean_squared_error: 103729.6091\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 99154.60268\n",
      "Epoch 182/350\n",
      " - 0s - loss: 49013.6984 - mean_squared_error: 48354.1038 - val_loss: 104285.2553 - val_mean_squared_error: 103706.2584\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 99154.60268\n",
      "Epoch 183/350\n",
      " - 0s - loss: 44152.0509 - mean_squared_error: 43564.1609 - val_loss: 108023.2354 - val_mean_squared_error: 107461.9307\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 99154.60268\n",
      "Epoch 184/350\n",
      " - 0s - loss: 43276.0427 - mean_squared_error: 42664.5562 - val_loss: 104515.6246 - val_mean_squared_error: 103941.7394\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 99154.60268\n",
      "Epoch 185/350\n",
      " - 0s - loss: 41939.4988 - mean_squared_error: 41330.4675 - val_loss: 97590.8245 - val_mean_squared_error: 97015.8174\n",
      "\n",
      "Epoch 00185: val_loss improved from 99154.60268 to 97590.82450, saving model to test.hdf5\n",
      "Epoch 186/350\n",
      " - 0s - loss: 41665.7280 - mean_squared_error: 41019.0448 - val_loss: 96930.0631 - val_mean_squared_error: 96366.9886\n",
      "\n",
      "Epoch 00186: val_loss improved from 97590.82450 to 96930.06306, saving model to test.hdf5\n",
      "Epoch 187/350\n",
      " - 0s - loss: 44311.7921 - mean_squared_error: 43699.4784 - val_loss: 99128.1154 - val_mean_squared_error: 98536.4463\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 96930.06306\n",
      "Epoch 188/350\n",
      " - 0s - loss: 36172.5344 - mean_squared_error: 35536.7661 - val_loss: 101298.3414 - val_mean_squared_error: 100694.0137\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 96930.06306\n",
      "Epoch 189/350\n",
      " - 0s - loss: 39989.9045 - mean_squared_error: 39358.9789 - val_loss: 98587.4291 - val_mean_squared_error: 97984.4965\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 96930.06306\n",
      "Epoch 190/350\n",
      " - 0s - loss: 50882.8811 - mean_squared_error: 50245.1986 - val_loss: 101434.4554 - val_mean_squared_error: 100851.9407\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 96930.06306\n",
      "Epoch 191/350\n",
      " - 0s - loss: 37728.0124 - mean_squared_error: 37080.0804 - val_loss: 103306.3210 - val_mean_squared_error: 102718.0801\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 96930.06306\n",
      "Epoch 192/350\n",
      " - 0s - loss: 39897.4358 - mean_squared_error: 39266.1400 - val_loss: 104935.2021 - val_mean_squared_error: 104368.8119\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 96930.06306\n",
      "Epoch 193/350\n",
      " - 0s - loss: 33000.8776 - mean_squared_error: 32354.6472 - val_loss: 104062.7532 - val_mean_squared_error: 103513.4085\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 96930.06306\n",
      "Epoch 194/350\n",
      " - 0s - loss: 44752.1104 - mean_squared_error: 44138.4475 - val_loss: 107810.8690 - val_mean_squared_error: 107270.4894\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 96930.06306\n",
      "Epoch 195/350\n",
      " - 0s - loss: 40179.1054 - mean_squared_error: 39563.6172 - val_loss: 106885.8380 - val_mean_squared_error: 106343.5080\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 96930.06306\n",
      "Epoch 196/350\n",
      " - 0s - loss: 37079.5774 - mean_squared_error: 36455.5371 - val_loss: 103947.0670 - val_mean_squared_error: 103400.2896\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 96930.06306\n",
      "Epoch 197/350\n",
      " - 0s - loss: 51309.3492 - mean_squared_error: 50709.6080 - val_loss: 106532.3322 - val_mean_squared_error: 105975.9229\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 96930.06306\n",
      "Epoch 198/350\n",
      " - 0s - loss: 36910.0386 - mean_squared_error: 36275.4889 - val_loss: 108359.2676 - val_mean_squared_error: 107806.4438\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 96930.06306\n",
      "Epoch 199/350\n",
      " - 0s - loss: 41343.3345 - mean_squared_error: 40755.8955 - val_loss: 103982.7804 - val_mean_squared_error: 103430.9422\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 96930.06306\n",
      "Epoch 200/350\n",
      " - 0s - loss: 35171.9078 - mean_squared_error: 34558.4420 - val_loss: 102553.2878 - val_mean_squared_error: 101978.9795\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 96930.06306\n",
      "Epoch 201/350\n",
      " - 0s - loss: 37823.3845 - mean_squared_error: 37201.6531 - val_loss: 105201.7905 - val_mean_squared_error: 104644.1088\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 96930.06306\n",
      "Epoch 202/350\n",
      " - 0s - loss: 44972.7658 - mean_squared_error: 44350.0514 - val_loss: 106646.2981 - val_mean_squared_error: 106122.1357\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 96930.06306\n",
      "Epoch 203/350\n",
      " - 0s - loss: 46291.7375 - mean_squared_error: 45710.9765 - val_loss: 103782.5967 - val_mean_squared_error: 103240.6045\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 96930.06306\n",
      "Epoch 204/350\n",
      " - 0s - loss: 48596.9004 - mean_squared_error: 47979.3167 - val_loss: 106735.8440 - val_mean_squared_error: 106208.2871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00204: val_loss did not improve from 96930.06306\n",
      "Epoch 205/350\n",
      " - 0s - loss: 41576.0886 - mean_squared_error: 40935.2357 - val_loss: 104912.4867 - val_mean_squared_error: 104369.8186\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 96930.06306\n",
      "Epoch 206/350\n",
      " - 0s - loss: 39570.7472 - mean_squared_error: 38964.0570 - val_loss: 104674.2864 - val_mean_squared_error: 104123.9876\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 96930.06306\n",
      "Epoch 207/350\n",
      " - 0s - loss: 43081.1523 - mean_squared_error: 42465.4829 - val_loss: 102466.6585 - val_mean_squared_error: 101905.1720\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 96930.06306\n",
      "Epoch 208/350\n",
      " - 0s - loss: 45720.6302 - mean_squared_error: 45119.6734 - val_loss: 101004.9032 - val_mean_squared_error: 100420.1765\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 96930.06306\n",
      "Epoch 209/350\n",
      " - 0s - loss: 41783.6824 - mean_squared_error: 41144.2976 - val_loss: 102950.9826 - val_mean_squared_error: 102363.2182\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 96930.06306\n",
      "Epoch 210/350\n",
      " - 0s - loss: 41899.7016 - mean_squared_error: 41249.8804 - val_loss: 103095.4713 - val_mean_squared_error: 102475.5463\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 96930.06306\n",
      "Epoch 211/350\n",
      " - 0s - loss: 44167.6258 - mean_squared_error: 43517.2449 - val_loss: 101079.3069 - val_mean_squared_error: 100485.6307\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 96930.06306\n",
      "Epoch 212/350\n",
      " - 0s - loss: 37679.0663 - mean_squared_error: 37060.2513 - val_loss: 100033.8161 - val_mean_squared_error: 99442.2436\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 96930.06306\n",
      "Epoch 213/350\n",
      " - 0s - loss: 36504.4453 - mean_squared_error: 35865.1758 - val_loss: 100863.7422 - val_mean_squared_error: 100267.6829\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 96930.06306\n",
      "Epoch 214/350\n",
      " - 0s - loss: 43666.8396 - mean_squared_error: 43038.8087 - val_loss: 101849.0917 - val_mean_squared_error: 101277.5015\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 96930.06306\n",
      "Epoch 215/350\n",
      " - 0s - loss: 34968.7798 - mean_squared_error: 34320.8252 - val_loss: 103100.3415 - val_mean_squared_error: 102508.0755\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 96930.06306\n",
      "Epoch 216/350\n",
      " - 0s - loss: 42697.0223 - mean_squared_error: 42085.3934 - val_loss: 107854.3511 - val_mean_squared_error: 107291.2819\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 96930.06306\n",
      "Epoch 217/350\n",
      " - 0s - loss: 51937.8656 - mean_squared_error: 51297.0630 - val_loss: 107901.3313 - val_mean_squared_error: 107345.2958\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 96930.06306\n",
      "Epoch 218/350\n",
      " - 0s - loss: 52098.7427 - mean_squared_error: 51454.7964 - val_loss: 108944.2847 - val_mean_squared_error: 108357.9795\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 96930.06306\n",
      "Epoch 219/350\n",
      " - 0s - loss: 39167.5588 - mean_squared_error: 38533.5611 - val_loss: 105496.5054 - val_mean_squared_error: 104877.3641\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 96930.06306\n",
      "Epoch 220/350\n",
      " - 0s - loss: 39380.4036 - mean_squared_error: 38721.2285 - val_loss: 101879.2250 - val_mean_squared_error: 101285.4706\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 96930.06306\n",
      "Epoch 221/350\n",
      " - 0s - loss: 39046.6174 - mean_squared_error: 38423.8333 - val_loss: 103299.8647 - val_mean_squared_error: 102716.1208\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 96930.06306\n",
      "Epoch 222/350\n",
      " - 0s - loss: 35396.0169 - mean_squared_error: 34734.1955 - val_loss: 103058.5053 - val_mean_squared_error: 102468.2698\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 96930.06306\n",
      "Epoch 223/350\n",
      " - 0s - loss: 35392.4630 - mean_squared_error: 34785.0040 - val_loss: 103065.5557 - val_mean_squared_error: 102498.6063\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 96930.06306\n",
      "Epoch 224/350\n",
      " - 0s - loss: 44578.3704 - mean_squared_error: 43908.6938 - val_loss: 102116.4556 - val_mean_squared_error: 101527.4517\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 96930.06306\n",
      "Epoch 225/350\n",
      " - 0s - loss: 41828.6113 - mean_squared_error: 41186.7868 - val_loss: 103118.7105 - val_mean_squared_error: 102520.1583\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 96930.06306\n",
      "Epoch 226/350\n",
      " - 0s - loss: 32369.4289 - mean_squared_error: 31695.8856 - val_loss: 102794.8227 - val_mean_squared_error: 102192.7739\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 96930.06306\n",
      "Epoch 227/350\n",
      " - 0s - loss: 36101.2539 - mean_squared_error: 35469.0650 - val_loss: 99949.5204 - val_mean_squared_error: 99345.6498\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 96930.06306\n",
      "Epoch 228/350\n",
      " - 0s - loss: 44108.5417 - mean_squared_error: 43447.5639 - val_loss: 100677.6360 - val_mean_squared_error: 100067.0552\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 96930.06306\n",
      "Epoch 229/350\n",
      " - 0s - loss: 41651.4012 - mean_squared_error: 41010.7379 - val_loss: 101283.7383 - val_mean_squared_error: 100677.1752\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 96930.06306\n",
      "Epoch 230/350\n",
      " - 0s - loss: 44651.9585 - mean_squared_error: 44000.1637 - val_loss: 102861.4008 - val_mean_squared_error: 102264.0405\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 96930.06306\n",
      "Epoch 231/350\n",
      " - 0s - loss: 38330.8725 - mean_squared_error: 37660.3621 - val_loss: 104557.8647 - val_mean_squared_error: 103980.3280\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 96930.06306\n",
      "Epoch 232/350\n",
      " - 0s - loss: 47623.1925 - mean_squared_error: 46978.3230 - val_loss: 102052.2743 - val_mean_squared_error: 101478.4911\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 96930.06306\n",
      "Epoch 233/350\n",
      " - 0s - loss: 38497.2231 - mean_squared_error: 37870.9380 - val_loss: 102165.9097 - val_mean_squared_error: 101612.1950\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 96930.06306\n",
      "Epoch 234/350\n",
      " - 0s - loss: 42340.9101 - mean_squared_error: 41699.4725 - val_loss: 105145.5723 - val_mean_squared_error: 104591.1762\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 96930.06306\n",
      "Epoch 235/350\n",
      " - 0s - loss: 33911.4424 - mean_squared_error: 33283.6680 - val_loss: 105450.3064 - val_mean_squared_error: 104915.6030\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 96930.06306\n",
      "Epoch 236/350\n",
      " - 0s - loss: 44687.6560 - mean_squared_error: 44045.6850 - val_loss: 107490.7849 - val_mean_squared_error: 106977.9068\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 96930.06306\n",
      "Epoch 237/350\n",
      " - 0s - loss: 37721.6343 - mean_squared_error: 37124.8963 - val_loss: 104335.5050 - val_mean_squared_error: 103805.6039\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 96930.06306\n",
      "Epoch 238/350\n",
      " - 0s - loss: 44403.6723 - mean_squared_error: 43791.9836 - val_loss: 102041.2319 - val_mean_squared_error: 101476.8417\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 96930.06306\n",
      "Epoch 239/350\n",
      " - 0s - loss: 38228.4866 - mean_squared_error: 37596.3744 - val_loss: 101376.0487 - val_mean_squared_error: 100783.5366\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 96930.06306\n",
      "Epoch 240/350\n",
      " - 0s - loss: 40423.4126 - mean_squared_error: 39781.7468 - val_loss: 102593.7306 - val_mean_squared_error: 102037.4847\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 96930.06306\n",
      "Epoch 241/350\n",
      " - 0s - loss: 38443.0884 - mean_squared_error: 37812.7006 - val_loss: 104046.3927 - val_mean_squared_error: 103471.5731\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 96930.06306\n",
      "Epoch 242/350\n",
      " - 0s - loss: 39246.2465 - mean_squared_error: 38568.6307 - val_loss: 102829.0259 - val_mean_squared_error: 102252.5476\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 96930.06306\n",
      "Epoch 243/350\n",
      " - 0s - loss: 43658.9191 - mean_squared_error: 43018.3819 - val_loss: 106604.9202 - val_mean_squared_error: 106028.8050\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 96930.06306\n",
      "Epoch 244/350\n",
      " - 0s - loss: 42915.3955 - mean_squared_error: 42312.5057 - val_loss: 105011.3114 - val_mean_squared_error: 104453.2699\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 96930.06306\n",
      "Epoch 245/350\n",
      " - 0s - loss: 34278.3880 - mean_squared_error: 33645.8179 - val_loss: 106655.1922 - val_mean_squared_error: 106103.2553\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 96930.06306\n",
      "Epoch 246/350\n",
      " - 0s - loss: 38443.6563 - mean_squared_error: 37820.0892 - val_loss: 99219.6307 - val_mean_squared_error: 98666.2952\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 96930.06306\n",
      "Epoch 247/350\n",
      " - 0s - loss: 49920.1515 - mean_squared_error: 49289.2403 - val_loss: 103532.2914 - val_mean_squared_error: 102975.5479\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 96930.06306\n",
      "Epoch 248/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 41391.6215 - mean_squared_error: 40753.4477 - val_loss: 107381.9665 - val_mean_squared_error: 106826.3902\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 96930.06306\n",
      "Epoch 249/350\n",
      " - 0s - loss: 33195.3757 - mean_squared_error: 32572.4785 - val_loss: 106406.0332 - val_mean_squared_error: 105845.8881\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 96930.06306\n",
      "Epoch 250/350\n",
      " - 0s - loss: 38199.0870 - mean_squared_error: 37584.4435 - val_loss: 106934.1529 - val_mean_squared_error: 106382.0367\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 96930.06306\n",
      "Epoch 251/350\n",
      " - 0s - loss: 43043.8987 - mean_squared_error: 42434.5514 - val_loss: 107073.9036 - val_mean_squared_error: 106517.3087\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 96930.06306\n",
      "Epoch 252/350\n",
      " - 0s - loss: 38973.1375 - mean_squared_error: 38353.7913 - val_loss: 105723.0640 - val_mean_squared_error: 105196.2582\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 96930.06306\n",
      "Epoch 253/350\n",
      " - 0s - loss: 43380.4039 - mean_squared_error: 42798.1398 - val_loss: 102548.9552 - val_mean_squared_error: 102029.2686\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 96930.06306\n",
      "Epoch 254/350\n",
      " - 0s - loss: 36121.0532 - mean_squared_error: 35532.2799 - val_loss: 104057.8140 - val_mean_squared_error: 103521.6170\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 96930.06306\n",
      "Epoch 255/350\n",
      " - 0s - loss: 37914.2498 - mean_squared_error: 37301.5610 - val_loss: 104417.6885 - val_mean_squared_error: 103888.7003\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 96930.06306\n",
      "Epoch 256/350\n",
      " - 0s - loss: 42906.3782 - mean_squared_error: 42308.7364 - val_loss: 102146.6062 - val_mean_squared_error: 101599.4032\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 96930.06306\n",
      "Epoch 257/350\n",
      " - 0s - loss: 40495.3022 - mean_squared_error: 39867.6891 - val_loss: 105529.5771 - val_mean_squared_error: 104984.6842\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 96930.06306\n",
      "Epoch 258/350\n",
      " - 0s - loss: 36667.0970 - mean_squared_error: 36044.9292 - val_loss: 102779.2167 - val_mean_squared_error: 102252.8523\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 96930.06306\n",
      "Epoch 259/350\n",
      " - 0s - loss: 35494.9675 - mean_squared_error: 34872.2101 - val_loss: 103713.3277 - val_mean_squared_error: 103171.4701\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 96930.06306\n",
      "Epoch 260/350\n",
      " - 0s - loss: 40253.3212 - mean_squared_error: 39606.8413 - val_loss: 105899.0628 - val_mean_squared_error: 105353.2973\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 96930.06306\n",
      "Epoch 261/350\n",
      " - 0s - loss: 33137.0520 - mean_squared_error: 32516.9062 - val_loss: 105890.4064 - val_mean_squared_error: 105375.6496\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 96930.06306\n",
      "Epoch 262/350\n",
      " - 0s - loss: 35883.7548 - mean_squared_error: 35290.4643 - val_loss: 103906.4625 - val_mean_squared_error: 103379.5665\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 96930.06306\n",
      "Epoch 263/350\n",
      " - 0s - loss: 38812.7137 - mean_squared_error: 38206.0545 - val_loss: 103945.7715 - val_mean_squared_error: 103430.8496\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 96930.06306\n",
      "Epoch 264/350\n",
      " - 0s - loss: 41934.0121 - mean_squared_error: 41304.7086 - val_loss: 103401.4492 - val_mean_squared_error: 102854.1355\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 96930.06306\n",
      "Epoch 265/350\n",
      " - 0s - loss: 45598.3710 - mean_squared_error: 44989.9436 - val_loss: 104535.0477 - val_mean_squared_error: 103976.0518\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 96930.06306\n",
      "Epoch 266/350\n",
      " - 0s - loss: 36017.5876 - mean_squared_error: 35355.6640 - val_loss: 101179.3584 - val_mean_squared_error: 100618.9865\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 96930.06306\n",
      "Epoch 267/350\n",
      " - 0s - loss: 37008.1063 - mean_squared_error: 36387.7792 - val_loss: 101863.9951 - val_mean_squared_error: 101308.6722\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 96930.06306\n",
      "Epoch 268/350\n",
      " - 0s - loss: 46635.7683 - mean_squared_error: 46001.4697 - val_loss: 103052.0075 - val_mean_squared_error: 102499.2814\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 96930.06306\n",
      "Epoch 269/350\n",
      " - 0s - loss: 30620.3395 - mean_squared_error: 29973.1350 - val_loss: 101279.6735 - val_mean_squared_error: 100736.1225\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 96930.06306\n",
      "Epoch 270/350\n",
      " - 0s - loss: 42036.9618 - mean_squared_error: 41439.9848 - val_loss: 101123.6343 - val_mean_squared_error: 100599.0333\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 96930.06306\n",
      "Epoch 271/350\n",
      " - 0s - loss: 38513.1302 - mean_squared_error: 37912.7361 - val_loss: 101696.8214 - val_mean_squared_error: 101158.9208\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 96930.06306\n",
      "Epoch 272/350\n",
      " - 0s - loss: 45104.8218 - mean_squared_error: 44522.9698 - val_loss: 102439.1830 - val_mean_squared_error: 101910.6914\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 96930.06306\n",
      "Epoch 273/350\n",
      " - 0s - loss: 44500.2441 - mean_squared_error: 43906.6662 - val_loss: 104051.7730 - val_mean_squared_error: 103542.3697\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 96930.06306\n",
      "Epoch 274/350\n",
      " - 0s - loss: 42505.1017 - mean_squared_error: 41913.6435 - val_loss: 103484.0544 - val_mean_squared_error: 102981.2476\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 96930.06306\n",
      "Epoch 275/350\n",
      " - 0s - loss: 40931.7313 - mean_squared_error: 40329.0022 - val_loss: 103854.1491 - val_mean_squared_error: 103349.7999\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 96930.06306\n",
      "Epoch 276/350\n",
      " - 0s - loss: 33780.7779 - mean_squared_error: 33170.2191 - val_loss: 102840.4188 - val_mean_squared_error: 102294.2185\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 96930.06306\n",
      "Epoch 277/350\n",
      " - 0s - loss: 40975.3765 - mean_squared_error: 40364.1439 - val_loss: 104082.1249 - val_mean_squared_error: 103538.0350\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 96930.06306\n",
      "Epoch 278/350\n",
      " - 0s - loss: 41659.0012 - mean_squared_error: 41060.3373 - val_loss: 105066.5409 - val_mean_squared_error: 104533.4513\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 96930.06306\n",
      "Epoch 279/350\n",
      " - 0s - loss: 32636.2909 - mean_squared_error: 32050.8892 - val_loss: 103442.7261 - val_mean_squared_error: 102904.7990\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 96930.06306\n",
      "Epoch 280/350\n",
      " - 0s - loss: 47146.7780 - mean_squared_error: 46533.5409 - val_loss: 103743.9385 - val_mean_squared_error: 103207.4630\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 96930.06306\n",
      "Epoch 281/350\n",
      " - 0s - loss: 37176.5442 - mean_squared_error: 36575.6245 - val_loss: 106304.8036 - val_mean_squared_error: 105768.6738\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 96930.06306\n",
      "Epoch 282/350\n",
      " - 0s - loss: 35184.8429 - mean_squared_error: 34580.5638 - val_loss: 108549.1165 - val_mean_squared_error: 108016.3092\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 96930.06306\n",
      "Epoch 283/350\n",
      " - 0s - loss: 35747.5890 - mean_squared_error: 35177.4737 - val_loss: 104911.0504 - val_mean_squared_error: 104341.3156\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 96930.06306\n",
      "Epoch 284/350\n",
      " - 0s - loss: 46590.4159 - mean_squared_error: 45971.4255 - val_loss: 102681.2633 - val_mean_squared_error: 102116.9450\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 96930.06306\n",
      "Epoch 285/350\n",
      " - 0s - loss: 45230.3704 - mean_squared_error: 44609.1654 - val_loss: 102165.6684 - val_mean_squared_error: 101578.0110\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 96930.06306\n",
      "Epoch 286/350\n",
      " - 0s - loss: 35904.5874 - mean_squared_error: 35236.1895 - val_loss: 102095.5319 - val_mean_squared_error: 101496.4194\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 96930.06306\n",
      "Epoch 287/350\n",
      " - 0s - loss: 37949.6524 - mean_squared_error: 37296.9047 - val_loss: 103861.4851 - val_mean_squared_error: 103265.0734\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 96930.06306\n",
      "Epoch 288/350\n",
      " - 0s - loss: 39718.7811 - mean_squared_error: 39097.5377 - val_loss: 105682.1095 - val_mean_squared_error: 105083.4976\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 96930.06306\n",
      "Epoch 289/350\n",
      " - 0s - loss: 52892.3955 - mean_squared_error: 52272.8843 - val_loss: 105746.6802 - val_mean_squared_error: 105152.5488\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 96930.06306\n",
      "Epoch 290/350\n",
      " - 0s - loss: 41277.4950 - mean_squared_error: 40626.4725 - val_loss: 106824.5972 - val_mean_squared_error: 106258.4918\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 96930.06306\n",
      "Epoch 291/350\n",
      " - 0s - loss: 38092.3570 - mean_squared_error: 37468.9256 - val_loss: 107691.0427 - val_mean_squared_error: 107113.4188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00291: val_loss did not improve from 96930.06306\n",
      "Epoch 292/350\n",
      " - 0s - loss: 46682.9116 - mean_squared_error: 46040.6141 - val_loss: 106121.3008 - val_mean_squared_error: 105506.5179\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 96930.06306\n",
      "Epoch 293/350\n",
      " - 0s - loss: 32030.0982 - mean_squared_error: 31354.7128 - val_loss: 102235.9029 - val_mean_squared_error: 101647.4016\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 96930.06306\n",
      "Epoch 294/350\n",
      " - 0s - loss: 39239.4662 - mean_squared_error: 38571.8351 - val_loss: 101937.2077 - val_mean_squared_error: 101342.1629\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 96930.06306\n",
      "Epoch 295/350\n",
      " - 0s - loss: 36607.5055 - mean_squared_error: 35925.4934 - val_loss: 103171.7222 - val_mean_squared_error: 102568.9413\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 96930.06306\n",
      "Epoch 296/350\n",
      " - 0s - loss: 33787.9805 - mean_squared_error: 33137.3180 - val_loss: 103486.5310 - val_mean_squared_error: 102898.5949\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 96930.06306\n",
      "Epoch 297/350\n",
      " - 0s - loss: 45722.6082 - mean_squared_error: 45055.3784 - val_loss: 106525.9775 - val_mean_squared_error: 105943.3315\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 96930.06306\n",
      "Epoch 298/350\n",
      " - 0s - loss: 51840.6717 - mean_squared_error: 51217.0341 - val_loss: 110788.4473 - val_mean_squared_error: 110234.9919\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 96930.06306\n",
      "Epoch 299/350\n",
      " - 0s - loss: 41419.5462 - mean_squared_error: 40774.7908 - val_loss: 104519.2259 - val_mean_squared_error: 103949.2165\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 96930.06306\n",
      "Epoch 300/350\n",
      " - 0s - loss: 46260.6063 - mean_squared_error: 45642.1501 - val_loss: 104566.8037 - val_mean_squared_error: 103996.8393\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 96930.06306\n",
      "Epoch 301/350\n",
      " - 0s - loss: 44455.6635 - mean_squared_error: 43818.4928 - val_loss: 103657.1795 - val_mean_squared_error: 103062.0741\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 96930.06306\n",
      "Epoch 302/350\n",
      " - 0s - loss: 40643.0441 - mean_squared_error: 40000.8384 - val_loss: 103055.9304 - val_mean_squared_error: 102472.8592\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 96930.06306\n",
      "Epoch 303/350\n",
      " - 0s - loss: 43756.0586 - mean_squared_error: 43135.1521 - val_loss: 106351.8185 - val_mean_squared_error: 105764.4527\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 96930.06306\n",
      "Epoch 304/350\n",
      " - 0s - loss: 45623.8301 - mean_squared_error: 44987.5910 - val_loss: 106492.0491 - val_mean_squared_error: 105913.9805\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 96930.06306\n",
      "Epoch 305/350\n",
      " - 0s - loss: 41133.3302 - mean_squared_error: 40534.3236 - val_loss: 110058.5278 - val_mean_squared_error: 109508.5799\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 96930.06306\n",
      "Epoch 306/350\n",
      " - 0s - loss: 37381.1659 - mean_squared_error: 36748.4408 - val_loss: 108790.5488 - val_mean_squared_error: 108231.1482\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 96930.06306\n",
      "Epoch 307/350\n",
      " - 0s - loss: 44621.4143 - mean_squared_error: 44051.0005 - val_loss: 109630.4187 - val_mean_squared_error: 109081.3789\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 96930.06306\n",
      "Epoch 308/350\n",
      " - 0s - loss: 36525.9848 - mean_squared_error: 35895.4407 - val_loss: 107790.5718 - val_mean_squared_error: 107219.5950\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 96930.06306\n",
      "Epoch 309/350\n",
      " - 0s - loss: 47547.8525 - mean_squared_error: 46906.8175 - val_loss: 109110.3044 - val_mean_squared_error: 108571.0467\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 96930.06306\n",
      "Epoch 310/350\n",
      " - 0s - loss: 47246.3156 - mean_squared_error: 46659.4199 - val_loss: 106709.6037 - val_mean_squared_error: 106146.0215\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 96930.06306\n",
      "Epoch 311/350\n",
      " - 0s - loss: 39681.3830 - mean_squared_error: 39053.5529 - val_loss: 104656.2879 - val_mean_squared_error: 104064.5346\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 96930.06306\n",
      "Epoch 312/350\n",
      " - 0s - loss: 41690.8457 - mean_squared_error: 41050.2869 - val_loss: 104518.5600 - val_mean_squared_error: 103942.4819\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 96930.06306\n",
      "Epoch 313/350\n",
      " - 0s - loss: 37672.3036 - mean_squared_error: 37038.1527 - val_loss: 103528.2623 - val_mean_squared_error: 102975.5498\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 96930.06306\n",
      "Epoch 314/350\n",
      " - 0s - loss: 40086.4220 - mean_squared_error: 39457.5056 - val_loss: 101775.8245 - val_mean_squared_error: 101207.0534\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 96930.06306\n",
      "Epoch 315/350\n",
      " - 0s - loss: 35759.3519 - mean_squared_error: 35096.5121 - val_loss: 102602.8949 - val_mean_squared_error: 102036.1318\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 96930.06306\n",
      "Epoch 316/350\n",
      " - 0s - loss: 42743.3133 - mean_squared_error: 42118.7153 - val_loss: 106114.8975 - val_mean_squared_error: 105583.5257\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 96930.06306\n",
      "Epoch 317/350\n",
      " - 0s - loss: 40350.9035 - mean_squared_error: 39741.1771 - val_loss: 108324.8288 - val_mean_squared_error: 107798.8185\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 96930.06306\n",
      "Epoch 318/350\n",
      " - 0s - loss: 32872.2640 - mean_squared_error: 32245.8213 - val_loss: 109593.0600 - val_mean_squared_error: 109054.4348\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 96930.06306\n",
      "Epoch 319/350\n",
      " - 0s - loss: 47898.9431 - mean_squared_error: 47290.7542 - val_loss: 111604.1300 - val_mean_squared_error: 111047.0505\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 96930.06306\n",
      "Epoch 320/350\n",
      " - 0s - loss: 37508.5812 - mean_squared_error: 36882.6459 - val_loss: 108952.5550 - val_mean_squared_error: 108398.0490\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 96930.06306\n",
      "Epoch 321/350\n",
      " - 0s - loss: 36387.8564 - mean_squared_error: 35769.6743 - val_loss: 105222.6285 - val_mean_squared_error: 104672.1851\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 96930.06306\n",
      "Epoch 322/350\n",
      " - 0s - loss: 44508.4298 - mean_squared_error: 43910.6116 - val_loss: 107245.4206 - val_mean_squared_error: 106711.5744\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 96930.06306\n",
      "Epoch 323/350\n",
      " - 0s - loss: 41043.4657 - mean_squared_error: 40449.5267 - val_loss: 108176.2275 - val_mean_squared_error: 107642.8557\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 96930.06306\n",
      "Epoch 324/350\n",
      " - 0s - loss: 39101.0754 - mean_squared_error: 38471.2920 - val_loss: 104997.1756 - val_mean_squared_error: 104459.4143\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 96930.06306\n",
      "Epoch 325/350\n",
      " - 0s - loss: 42876.7327 - mean_squared_error: 42262.1282 - val_loss: 108448.8164 - val_mean_squared_error: 107940.3623\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 96930.06306\n",
      "Epoch 326/350\n",
      " - 0s - loss: 41073.6230 - mean_squared_error: 40472.0605 - val_loss: 103786.8883 - val_mean_squared_error: 103261.4015\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 96930.06306\n",
      "Epoch 327/350\n",
      " - 0s - loss: 45251.7229 - mean_squared_error: 44669.0559 - val_loss: 105224.5674 - val_mean_squared_error: 104688.8838\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 96930.06306\n",
      "Epoch 328/350\n",
      " - 0s - loss: 49737.3533 - mean_squared_error: 49122.1065 - val_loss: 108229.0356 - val_mean_squared_error: 107703.6915\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 96930.06306\n",
      "Epoch 329/350\n",
      " - 0s - loss: 41067.1752 - mean_squared_error: 40438.1532 - val_loss: 106114.8976 - val_mean_squared_error: 105590.1809\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 96930.06306\n",
      "Epoch 330/350\n",
      " - 0s - loss: 47588.3867 - mean_squared_error: 46988.4299 - val_loss: 105010.7151 - val_mean_squared_error: 104468.4838\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 96930.06306\n",
      "Epoch 331/350\n",
      " - 0s - loss: 37745.3451 - mean_squared_error: 37136.6121 - val_loss: 104001.1611 - val_mean_squared_error: 103444.3874\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 96930.06306\n",
      "Epoch 332/350\n",
      " - 0s - loss: 45342.9777 - mean_squared_error: 44711.6907 - val_loss: 104684.3041 - val_mean_squared_error: 104117.4593\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 96930.06306\n",
      "Epoch 333/350\n",
      " - 0s - loss: 36972.7435 - mean_squared_error: 36359.0835 - val_loss: 102694.2651 - val_mean_squared_error: 102116.6360\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 96930.06306\n",
      "Epoch 334/350\n",
      " - 0s - loss: 50982.3063 - mean_squared_error: 50404.3470 - val_loss: 101477.7328 - val_mean_squared_error: 100912.9414\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 96930.06306\n",
      "Epoch 335/350\n",
      " - 0s - loss: 43737.1680 - mean_squared_error: 43109.6910 - val_loss: 102513.1715 - val_mean_squared_error: 101924.8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00335: val_loss did not improve from 96930.06306\n",
      "Epoch 336/350\n",
      " - 0s - loss: 41427.5498 - mean_squared_error: 40799.1523 - val_loss: 104703.3958 - val_mean_squared_error: 104127.1198\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 96930.06306\n",
      "Epoch 337/350\n",
      " - 0s - loss: 32902.2441 - mean_squared_error: 32287.1218 - val_loss: 102251.4845 - val_mean_squared_error: 101683.7222\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 96930.06306\n",
      "Epoch 338/350\n",
      " - 0s - loss: 40331.9902 - mean_squared_error: 39710.1218 - val_loss: 102322.2853 - val_mean_squared_error: 101773.2302\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 96930.06306\n",
      "Epoch 339/350\n",
      " - 0s - loss: 35523.0964 - mean_squared_error: 34937.4523 - val_loss: 104098.3772 - val_mean_squared_error: 103567.4081\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 96930.06306\n",
      "Epoch 340/350\n",
      " - 0s - loss: 33768.4795 - mean_squared_error: 33168.6883 - val_loss: 103612.6175 - val_mean_squared_error: 103070.2298\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 96930.06306\n",
      "Epoch 341/350\n",
      " - 0s - loss: 37341.9722 - mean_squared_error: 36730.4803 - val_loss: 104329.7211 - val_mean_squared_error: 103784.3902\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 96930.06306\n",
      "Epoch 342/350\n",
      " - 0s - loss: 43087.9468 - mean_squared_error: 42469.3675 - val_loss: 104785.5435 - val_mean_squared_error: 104243.4915\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 96930.06306\n",
      "Epoch 343/350\n",
      " - 0s - loss: 38599.9252 - mean_squared_error: 38012.8079 - val_loss: 107847.9697 - val_mean_squared_error: 107332.4996\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 96930.06306\n",
      "Epoch 344/350\n",
      " - 0s - loss: 38550.2161 - mean_squared_error: 37962.6787 - val_loss: 105553.6243 - val_mean_squared_error: 105023.3592\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 96930.06306\n",
      "Epoch 345/350\n",
      " - 0s - loss: 37999.2312 - mean_squared_error: 37411.4675 - val_loss: 107391.3330 - val_mean_squared_error: 106859.1611\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 96930.06306\n",
      "Epoch 346/350\n",
      " - 0s - loss: 38654.6715 - mean_squared_error: 38065.9460 - val_loss: 106006.4721 - val_mean_squared_error: 105469.0985\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 96930.06306\n",
      "Epoch 347/350\n",
      " - 0s - loss: 51492.5045 - mean_squared_error: 50920.7733 - val_loss: 108443.2870 - val_mean_squared_error: 107924.7879\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 96930.06306\n",
      "Epoch 348/350\n",
      " - 0s - loss: 39162.8112 - mean_squared_error: 38585.9418 - val_loss: 104799.8836 - val_mean_squared_error: 104271.3383\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 96930.06306\n",
      "Epoch 349/350\n",
      " - 0s - loss: 39474.0986 - mean_squared_error: 38871.3807 - val_loss: 100646.8781 - val_mean_squared_error: 100106.4724\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 96930.06306\n",
      "Epoch 350/350\n",
      " - 0s - loss: 55597.9422 - mean_squared_error: 54976.2451 - val_loss: 103570.4580 - val_mean_squared_error: 103029.4210\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 96930.06306\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 350, \n",
    "          batch_size = 15, \n",
    "          verbose=2, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b24b1d0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b24c1d0908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(np.array(X_test))\n",
    "original = Y_test\n",
    "predicted = pred\n",
    "\n",
    "plt.plot(original, color='black', label = 'Original data')\n",
    "plt.plot(predicted, color='blue', label = 'Predicted data')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Actual and predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод по регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. классические функции активации (sigmoid, tanh) не работают вовсе - relu, leaky relu существенно лучше\n",
    "2. добавление dropout, batchnormalization помогло увеличить общую точность, но пик продаж модель так и не схватывает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперопт перестал выдавать прежнюю ошибку, но пока еще не закончен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(164, input_dim=WINDOW, activity_regularizer=regularizers.l2(0.0001)))\n",
    "#model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "    model.add(Dense(360, activity_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    opt = Nadam(lr=0.001)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    model.fit(X_train, Y_train, \n",
    "          nb_epoch = 150, \n",
    "          batch_size = 15, \n",
    "          verbose=2, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)\n",
    "\n",
    "    score, acc = model.evaluate(X_test, Y_test, verbose=2)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import statsmodels.api as sm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import statsmodels.tsa.api as smt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from statsmodels.tsa.stattools import adfuller\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from dateutil.relativedelta import relativedelta\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from arch import arch_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pylab as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.normalization import BatchNormalization\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Merge\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.advanced_activations import *\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Convolution1D, MaxPooling1D, AtrousConvolution1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.recurrent import LSTM, GRU\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import regularizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import copy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.wrappers.scikit_learn import KerasRegressor\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import GridSearchCV\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import hyperas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "    }\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "2012-09-09      23\n2012-09-16      10\n2012-09-23       9\n2012-09-30       4\n2012-10-07       4\n2012-10-14       6\n2012-10-21       2\n2012-10-28       1\n2012-11-04       2\n2012-11-11       0\n2012-11-18       1\n2012-11-25       1\n2012-12-02       0\n2012-12-09       2\n2012-12-16       0\n2012-12-23       0\n2012-12-30       0\n2013-01-06       0\n2013-01-13       0\n2013-01-20       0\n2013-01-27       5\n2013-02-03       2\n2013-02-10       3\n2013-02-17      18\n2013-02-24      57\n2013-03-03     161\n2013-03-10     115\n2013-03-17     101\n2013-03-24     101\n2013-03-31     121\n              ... \n2018-01-14      42\n2018-01-21      33\n2018-01-28      23\n2018-02-04      34\n2018-02-11      31\n2018-02-18      36\n2018-02-25      38\n2018-03-04      72\n2018-03-11     269\n2018-03-18     150\n2018-03-25     145\n2018-04-01     180\n2018-04-08     274\n2018-04-15     695\n2018-04-22     589\n2018-04-29     650\n2018-05-06    1163\n2018-05-13     972\n2018-05-20    1714\n2018-05-27    1586\n2018-06-03    1832\n2018-06-10    1021\n2018-06-17    1062\n2018-06-24     914\n2018-07-01     778\n2018-07-08     661\n2018-07-15     656\n2018-07-22     529\n2018-07-29     488\n2018-08-05     259\nName: sales, Length: 309, dtype: int64 is not a module, class, method, function, traceback, frame, or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-ac7576bb83a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                           notebook_name='Keras only')\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Evalutation of best performing model:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_model_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hyperopt_model_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mtemp_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./temp_model.py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mwrite_temp_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mget_hyperopt_model_string\u001b[1;34m(model, data, functions, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0mfunctions_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_function_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[0mdata_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_data_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyperopt_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mretrieve_data_string\u001b[1;34m(data, verbose)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mretrieve_data_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[0mdata_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[0mfirst_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mindent_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetermine_indent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0msource\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mAn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     OSError is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m--> 968\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetsourcelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcelines\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    953\u001b[0m     raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    954\u001b[0m     \u001b[0mobject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m     \u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    766\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Invalidate cache if needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mway\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0midentified\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m     \"\"\"\n\u001b[1;32m--> 684\u001b[1;33m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG_BYTECODE_SUFFIXES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m     \u001b[0mall_bytecode_suffixes\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachinery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZED_BYTECODE_SUFFIXES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Pythonn\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mco_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     raise TypeError('{!r} is not a module, class, method, '\n\u001b[1;32m--> 666\u001b[1;33m                     'function, traceback, frame, or code object'.format(object))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetmodulename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 2012-09-09      23\n2012-09-16      10\n2012-09-23       9\n2012-09-30       4\n2012-10-07       4\n2012-10-14       6\n2012-10-21       2\n2012-10-28       1\n2012-11-04       2\n2012-11-11       0\n2012-11-18       1\n2012-11-25       1\n2012-12-02       0\n2012-12-09       2\n2012-12-16       0\n2012-12-23       0\n2012-12-30       0\n2013-01-06       0\n2013-01-13       0\n2013-01-20       0\n2013-01-27       5\n2013-02-03       2\n2013-02-10       3\n2013-02-17      18\n2013-02-24      57\n2013-03-03     161\n2013-03-10     115\n2013-03-17     101\n2013-03-24     101\n2013-03-31     121\n              ... \n2018-01-14      42\n2018-01-21      33\n2018-01-28      23\n2018-02-04      34\n2018-02-11      31\n2018-02-18      36\n2018-02-25      38\n2018-03-04      72\n2018-03-11     269\n2018-03-18     150\n2018-03-25     145\n2018-04-01     180\n2018-04-08     274\n2018-04-15     695\n2018-04-22     589\n2018-04-29     650\n2018-05-06    1163\n2018-05-13     972\n2018-05-20    1714\n2018-05-27    1586\n2018-06-03    1832\n2018-06-10    1021\n2018-06-17    1062\n2018-06-24     914\n2018-07-01     778\n2018-07-08     661\n2018-07-15     656\n2018-07-22     529\n2018-07-29     488\n2018-08-05     259\nName: sales, Length: 309, dtype: int64 is not a module, class, method, function, traceback, frame, or code object"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='Keras only')\n",
    "    X_train, Y_train, X_test, Y_test = data()\n",
    "    print('Evalutation of best performing model:')\n",
    "    print(best_model.evaluate(X_test, Y_test))\n",
    "    print('Best performing model chosen hyper-parameters:')\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другой подход к Keras, через кроссвалидацию, такой же подход использовался затем на методах  sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### функция кроссвалидации, функции ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTimeSeriesCV(X_train, y_train, number_folds, model, metrics):\n",
    "    print('Size train set: {}'.format(X_train.shape))\n",
    "\n",
    "    k = int(np.floor(float(X_train.shape[0]) / number_folds))\n",
    "    print('Size of each fold: {}'.format(k))\n",
    "\n",
    "    errors = np.zeros(number_folds-1)\n",
    "\n",
    "    for i in range(2, number_folds + 1):\n",
    "        print('')\n",
    "        split = float(i-1)/i\n",
    "        print('Splitting the first ' + str(i) + ' chunks at ' + str(i-1) + '/' + str(i) )\n",
    "\n",
    "        X = X_train[:(k*i)]\n",
    "        y = y_train[:(k*i)]\n",
    "        print('Size of train + test: {}'.format(X.shape)) \n",
    "\n",
    "        index = int(np.floor(X.shape[0] * split))\n",
    "    \n",
    "        X_trainFolds = X[:index]        \n",
    "        y_trainFolds = y[:index]\n",
    "\n",
    "        X_testFold = X[(index + 1):]\n",
    "        y_testFold = y[(index + 1):]\n",
    "\n",
    "        model.fit(X_trainFolds, y_trainFolds)\n",
    "        errors[i-2] = metrics(model.predict(X_testFold), y_testFold)\n",
    "   \n",
    "    return errors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score, mean_absolute_error, mean_squared_log_error, median_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(ytrue,ypred):\n",
    "    return np.sqrt(mean_squared_error(ytrue, ypred));\n",
    "def mse(ytrue,ypred):\n",
    "    return (mean_squared_error(ytrue, ypred));\n",
    "def rmsle(ytrue, ypred):\n",
    "    return mean_squared_log_error(ytrue, ypred);\n",
    "def mae (ytrue,ypred):\n",
    "    return mean_absolute_error(ytrue,ypred);\n",
    "def r2 (ytrue,ypred):\n",
    "    return r2_score(ytrue,ypred);\n",
    "def evs (ytrue,ypred):\n",
    "    return explained_variance_score(ytrue,ypred);\n",
    "def medae (ytrue,ypred):\n",
    "    return median_absolute_error(ytrue,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты, подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name=None\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(\"2012-09-09\", \"%Y-%m-%d\")\n",
    "date_list = [start + relativedelta(weeks=x) for x in range(0,len(df.sales))]\n",
    "df['index'] =date_list\n",
    "df.set_index(['index'], inplace=True)\n",
    "df.index.name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>dates</th>\n",
       "      <th>sales</th>\n",
       "      <th>AUP_RUR</th>\n",
       "      <th>AUP_RUR_RRP</th>\n",
       "      <th>AUP+bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-09</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>23</td>\n",
       "      <td>5658.513739</td>\n",
       "      <td>9619.448357</td>\n",
       "      <td>6612.109391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-16</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-09-16</td>\n",
       "      <td>10</td>\n",
       "      <td>6065.175200</td>\n",
       "      <td>10238.858811</td>\n",
       "      <td>6762.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>5876.925926</td>\n",
       "      <td>9058.186700</td>\n",
       "      <td>6231.744815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>5319.947500</td>\n",
       "      <td>9415.000000</td>\n",
       "      <td>6163.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>4</td>\n",
       "      <td>6731.930000</td>\n",
       "      <td>9415.000000</td>\n",
       "      <td>6807.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ind       dates  sales      AUP_RUR   AUP_RUR_RRP    AUP+bonus\n",
       "2012-09-09    1  2012-09-09     23  5658.513739   9619.448357  6612.109391\n",
       "2012-09-16    2  2012-09-16     10  6065.175200  10238.858811  6762.978200\n",
       "2012-09-23    3  2012-09-23      9  5876.925926   9058.186700  6231.744815\n",
       "2012-09-30    4  2012-09-30      4  5319.947500   9415.000000  6163.250000\n",
       "2012-10-07    5  2012-10-07      4  6731.930000   9415.000000  6807.750000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = copy.deepcopy(df[['dates','sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data2.dates = pd.to_datetime(data2.dates)\n",
    "data2.TRDATETIME = pd.to_datetime(data2['dates'],  dayfirst= True, format='%d%b%y:%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['date'] = data2['dates'].dt.date\n",
    "data2['day'] = data2['dates'].dt.day\n",
    "data2['month'] = data2['dates'].dt.month\n",
    "data2['year'] = data2['dates'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-09</th>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>23</td>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-16</th>\n",
       "      <td>2012-09-16</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-09-16</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dates  sales        date  day  month  year\n",
       "2012-09-09 2012-09-09     23  2012-09-09    9      9  2012\n",
       "2012-09-16 2012-09-16     10  2012-09-16   16      9  2012\n",
       "2012-09-23 2012-09-23      9  2012-09-23   23      9  2012\n",
       "2012-09-30 2012-09-30      4  2012-09-30   30      9  2012\n",
       "2012-10-07 2012-10-07      4  2012-10-07    7     10  2012"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['season'] = data2.sales"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data2['season'].loc['2012':'2013-03-01'] = \"aw13\"\n",
    "data2['season'].loc['2013-03-01':'2013-09-01'] = \"ss13\"\n",
    "data2['season'].loc['2013-09-01':'2014-03-01'] = \"aw14\"\n",
    "data2['season'].loc['2014-03-01':'2014-09-01'] = \"ss14\"\n",
    "data2['season'].loc['2014-09-01':'2015-03-01'] = \"aw15\"\n",
    "data2['season'].loc['2015-03-01':'2015-09-01'] = \"ss15\"\n",
    "data2['season'].loc['2015-09-01':'2016-03-01'] = \"aw16\"\n",
    "data2['season'].loc['2016-03-01':'2016-09-01'] = \"ss16\"\n",
    "data2['season'].loc['2016-09-01':'2017-03-01'] = \"aw17\"\n",
    "data2['season'].loc['2017-03-01':'2017-09-01'] = \"ss17\"\n",
    "data2['season'].loc['2017-09-01':'2018-03-01'] = \"aw18\"\n",
    "data2['season'].loc['2018-03-01':'2018-09-01'] = \"ss18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pythonn\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data2['season'].loc['2012':'2013-03-01'] = \"aw\"\n",
    "data2['season'].loc['2013-03-01':'2013-09-01'] = \"ss\"\n",
    "data2['season'].loc['2013-09-01':'2014-03-01'] = \"aw\"\n",
    "data2['season'].loc['2014-03-01':'2014-09-01'] = \"ss\"\n",
    "data2['season'].loc['2014-09-01':'2015-03-01'] = \"aw\"\n",
    "data2['season'].loc['2015-03-01':'2015-09-01'] = \"ss\"\n",
    "data2['season'].loc['2015-09-01':'2016-03-01'] = \"aw\"\n",
    "data2['season'].loc['2016-03-01':'2016-09-01'] = \"ss\"\n",
    "data2['season'].loc['2016-09-01':'2017-03-01'] = \"aw\"\n",
    "data2['season'].loc['2017-03-01':'2017-09-01'] = \"ss\"\n",
    "data2['season'].loc['2017-09-01':'2018-03-01'] = \"aw\"\n",
    "data2['season'].loc['2018-03-01':'2018-09-01'] = \"ss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Last_Week_Sales'] = data2['sales'].shift()\n",
    "data2['Last_Week_Diff'] = data2['Last_Week_Sales'].diff()\n",
    "data2 = data2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>Last_Week_Sales</th>\n",
       "      <th>Last_Week_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-09-23</th>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-30</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-07</th>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-07</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-14</th>\n",
       "      <td>2012-10-14</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-10-14</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-21</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dates  sales        date  day  month  year season  \\\n",
       "2012-09-23 2012-09-23      9  2012-09-23   23      9  2012     aw   \n",
       "2012-09-30 2012-09-30      4  2012-09-30   30      9  2012     aw   \n",
       "2012-10-07 2012-10-07      4  2012-10-07    7     10  2012     aw   \n",
       "2012-10-14 2012-10-14      6  2012-10-14   14     10  2012     aw   \n",
       "2012-10-21 2012-10-21      2  2012-10-21   21     10  2012     aw   \n",
       "\n",
       "            Last_Week_Sales  Last_Week_Diff  \n",
       "2012-09-23             10.0           -13.0  \n",
       "2012-09-30              9.0            -1.0  \n",
       "2012-10-07              4.0            -5.0  \n",
       "2012-10-14              4.0             0.0  \n",
       "2012-10-21              6.0             2.0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['weeks'] = list(range(len(data2.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.index = list(range(len(data2.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('dates', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('date', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>Last_Week_Sales</th>\n",
       "      <th>Last_Week_Diff</th>\n",
       "      <th>weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>aw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  day  month  year season  Last_Week_Sales  Last_Week_Diff  weeks\n",
       "0      9   23      9  2012     aw             10.0           -13.0      0\n",
       "1      4   30      9  2012     aw              9.0            -1.0      1\n",
       "2      4    7     10  2012     aw              4.0            -5.0      2\n",
       "3      6   14     10  2012     aw              4.0             0.0      3\n",
       "4      2   21     10  2012     aw              6.0             2.0      4"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.get_dummies(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Last_Week_Sales</th>\n",
       "      <th>Last_Week_Diff</th>\n",
       "      <th>weeks</th>\n",
       "      <th>season_aw</th>\n",
       "      <th>season_ss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  day  month  year  Last_Week_Sales  Last_Week_Diff  weeks  season_aw  \\\n",
       "0      9   23      9  2012             10.0           -13.0      0          1   \n",
       "1      4   30      9  2012              9.0            -1.0      1          1   \n",
       "2      4    7     10  2012              4.0            -5.0      2          1   \n",
       "3      6   14     10  2012              4.0             0.0      3          1   \n",
       "4      2   21     10  2012              6.0             2.0      4          1   \n",
       "\n",
       "   season_ss  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data3.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data3.drop('sales', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data3[:302].drop('sales', axis = 1)\n",
    "Y_train = data3[:302].sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### используем последнюю модель из keras-регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=8,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(360,\n",
    "                activity_regularizer=regularizers.l2(0.05)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.9, patience=50, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"test.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, \n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train set: (302, 8)\n",
      "Size of each fold: 3\n",
      "\n",
      "Splitting the first 2 chunks at 1/2\n",
      "Size of train + test: (6, 8)\n",
      "Epoch 1/1\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 1011421.0000 - mean_squared_error: 36.7755\n",
      "\n",
      "Splitting the first 3 chunks at 2/3\n",
      "Size of train + test: (9, 8)\n",
      "Epoch 1/1\n",
      "6/6 [==============================] - 0s 333us/step - loss: 1830994.2500 - mean_squared_error: 16.7057\n",
      "\n",
      "Splitting the first 4 chunks at 3/4\n",
      "Size of train + test: (12, 8)\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 0s 332us/step - loss: 2472398.5000 - mean_squared_error: 5.9331\n",
      "\n",
      "Splitting the first 5 chunks at 4/5\n",
      "Size of train + test: (15, 8)\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 0s 247us/step - loss: 2936887.5000 - mean_squared_error: 3.8330\n",
      "\n",
      "Splitting the first 6 chunks at 5/6\n",
      "Size of train + test: (18, 8)\n",
      "Epoch 1/1\n",
      "15/15 [==============================] - 0s 134us/step - loss: 3241257.2500 - mean_squared_error: 8.9236\n",
      "\n",
      "Splitting the first 7 chunks at 6/7\n",
      "Size of train + test: (21, 8)\n",
      "Epoch 1/1\n",
      "18/18 [==============================] - 0s 166us/step - loss: 3370004.5000 - mean_squared_error: 31.8705\n",
      "\n",
      "Splitting the first 8 chunks at 7/8\n",
      "Size of train + test: (24, 8)\n",
      "Epoch 1/1\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3411820.2500 - mean_squared_error: 11.2982\n",
      "\n",
      "Splitting the first 9 chunks at 8/9\n",
      "Size of train + test: (27, 8)\n",
      "Epoch 1/1\n",
      "24/24 [==============================] - 0s 165us/step - loss: 3349927.7500 - mean_squared_error: 1212.2100\n",
      "\n",
      "Splitting the first 10 chunks at 9/10\n",
      "Size of train + test: (30, 8)\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 0s 111us/step - loss: 3185008.7500 - mean_squared_error: 1620.6123\n",
      "\n",
      "Splitting the first 11 chunks at 10/11\n",
      "Size of train + test: (33, 8)\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 0s 100us/step - loss: 2951517.2500 - mean_squared_error: 6005.8491\n",
      "\n",
      "Splitting the first 12 chunks at 11/12\n",
      "Size of train + test: (36, 8)\n",
      "Epoch 1/1\n",
      "33/33 [==============================] - 0s 181us/step - loss: 2569507.5417 - mean_squared_error: 61539.4356\n",
      "\n",
      "Splitting the first 13 chunks at 12/13\n",
      "Size of train + test: (39, 8)\n",
      "Epoch 1/1\n",
      "36/36 [==============================] - 0s 166us/step - loss: 1921904.9306 - mean_squared_error: 134087.9975\n",
      "\n",
      "Splitting the first 14 chunks at 13/14\n",
      "Size of train + test: (42, 8)\n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 0s 128us/step - loss: 1463958.9984 - mean_squared_error: 190072.3287\n",
      "\n",
      "Splitting the first 15 chunks at 14/15\n",
      "Size of train + test: (45, 8)\n",
      "Epoch 1/1\n",
      "42/42 [==============================] - 0s 142us/step - loss: 1100115.2336 - mean_squared_error: 188274.2046\n",
      "\n",
      "Splitting the first 16 chunks at 15/16\n",
      "Size of train + test: (48, 8)\n",
      "Epoch 1/1\n",
      "45/45 [==============================] - 0s 133us/step - loss: 813383.3083 - mean_squared_error: 177917.6354\n",
      "\n",
      "Splitting the first 17 chunks at 16/17\n",
      "Size of train + test: (51, 8)\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 0s 125us/step - loss: 625362.6458 - mean_squared_error: 161333.4792\n",
      "\n",
      "Splitting the first 18 chunks at 17/18\n",
      "Size of train + test: (54, 8)\n",
      "Epoch 1/1\n",
      "51/51 [==============================] - 0s 98us/step - loss: 480638.8033 - mean_squared_error: 142141.4479\n",
      "\n",
      "Splitting the first 19 chunks at 18/19\n",
      "Size of train + test: (57, 8)\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 0s 129us/step - loss: 379955.3611 - mean_squared_error: 127502.9948\n",
      "\n",
      "Splitting the first 20 chunks at 19/20\n",
      "Size of train + test: (60, 8)\n",
      "Epoch 1/1\n",
      "57/57 [==============================] - 0s 105us/step - loss: 300487.2922 - mean_squared_error: 110012.1705\n",
      "\n",
      "Splitting the first 21 chunks at 20/21\n",
      "Size of train + test: (63, 8)\n",
      "Epoch 1/1\n",
      "60/60 [==============================] - 0s 100us/step - loss: 241757.5792 - mean_squared_error: 96930.3885\n",
      "\n",
      "Splitting the first 22 chunks at 21/22\n",
      "Size of train + test: (66, 8)\n",
      "Epoch 1/1\n",
      "63/63 [==============================] - 0s 95us/step - loss: 197117.1843 - mean_squared_error: 85949.4783\n",
      "\n",
      "Splitting the first 23 chunks at 22/23\n",
      "Size of train + test: (69, 8)\n",
      "Epoch 1/1\n",
      "66/66 [==============================] - 0s 121us/step - loss: 156948.0450 - mean_squared_error: 73721.1103\n",
      "\n",
      "Splitting the first 24 chunks at 23/24\n",
      "Size of train + test: (72, 8)\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 130us/step - loss: 116111.8614 - mean_squared_error: 64507.2767\n",
      "\n",
      "Splitting the first 25 chunks at 24/25\n",
      "Size of train + test: (75, 8)\n",
      "Epoch 1/1\n",
      "72/72 [==============================] - 0s 139us/step - loss: 97631.1951 - mean_squared_error: 55079.6654\n",
      "\n",
      "Splitting the first 26 chunks at 25/26\n",
      "Size of train + test: (78, 8)\n",
      "Epoch 1/1\n",
      "75/75 [==============================] - 0s 106us/step - loss: 71593.5389 - mean_squared_error: 42237.0693\n",
      "\n",
      "Splitting the first 27 chunks at 26/27\n",
      "Size of train + test: (81, 8)\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 0s 115us/step - loss: 62738.9195 - mean_squared_error: 43818.8213\n",
      "\n",
      "Splitting the first 28 chunks at 27/28\n",
      "Size of train + test: (84, 8)\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 0s 92us/step - loss: 43284.3117 - mean_squared_error: 28009.2772\n",
      "\n",
      "Splitting the first 29 chunks at 28/29\n",
      "Size of train + test: (87, 8)\n",
      "Epoch 1/1\n",
      "84/84 [==============================] - 0s 95us/step - loss: 42205.6124 - mean_squared_error: 29948.7517\n",
      "\n",
      "Splitting the first 30 chunks at 29/30\n",
      "Size of train + test: (90, 8)\n",
      "Epoch 1/1\n",
      "87/87 [==============================] - 0s 103us/step - loss: 51058.3799 - mean_squared_error: 40313.5694\n",
      "\n",
      "Splitting the first 31 chunks at 30/31\n",
      "Size of train + test: (93, 8)\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 111us/step - loss: 73625.3266 - mean_squared_error: 57728.4100\n",
      "\n",
      "Splitting the first 32 chunks at 31/32\n",
      "Size of train + test: (96, 8)\n",
      "Epoch 1/1\n",
      "93/93 [==============================] - 0s 86us/step - loss: 71231.0215 - mean_squared_error: 57966.8537\n",
      "\n",
      "Splitting the first 33 chunks at 32/33\n",
      "Size of train + test: (99, 8)\n",
      "Epoch 1/1\n",
      "96/96 [==============================] - 0s 83us/step - loss: 97132.1146 - mean_squared_error: 82655.3411\n",
      "\n",
      "Splitting the first 34 chunks at 33/34\n",
      "Size of train + test: (102, 8)\n",
      "Epoch 1/1\n",
      "99/99 [==============================] - 0s 101us/step - loss: 93669.0372 - mean_squared_error: 80725.8604\n",
      "\n",
      "Splitting the first 35 chunks at 34/35\n",
      "Size of train + test: (105, 8)\n",
      "Epoch 1/1\n",
      "102/102 [==============================] - 0s 108us/step - loss: 82374.4121 - mean_squared_error: 66052.4170\n",
      "\n",
      "Splitting the first 36 chunks at 35/36\n",
      "Size of train + test: (108, 8)\n",
      "Epoch 1/1\n",
      "105/105 [==============================] - 0s 104us/step - loss: 62663.4629 - mean_squared_error: 49735.3885\n",
      "\n",
      "Splitting the first 37 chunks at 36/37\n",
      "Size of train + test: (111, 8)\n",
      "Epoch 1/1\n",
      "108/108 [==============================] - 0s 92us/step - loss: 39400.3942 - mean_squared_error: 30535.5548\n",
      "\n",
      "Splitting the first 38 chunks at 37/38\n",
      "Size of train + test: (114, 8)\n",
      "Epoch 1/1\n",
      "111/111 [==============================] - 0s 90us/step - loss: 60653.0413 - mean_squared_error: 47774.2801\n",
      "\n",
      "Splitting the first 39 chunks at 38/39\n",
      "Size of train + test: (117, 8)\n",
      "Epoch 1/1\n",
      "114/114 [==============================] - 0s 96us/step - loss: 49261.9807 - mean_squared_error: 39381.0642\n",
      "\n",
      "Splitting the first 40 chunks at 39/40\n",
      "Size of train + test: (120, 8)\n",
      "Epoch 1/1\n",
      "117/117 [==============================] - 0s 111us/step - loss: 27365.8212 - mean_squared_error: 19270.1791\n",
      "\n",
      "Splitting the first 41 chunks at 40/41\n",
      "Size of train + test: (123, 8)\n",
      "Epoch 1/1\n",
      "120/120 [==============================] - 0s 108us/step - loss: 39911.2766 - mean_squared_error: 26735.1117\n",
      "\n",
      "Splitting the first 42 chunks at 41/42\n",
      "Size of train + test: (126, 8)\n",
      "Epoch 1/1\n",
      "123/123 [==============================] - 0s 89us/step - loss: 55414.0789 - mean_squared_error: 44405.0444\n",
      "\n",
      "Splitting the first 43 chunks at 42/43\n",
      "Size of train + test: (129, 8)\n",
      "Epoch 1/1\n",
      "126/126 [==============================] - 0s 87us/step - loss: 31529.0144 - mean_squared_error: 21858.8868\n",
      "\n",
      "Splitting the first 44 chunks at 43/44\n",
      "Size of train + test: (132, 8)\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 101us/step - loss: 45059.8857 - mean_squared_error: 34779.0591\n",
      "\n",
      "Splitting the first 45 chunks at 44/45\n",
      "Size of train + test: (135, 8)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 98us/step - loss: 33681.2086 - mean_squared_error: 24516.3891\n",
      "\n",
      "Splitting the first 46 chunks at 45/46\n",
      "Size of train + test: (138, 8)\n",
      "Epoch 1/1\n",
      "135/135 [==============================] - 0s 103us/step - loss: 30310.8307 - mean_squared_error: 18392.3973\n",
      "\n",
      "Splitting the first 47 chunks at 46/47\n",
      "Size of train + test: (141, 8)\n",
      "Epoch 1/1\n",
      "138/138 [==============================] - 0s 87us/step - loss: 34158.3627 - mean_squared_error: 25375.4474\n",
      "\n",
      "Splitting the first 48 chunks at 47/48\n",
      "Size of train + test: (144, 8)\n",
      "Epoch 1/1\n",
      "141/141 [==============================] - 0s 92us/step - loss: 62911.4610 - mean_squared_error: 47798.5496\n",
      "\n",
      "Splitting the first 49 chunks at 48/49\n",
      "Size of train + test: (147, 8)\n",
      "Epoch 1/1\n",
      "144/144 [==============================] - 0s 111us/step - loss: 47179.3372 - mean_squared_error: 34549.7101\n",
      "\n",
      "Splitting the first 50 chunks at 49/50\n",
      "Size of train + test: (150, 8)\n",
      "Epoch 1/1\n",
      "147/147 [==============================] - 0s 102us/step - loss: 39784.6271 - mean_squared_error: 30596.9817\n",
      "\n",
      "Splitting the first 51 chunks at 50/51\n",
      "Size of train + test: (153, 8)\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 86us/step - loss: 46088.5439 - mean_squared_error: 36625.7057\n",
      "\n",
      "Splitting the first 52 chunks at 51/52\n",
      "Size of train + test: (156, 8)\n",
      "Epoch 1/1\n",
      "153/153 [==============================] - 0s 85us/step - loss: 40000.4797 - mean_squared_error: 30063.6293\n",
      "\n",
      "Splitting the first 53 chunks at 52/53\n",
      "Size of train + test: (159, 8)\n",
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 77us/step - loss: 42715.9290 - mean_squared_error: 33293.4461\n",
      "\n",
      "Splitting the first 54 chunks at 53/54\n",
      "Size of train + test: (162, 8)\n",
      "Epoch 1/1\n",
      "159/159 [==============================] - 0s 75us/step - loss: 36273.6470 - mean_squared_error: 28226.9011\n",
      "\n",
      "Splitting the first 55 chunks at 54/55\n",
      "Size of train + test: (165, 8)\n",
      "Epoch 1/1\n",
      "162/162 [==============================] - 0s 86us/step - loss: 32160.7446 - mean_squared_error: 23420.1890\n",
      "\n",
      "Splitting the first 56 chunks at 55/56\n",
      "Size of train + test: (168, 8)\n",
      "Epoch 1/1\n",
      "165/165 [==============================] - 0s 91us/step - loss: 35497.8269 - mean_squared_error: 28552.1581\n",
      "\n",
      "Splitting the first 57 chunks at 56/57\n",
      "Size of train + test: (171, 8)\n",
      "Epoch 1/1\n",
      "168/168 [==============================] - 0s 95us/step - loss: 41958.0089 - mean_squared_error: 33930.5766\n",
      "\n",
      "Splitting the first 58 chunks at 57/58\n",
      "Size of train + test: (174, 8)\n",
      "Epoch 1/1\n",
      "171/171 [==============================] - 0s 93us/step - loss: 37944.0918 - mean_squared_error: 31176.8367\n",
      "\n",
      "Splitting the first 59 chunks at 58/59\n",
      "Size of train + test: (177, 8)\n",
      "Epoch 1/1\n",
      "174/174 [==============================] - 0s 80us/step - loss: 32841.3128 - mean_squared_error: 27516.4423\n",
      "\n",
      "Splitting the first 60 chunks at 59/60\n",
      "Size of train + test: (180, 8)\n",
      "Epoch 1/1\n",
      "177/177 [==============================] - 0s 85us/step - loss: 38525.6429 - mean_squared_error: 31631.7240\n",
      "\n",
      "Splitting the first 61 chunks at 60/61\n",
      "Size of train + test: (183, 8)\n",
      "Epoch 1/1\n",
      "180/180 [==============================] - 0s 83us/step - loss: 26094.5572 - mean_squared_error: 20854.7559\n",
      "\n",
      "Splitting the first 62 chunks at 61/62\n",
      "Size of train + test: (186, 8)\n",
      "Epoch 1/1\n",
      "183/183 [==============================] - 0s 82us/step - loss: 25418.6442 - mean_squared_error: 19793.6885\n",
      "\n",
      "Splitting the first 63 chunks at 62/63\n",
      "Size of train + test: (189, 8)\n",
      "Epoch 1/1\n",
      "186/186 [==============================] - 0s 86us/step - loss: 30298.5297 - mean_squared_error: 25177.4761\n",
      "\n",
      "Splitting the first 64 chunks at 63/64\n",
      "Size of train + test: (192, 8)\n",
      "Epoch 1/1\n",
      "189/189 [==============================] - 0s 79us/step - loss: 29745.4875 - mean_squared_error: 24683.4723\n",
      "\n",
      "Splitting the first 65 chunks at 64/65\n",
      "Size of train + test: (195, 8)\n",
      "Epoch 1/1\n",
      "192/192 [==============================] - 0s 83us/step - loss: 45221.1689 - mean_squared_error: 37521.2599\n",
      "\n",
      "Splitting the first 66 chunks at 65/66\n",
      "Size of train + test: (198, 8)\n",
      "Epoch 1/1\n",
      "195/195 [==============================] - 0s 82us/step - loss: 37593.5401 - mean_squared_error: 26584.7167\n",
      "\n",
      "Splitting the first 67 chunks at 66/67\n",
      "Size of train + test: (201, 8)\n",
      "Epoch 1/1\n",
      "198/198 [==============================] - 0s 86us/step - loss: 33463.9415 - mean_squared_error: 23775.9623\n",
      "\n",
      "Splitting the first 68 chunks at 67/68\n",
      "Size of train + test: (204, 8)\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 0s 99us/step - loss: 39883.9811 - mean_squared_error: 30902.5133\n",
      "\n",
      "Splitting the first 69 chunks at 68/69\n",
      "Size of train + test: (207, 8)\n",
      "Epoch 1/1\n",
      "204/204 [==============================] - 0s 88us/step - loss: 33440.9576 - mean_squared_error: 26066.8891\n",
      "\n",
      "Splitting the first 70 chunks at 69/70\n",
      "Size of train + test: (210, 8)\n",
      "Epoch 1/1\n",
      "207/207 [==============================] - 0s 82us/step - loss: 30021.5045 - mean_squared_error: 25218.5009\n",
      "\n",
      "Splitting the first 71 chunks at 70/71\n",
      "Size of train + test: (213, 8)\n",
      "Epoch 1/1\n",
      "210/210 [==============================] - 0s 81us/step - loss: 25991.7898 - mean_squared_error: 21934.2882\n",
      "\n",
      "Splitting the first 72 chunks at 71/72\n",
      "Size of train + test: (216, 8)\n",
      "Epoch 1/1\n",
      "213/213 [==============================] - 0s 84us/step - loss: 24538.0978 - mean_squared_error: 18243.7404\n",
      "\n",
      "Splitting the first 73 chunks at 72/73\n",
      "Size of train + test: (219, 8)\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 0s 97us/step - loss: 28506.0351 - mean_squared_error: 23843.3298\n",
      "\n",
      "Splitting the first 74 chunks at 73/74\n",
      "Size of train + test: (222, 8)\n",
      "Epoch 1/1\n",
      "219/219 [==============================] - 0s 91us/step - loss: 26274.0244 - mean_squared_error: 20658.9043\n",
      "\n",
      "Splitting the first 75 chunks at 74/75\n",
      "Size of train + test: (225, 8)\n",
      "Epoch 1/1\n",
      "222/222 [==============================] - 0s 90us/step - loss: 25293.1432 - mean_squared_error: 19890.4945\n",
      "\n",
      "Splitting the first 76 chunks at 75/76\n",
      "Size of train + test: (228, 8)\n",
      "Epoch 1/1\n",
      "225/225 [==============================] - 0s 84us/step - loss: 26360.8833 - mean_squared_error: 19328.0414\n",
      "\n",
      "Splitting the first 77 chunks at 76/77\n",
      "Size of train + test: (231, 8)\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 0s 87us/step - loss: 43612.9606 - mean_squared_error: 35210.1589\n",
      "\n",
      "Splitting the first 78 chunks at 77/78\n",
      "Size of train + test: (234, 8)\n",
      "Epoch 1/1\n",
      "231/231 [==============================] - 0s 86us/step - loss: 27672.6870 - mean_squared_error: 21394.4624\n",
      "\n",
      "Splitting the first 79 chunks at 78/79\n",
      "Size of train + test: (237, 8)\n",
      "Epoch 1/1\n",
      "234/234 [==============================] - 0s 90us/step - loss: 25294.6756 - mean_squared_error: 21323.5389\n",
      "\n",
      "Splitting the first 80 chunks at 79/80\n",
      "Size of train + test: (240, 8)\n",
      "Epoch 1/1\n",
      "237/237 [==============================] - 0s 80us/step - loss: 31267.2230 - mean_squared_error: 27536.2354\n",
      "\n",
      "Splitting the first 81 chunks at 80/81\n",
      "Size of train + test: (243, 8)\n",
      "Epoch 1/1\n",
      "240/240 [==============================] - 0s 79us/step - loss: 23100.6831 - mean_squared_error: 19843.8971\n",
      "\n",
      "Splitting the first 82 chunks at 81/82\n",
      "Size of train + test: (246, 8)\n",
      "Epoch 1/1\n",
      "243/243 [==============================] - 0s 82us/step - loss: 20294.2489 - mean_squared_error: 17379.8100\n",
      "\n",
      "Splitting the first 83 chunks at 82/83\n",
      "Size of train + test: (249, 8)\n",
      "Epoch 1/1\n",
      "246/246 [==============================] - 0s 81us/step - loss: 38290.5745 - mean_squared_error: 33289.0831\n",
      "\n",
      "Splitting the first 84 chunks at 83/84\n",
      "Size of train + test: (252, 8)\n",
      "Epoch 1/1\n",
      "249/249 [==============================] - 0s 84us/step - loss: 30642.9575 - mean_squared_error: 25872.3959\n",
      "\n",
      "Splitting the first 85 chunks at 84/85\n",
      "Size of train + test: (255, 8)\n",
      "Epoch 1/1\n",
      "252/252 [==============================] - 0s 87us/step - loss: 30655.1061 - mean_squared_error: 24874.1816\n",
      "\n",
      "Splitting the first 86 chunks at 85/86\n",
      "Size of train + test: (258, 8)\n",
      "Epoch 1/1\n",
      "255/255 [==============================] - 0s 78us/step - loss: 37432.2592 - mean_squared_error: 26711.7709\n",
      "\n",
      "Splitting the first 87 chunks at 86/87\n",
      "Size of train + test: (261, 8)\n",
      "Epoch 1/1\n",
      "258/258 [==============================] - 0s 85us/step - loss: 33026.2082 - mean_squared_error: 24347.8287\n",
      "\n",
      "Splitting the first 88 chunks at 87/88\n",
      "Size of train + test: (264, 8)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 84us/step - loss: 34178.5720 - mean_squared_error: 25560.8899\n",
      "\n",
      "Splitting the first 89 chunks at 88/89\n",
      "Size of train + test: (267, 8)\n",
      "Epoch 1/1\n",
      "264/264 [==============================] - 0s 91us/step - loss: 33537.3401 - mean_squared_error: 26409.5452\n",
      "\n",
      "Splitting the first 90 chunks at 89/90\n",
      "Size of train + test: (270, 8)\n",
      "Epoch 1/1\n",
      "267/267 [==============================] - 0s 86us/step - loss: 43918.3685 - mean_squared_error: 37363.5886\n",
      "\n",
      "Splitting the first 91 chunks at 90/91\n",
      "Size of train + test: (273, 8)\n",
      "Epoch 1/1\n",
      "270/270 [==============================] - 0s 89us/step - loss: 26425.3574 - mean_squared_error: 22362.6870\n",
      "\n",
      "Splitting the first 92 chunks at 91/92\n",
      "Size of train + test: (276, 8)\n",
      "Epoch 1/1\n",
      "273/273 [==============================] - 0s 77us/step - loss: 28108.1251 - mean_squared_error: 23984.7644\n",
      "\n",
      "Splitting the first 93 chunks at 92/93\n",
      "Size of train + test: (279, 8)\n",
      "Epoch 1/1\n",
      "276/276 [==============================] - 0s 90us/step - loss: 28958.1128 - mean_squared_error: 25341.7961\n",
      "\n",
      "Splitting the first 94 chunks at 93/94\n",
      "Size of train + test: (282, 8)\n",
      "Epoch 1/1\n",
      "279/279 [==============================] - 0s 86us/step - loss: 28240.5284 - mean_squared_error: 24716.6854\n",
      "\n",
      "Splitting the first 95 chunks at 94/95\n",
      "Size of train + test: (285, 8)\n",
      "Epoch 1/1\n",
      "282/282 [==============================] - 0s 78us/step - loss: 27037.3978 - mean_squared_error: 23356.3862\n",
      "\n",
      "Splitting the first 96 chunks at 95/96\n",
      "Size of train + test: (288, 8)\n",
      "Epoch 1/1\n",
      "285/285 [==============================] - 0s 83us/step - loss: 28386.4197 - mean_squared_error: 23958.7526\n",
      "\n",
      "Splitting the first 97 chunks at 96/97\n",
      "Size of train + test: (291, 8)\n",
      "Epoch 1/1\n",
      "288/288 [==============================] - 0s 76us/step - loss: 33947.3963 - mean_squared_error: 29446.2335\n",
      "\n",
      "Splitting the first 98 chunks at 97/98\n",
      "Size of train + test: (294, 8)\n",
      "Epoch 1/1\n",
      "291/291 [==============================] - 0s 89us/step - loss: 32681.6963 - mean_squared_error: 28471.9094\n",
      "\n",
      "Splitting the first 99 chunks at 98/99\n",
      "Size of train + test: (297, 8)\n",
      "Epoch 1/1\n",
      "294/294 [==============================] - 0s 78us/step - loss: 62506.0639 - mean_squared_error: 36498.2649\n",
      "\n",
      "Splitting the first 100 chunks at 99/100\n",
      "Size of train + test: (300, 8)\n",
      "Epoch 1/1\n",
      "297/297 [==============================] - 0s 77us/step - loss: 42703.2835 - mean_squared_error: 22416.3918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "214.18924004678226"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performTimeSeriesCV(X_train, Y_train, 100, model, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???? еще не сделано финальное предсказание на валидационной выборке. для этого, судя по всему, нужно прописать обучение отдельно без функции????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод по регрессии на другом наборе данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. подход использования данных не в классическом формате временных рядов, а с добавлением фич существенно превзошел классическое использование Keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
